<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nepal on Ayush Subedi</title>
    <link>https://ayushsubedi.github.io/tags/nepal/</link>
    <description>Recent content in Nepal on Ayush Subedi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 27 Aug 2024 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://ayushsubedi.github.io/tags/nepal/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tedx Talk: Nepal in the Loop</title>
      <link>https://ayushsubedi.github.io/posts/nepal_in_the_loop/</link>
      <pubDate>Tue, 27 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/nepal_in_the_loop/</guid>
      <description>&lt;h1 id=&#34;tedx-talk-nepal-in-the-loop&#34;&gt;Tedx Talk: Nepal in the Loop&lt;/h1&gt;
&lt;p&gt;I spoke at &lt;a href=&#34;https://www.ted.com/tedx/events/58705&#34;&gt;TEDx (DWIT College)&lt;/a&gt; on &amp;ldquo;Nepal in the Loop.&amp;rdquo; The talk focused on the remarkable role Nepal is playing—and can play—in the global data landscape.&lt;/p&gt;
&lt;p&gt;From data annotators to ML engineers, Nepal has the talent and the drive to be a vital component in the AI ecosystem. I shared the stories of our growing data community, our innovative spirit, and the potential that lies ahead.&lt;/p&gt;
&lt;iframe width=&#34;100%&#34; height=&#34;512&#34; src=&#34;https://www.youtube.com/embed/oJndRc7QY3g?si=Wq-sEZ_70cbI0-mX&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;iframe width=&#34;100%&#34; height =&#34;1024&#34; src=&#34;https://ayushsubedi.github.io/pdfs/NepalintheLoop.pdf#toolbar=0&#34;&gt;&lt;/iframe&gt;</description>
    </item>
    
    <item>
      <title>Diabetic Retinopathy and Glaucoma Detection (Cheers AI Demo)</title>
      <link>https://ayushsubedi.github.io/posts/cheers_ai_demo/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/cheers_ai_demo/</guid>
      <description>&lt;h1 id=&#34;cheers-ai-demo-for-diabetic-retinopathy-and-glaucoma-detection&#34;&gt;Cheers AI Demo for Diabetic Retinopathy and Glaucoma Detection&lt;/h1&gt;
&lt;iframe width=&#34;100%&#34; height=&#34;420&#34; src=&#34;https://www.youtube.com/embed/TXy0J3wydnU&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;h4 id=&#34;efficient-prediction-models&#34;&gt;Efficient Prediction Models&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Efficient models trained on Inception-v3, with weightage on recall.&lt;/li&gt;
&lt;li&gt;Powerful hospital-MIS to create and track patient, and patient&amp;rsquo;s historical predictions.&lt;/li&gt;
&lt;li&gt;Inputs reviewed by opthalmologists and added to training.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;diabetic-retinopathy&#34;&gt;Diabetic Retinopathy&lt;/h3&gt;
&lt;p&gt;Diabetic Retinopathy is an eye illness caused by diabetes that may lead to vision impairment and even to blindness if it isn&amp;rsquo;t identified and treated early. Of the estimated 422 million diabetics globally, more than 148 million have DR and 48 million have Vision Threating DR (VTDR).&lt;/p&gt;
&lt;p&gt;However, because of insufficient specialists and eye care health workers globally as well as locally to screen everyone at risk, the situation seems acute especially in developing countries like Nepal. Besides, Nepal has difficult geographical terrain and people living in remorse remote areas with limited or no access to clinics and screening facilities making the condition even worse.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://camo.githubusercontent.com/a6b040d6eca19246121fb7a4e3fca782ed625c42af1889778c4edf14151198ef/68747470733a2f2f6761647364656e6579652e636f6d2f77702d636f6e74656e742f75706c6f6164732f64696162657469632d726574696e6f70617468792d766563746f722e6a7067&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;glaucoma&#34;&gt;Glaucoma&lt;/h3&gt;
&lt;p&gt;Glaucoma is a diverse group of disorders representing the second prominent cause of blindness. It has already affected 91 million individuals all over the world. It has multiple risk factors such as older age, elevated intraocular pressure (IOP), and thinner central corneal thickness etc. However, one or more of these risk factors may or may not develop glaucoma making it difficult for accurate prediction of the disease. Additionally, since glaucoma can be asymptomatic, its detection before significant vision loss is critical. Hence, automated methods for predicting glaucoma could have a significant impact.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://camo.githubusercontent.com/71e24e233d0fc826e10230944b2a1cdfba81b4387862f899f1f7c400330b02c6/68747470733a2f2f7777772e696e6d6564706861726d612e636f6d2f77702d636f6e74656e742f75706c6f6164732f323032302f30352f476c6175636f6d612d636f6d70617265642d746f2d6e6f726d616c2d766973696f6e2e706e67&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;an-intuitive-app&#34;&gt;An intuitive app&lt;/h3&gt;
&lt;p&gt;Easy to use, access managed platform, with the primary focus on providing assistance to our opthalmologists.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cheersai.ml/static/img/demo.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;steps-involved-in-research-model-creation-and-deployment&#34;&gt;Steps involved in Research, Model Creation, and Deployment&lt;/h1&gt;
&lt;h1 id=&#34;glaucoma-prediction&#34;&gt;Glaucoma Prediction&lt;/h1&gt;
&lt;h2 id=&#34;what-worked-90-accuracy&#34;&gt;What worked? (90% accuracy)&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;densenet sequential with ben on himanchu dataset, using NLLLoss criterion, Adam optimizer&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;limitation&#34;&gt;Limitation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;very much dependent on dataset&lt;/li&gt;
&lt;li&gt;disk extraction is good but is very subjective to the dataset&lt;/li&gt;
&lt;li&gt;trained on very small dataset&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;preliminary&#34;&gt;Preliminary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; understand the difference between possibility of glaucoma by classification (vs measurements)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preprocessing&#34;&gt;Preprocessing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; ben transformation&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; extract disk from fundus images&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; improve extraction algorithms&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; perform EDA on disk image to find troubling images (cases where crop does not work)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; convert python function to extract disk to torch transform class (failed)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; transformation to disk during training failed. create a disk dataset before training the model.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; train on new dataset with and without ben transformation&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; handle imbalanced class with class weighting&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; convert Kaggle dataset to the format that we have templated our notebooks with&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; for kaggle dataset get disks using new algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;obseverations-in-regards-to-disk-generation&#34;&gt;Obseverations in regards to disk generation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;extraction of disk does not help (too many vague areas left unfilled)&lt;/li&gt;
&lt;li&gt;however, cropping shows very good promise&lt;/li&gt;
&lt;li&gt;but, cropping requires somewhat similar of fundus images&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;datasets&#34;&gt;Datasets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; find datasets &lt;a href=&#34;https://deepblue.lib.umich.edu/data/concern/data_sets/3b591905z&#34;&gt;https://deepblue.lib.umich.edu/data/concern/data_sets/3b591905z&lt;/a&gt;, &lt;a href=&#34;https://www.kaggle.com/andrewmvd/ocular-disease-recognition-odir5k&#34;&gt;https://www.kaggle.com/andrewmvd/ocular-disease-recognition-odir5k&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a dataset from Magrabia&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a dataset from Messidor&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a dataset from Ocular Disease Recognition&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create EDA on non measurement dataset (Ocular Disease Recognition)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a dataset from ocular disease recognition to include normal and glaucoma images&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; (Kaggle dataset, custom generated, filtered)https://www.kaggle.com/sshikamaru/glaucoma-detection?select=glaucoma.csv&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; train on Kaggle dataset (without changing anything)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;training&#34;&gt;Training&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; inception v3 with and without ben on ocular, kaggle, and himanchu dataset&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; inception v3 with ben on ocular, kaggle, and himanchu dataset (disk extracted, normal, and cropped dataset)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; densenet linear with ben on ocular, kaggle, and himanchu dataset&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; densenet linear with ben on ocular, kaggle, and himanchu dataset (disk extracted, normal, and cropped dataset)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; densenet sequential with ben on ocular, kaggle, and himanchu dataset&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; densenet sequential with ben on ocular, kaggle, and himanchu dataset (disk extracted, normal, and cropped dataset)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; add datasets from cheers for testing&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; add datasets from cheers for training&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;diabetic-retinopathy-prediction&#34;&gt;Diabetic Retinopathy Prediction&lt;/h1&gt;
&lt;h2 id=&#34;what-worked-90-accuracy-1&#34;&gt;What worked? (90% accuracy)&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Large dataset from EyePACS (Kaggle competition used training (30%) and testing data (70%) from Kaggle. After the competition, the labels were published). Flipped the ratios for our use case.&lt;/li&gt;
&lt;li&gt;Remove out of focus images&lt;/li&gt;
&lt;li&gt;Remove too bright, and too dark images.&lt;/li&gt;
&lt;li&gt;Link to clean dataset &lt;a href=&#34;https://www.kaggle.com/ayushsubedi/drunstratified&#34;&gt;https://www.kaggle.com/ayushsubedi/drunstratified&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;To handle class imbalanced issue, used weighted random samplers. Undersampling to match no of images in the least class (4) did not work. Pickled weights for future use.&lt;/li&gt;
&lt;li&gt;Ben Graham transformation and augmentations&lt;/li&gt;
&lt;li&gt;Inception v3 fine tuning, with aux logits trained (better results compared to other architecture)&lt;/li&gt;
&lt;li&gt;Perform EDA on inference to observe what images were causing issues&lt;/li&gt;
&lt;li&gt;Removed the images and created another dataset (Link to the new dataset &lt;a href=&#34;https://www.kaggle.com/ayushsubedi/cleannonstratifieddiabeticretinopathy&#34;&gt;https://www.kaggle.com/ayushsubedi/cleannonstratifieddiabeticretinopathy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;See 5, 6, and 7&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;datasets-1&#34;&gt;Datasets&lt;/h3&gt;
&lt;p&gt;Binary Stratified (cleaned): &lt;a href=&#34;https://drive.google.com/drive/folders/12-60Gm7c_TMu1rhnMhSZjrkSqqAuSsQf?usp=sharing&#34;&gt;https://drive.google.com/drive/folders/12-60Gm7c_TMu1rhnMhSZjrkSqqAuSsQf?usp=sharing&lt;/a&gt;
Categorical Stratified (cleaned): &lt;a href=&#34;https://drive.google.com/drive/folders/1-A_Mx9GdeUwCd03TUxUS3vwcutQHFFSM?usp=sharing&#34;&gt;https://drive.google.com/drive/folders/1-A_Mx9GdeUwCd03TUxUS3vwcutQHFFSM?usp=sharing&lt;/a&gt;
Non Stratified (cleaned): &lt;a href=&#34;https://www.kaggle.com/ayushsubedi/drunstratified&#34;&gt;https://www.kaggle.com/ayushsubedi/drunstratified&lt;/a&gt;
Recleaned Non Stratified: &lt;a href=&#34;https://www.kaggle.com/ayushsubedi/cleannonstratifieddiabeticretinopathy&#34;&gt;https://www.kaggle.com/ayushsubedi/cleannonstratifieddiabeticretinopathy&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;priliminary&#34;&gt;Priliminary&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=VIrkurR446s&amp;amp;ab_channel=khanacademymedicine&#34;&gt;https://www.youtube.com/watch?v=VIrkurR446s&amp;amp;ab_channel=khanacademymedicine&lt;/a&gt; What is diabetic retinopathy?&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; collect all previous analysis notebooks&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; conduct preliminary EDA (for balanced dataset, missing images etc)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create balanced test train split for DR (stratify)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; store the dataset in drive for colab&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; identify a few research papers, create a file to store subsequently found research papers&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; identify right technology stack to use (for ML, training, PM, model versioning, stage deployment, actual deployment)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; perform basic augmentation&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a version 0 base model&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; apply a random transfer learning model&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a metric for evaluation&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; store the model in zenodo, or find something for version control&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a model that takes image as an input&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a streamlit app that reads model&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; streamlit app to upload and test prediction&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; test deployment to free tier heroku&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; identify gaps&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create priliminary test set&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create folder structures for saved model in the drive&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; figure out a way to move files from kaggle to drive (without download/upload)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; research saving model (the frugal way)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; research saving model to google drive after each epoch so that during unforseen interuptions, the training of the model can be continued&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;resource&#34;&gt;Resource&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; upgrade to 25GB RAM in Google Colab possibly w/ Tesla P100 GPU&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; upgrade to Colab Pro&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;baseline&#34;&gt;Baseline&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; medicmind grading (accuracy: 0.8)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; medicmind classification (0.47)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;transfer-learning&#34;&gt;Transfer Learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; resnet&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; alexnet&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; vgg&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; squeezenet&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; densenet&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; inception&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; efficient net&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;dataset-clean-images&#34;&gt;Dataset clean images&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a backup of primary dataset (zip so that kaggle kernels can consume them too)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; find algorithms to detect black/out of focus images&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; identify correct threshold for dark and out of focus images&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; remove black images&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; remove out of focus images&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a stratified dataset with 2015 data only (convert train and test both to train and use), remove black images and out of focus images (also create test set)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create non-stratified dataset with 2015 clean data only (train, test, valid) (upload in kaggle if google drive full)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a binary dataset (train, test, valid)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create confusion matrices (train, test, valid) after clean up (dark and blurry)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; the model is confusing labels 0 and 1 as 2, is this due to disturbance in image in 0.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; concluded that the result is due to the model not capturing class 0 enough (due to undersampling)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;inference&#34;&gt;Inference&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a csv with preds probability and real label&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; calculate recall, precision, accuracy, confusion matrix&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; identify different prediction issues&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; relationship between difference in preds and accuracy&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; inference issue: labels 0 being predicted as 4&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; inference issue: Check images from Grade 2, 3 being predicted as Grade 0&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; inference issue: Check images from Grade 4 being predicted as Grade 0&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; inference issue: Check images from Grade 0 being predicted as Grade 4&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; inference issue: A significant Grade 2 is being predicted as Grade 0&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; inference issue: More than 50% of Grade 1 is being predicted as Grade 0&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create a new dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;model-improvement&#34;&gt;Model Improvement&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; research kaggle winning augmentation for DR&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; research appropriate augmentation: optical distortion, grid distortion, piecewise affine transform, horizontal flip, vertical flip, random rotation, random shift, random scale, a shift of RGB values, random brightness and contrast, additive Gaussian noise, blur, sharpening, embossing, random gamma, and cutout&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; train on various pretrained models or research which is supposed to be ideal for this case &lt;a href=&#34;https://pytorch.org/vision/stable/models.html&#34;&gt;https://pytorch.org/vision/stable/models.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create several neural nets (test different layers)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; experiment with batch size&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Reducing lighting-condition effects&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Cropping uninformative area&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Create custom dataloader based on ben graham kaggle winning strategy&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; finetune vs feature extract&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; oversample&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; undersample&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; add specificity and sensitivity to indicators&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; create train loss and valid loss charts&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; test regression models (treat this as a grading problem)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; pickle weights&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;additional-models&#34;&gt;Additional Models&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; check if left/right eye classification model is required&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;additional-datasets&#34;&gt;Additional datasets&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; make datasets more extensive (add test dataset with recoverd labels to train dataset 2015)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; add APTOS dataset&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; request labelled datasets from cheers&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; add datasets from cheers for testing&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; add datasets from cheers for training&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;test-datasets&#34;&gt;Test datasets&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; find datasets for testing (dataset apart from APTOS and EyePACS)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; update folder structures to match our use case&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; find dataset for testing after making sure old test datasets are not in vaid/train (4 will be empty)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;conceptsresearch-papers&#34;&gt;Concepts/Research Papers&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; read reports from kaggle competition winning authors&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Deep Learning Approach to Diabetic Retinopathy Detection &lt;a href=&#34;https://arxiv.org/pdf/2003.02261.pdf&#34;&gt;https://arxiv.org/pdf/2003.02261.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Google research &lt;a href=&#34;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45732.pdf&#34;&gt;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45732.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Nature article &lt;a href=&#34;https://www.nature.com/articles/s41746-019-0172-3&#34;&gt;https://www.nature.com/articles/s41746-019-0172-3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://deim.urv.cat/~itaka/itaka2/PDF/acabats/PhD_Thesis/TESI_doctoral_Jordi_De_la_Torre.pdf&#34;&gt;https://deim.urv.cat/~itaka/itaka2/PDF/acabats/PhD_Thesis/TESI_doctoral_Jordi_De_la_Torre.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; what can go wrong &lt;a href=&#34;https://yerevann.github.io/2015/08/17/diabetic-retinopathy-detection-contest-what-we-did-wrong/&#34;&gt;https://yerevann.github.io/2015/08/17/diabetic-retinopathy-detection-contest-what-we-did-wrong/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://arxiv.org/pdf/1902.07208.pdf&#34;&gt;https://arxiv.org/pdf/1902.07208.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Analytics for Ride Hailing Services</title>
      <link>https://ayushsubedi.github.io/posts/ride_hailing_analytics/</link>
      <pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/ride_hailing_analytics/</guid>
      <description>&lt;h2 id=&#34;analytics-for-ride-hailing-services&#34;&gt;Analytics for Ride Hailing Services&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.sanity.io/images/6xsct86j/production/e8fc0f789129b17cc8ae2e05b91e93d0752bef67-3840x2160.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;introduction-to-ride-hailing&#34;&gt;Introduction to Ride Hailing&lt;/h2&gt;
&lt;p&gt;At present, it is pretty common to hail a ride to get from one place to the other at a tap of a button. Almost all major cities in the world have some sort of ride-hailing service. Uber, Lyft, Didi, Ola, Gojek, etc. are some examples of service providers that come to mind. Additionally, the service is also proliferating to smaller cities and has become commonplace in many parts of the world. Analytics is a key component in making sure the service is provided efficiently. All of the aforementioned companies invest heavily in data science and analytics to be competitive and to provide better services.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For this post, I will focus on Ride-Hailing services (not Ride Sharing services). See the difference &lt;a href=&#34;https://www.ecolane.com/blog/ride-hailing-vs.-ride-sharing-the-key-difference-and-why-it-matters&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Predominantly, ride-hailing functions as a &lt;em&gt;Gig Economy&lt;/em&gt;. The drivers (sometimes referred to as partners, captains, etc.) are mostly independent contractors who bring their own vehicle and work at their own time and are paid based on their time commitment. This variability requires monitoring, sophisticated algorithms, good incentives, competitive pricing to passengers, etc. which is also common in other gig economy jobs. In most cases, the analytics models that will be built for one gig economy can be tweaked to fit another one as well.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at a few components of Ride-hailing that will be relevant for how we frame our models and the data we use.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For this post, &amp;ldquo;passengers&amp;rdquo; are referred to as service requesters/receivers and &amp;ldquo;drivers&amp;rdquo; are referred to as service providers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;components-of-the-problem&#34;&gt;Components of the problem&lt;/h2&gt;
&lt;hr&gt;
&lt;h3 id=&#34;balancing-act-supply-and-demand-and-chicken-and-egg-problem&#34;&gt;Balancing act: Supply and Demand, and Chicken and Egg Problem&lt;/h3&gt;
&lt;p&gt;There is a balancing act that all of these ride-sharing platforms need to perform to be efficient. A healthy ratio between driver and passenger (to go more granular, for a segment of geographic area at a given time) is very important.  The balancing act is even crucial when a ride-hailing service decides to introduce itself to a new city (especially one that is new to ride-hailing).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If an area has more drivers than demand from passengers, the drivers might not get ride requests causing them to lose interest and find a different job or move to a different competition.&lt;/li&gt;
&lt;li&gt;If an area has more passengers than a supply of drivers, the passengers might not get their ride requests accepted causing them to move onto another (direct/indirect) competition.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From an analytics perspective, this is a difficult problem to solve. However, good analytics can also be a competitive advantage here.&lt;/p&gt;
&lt;h3 id=&#34;pricing&#34;&gt;Pricing&lt;/h3&gt;
&lt;p&gt;Pricing is a by-product of the balancing act described above. The pricing must be competitive enough to lure the supply and the demand pool. The driver should feel like the pricing justifies the time, effort, and resources supplied. The passenger should feel the amount paid for the service justifies the service received.&lt;/p&gt;
&lt;p&gt;Few ride-hailing services opt-out for transparent and fixed payment (i.e the price is only dictated by the distance to destination), while some have complex pricing strategies to stand out, lure passengers or drivers, and manage supply and demand effectively.&lt;/p&gt;
&lt;h3 id=&#34;dynamic-pricing&#34;&gt;Dynamic Pricing&lt;/h3&gt;
&lt;p&gt;Some ride-hailing services implement dynamic pricing as a way to balance the chicken and egg problem described above. This is a large-scale, complex analytics problem involving several variables. Additionally, driver bonuses, discounts, and referrals might constitute the pricing strategy as well.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://thumbor.forbes.com/thumbor/711x274/https://blogs-images.forbes.com/nicolemartin1/files/2019/03/dynamic-pricing.jpg?width=960&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Credit: Forbes&lt;/p&gt;
&lt;h3 id=&#34;competition-direct-and-indirect&#34;&gt;Competition (Direct and Indirect)&lt;/h3&gt;
&lt;h4 id=&#34;direct-competition-passenger&#34;&gt;Direct Competition (Passenger)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;other ride hailing services&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;direct-competition-driver&#34;&gt;Direct Competition (Driver)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;other ride-hailing services&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;indirect-competition-passenger&#34;&gt;Indirect Competition (Passenger)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;public transportation&lt;/li&gt;
&lt;li&gt;taxi/cab&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;indirect-competition-driver&#34;&gt;Indirect Competition (Driver)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;other employment opportunities&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://thumbor.forbes.com/thumbor/fit-in/1200x0/filters%3Aformat%28jpg%29/https%3A%2F%2Fblogs-images.forbes.com%2Fliyanchen%2Ffiles%2F2015%2F09%2F0908_uber-map2_2000-1940x1487.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Credit: Forbes&lt;/p&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;h2 id=&#34;descriptive-analysis&#34;&gt;Descriptive analysis&lt;/h2&gt;
&lt;p&gt;Before we build complex models, it is essential to understand how the business/service is performing. These descriptive analyses will lay the foundation for us when we build complex and combined models later on.&lt;/p&gt;
&lt;h3 id=&#34;ride-completioncancellation-rate&#34;&gt;Ride Completion/Cancellation rate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the ride completion rate?&lt;/li&gt;
&lt;li&gt;To be more granular, what is the ride completion rate at a geographic segment of the city at a particular time?&lt;/li&gt;
&lt;li&gt;What is the ride cancellation rate?&lt;/li&gt;
&lt;li&gt;Similar to before, what is the ride cancellation rate at a geographic segment of the city at a particular time?&lt;/li&gt;
&lt;li&gt;Why do passengers cancel rides?&lt;/li&gt;
&lt;li&gt;Is cancellation more prominent in one area compared to the other?&lt;/li&gt;
&lt;li&gt;Is this dependent on the time of the day?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;passenger_id&lt;/li&gt;
&lt;li&gt;driver_id&lt;/li&gt;
&lt;li&gt;latitude (pickup, drop)&lt;/li&gt;
&lt;li&gt;longitude (pickup, drop)&lt;/li&gt;
&lt;li&gt;timestamps (requested, accepted, picked up, dropped, canceled)&lt;/li&gt;
&lt;li&gt;completion_status&lt;/li&gt;
&lt;li&gt;cancellation_reason&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;late-arrival-rate&#34;&gt;Late arrival rate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the late arrival rate?&lt;/li&gt;
&lt;li&gt;what is the late arrival rate at a geographic segment of the city at a particular time?&lt;/li&gt;
&lt;li&gt;Is the late arrival rate prominent for some time of the day or for a particular geographical area?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;passenger_id&lt;/li&gt;
&lt;li&gt;driver_id&lt;/li&gt;
&lt;li&gt;latitude (pickup, drop)&lt;/li&gt;
&lt;li&gt;longitude (pickup, drop)&lt;/li&gt;
&lt;li&gt;timestamps (requested, accepted, picked up, dropped, canceled)&lt;/li&gt;
&lt;li&gt;completion_status&lt;/li&gt;
&lt;li&gt;cancellation_reason&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;activation-acquisition-retention-referral-revenue&#34;&gt;Activation, Acquisition, Retention, Referral, Revenue&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What does the pirate metric funnel look like?&lt;/li&gt;
&lt;li&gt;Is there a specific area where the business should focus to improve business/efficiency?&lt;/li&gt;
&lt;li&gt;Is the funnel leaking somewhere?&lt;/li&gt;
&lt;li&gt;What is the passenger/driver churn rate?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;passenger_id/driver_id&lt;/li&gt;
&lt;li&gt;timestamps (created_date, last_ride_date)&lt;/li&gt;
&lt;li&gt;total_amount_spent_on_platform / total_money_made&lt;/li&gt;
&lt;li&gt;total_rides&lt;/li&gt;
&lt;li&gt;num_of_referrals&lt;/li&gt;
&lt;li&gt;acquisition_channel&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://hygger.io/wp-content/uploads/2018/01/Main-EN.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Credit: hygger.io&lt;/p&gt;
&lt;h3 id=&#34;channels&#34;&gt;Channels&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the acquisition rate from different marketing channels for drivers or for passengers?&lt;/li&gt;
&lt;li&gt;What marketing channel is more apt/effective for different demography/user segments?&lt;/li&gt;
&lt;li&gt;Can we use the multi-arm bandits model to identify a balance between exploration and exploitation to test on different channels?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;passenger_id/driver_id&lt;/li&gt;
&lt;li&gt;timestamps (created_date)&lt;/li&gt;
&lt;li&gt;acquisition_channel&lt;/li&gt;
&lt;li&gt;total_amount_spent_on_platform / total_money_made&lt;/li&gt;
&lt;li&gt;passenger/driver demographic information (age, gender, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;user-analysis&#34;&gt;User Analysis&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What does the demography (social, cultural, economic) of the driver look like?&lt;/li&gt;
&lt;li&gt;What does the demography (social, cultural, economic) of the passenger look like?&lt;/li&gt;
&lt;li&gt;What does the demography of the city look like?&lt;/li&gt;
&lt;li&gt;What does the demography of the segment that uses the service the most look like?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;passenger_id/driver_id&lt;/li&gt;
&lt;li&gt;timestamps (created_date)&lt;/li&gt;
&lt;li&gt;acquisition_channel&lt;/li&gt;
&lt;li&gt;total_amount_spent_on_platform / total_money_made&lt;/li&gt;
&lt;li&gt;passenger/driver/city demographic information (age, gender etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;driver-rankingdriver-performance&#34;&gt;Driver Ranking/Driver Performance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;How is a driver performing? (this could be based on multiple factors including customer rating, and other factors)&lt;/li&gt;
&lt;li&gt;Based on the index for performance, what is the rank of a driver?&lt;/li&gt;
&lt;li&gt;What is the rank of a driver among a segment of drivers? (this will be useful for priority queue for driver dispatching)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;driver_id&lt;/li&gt;
&lt;li&gt;timestamps&lt;/li&gt;
&lt;li&gt;average_rating&lt;/li&gt;
&lt;li&gt;rides_complete_rate&lt;/li&gt;
&lt;li&gt;last_ride_date&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;h2 id=&#34;predictive-analysis&#34;&gt;Predictive analysis&lt;/h2&gt;
&lt;p&gt;If we are looking to make the system more efficient, it is also very important to understand what the future holds.&lt;/p&gt;
&lt;h3 id=&#34;growth-in-rides&#34;&gt;Growth in rides&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the number of expected daily rides next day/week/month/year?&lt;/li&gt;
&lt;li&gt;What is the expected revenue for the next day/week/month/year?&lt;/li&gt;
&lt;li&gt;Is there a daily/weekly/monthly seasonality?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;timestamp (daily)&lt;/li&gt;
&lt;li&gt;num_of_ride (completed rides or ride requests)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;passenger-growth&#34;&gt;Passenger growth&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the number of expected passenger growth next day/week/month/year?&lt;/li&gt;
&lt;li&gt;Is there a daily/weekly/monthly seasonality?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;timestamp (daily)&lt;/li&gt;
&lt;li&gt;num_of_unique_passengers (acquisition or ride request)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;driver-growth&#34;&gt;Driver growth&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the number of expected driver growth next day/week/month/year?&lt;/li&gt;
&lt;li&gt;Is there a daily/weekly/monthly seasonality?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;timestamp (daily)&lt;/li&gt;
&lt;li&gt;num_of_unique_drivers (acquisition or ride request)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;churn-over-the-period-of-time&#34;&gt;Churn over the period of time&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the expected churn in the next day/week/month/year?&lt;/li&gt;
&lt;li&gt;Is there a daily/weekly/monthly seasonality?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;timestamp (passenger acquisition)&lt;/li&gt;
&lt;li&gt;passenger&amp;rsquo;s number of rides each month (grouped acquisition to present)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;h2 id=&#34;prescriptive-analysis&#34;&gt;Prescriptive analysis&lt;/h2&gt;
&lt;p&gt;Descriptive and Predictive analysis will help us move towards prescriptive analysis, especially for optimization models. These models will help the service provider in decision making, especially with regards to an increase in efficiency for drivers and passengers.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;ratio-of-drivers-to-passengers&#34;&gt;Ratio of drivers to passengers&lt;/h3&gt;
&lt;h4 id=&#34;what-is-the-ideal-ratio-of-the-passenger-to-the-driver-to-maximize-rides-completion-rate&#34;&gt;What is the ideal ratio of the passenger to the driver to maximize rides completion rate?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Given&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Voronoi clustering for geographic indexing based on geographic hotspots (other indexing methods are more efficient like h3 developed by Uber, but Voronoi can be used to build something similar as well.)&lt;/li&gt;
&lt;li&gt;rides data (requested, canceled, completed)&lt;/li&gt;
&lt;li&gt;passenger data (raw data and data after descriptive analysis performed: Pirate metrics etc.)&lt;/li&gt;
&lt;li&gt;driver data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Optimization
&lt;ul&gt;
&lt;li&gt;with constraints: num_of_rides should be greater than a threshold (comes from future rides data)&lt;/li&gt;
&lt;li&gt;with objective functions: maximize rides completion rate for each geographic segment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;to find an optimal driver to passenger ratio&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Regression (or logistic regression if we only care about a healthy/unhealthy ratio) can also be used to do something similar as well.&lt;/li&gt;
&lt;li&gt;Additionally, the result from the model can also be used to model advertisement campaigns for the future if we find the number of driver or passenger (in a particular geographic area) need to be increased for a stable ratio.&lt;/li&gt;
&lt;li&gt;This is an important indicator because it allows the service provider to focus on growth while keeping this indicator at a healthy level.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;dynamic-pricing-1&#34;&gt;Dynamic pricing&lt;/h3&gt;
&lt;h4 id=&#34;what-should-the-dynamicsurge-pricing-be-at-a-given-time&#34;&gt;What should the dynamic/surge pricing be at a given time?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Given&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;ratio of the driver to passenger&lt;/li&gt;
&lt;li&gt;paying capacity of passengers (based on descriptive analysis of users, useful for capping at some multiplier so that it does not go wild)&lt;/li&gt;
&lt;li&gt;number of requests in the queue in a geographic segment&lt;/li&gt;
&lt;li&gt;competition surge at the moment&lt;/li&gt;
&lt;li&gt;number of requests completed in the geographic segment (and neighboring segment) in last x minutes (arbitrary but can be defined by waiting for time analysis from descriptive analysis)&lt;/li&gt;
&lt;li&gt;geographic location information (grid-based on Voronoi for the availability of drivers in other cells)&lt;/li&gt;
&lt;li&gt;number of drivers that will be free (complete a ride soon or are predicted to come online soon) in the grid or neighboring grids&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Linear regression&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;to find ideal dynamic pricing multiplier&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The cap might/might not be necessary, and that might be another analytics problem altogether. There have been some cases where a natural disaster/terrorist attack increased surge multiplier to an exorbitant number causing massive backlash.&lt;/li&gt;
&lt;li&gt;grid above refers to one unit of Voronoi based geographic segmentation&lt;/li&gt;
&lt;li&gt;It is necessary to study the correlation of some of the predictors mentioned above.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;ride-dispatching&#34;&gt;Ride Dispatching&lt;/h3&gt;
&lt;h4 id=&#34;what-is-a-robust-ride-dispatching-mechanism-that-will-increase-passengers-and-drivers&#34;&gt;What is a robust ride dispatching mechanism that will increase passengers and drivers?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Given&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Drivers in Geographic Grid (and neighboring Grid)&lt;/li&gt;
&lt;li&gt;Driver Rating/Driver Ranking&lt;/li&gt;
&lt;li&gt;Geographic Grid&lt;/li&gt;
&lt;li&gt;Pickup/Drop location (distance and Grid)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Optimization
&lt;ul&gt;
&lt;li&gt;with constraints: the probability of each driver getting ride should be close to 1, waiting time should be less than some threshold for the request to be accepted  or not accepted (which comes from descriptive analysis), the time between request dispatching (time window a driver gets before the request is passed on to a different driver, also comes from descriptive analysis) should be equal to the acceptable waiting time divided by some constant (integer)&lt;/li&gt;
&lt;li&gt;with objective functions: maximize rides completion rate for each geographic segment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;** Notes **&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Queuing models can also be here to identify correct values for the dispatching system (waiting time, dynamic geographic grid, etc.). However, there is a need to check the distribution of different events (booking created, booking accepted, waiting time, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;It seems analytics is extremely relevant in all aspects of ride-hailing. In this project, I merely covered a few use cases, with one or two relevant models. Even with this brief exploration, I can conclude that analytics can lead to better outcomes for both drivers and passengers.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>