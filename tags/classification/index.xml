<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>classification on Ayush Subedi</title>
    <link>https://ayushsubedi.github.io/tags/classification/</link>
    <description>Recent content in classification on Ayush Subedi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 02 Feb 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://ayushsubedi.github.io/tags/classification/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Birds, Plane, Superman</title>
      <link>https://ayushsubedi.github.io/posts/bird_plane_superman/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/bird_plane_superman/</guid>
      <description>&lt;h1 id=&#34;heading&#34;&gt;&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://4.bp.blogspot.com/-VRnyjR8-1FQ/W5EZ4WhvRpI/AAAAAAAAOPM/rNiNP_X9haIqqSt4692inhEUiucUuILewCLcBGAs/s400/001109.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;br&gt;
I have been experimenting with Deep Learning models in &lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt; for a couple of weeks now. PyTorch is an open source python package that provides Tensor computation (similar to numpy) with GPU support. The dataset used for this particular blog post does no justice to the real-life usage of PyTorch for image classification. However, it serves as a general idea of how Transfer Learning can be used for more complicated image classification. Transfer learning, in a nutshell, is reusing a model developed for some other classification task, for your classification purposes. The dataset was created by scraping images from google image search.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Creating the dataset&lt;/strong&gt;&lt;br&gt;
For our dataset, we need images of birds, planes, and Superman. We will be using the &lt;a href=&#34;https://github.com/hellock/icrawler&#34;&gt;icrawler&lt;/a&gt; package to download the images from google image search.&lt;/p&gt;
&lt;p&gt;We repeat the same for birds and Superman. Once all the files have been downloaded, we will restructure the folders to contain our training, testing and validating samples. I am allocating 70% for training, 20% for validating and 10% for testing.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1.bp.blogspot.com/--JBHptSr22k/W5EhKG9S0FI/AAAAAAAAOPY/b1JuDndQ6qAbXSgomBTZUZkjPRNEK-N-ACLcBGAs/s320/Capture.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Loading the data&lt;/strong&gt;&lt;br&gt;
PyTorch uses generators to read the data. Since datasets are usually large, it makes sense to not load everything in memory. Let&amp;rsquo;s import useful libraries that we will be using for classification.&lt;/p&gt;
&lt;p&gt;Now that we have imported useful libraries, we need to augment and normalize the images. Torchvision transforms is used to augment the training data with random scaling, rotations, mirroring and cropping. We do not need to rotate or flip our testing and validating sets. The data for each set will also be loaded with Torchivision&amp;rsquo;s DataLoader and ImageFolder.&lt;/p&gt;
&lt;p&gt;Let us visualize a few training images to understand the data augmentation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://3.bp.blogspot.com/-LNJ3iv_C5Zs/W5Elb_VXgmI/AAAAAAAAOPk/ThiNb-NKIUU5fFx-2oEaO4FzRcMTBvuwgCLcBGAs/s640/download%2B%25281%2529.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Loading a pre-trained model&lt;/strong&gt;
We will be using Densenet for our purposes.&lt;/p&gt;
&lt;p&gt;The pre-trained model&amp;rsquo;s classifier takes 1920 features as input. We need to be consistent with that. However, the output feature for our case is 3 (bird, plane, and Superman).&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s create our classifier and replace the model&amp;rsquo;s classifier.&lt;/p&gt;
&lt;p&gt;We are using ReLU activation function with random dropouts with a probability of 20% in the hidden layers. For the output layer, we are using LogSoftmax.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Training Criterion, Optimizer, and Decay&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;Model Training and Testing&lt;/strong&gt;&lt;br&gt;
Let us calculate the accuracy of the model without training it first.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://4.bp.blogspot.com/-heWEFxARMek/W5E49Y_TsPI/AAAAAAAAOPw/ha1h5ZBOs8ApPT0t5RcDsRWfvOXHwcnWACLcBGAs/s640/Capture.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The accuracy is pretty low at this time, which is expected. The &lt;em&gt;cuda&lt;/em&gt; parameter here is the boolean object passed for the availability of GPU hardware in the machine.&lt;/p&gt;
&lt;p&gt;Let us train the model.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://4.bp.blogspot.com/-InDGqH9w1co/W5E520-6ANI/AAAAAAAAOP4/QJ_tiogtGmcdNkHB33ieKWk-UJ2AHfQqwCLcBGAs/s640/Capture.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Since GPU is supported, the training took around 10 mins. The validation accuracy is almost 99%. Let us check the accuracy over training data again.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://3.bp.blogspot.com/-TwYWdmXYGyI/W5E7v95GTiI/AAAAAAAAOQE/FCIpQ7MPr4wXEFY_YqxsCl46ZdZlebg1ACLcBGAs/s640/Capture.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Image Preprocessing&lt;/strong&gt;
We declare a few functions to preprocess images and pass on the trained model.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://3.bp.blogspot.com/-q3hQVfCnDmE/W5E9S5vSizI/AAAAAAAAOQQ/r1hP9xV1Tw4eoh6E5MzGbFGh7haNkn3BQCLcBGAs/s640/Untitled-1.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Predicting by passing an image&lt;/strong&gt;&lt;br&gt;
Since our model is ready and we have built functions that allows us to visualize, let us try it out on one of the sample images.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://3.bp.blogspot.com/-mv2wuvBJIcA/W5E_R-qFjZI/AAAAAAAAOQk/HDEZYXgYYM8kYGVvg5w5Y3KNHkUZs8KJQCLcBGAs/s640/Capture.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;So, that is it.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>