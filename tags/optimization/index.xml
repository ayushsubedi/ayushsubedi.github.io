<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>optimization on Ayush Subedi</title>
    <link>https://ayushsubedi.github.io/tags/optimization/</link>
    <description>Recent content in optimization on Ayush Subedi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 16 Sep 2023 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://ayushsubedi.github.io/tags/optimization/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Topics on High-Dimensional Data Analytics (Machine Learning 2)</title>
      <link>https://ayushsubedi.github.io/posts/topics_on_high_dimensional_data_analytics/</link>
      <pubDate>Sat, 16 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/topics_on_high_dimensional_data_analytics/</guid>
      <description>&lt;h1 id=&#34;topics-on-high-dimensional-data-analytics&#34;&gt;Topics on High-Dimensional Data Analytics&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#functional-data-analysis&#34;&gt;Functional Data Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#image-analysis&#34;&gt;Image Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tensor-data-analysis&#34;&gt;Tensor Data Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#optimization-and-application&#34;&gt;Optimization and Application&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#regularization&#34;&gt;Regularization&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- ## Tensor Decomposition Methods - CP Decomposition
## Tensor Decomposition Methods - Tucker Decomposition
## Tensor Analysis Applications I
## Tensor Analysis Application II --&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;h3 id=&#34;big-data&#34;&gt;Big Data&lt;/h3&gt;
&lt;p&gt;Big data is a term used to describe extremely large and complex datasets that traditional data processing applications are not well-equipped to handle. The concept of &amp;ldquo;big data&amp;rdquo; is often associated with what is referred to as the &amp;ldquo;4V&amp;rdquo; framework, which describes the key characteristics of big data:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Volume:&lt;/strong&gt;  This refers to the sheer scale of data generated and collected. Big data involves datasets that are too large to be managed and processed using traditional databases and tools. This massive volume can range from terabytes to petabytes and beyond.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Velocity:&lt;/strong&gt;  This characteristic pertains to the speed at which data is generated, collected, and processed. In today&amp;rsquo;s fast-paced digital world, data is generated at an unprecedented rate, often in real-time or near-real-time. Examples include social media interactions, sensor data from IoT devices, financial transactions, and more.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Variety:&lt;/strong&gt;  Big data comes in various formats and types, such as structured, semi-structured, and unstructured data. Structured data is organized into a well-defined format (e.g., tables in a relational database), whereas unstructured data lacks a specific structure (e.g., text documents, images, videos, social media posts). Semi-structured data lies somewhere in between, having a partial structure but not fitting neatly into traditional databases.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Veracity:&lt;/strong&gt;  Veracity refers to the quality and reliability of the data. With the proliferation of data sources, there&amp;rsquo;s an increased potential for data to be incomplete, inaccurate, or inconsistent. Ensuring the accuracy and trustworthiness of big data is a significant challenge, and data quality management is crucial for meaningful insights.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;high-dimensional-data&#34;&gt;High Dimensional Data&lt;/h3&gt;
&lt;p&gt;High-dimensional data refers to datasets where the number of features or variables (dimensions) is significantly larger than the number of observations or samples. In other words, the data has a high number of attributes compared to the number of data points available. This kind of data is prevalent in various fields such as genomics, image analysis, social networks, and more.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/high_dimensional_.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;difference-between-high-dimensional-data-and-big-data&#34;&gt;Difference between High Dimensional Data and Big Data&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/diff_bet_high_and_low.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;p = dimension
n = samples&lt;/p&gt;
&lt;h3 id=&#34;the-curse-of-dimensionality&#34;&gt;The Curse of Dimensionality&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;As the number of features or dimensions grows, the amount of data we need to generalize accurately grows exponentially!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/distance_dimension.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;As distance between observations increases with the dimensions, the sample size required for learning a model drastically increases.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Increased Sparsity:&lt;/strong&gt;  In higher dimensions, the available data points are spread out more thinly across the space. This means that data points become farther apart from each other, making it challenging to find meaningful clusters or patterns. It&amp;rsquo;s like having a lot of points scattered in a large, high-dimensional space, and they&amp;rsquo;re so spread out that it&amp;rsquo;s difficult to identify any consistent relationships.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;More Data Needed:&lt;/strong&gt;  With higher-dimensional data, you need a disproportionately larger amount of data to capture the underlying patterns accurately. When the data is sparse, it&amp;rsquo;s harder to generalize from the observed points to make accurate predictions or draw conclusions. As the dimensionality increases, you might need exponentially more data to maintain the same level of accuracy in your models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Impact on Complexity:&lt;/strong&gt;  The complexity of machine learning models increases with dimensionality. More dimensions mean more parameters to estimate, which can lead to overfitting â€“ a situation where a model fits the training data too closely and fails to generalize well to new data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Increased Computational Demands:&lt;/strong&gt;  Processing and analyzing high-dimensional data require more computational resources and time. Many algorithms become slower and more memory-intensive as the number of dimensions grows. This can make experimentation and model training more challenging and time-consuming.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Difficulties in Visualization:&lt;/strong&gt;  Our ability to visualize data effectively diminishes as the number of dimensions increases. We are accustomed to thinking in 2D and 3D space, but visualizing data in, say, 10 dimensions is practically impossible. This can make it hard to understand the structure of the data and the relationships between variables.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;low-dimensional-learning-from-high-dimensional-data&#34;&gt;Low Dimensional Learning From High Dimensional Data&lt;/h3&gt;
&lt;p&gt;High dimensional data usually have low dimensional structure.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.mathworks.com/help/examples/stats/win64/ChangeTsneSettingsExample_01.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;This can be achieved through Functional Data Analysis, Tensor Analysis, Rank Deficient Methods among others.&lt;/p&gt;
&lt;h3 id=&#34;solutions-for-the-curse-of-dimensionality&#34;&gt;Solutions for the curse of dimensionality&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Feature extraction&lt;/li&gt;
&lt;li&gt;Dimensionality reduction&lt;/li&gt;
&lt;li&gt;Collecting much more observations&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;functional-data-analysis&#34;&gt;Functional Data Analysis&lt;/h1&gt;
&lt;p&gt;A fluctuating quantity or impulse whose variations represent information and is often represented as a function of time or space.&lt;/p&gt;
&lt;p&gt;From Wikipedia&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Functional data analysis (FDA)&lt;/strong&gt; is a branch of statistics that analyses data providing information about curves, surfaces or anything else varying over a continuum. In its most general form, under an FDA framework, each sample element of functional data is considered to be a random function. The physical continuum over which these functions are defined is often time, but may also be spatial location, wavelength, probability, etc. Intrinsically, functional data are infinite dimensional. The high intrinsic dimensionality of these data brings challenges for theory as well as computation, where these challenges vary with how the functional data were sampled. However, the high or infinite dimensional structure of the data is a rich source of information and there are many interesting challenges for research and data analysis.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://lands.let.ru.nl/FDA/images/FDA_pic4website.bmp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;regression---least-square-estimates&#34;&gt;Regression - Least square Estimates&lt;/h2&gt;
&lt;p&gt;A linear regression model assumes that the regression function $E(Y|X)$ is linear in the inputs $X_1, &amp;hellip;, X_p$. They were developed in the pre-computer age of statistics, but even in today&amp;rsquo;s computer era there are still good reasons to study and use them. They are simple and often provide an adequate and interpretable description of how the inputs affect the output.&lt;/p&gt;
&lt;p&gt;The linear regression model has the form:&lt;/p&gt;
&lt;p&gt;$f(X) = \beta_0 + \sum_{j=1}^p X_j\beta_j$&lt;/p&gt;
&lt;p&gt;Typically we have a set of training data $(x_1, y_1)&amp;hellip;(x_N, y_N)$ from which to estimate the parameters $\beta$. Each $x_i = (x_{i1}, x_{i2} &amp;hellip; x_{ip})^T$ is a vector of feature measurements for the $i$th case. The most popular estimation method is the least squares, in which we pick the coefficients $\beta = (\beta_0, \beta_1,&amp;hellip;.\beta_p)^T$ to minimize the residual sum of squares.&lt;/p&gt;
&lt;p&gt;$\sum_{i=1}^N (y_i - f(x))^2 = \sum_{i=1}^N (y_i - \beta_0 - \sum_{j=1}^p X_j\beta_j)^2$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/lr.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Denote $X$ by the $N \times (p+1)$ matrix with each row an input vector (with a 1 in the first position, to represent the intercept), and similarity let $y$ be the $N$ vector of outputs in the training set. Then we can write the residual sum-of-squares as :&lt;/p&gt;
&lt;p&gt;$RSS(\beta) = (y-X\beta)^T(y-X\beta)$&lt;/p&gt;
&lt;p&gt;Differentiating with respect to $\beta$, &amp;hellip;.&lt;/p&gt;
&lt;p&gt;$\hat{\beta} = (X^TX)^{-1}X^Ty$&lt;/p&gt;
&lt;h2 id=&#34;geometric-interpretation&#34;&gt;Geometric Interpretation&lt;/h2&gt;
&lt;p&gt;$\hat{y} = X\hat{\beta} = X(X^TX)^{-1}X^Ty = Hy $&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Projection Matrix&lt;/strong&gt; (or Hat matrix): The outcome vector $y$ is orthogonally projected onto the hyperplane spanned by the input vectors $x_1$ and $x_2$. The Projection $\hat{y}$ represents the vector of predictions obtained by the least square method.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/ols_projection.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;properties-of-ols&#34;&gt;Properties of OLS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;They are unbiased estimators. That is the expected value of estimators and actual parameters are the same $E(\hat{\beta}) = \beta$&lt;/li&gt;
&lt;li&gt;The covariance can be obtained by $cov(\hat{\beta}) = \sigma^2 (X^TX)^{-1}$, where $\sigma^2 = SSE/(n-p)$&lt;/li&gt;
&lt;li&gt;According to the &lt;strong&gt;Gauss-Markov Theorem&lt;/strong&gt;, &lt;em&gt;among all unbiased linear estimates&lt;/em&gt;, the least square estimate (LSE) has the minimum variance and it is unique.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Regression can be used for Feature Extraction&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;splines&#34;&gt;Splines&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Polynomial Regression&lt;/strong&gt; is a type of regression analysis where the relationship between the independent variable (input) and the dependent variable (output) is modeled as an nth-degree polynomial. In other words, instead of fitting a straight line (linear regression), a polynomial regression can fit curves of various degrees, allowing for more flexibility in capturing complex relationships. For example, a quadratic polynomial regression (degree 2) can model a parabolic relationship, and a cubic polynomial regression (degree 3) can model more intricate curves.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Polynomial regression is still considered a type of linear regression&lt;/strong&gt; because the relationship between the input and output variables is linear with respect to the coefficients, even though the input variables may be raised to different powers. The model equation for polynomial regression of degree n is:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$y = \beta_0 + \beta_1x + \beta_2x^2 + \beta_3x^3 + &amp;hellip; + \beta_mx^m + \epsilon$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nonlinear Regression&lt;/strong&gt;, on the other hand, refers to a broader class of regression models where the relationship between the independent and dependent variables is not a linear function. Nonlinear regression can encompass a wide range of functional forms, including exponential, logarithmic, sigmoidal, and other complex shapes. The main characteristic of nonlinear regression is that the model parameters are estimated in a way that best fits the chosen nonlinear function to the data.&lt;/p&gt;
&lt;p&gt;Unlike polynomial regression, nonlinear regression models can&amp;rsquo;t be expressed in terms of a simple equation with polynomial terms. The specific form of the nonlinear function needs to be determined based on the problem&amp;rsquo;s nature and domain knowledge.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disadvantages of Polynomial Regression&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Remote part of the function is very sensitive to outliers&lt;/li&gt;
&lt;li&gt;Less flexibility due to global function structure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/dis_pr.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The global function structure causes underfitting or overfitting.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The solution is to move from global to local structure -&amp;gt; Splines.&lt;/p&gt;
&lt;h3 id=&#34;splines-1&#34;&gt;Splines&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Linear combination of Piecewise Polynomial Function &lt;strong&gt;under continuity assumption&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Partition the domain of x into continuous intervals and fit polynomials in each interval separately&lt;/li&gt;
&lt;li&gt;Provides flexibility and local fitting&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Suppose $x \in [a,b]$. Partition the x domain using the following points (a.k.a knots):&lt;/p&gt;
&lt;p&gt;$a&amp;lt;\xi_1&amp;lt;\xi_2&amp;hellip;&amp;lt;\xi_k&amp;lt;b, &amp;lt;\xi_0=a, &amp;lt;\xi_{k+1}=b$&lt;/p&gt;
&lt;p&gt;Fit a polynomial in each interval under the continuity conditions and integrate them by&lt;/p&gt;
&lt;p&gt;$f(X) = \sum_{m=1}^K \beta_mh_m(X)$&lt;/p&gt;
&lt;h3 id=&#34;simple-example&#34;&gt;Simple Example&lt;/h3&gt;
&lt;h3 id=&#34;piecewise-constant&#34;&gt;Piecewise Constant&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/pwc.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here we are using a zero order polynomial. A zero order polynomial can be defined by an indicator function. If we use OLS, the beta would be the average of point in each local region.&lt;/p&gt;
&lt;p&gt;$f(X) = \sum_{m=1}^3 \beta_mh_m(X)$&lt;/p&gt;
&lt;h3 id=&#34;piecewise-linear&#34;&gt;Piecewise Linear&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/pwl.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here we are using a first order polynomial. A first order polynomial includes slopes and intercept (and therefore $K=6$ here.)&lt;/p&gt;
&lt;p&gt;$f(X) = \sum_{m=1}^6 \beta_mh_m(X)$&lt;/p&gt;
&lt;p&gt;There are two issues here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Discontinuity&lt;/li&gt;
&lt;li&gt;Underfitting&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;solving-for-discontinuity&#34;&gt;Solving for Discontinuity&lt;/h2&gt;
&lt;p&gt;We can impose continuity constraint for each knot:&lt;/p&gt;
&lt;p&gt;$f{\xi^-_1}=f(\xi^+_1)$&lt;/p&gt;
&lt;p&gt;This can be translated to $\beta_1+\xi_1\beta_4 = \beta_2 + \xi_1\beta_5$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Not sure how&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;By adding constraints we are losing some degrees of freedom.
The total number of free parameters (degree of freedom) = 6 (total number of parameters -2 (total number of constraints) = 4&lt;/p&gt;
&lt;p&gt;Alternatively, once could incorporate the constraints into the basis functions:&lt;/p&gt;
&lt;p&gt;$h_1(X) = 1$,&lt;/p&gt;
&lt;p&gt;$h_2(X) = X$,&lt;/p&gt;
&lt;p&gt;$h_3(X) = (X-\xi_1)_+$,&lt;/p&gt;
&lt;p&gt;$h_4(X) = (X-\xi_2)_+$&lt;/p&gt;
&lt;p&gt;This basis is known as truncated power basis&lt;/p&gt;
&lt;p&gt;$(X-\xi_k)_+ = (X-\xi_k)$ if $x \ge xi_k$ $0$ if $x&amp;lt;xi_k$&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/790G152GYz4?si=PIkkurtDgaioUCMu&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;solving-for-underfitting&#34;&gt;Solving for Underfitting&lt;/h2&gt;
&lt;p&gt;Splines with Higher Order of Continuity can be used to tackle underfitting.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/cp.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Continuity constraints for smoothness&lt;/p&gt;
&lt;p&gt;$f{\xi^-_1}=f(\xi^+_1)$&lt;/p&gt;
&lt;p&gt;$f^&amp;rsquo;{\xi^-_1}=f^&amp;rsquo;(\xi^+_1)$&lt;/p&gt;
&lt;p&gt;$f^{&amp;rsquo;&amp;rsquo;}{\xi^-_1}=f^{&amp;rsquo;&amp;rsquo;}(\xi^+_1)$&lt;/p&gt;
&lt;p&gt;$h_1(X) = 1$,&lt;/p&gt;
&lt;p&gt;$h_2(X) = X$,&lt;/p&gt;
&lt;p&gt;$h_3(X) = X^2$,&lt;/p&gt;
&lt;p&gt;$h_4(X) = X^3$,&lt;/p&gt;
&lt;p&gt;$h_5(X) = (X-\xi_1)^3_+$,&lt;/p&gt;
&lt;p&gt;$h_6(X) = (X-\xi_2)^3_+$&lt;/p&gt;
&lt;p&gt;The degree of freedom is calculated by:
Number of regions * Number of parameters in each region) - (Number of knots)*(Number of constraints per knot)&lt;/p&gt;
&lt;h2 id=&#34;order-m-splines&#34;&gt;Order-M Splines&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;M=1 piecewise-constant splines&lt;/li&gt;
&lt;li&gt;M=2 linear splines&lt;/li&gt;
&lt;li&gt;M=3 quadratic splines&lt;/li&gt;
&lt;li&gt;M=4 cubic splines&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For Truncated power basis functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Total degree of freedom is K+M&lt;/li&gt;
&lt;li&gt;Cubic spline is the lowest order spline for which the knot discontinuity is not visible to human eyes&lt;/li&gt;
&lt;li&gt;Knots selection: a simple method is to use x quantiles. However, the choice of knots is a variable/model selection problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;estimation&#34;&gt;Estimation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;After creating the basis function, we can use OLS to estimate parameters $\beta$&lt;/li&gt;
&lt;li&gt;First of all, create a basis matrix by concatinating basis vectors. For example if we have cubic splines with two knots, we will have six basis vectors.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$H = [h_1(x) \quad h_2(x) \quad h_3(x) \quad h_4(x) \quad h_5(x) \quad h_6(x)]$&lt;/p&gt;
&lt;p&gt;gives $\hat\beta = (H^TH)^-1H^Ty$&lt;/p&gt;
&lt;p&gt;Linear Smoother: $\hat y= H\hat\beta = H(H^TH)^{-1}H^Ty = Sy$&lt;/p&gt;
&lt;p&gt;Degrees of Freedom $df=trace S$&lt;/p&gt;
&lt;p&gt;Although truncated power basis functions are simple and algebraically appealing, it is not efficient for computation and ill-posed and numerically unstable. The matrix is close to singular (because of correlations among themselves, and determinant being very close to zero), and inverting it becomes challenging.&lt;/p&gt;
&lt;p&gt;The solution is to user Bsplines.&lt;/p&gt;
&lt;h2 id=&#34;bsplines&#34;&gt;Bsplines&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Alternative basis vectors for piecewise polynomials that are computationally more efficient&lt;/li&gt;
&lt;li&gt;Each basis function has a local support, that is, it is nonzero over at most M (spline order) consecutive intervals&lt;/li&gt;
&lt;li&gt;The basis matrix is banded&lt;/li&gt;
&lt;li&gt;The low bandwidth of the matrix reduces the linear dependency of the columns, and therefore, removes the numeric column stability.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/bspline.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;bspline-basis&#34;&gt;Bspline Basis&lt;/h2&gt;
&lt;p&gt;Let $B_{j,m}(x)$ be the $j^{th}$ B-spline basis function of order $m(m \le M)$ for the knot sequence $\tau$&lt;/p&gt;
&lt;p&gt;$a &amp;lt; \xi_1 &amp;lt; \xi_2 &amp;lt; &amp;hellip; &amp;lt; \xi_k &amp;lt; b$&lt;/p&gt;
&lt;p&gt;Define the augmented knots sequence $\tau$&lt;/p&gt;
&lt;p&gt;$\tau_1 \le \tau_2 &amp;hellip;\le \tau_M \le \xi_0$ (before the lower bound)&lt;/p&gt;
&lt;p&gt;$\tau_{M+j} = \xi_j, j = 1, &amp;hellip; , K$&lt;/p&gt;
&lt;p&gt;$\xi_{K+1} \le \tau_{M+K+1} \le \tau_{M+K+2} \le &amp;hellip; \le \tau_{2M+K}$ (after the lower bound)&lt;/p&gt;
&lt;h3 id=&#34;smoother-matrix&#34;&gt;Smoother Matrix&lt;/h3&gt;
&lt;p&gt;Consider a regression Spline basis B&lt;/p&gt;
&lt;p&gt;$\hat f = B(B^TB)^{-1}B^Ty = Hy$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;H is the smoother matrix (projection matrix)&lt;/li&gt;
&lt;li&gt;H is idempotent ($H \times H = H$)&lt;/li&gt;
&lt;li&gt;H is symmetric&lt;/li&gt;
&lt;li&gt;Degrees of freedom trace (H)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;smoothing-splines&#34;&gt;Smoothing Splines&lt;/h2&gt;
&lt;h3 id=&#34;bspline-basis-boundary-issue&#34;&gt;Bspline basis boundary issue&lt;/h3&gt;
&lt;p&gt;Consider the following setting with the fixed training data&lt;/p&gt;
&lt;p&gt;$y_i = f(x_i) + \epsilon_i$&lt;/p&gt;
&lt;p&gt;$\epsilon_i \approx iid(0, \sigma^2)$&lt;/p&gt;
&lt;p&gt;$Var(\hat f(x)) = h(x)^T(H^TH)^{-1}h(x)\sigma^2$ (variance of estimated function using spline)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Behavior of splines tends to be sporadic near the boundaries, and extrapolation can be problematic. The main reason is that the complexity of Cubic Spline is more than the complexity of Global Cubic Polynomial, due to the large number of parameters (less bias, more variance). The solution is to use linear splines instead of cubic splines (Natural Cubic Splines).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;natural-cubic-splines&#34;&gt;Natural Cubic Splines&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Additional constraints are added to make the function linear beyond the boundary knots&lt;/li&gt;
&lt;li&gt;Assuming the function is linear near the boundaries (where there is less information) is often reasonable&lt;/li&gt;
&lt;li&gt;Cubic spline; linear on $[-\inf, \xi_1]$ and $[\xi_k , \inf]$&lt;/li&gt;
&lt;li&gt;Prediction variance decreases&lt;/li&gt;
&lt;li&gt;The price is the bias near the boundaries&lt;/li&gt;
&lt;li&gt;Degrees of freedom is K, the number of knots&lt;/li&gt;
&lt;li&gt;Each of these basis functions has zero second and third derivative in the linear region.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;penalized-residual-sum-of-squares&#34;&gt;Penalized residual sum of squares&lt;/h2&gt;
&lt;p&gt;$\min_f \frac{1}{n}\sum_{i-1}^n[y_i - f(x_i)]^2+\lambda \int^a_b[f^{&amp;quot;}(x)^2dx]$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first term measures the closeness of the model to the data (related to bias)&lt;/li&gt;
&lt;li&gt;The second term penalizes curvature of the function (related to variance)&lt;/li&gt;
&lt;li&gt;$\lambda$ is the smoothing parameter controlling the trade between bias and variance&lt;/li&gt;
&lt;li&gt;$\lambda = 0$ interpolate the data (overfitting)&lt;/li&gt;
&lt;li&gt;$\lambda = \inf$ linear least-square regression (underfitting)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It can be shown that the minimizer is a natural cubic spline.&lt;/p&gt;
&lt;p&gt;Solution: $\hat \theta = (N^TN + \lambda\Omega)^{-1}N^Ty$
, $\Omega$ represents the second derivative&lt;/p&gt;
&lt;p&gt;$ f = (N^TN + \lambda\Omega)^{-1}N^Ty = S_\lambda y$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Smoothing spline estimator is a linear smoother&lt;/li&gt;
&lt;li&gt;$S_\lambda$ is the smoother matrix&lt;/li&gt;
&lt;li&gt;$S_\lambda$ is NOT idempotent&lt;/li&gt;
&lt;li&gt;$S_\lambda$ is symmetric&lt;/li&gt;
&lt;li&gt;$S_\lambda$ is positive definite&lt;/li&gt;
&lt;li&gt;Degrees of freedom: trace($S_\lambda$)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;choice-of-tuning-parameters&#34;&gt;Choice of Tuning Parameters&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Train Test Validation
&lt;img src=&#34;https://ayushsubedi.github.io/img/pt.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cross Validation
If an independent validation dataset is not affordable, the K-fold cross validation or leave-one-out CV can be useful&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Akaike Information Criteria (AIC)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bayesian Information Criteria (BIC)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generalized Cross-validation&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kernel-smoothers&#34;&gt;Kernel Smoothers&lt;/h2&gt;
&lt;h3 id=&#34;k-nearest-neighbor-knn&#34;&gt;K-Nearest Neighbor (KNN)&lt;/h3&gt;
&lt;p&gt;KNN Average $\hat f(x_0) = \sum_{i=1}^nw(x_0, x_i)y_i$&lt;/p&gt;
&lt;p&gt;where $\sum_{i=1}^nw(x_0, x_i)$ = $\frac{1}{K}$ if $x_i \in N_k(x_0)$ else $0$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple average of the k nearest observations to $x_0$ (local averaging)&lt;/li&gt;
&lt;li&gt;Equal weights are assigned to all neighbors&lt;/li&gt;
&lt;li&gt;However, the fitted function is in the form of a step function (non-smooth function)&lt;/li&gt;
&lt;li&gt;Also, the bias is quite high&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kernel-function&#34;&gt;Kernel Function&lt;/h3&gt;
&lt;p&gt;Any non-negative real-valued integrable function that satisfies the following conditions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\int_{-\inf}^{\inf}K(u)du=1$&lt;/li&gt;
&lt;li&gt;K is an even function; $K(-u) = K(u)$&lt;/li&gt;
&lt;li&gt;It has a finite second moment; $u^2\int_{-\inf}^{\inf}K(u)du &amp;lt; \inf$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kernel-smoother-regression&#34;&gt;Kernel Smoother Regression&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Kernel Regression&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is weighted local averaging that fits a simple model separately at each query point $x_0$&lt;/li&gt;
&lt;li&gt;More weights are assigned to closer observation&lt;/li&gt;
&lt;li&gt;Localization is defined by the weighting function&lt;/li&gt;
&lt;li&gt;Kernel regression requires little training, all calculations get done at the evaluation time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/kregression.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;choice-of-lambda&#34;&gt;Choice of $\lambda$&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$\lambda$ defines the width of the neighbourhood&lt;/li&gt;
&lt;li&gt;Only points withing $[x_0-\lambda, x_0+\lambda]$ receive positive weights&lt;/li&gt;
&lt;li&gt;Smaller $\lambda$: rough estimate, larger bias, smaller variance&lt;/li&gt;
&lt;li&gt;Larger $\lambda$: smoother estimate, smaller bias, larger variance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cross-validation can be used for determining of $\lambda$:&lt;/p&gt;
&lt;h3 id=&#34;drawbacks-of-local-averaging&#34;&gt;Drawbacks of Local Averaging&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The local averaging can be biased on the boundaries of the domain due to the asymmetry of the kernel in that region.&lt;/li&gt;
&lt;li&gt;This can be solved by local linear regression&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/nw_kernel.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Local linear regression corrects the bias on the boundaries&lt;/li&gt;
&lt;li&gt;Local polynomial regression corrects the bias in the curvature region&lt;/li&gt;
&lt;li&gt;However, local polynomial regression is complex due to higher order of polynomials, therefore, it increases the prediction variance.&lt;/li&gt;
&lt;li&gt;A good solution would be to use local linear model for points in the boundaries, and local quadratic regression in the interior regions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;functional-principal-component&#34;&gt;Functional Principal Component&lt;/h2&gt;
&lt;p&gt;Similar to PCA, FPCA aims to reduce the dimension of functional data by extracting a small set of uncorrelated features, which capture the most of the variation.&lt;/p&gt;
&lt;p&gt;Functional data (observed signals) are comprised of two main components. The first component is the continuous functional mean, and the second component is the error term, that is, the realizations from a stochastic process with mean function 0 and covariance function $C(t, t^&amp;rsquo;)$. It includes both random noise and signal-to-signal variations&lt;/p&gt;
&lt;p&gt;$s_i(t) = \mu(t) + \epsilon_i(t)$&lt;/p&gt;
&lt;p&gt;The mean function is common across all signals (notice that it does not have the $i$ subscript)&lt;/p&gt;
&lt;p&gt;Since signal variance comes from the noise function, we first focus on this for dimensionality reduction using the Karhunen-Loeve Theorem.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/kl.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The variance of $\xi_{ik}$ quickly decays with k. Therefore, only a few $\xi_{ik}$ also known as FPC-scores, would be enough to accurately approximate the noise function. That is,&lt;/p&gt;
&lt;p&gt;$\epsilon_i(t) \approx \sum_{k=1}^K \xi_{ik}\phi_{k}(t)$&lt;/p&gt;
&lt;p&gt;Signals decomposition is given by&lt;/p&gt;
&lt;p&gt;$s_i(t) = \mu(t) + \epsilon_i(t) \implies \mu(t) + \sum_{k=1}^K \xi_{ik}\phi_{k}(t)$&lt;/p&gt;
&lt;h2 id=&#34;model-estimation&#34;&gt;Model Estimation&lt;/h2&gt;
&lt;p&gt;Both the mean and covariance is unknown, and should be measured using training data. In practice, we have two types of signals/data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complete signals: Sampled regularly&lt;/li&gt;
&lt;li&gt;Incomplete signals: Sampled irregularly, sparse, fragmented&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;steps-for-fpca-when-the-signals-are-incomplete&#34;&gt;Steps for FPCA when the signals are incomplete:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Estimate the mean function using local linear regression&lt;/li&gt;
&lt;li&gt;Estimate the raw covariance function using the estimated mean function&lt;/li&gt;
&lt;li&gt;Estimate the covariance surface using local quadratic regression&lt;/li&gt;
&lt;li&gt;Compute the Eigen functions&lt;/li&gt;
&lt;li&gt;Compute the FPC scores&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;image-analysis&#34;&gt;Image Analysis&lt;/h1&gt;
&lt;h2 id=&#34;introduction-to-image-processing&#34;&gt;Introduction to Image Processing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The process of processing raw images and extracting useful information for decision making.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Level 0:&lt;/strong&gt; Image representation (acquisition, sampling, quantization, compression)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Level 1:&lt;/strong&gt; Image to Image transformations (enhancement, filtering, restoration, smoothing, segmentation)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Level 2:&lt;/strong&gt; Image to vector transformation (feature extraction and dimension reduction)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Level 3:&lt;/strong&gt; Feature to decision mapping&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/image_analysis.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-an-image&#34;&gt;What is an Image?&lt;/h2&gt;
&lt;p&gt;A gray (color-RGB) image is a 2-D (3-D) light intensity function, $f (x_1, x_2)$, where $f$ measures brightness at position $f(x_1, x_2)$ . A digital gray (color) image is a representation of an image by a 2-D (3-D) array of discrete samples. &lt;strong&gt;Pixel&lt;/strong&gt; is referred to an element of the array.&lt;/p&gt;
&lt;p&gt;Possible values each pixel can have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Black and white image: 2&lt;/li&gt;
&lt;li&gt;8-bit Gray image: 256&lt;/li&gt;
&lt;li&gt;RGB: 256 x 256 x 256 = 16777216&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;basic-manipulation-in-python&#34;&gt;Basic Manipulation in Python&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Load the image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;your_image.jpg&amp;#39;&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# Replace with the path to your image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;original_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Check if the image was loaded successfully&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; original_image &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Error: Could not open or find the image.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Convert the image to grayscale&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    gray_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cvtColor(original_image, cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;COLOR_BGR2GRAY)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Convert the grayscale image to black and white using thresholding&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    _, binary_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;threshold(gray_image, &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;, cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;THRESH_BINARY)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Resize the image (e.g., to a width of 800 pixels while maintaining aspect ratio)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_width &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;800&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    aspect_ratio &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; original_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; original_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_height &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(new_width &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; aspect_ratio)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    resized_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(binary_image, (new_width, new_height))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Save the processed images to disk&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray_image.jpg&amp;#39;&lt;/span&gt;, gray_image)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;black_and_white_image.jpg&amp;#39;&lt;/span&gt;, binary_image)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;resized_image.jpg&amp;#39;&lt;/span&gt;, resized_image)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Images processed and saved successfully.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;image-transformation&#34;&gt;Image Transformation&lt;/h2&gt;
&lt;h3 id=&#34;image-histogram&#34;&gt;Image Histogram&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Histogram represents the distribution of gray levels.&lt;/li&gt;
&lt;li&gt;It is an estimate of the probability density function (pdf) of the underlying random process.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Image can be transformed by applying a function on the image matrix.&lt;/p&gt;
&lt;p&gt;$g(x,y) = T(f(x,y))$&lt;/p&gt;
&lt;p&gt;For example if a threshold function is sued as the transformation function a gray-scale image can be converted to a BW image.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/step_function.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The brightness of an image can be changed by shifting its histogram.&lt;/li&gt;
&lt;li&gt;The contrast of an image is defined by the difference in maximum and minimum pixel intensity.&lt;/li&gt;
&lt;li&gt;Gray level resolution refers to change in the shades or levels of gray in an image.&lt;/li&gt;
&lt;li&gt;The number of different colors in an image depends on bits per pixel (bpp).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$L = 2^{bpp}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gray level transformation is often used for image enchantment.&lt;/li&gt;
&lt;li&gt;Three typical transformation functions are:
&lt;ul&gt;
&lt;li&gt;Linear (negative image)&lt;/li&gt;
&lt;li&gt;Log&lt;/li&gt;
&lt;li&gt;Power-Law&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convolution-and-image-filtering&#34;&gt;Convolution and image filtering&lt;/h3&gt;
&lt;p&gt;The convolution of functions $f$ and $g$ is defined by:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/convolutions.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Convolution is widely used in image processing for denoising, blurring, sharpening, embossing, and edge detection.&lt;/li&gt;
&lt;li&gt;Image filter is a convolution of a mask (aka kernel, and convolution matrix) with an image that can be used for blurring, sharpening, edge detection, etc.&lt;/li&gt;
&lt;li&gt;A mask is a matrix convolved with an image.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;image-convolution-with-a-mask&#34;&gt;Image Convolution with a Mask&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Flip the mask (kernel) both horizontally and vertically.&lt;/li&gt;
&lt;li&gt;Put the center element of the mask at every pixel of the image. Multiply the corresponding elements and then add them up. Replace the pixel value corresponding to the center of the mask with the resulting sum.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/convolution.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For pixels on the border of image matrix, some elements of the mask might fall out of the image matrix. In this case, we can extend the image by adding zeros. This is known as padding.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/padding.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;denoising-of-smooth-images-using-splines&#34;&gt;Denoising of Smooth Images using Splines&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Another approach for denoising smooth images is to use local regression with smooth basis (eg. splines)&lt;/li&gt;
&lt;li&gt;Using Kronecker product, a 2D-spline basis can be generated from 1D basis matrices&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;image-segmentation&#34;&gt;Image Segmentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The main goal of image segmentation is to partition an image into multiple sets of pixels (segments)&lt;/li&gt;
&lt;li&gt;Image segmentation has been widely used for object detection, face and fingerprint recognition, medical imaging, video surveillance, etc.&lt;/li&gt;
&lt;li&gt;Various methods exist for image segmentation including:
&lt;ul&gt;
&lt;li&gt;Local and global thresholding&lt;/li&gt;
&lt;li&gt;Otsu&amp;rsquo;s method&lt;/li&gt;
&lt;li&gt;K-means clustering&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Thresholding is a simple segmentation approach that converts grayscale image to binary image by applying the thresholding function on histogram.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;otsus-method&#34;&gt;Otsu&amp;rsquo;s Method&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The goal is to automatically determine the threshold $t$ given an image histogram.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Otsu%27s_Method_Visualization.gif/440px-Otsu%27s_Method_Visualization.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get the histogram of the image&lt;/li&gt;
&lt;li&gt;Calculate group mean and variance&lt;/li&gt;
&lt;li&gt;Find the maximum value for the variance&lt;/li&gt;
&lt;li&gt;Threshold the image&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compute_otsu_criteria&lt;/span&gt;(im, th):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Otsu&amp;#39;s method to compute criteria.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# create the thresholded image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    thresholded_im &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(im&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    thresholded_im[im &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; th] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# compute weights&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    nb_pixels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; im&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;size
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    nb_pixels1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;count_nonzero(thresholded_im)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    weight1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nb_pixels1 &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; nb_pixels
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    weight0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; weight1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# if one of the classes is empty, eg all pixels are below or above the threshold, that threshold will not be considered&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# in the search for the best threshold&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; weight1 &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; weight0 &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# find all pixels belonging to each class&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    val_pixels1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; im[thresholded_im &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    val_pixels0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; im[thresholded_im &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# compute variance of these classes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    var1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;var(val_pixels1) &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(val_pixels1) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    var0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;var(val_pixels0) &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(val_pixels0) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; weight0 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; var0 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; weight1 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; var1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;im &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# load your image as a numpy array.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# For testing purposes, one can use for example im = np.random.randint(0,255, size = (50,50))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# testing all thresholds from 0 to the maximum of the image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;threshold_range &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max(im)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;criterias &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [compute_otsu_criteria(im, th) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; th &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; threshold_range]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# best threshold is the one minimizing the Otsu criteria&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;best_threshold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; threshold_range[np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmin(criterias)]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;k-means-clustering-method&#34;&gt;K-Means Clustering Method&lt;/h3&gt;
&lt;p&gt;K-means clustering is a method for partitioning a set of observations to K clusters, such that the within-cluster variation is minimized.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rearrange the image pixels such that the number of rows in the resulting matrix is equal to the number of pixels and the number of columns is the same as the number of color channels&lt;/li&gt;
&lt;li&gt;Randomly select K centers&lt;/li&gt;
&lt;li&gt;Assign each pixel to the closest cluster&lt;/li&gt;
&lt;li&gt;Update the cluster mean&lt;/li&gt;
&lt;li&gt;Repeat the last two process until convergence&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;The objective of K-means is to minimize the within cluster variation, and maximize the inter-class variation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;edge-detection&#34;&gt;Edge Detection&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Edges are significant local changes of intensity in an image.&lt;/li&gt;
&lt;li&gt;Edge Detection: Detect pixel with sudden intensity change&lt;/li&gt;
&lt;li&gt;Often points that lie on an edge are detected by:
&lt;ul&gt;
&lt;li&gt;Detecting the local &lt;strong&gt;maxima&lt;/strong&gt; or &lt;strong&gt;minima&lt;/strong&gt; of the first derivative.&lt;/li&gt;
&lt;li&gt;Detecting the &lt;strong&gt;zero-crossings&lt;/strong&gt; of the second derivative.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/edge.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;sobel-operator&#34;&gt;Sobel Operator&lt;/h3&gt;
&lt;p&gt;The Sobel operator works by convolving an image with a pair of 3x3 kernels or filters, one for detecting edges in the horizontal direction (often referred to as the Sobel-X operator) and the other for detecting edges in the vertical direction (often referred to as the Sobel-Y operator). These kernels are as follows:&lt;/p&gt;
&lt;p&gt;Sobel-X Kernel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Sobel-Y Kernel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;krisch-operator&#34;&gt;Krisch Operator&lt;/h3&gt;
&lt;p&gt;Krisch is another derivative mask that finds the maximum edge strength in eight directions of a compass.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/kirsh.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It is more time consuming compare to Sobel&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;prewitt-mask&#34;&gt;Prewitt Mask&lt;/h3&gt;
&lt;p&gt;The Prewitt operator, like the Sobel operator, employs a pair of 3x3 convolution kernels, one for detecting edges in the horizontal direction and the other for detecting edges in the vertical direction.&lt;/p&gt;
&lt;p&gt;Here are the two Prewitt kernels:&lt;/p&gt;
&lt;p&gt;Prewitt-X Kernel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Prewitt-Y Kernel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;laplacian-and-laplacian-of-gaussian-mask&#34;&gt;Laplacian and Laplacian of Gaussian Mask&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Laplacian mask is a second order derivative mask.&lt;/li&gt;
&lt;li&gt;For noisy images, is combined with a Gaussian mask to reduce the noise&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Laplacian, Sobel, and Prewitt are masks used for edge detection. Gaussian is not a mask for edge detection.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;tensor-data-analysis&#34;&gt;Tensor Data Analysis&lt;/h1&gt;
&lt;h2 id=&#34;tensor-introduction&#34;&gt;Tensor Introduction&lt;/h2&gt;
&lt;p&gt;A tensor is an algebraic object that describes a multi-linear relationship between sets of algebraic objects related to a vector space. Tensors may map between different objects such as vectors, scalars, and even other tensors.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hkilter.com/images/7/7a/Tensors.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;terminologies&#34;&gt;Terminologies:&lt;/h3&gt;
&lt;h4 id=&#34;order&#34;&gt;Order&lt;/h4&gt;
&lt;p&gt;The order of a tensor refers to the number of indices or subscripts needed to specify its components in a given coordinate system. Tensors can have different orders, and the order determines their mathematical properties and how they transform under coordinate transformations. Here&amp;rsquo;s a brief overview of tensor orders:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zeroth-Order Tensor (Scalar)&lt;/strong&gt;: A zeroth-order tensor is also known as a scalar. It has no indices and represents a single numerical value. Scalars are invariant under coordinate transformations.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example: Temperature at a point in space.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;First-Order Tensor (Vector)&lt;/strong&gt;: A first-order tensor, also known as a vector, has one index. Vectors represent quantities with both magnitude and direction and transform linearly under coordinate transformations.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example: Velocity, force, displacement.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Second-Order Tensor (Matrix)&lt;/strong&gt;: A second-order tensor has two indices. It represents a linear transformation that maps one vector to another. Matrices are used to represent various physical quantities, such as stress tensors, moment of inertia tensors, and more.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example: Stress tensor, moment of inertia tensor.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Third-Order Tensor:&lt;/strong&gt; A third-order tensor has three indices, and it is used to represent more complex relationships between vectors and matrices. These tensors are less common but can arise in various physical and mathematical contexts.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example: Piezoelectric tensor in materials science.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/tensor_order.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;fibers&#34;&gt;Fibers&lt;/h4&gt;
&lt;p&gt;A fiber, the higher order analogue of matrix row and column, is defined by fixing every index but one, e.g.,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A matrix column is a mode-1 fiber and a matrix row is a mode-2 fiber&lt;/li&gt;
&lt;li&gt;Third-order tensors have column, row, and tube fibers&lt;/li&gt;
&lt;li&gt;Extracted fibers from a tensor are assumed to be oriented as column vectors.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/fibers.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;slices&#34;&gt;Slices&lt;/h4&gt;
&lt;p&gt;Two-dimensional sections of a tensor, defined by fixing all but two indices.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/slices.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;norm&#34;&gt;Norm&lt;/h4&gt;
&lt;p&gt;Norm of a tensor $X \in \R^{I_1 \times I_2 \times &amp;hellip;. \times I_N}$ is the square root of the sum of the squares of all its elements.&lt;/p&gt;
&lt;p&gt;This is analogous to the matrix Frobenius norm, which is denoted $||A||_F$ for matrix $A$&lt;/p&gt;
&lt;h4 id=&#34;outer-product&#34;&gt;Outer Product&lt;/h4&gt;
&lt;p&gt;A multi-way vector outer product is a tensor where each element is the product of corresponding elements in vectors&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/outer_product.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;inner-product&#34;&gt;Inner Product&lt;/h4&gt;
&lt;p&gt;The inner product of two tensors is a generalization of the dot product operation for vectors as calculated by dot. A dot product operation (multiply and sum) is performed on all corresponding dimensions in the tensors, so the operation returns a scalar value. For this operation, the tensors must have the same size.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/innter_product.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;using-tensorly-for-inner-and-outer-product&#34;&gt;Using Tensorly for inner and outer product&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorly &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Define the shape of the random tensors&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Generate random data for X and Y using NumPy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;X_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;shape)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Y_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;shape)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Convert the NumPy arrays to TensorLy tensors&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(X_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(Y_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Calculate the inner product of X and Y&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;inner_product &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tenalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner(X, Y)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Calculate the outer product of X and Y&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;outer_product &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tenalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;outer(X, Y)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the results&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Inner Product:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(inner_product)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Outer Product:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(outer_product)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;using-tensorly-for-unfolding-and-flattening&#34;&gt;Using Tensorly for unfolding, and flattening&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Unfold an N-way tensor into a matrix&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorly &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a random 2x2x2 tensor&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;random_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tensor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(random_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Mode-1 matricization (unfold along the first mode)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mode1_matricization &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unfold(tensor, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Mode-2 matricization (unfold along the second mode)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mode2_matricization &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unfold(tensor, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Mode-3 matricization (unfold along the third mode)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mode3_matricization &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unfold(tensor, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the results&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Mode-1 Matricization:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(mode1_matricization)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Mode-2 Matricization:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(mode2_matricization)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Mode-3 Matricization:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(mode3_matricization)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/matrixization.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;tensor-multiplication&#34;&gt;Tensor Multiplication&lt;/h2&gt;
&lt;p&gt;The n-mode product is referred to as multiplying a tensor by a matrix (or a vector) in mode n.&lt;/p&gt;
&lt;p&gt;The n-mode (matrix) product of a tensor $X \in \R^{I_1 \times I_2 \times &amp;hellip;. \times I_N}$ with a matrix $U \in R^{J \times I_n}$ is denoted by $X \times_n U$ and is of size $I_1 \times I_2 \times &amp;hellip;. \times I_{n-1} \times J \times I_{n+1} \times &amp;hellip;\times I_N $&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorly &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a random 3x2x4 tensor&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;random_tensor_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tensor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(random_tensor_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a random matrix compatible with mode-1 multiplication&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;random_matrix_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(random_matrix_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Multiply the tensor and matrix in mode-1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tenalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mode_dot(tensor, matrix, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the result&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Random Tensor:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(tensor)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Random Matrix:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(matrix)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Result of Mode-1 Multiplication:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(result)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;n-mode-vector-product&#34;&gt;n-Mode Vector Product&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorly &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a random 3x2x4 tensor&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;random_tensor_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tensor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(random_tensor_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a random vector compatible with mode-1 multiplication&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;random_vector_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(random_vector_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Multiply the tensor and vector in mode-1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tenalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mode_dot(tensor, vector, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the random tensor, random vector, and the result of Mode-1 multiplication&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Random Tensor:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(tensor)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Random Vector:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(vector)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Result of Mode-1 Multiplication:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(result)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;kronecker-product&#34;&gt;Kronecker Product&lt;/h4&gt;
&lt;p&gt;The Kronecker product, denoted by âŠ—, is a mathematical operation that combines two matrices to create a larger matrix. It is a tensor product of two matrices and results in a block matrix where each block is a scalar multiple of one of the elements of the first matrix, multiplied by the second matrix.&lt;/p&gt;
&lt;p&gt;The Kronecker Product of matrices $A \in R^{I \times J}$ and $B \in R^{K \times L}$ is denoted by $A \bigotimes B$. The result is a matrix size ($IK) \times (JL)$ and defined by&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/kronecker.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;examples&#34;&gt;Examples&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://wikimedia.org/api/rest_v1/media/math/render/svg/74fc4867467d053ae700ebb040ddfbe42600288c&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wikimedia.org/api/rest_v1/media/math/render/svg/1d5453c59a261174eb2458c21ff9bdd30dc2c87d&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create two matrices&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;A &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;B &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Compute the Kronecker product&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kronecker_product &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kron(A, B)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the result&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Kronecker Product:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(kronecker_product)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;khatri-rao-product&#34;&gt;Khatri-Rao Product&lt;/h4&gt;
&lt;p&gt;The Khatri-Rao product, also known as the column-wise Kronecker product or simply the Khatri-Rao product, is an operation on two matrices that results in a matrix. It&amp;rsquo;s used in various applications in signal processing and linear algebra, especially in multilinear models and factorization problems. The Khatri-Rao product is denoted by âŠ™.&lt;/p&gt;
&lt;p&gt;Given two matrices, A of size m x n and B of size p x n, the Khatri-Rao product of A and B results in a matrix C of size (m * p) x n, where each column of C is formed by taking the Kronecker product of the corresponding columns of A and B.&lt;/p&gt;
&lt;h4 id=&#34;example&#34;&gt;Example&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://wikimedia.org/api/rest_v1/media/math/render/svg/311fb96a2459096ea05d8f0461e67a8b49f5ee43&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;so that:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wikimedia.org/api/rest_v1/media/math/render/svg/1e951f306d0dd52a9a56a35d767f2117db8a5ee6&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create two matrices A and B&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;A &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;B &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Compute the Khatri-Rao product&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;C &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kron(A, B)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the result&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Khatri-Rao Product:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(C)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;If a and b are vectors, then the Khatri-Rao and Kronecker products are identical&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;hadamard-product&#34;&gt;Hadamard Product&lt;/h4&gt;
&lt;p&gt;The Hadamard product, also known as the element-wise product or Schur product, is an operation between two matrices or vectors of the same size, resulting in another matrix or vector of the same size. In this operation, each element of the resulting matrix is the product of the corresponding elements of the input matrices. It is denoted by âŠ™.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create two matrices or vectors of the same size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;A &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;B &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Compute the Hadamard product&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;C &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; B
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the result&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hadamard Product:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(C)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;tensor-decomposition&#34;&gt;Tensor Decomposition&lt;/h2&gt;
&lt;iframe width=&#34;100%&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/L8uT6hgMt00?si=l6KQPaHQk80f7Nh9&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;h3 id=&#34;rank-one-tensor&#34;&gt;Rank-One Tensor&lt;/h3&gt;
&lt;p&gt;A Rank-One Tensor can be created by the outer product of multiple vectors, e.g., a 3-order rank-one tensor is obtained by&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/outer_product.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;candecompparafac-cp-decomposition&#34;&gt;Candecomp/Parafac (CP) Decomposition&lt;/h3&gt;
&lt;p&gt;Candecomp/Parafac (CP)(Parallel Factor Analysis) decomposition is a tensor decomposition method used in multilinear algebra and multivariate data analysis. It is an extension of the matrix factorization technique, like Singular Value Decomposition (SVD), to higher-order tensors, often referred to as multi-way arrays.&lt;/p&gt;
&lt;p&gt;The CP decomposition factorizes a tensor into a sum of component rank-one tensors, e.g. given a third-order tensor $X \in R^{I \times J\ times K}$, CP decomposition is given by,&lt;/p&gt;
&lt;p&gt;$X \approx \sum_{r=1}^{R} a_r \cdot b_r \cdot c_r$&lt;/p&gt;
&lt;p&gt;$R$ is a positive integer.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If R is the rank of higher-tensor then CP decomposition will be exact and unique.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;rank-of-tensor&#34;&gt;Rank of Tensor&lt;/h3&gt;
&lt;p&gt;Rank of a tensor $X$, denoted by $rank(X)$ is the smallest number of rank-one tensors whose sum can generate $X$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Determining the rank of a tensor is an NP-hard problem. Some weaker upper bounds, however, exits that helps restrict the rank space. For example,&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$X^{I \times J \times K}$,&lt;/p&gt;
&lt;p&gt;$rank(X)$ $\le min(IJ,JK, IK)$&lt;/p&gt;
&lt;h3 id=&#34;cp-decomposition-in-python&#34;&gt;CP Decomposition in Python&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorly &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Define the dimensions of the tensor&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;I &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;J &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;K &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a random tensor with the specified dimensions&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(I, J, K)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Set the desired rank for the decomposition&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rank &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Perform CP decomposition using TensorLy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;factors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decomposition&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parafac(X, rank&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;rank)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Reconstruct the original tensor&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;reconstructed_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kruskal_to_tensor(factors)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Evaluate the reconstruction error&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;reconstruction_error &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(X &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; reconstructed_X, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Reconstruction Error: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;reconstruction_error&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;tucker-decomposition&#34;&gt;Tucker Decomposition&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Tucker Decomposition is &lt;strong&gt;not&lt;/strong&gt; a special case of CP Decomposition&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Tucker decomposition, also known as Tucker factorization or Tucker model, is a tensor decomposition method used to represent a multi-dimensional tensor as a core tensor and a set of factor matrices that capture the relationships between the tensor&amp;rsquo;s modes or dimensions. Tucker decomposition is a higher-order extension of matrix factorization techniques like Singular Value Decomposition (SVD) to tensors.&lt;/p&gt;
&lt;p&gt;In Tucker decomposition, a given tensor is approximated as the product of a core tensor and a set of factor matrices for each mode. The core tensor contains the most important information about the original tensor&amp;rsquo;s structure, while the factor matrices capture how each mode contributes to the overall tensor. Here&amp;rsquo;s an overview of the Tucker decomposition process:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorly &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Define the dimensions of the tensor&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# Change these dimensions according to your data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a random tensor with the specified dimensions&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;shape))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Specify the Tucker rank (adjust these values as needed)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rank &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Perform Tucker decomposition using TensorLy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;core, factors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decomposition&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tucker(X, rank&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;rank)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Reconstruct the original tensor&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;reconstructed_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tucker_to_tensor(core, factors)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Evaluate the reconstruction error&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;reconstruction_error &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(X &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; reconstructed_X, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Reconstruction Error: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;reconstruction_error&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;optimization-and-application&#34;&gt;Optimization and Application&lt;/h1&gt;
&lt;p&gt;In plain English, &lt;strong&gt;optimization&lt;/strong&gt; is the action of making the best or most effective use of a situation or resource. Optimization problems are of great practical interest. For example, in manufacturing, how should one cut plates of a material so that the waste is minimized? In business, how should a company allocate the available resources that its profit is maximized? Some of the first optimization problems have been solved in ancient Greece and are regarded among the most significant discoveries of that time. In the first century A.D., the Alexandrian mathematician Heron solved the problem of finding the shortest path between two points by way of the mirror.&lt;/p&gt;
&lt;p&gt;This result, also known as Heronâ€™s theorem of the light ray, can be viewed as the origin of the theory of geometrical optics. The problem of finding extreme values gained special importance in the seventeenth century, when it served as one of the motivations in the invention of differential calculus, which is the foundation of the modern theory of mathematical optimization.&lt;/p&gt;
&lt;h2 id=&#34;generic-form-of-optimization-problem&#34;&gt;Generic form of optimization problem:&lt;/h2&gt;
&lt;p&gt;$min$ $f(x)$ $s.t.$ $x \in X $&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The vector $x = (x_1, . . . , x_n)$ is the optimization variable (or decision variable) of the problem&lt;/li&gt;
&lt;li&gt;The function $f$ is the objective function&lt;/li&gt;
&lt;li&gt;A vector $x$ is called optimal, or a solution (not optimal solution) of the problem, if it has the smallest objective value among all vectors that satisfy the constraints&lt;/li&gt;
&lt;li&gt;$X$ is the set of inequality constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mathematical-ingredients&#34;&gt;Mathematical ingredients:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Encode decisions/actions as &lt;strong&gt;decision variables&lt;/strong&gt; whose values we are seeking&lt;/li&gt;
&lt;li&gt;Identify the relevant &lt;strong&gt;problem data&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Express &lt;strong&gt;constraints&lt;/strong&gt; on the values of the decision variables as mathematical relationships (inequalities) between the variables and problem data&lt;/li&gt;
&lt;li&gt;Express the &lt;strong&gt;objective function&lt;/strong&gt; as a function of the decision variables and the problem data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Minimize or Maximize an objective function of decision variable subject to constraints on the values of the decision variables.&lt;/strong&gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;min or max f(x1, x2, .... , xn)
subject to gi(x1, x2, ...., ) &amp;lt;= bi     i = 1,....,m 
        xj is continuous or discrete    j = 1,....,n
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;the-problem-setting&#34;&gt;The problem setting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Finite number of decision variables&lt;/li&gt;
&lt;li&gt;A single objective function of decision variables and problem data
&lt;ul&gt;
&lt;li&gt;Multiple objective functions are handled by either taking a weighted combination of them or by optimizing one of the objectives while ensuring the other objectives meet target requirements.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The constraints are defined by a finite number of inequalities or equalities involving functions of the decision variables and problem data&lt;/li&gt;
&lt;li&gt;There may be domain restrictions (continuous or discrete) on some of the variables&lt;/li&gt;
&lt;li&gt;The functions defining the objective and constraints are algebraic (typically with rational coefficients)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;minimization-vs-maximization&#34;&gt;Minimization vs Maximization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Without the loss of generality, it is sufficient to consider a minimization objective since maximization of objective function is minimization of the negation of the objective function&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;program-vs-optimization&#34;&gt;Program vs Optimization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A program or mathematical program is an optimization problem with a finite number of variables and constraints written out using explicit mathematical (algebraic) expressions&lt;/li&gt;
&lt;li&gt;The word program means plan/planning&lt;/li&gt;
&lt;li&gt;Early application of optimization arose in planning resource allocations and gave rise to programming to mean optimization (predates computer programming)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;example-designing-a-box&#34;&gt;Example: Designing a box:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Given a $1$ feet by $1$ feet piece of cardboard, cut out corners and fold to make a box of maximum volume:&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;Decision:&lt;/strong&gt; $x$ = how much to cut from each of the corners?&lt;br/&gt;
&lt;strong&gt;Alternatives:&lt;/strong&gt; $0&amp;lt;=x&amp;lt;=1/2$&lt;br/&gt;
&lt;strong&gt;Best:&lt;/strong&gt; Maximize volume: $V(x) = x(1-2x)^2$ ($x$ is the height and $(1-2x)^2$ is the base, and their product is the volume)&lt;br/&gt;
&lt;strong&gt;Optimization formulation:&lt;/strong&gt; $max$ $x(1-2x)^2$ subject to $0&amp;lt;=x&amp;lt;=1/2$ (which are the constraints in this case)&lt;br/&gt;&lt;/p&gt;
&lt;iframe src=&#34;https://www.desmos.com/calculator/ily45jyfsv?embed&#34; width=&#34;100%&#34; height=&#34;500&#34; style=&#34;border: 1px solid #ccc&#34; frameborder=0&gt;&lt;/iframe&gt;
&lt;p&gt;This is an unconstrained optimization problem since the constraint is a simple bound based.&lt;/p&gt;
&lt;h3 id=&#34;example-data-fitting&#34;&gt;Example: Data Fitting:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Given $N$ data points $(y_1, x_1)&amp;hellip;(y_N, x_N)$ where $y_i$ belongs to $\mathbb{R}$ and $x_i$ belongs to $\mathbb{R}^n$, for all $i = 1..N$, find a line $y = a^Tx+b$ that best fits the data.&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;Decision&lt;/strong&gt;: A vector $a$ that belongs to $\mathbb{R}^n$ and a scalar $b$ that belongs to $\mathbb{R}$&lt;br/&gt;
&lt;strong&gt;Alternatives&lt;/strong&gt;: All $n$-dimensional vectors and scalars&lt;br/&gt;
&lt;strong&gt;Best&lt;/strong&gt;: Minimize the sum of squared errors&lt;br/&gt;
&lt;strong&gt;Optimization formulation&lt;/strong&gt;:
$\begin{array}{ll}\min &amp;amp; \sum_{i=1}^N\left(y_i-a^{\top} x_i-b\right)^2 \ \text { s.t. } &amp;amp; a \in \mathbb{R}^n, b \in \mathbb{R}\end{array}$&lt;/p&gt;
&lt;p&gt;This is also an unconstrained optimization problem.&lt;/p&gt;
&lt;h3 id=&#34;example-product-mix&#34;&gt;Example: Product Mix:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A firm make $n$ different products using $m$ types of resources. Each unit of product $i$ generates $p_i$ dollars of profit, and requires $r_{ij}$ units of resource $j$. The firm has $u_j$ units of resource $j$ available. How much of each product should the firm make to maximize profits?&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;Decision&lt;/strong&gt;: how much of each product to make&lt;br/&gt;
&lt;strong&gt;Alternatives&lt;/strong&gt;: defined by the resource limits&lt;br/&gt;
&lt;strong&gt;Best&lt;/strong&gt;: Maximize profits&lt;br/&gt;
&lt;strong&gt;Optimization formulation:&lt;/strong&gt; &lt;br/&gt;
Sum notation: $\begin{array}{lll}\max &amp;amp; \sum_{i=1}^n p_i x_i \ \text { s.t. } &amp;amp; \sum_{i=1}^n r_{i j} x_i \leq u_j &amp;amp; \forall j=1, \ldots, m \ &amp;amp; x_i \geq 0 &amp;amp; \forall i=1, \ldots, n\end{array}$ &lt;br/&gt;
Matrix notation: $\begin{array}{cl}\max &amp;amp; p^{\top} x \ \text { s.t. } &amp;amp; R x \leq u \ &amp;amp; x \geq 0\end{array}$&lt;/p&gt;
&lt;h3 id=&#34;example-project-investment&#34;&gt;Example: Project investment&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt; A firm is considering investing in $n$ different R&amp;amp;D projects. Project $j$ requires an investment of $c_j$ dollars and promises a return of $r_j$ dollars. The firm has a budget of $B$ dollars. Which projects should the firm invest in?&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;Decision&lt;/strong&gt;: Whether or not to invest in project&lt;br/&gt;
&lt;strong&gt;Alternatives&lt;/strong&gt;: Defined by budget&lt;br/&gt;
&lt;strong&gt;Best&lt;/strong&gt;: Maximize return on investment&lt;br/&gt;
Sum notation: $\begin{aligned} \max &amp;amp; \sum_{j=1}^n r_j x_j \ \text { s.t. } &amp;amp; \sum_{j=1}^n c_j x_j \leq B \ &amp;amp; x_j \in{0,1} \forall j=1, \ldots, n\end{aligned}$ &lt;br/&gt;
Matrix notation: $\begin{aligned} \max  &amp;amp; r^{\top} x \ \text { s.t. } &amp;amp; c^{\top} x \leq B \ &amp;amp; x \in{0,1}^n\end{aligned}$&lt;/p&gt;
&lt;p&gt;This is not an unconstrained problem.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify basic portfolio optimization and associated issues&lt;/li&gt;
&lt;li&gt;Examine the Markowitz Portfolio Optimization approach
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Markowitz Principle&lt;/strong&gt;: Select a portfolio that attempts to maximize the expected return and minimize the variance of returns (risk)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For multi objective problem (like defined by the Markowitz Principle), two objectives can be combined:
&lt;ul&gt;
&lt;li&gt;Maximize Expected Return - $\lambda$*risk&lt;/li&gt;
&lt;li&gt;Maximize Expected Return subject to risk &amp;lt;= s_max (constraint on risk)&lt;/li&gt;
&lt;li&gt;Minimize Risk subject to return &amp;gt;= r_min (threshold on expected returns)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Optimization Problem Statement&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Given $1000, how much should we invest in each of the three stocks MSFT, V and WMT so as to :
- have a one month expected return of at least a given threshold
- minimize the risk(variance) of the portfolio return
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Decision&lt;/strong&gt;: investment in each stock&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;alternatives&lt;/strong&gt;: any investment that meets the budget and the minimum expected return requirement&lt;/li&gt;
&lt;li&gt;best: minimize variance&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key trade-off&lt;/strong&gt;: How much of the detail of the actual problem to consider while maintaining computational tractability of the mathematical model?&lt;/li&gt;
&lt;li&gt;Requires making simplifying assumptions, either because some of the problem characteristics are not well-defined mathematically, or because we wish to develop a model that can actually be solved&lt;/li&gt;
&lt;li&gt;Need to exercise great caution in these assumptions and not loose sight of the true underlying problem&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Assumptions&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;No transaction cost&lt;/li&gt;
&lt;li&gt;Stocks does not need to be bought in blocks (any amount &amp;gt;=0 is fine)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optimization Process&lt;/strong&gt;: Decision Problem -&amp;gt; Model -&amp;gt; Data Collection -&amp;gt; Model Solution -&amp;gt; Analysis -&amp;gt; Problem solution&lt;/li&gt;
&lt;li&gt;No clear cut recipe&lt;/li&gt;
&lt;li&gt;Lots of feedbacks and iterations&lt;/li&gt;
&lt;li&gt;Approximations and assumptions involved in each stage&lt;/li&gt;
&lt;li&gt;Success requires good understanding of the actual problem (domain knowledge is important)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;classification-of-optimization-problems&#34;&gt;Classification of optimization problems&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The tractability of a large scale optimization problem depends on the structure of the functions that make up the objective and constraints, and the domain restrictions on the variables.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Functions&lt;/th&gt;
&lt;th&gt;Variable domains&lt;/th&gt;
&lt;th&gt;Problem Type&lt;/th&gt;
&lt;th&gt;Difficulty&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;All linear&lt;/td&gt;
&lt;td&gt;Continuous variables&lt;/td&gt;
&lt;td&gt;Linear Program&lt;/td&gt;
&lt;td&gt;Easy&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Some nonlinear&lt;/td&gt;
&lt;td&gt;Continuous variables&lt;/td&gt;
&lt;td&gt;Nonlinear Program or Nonlinear Optimization Problem&lt;/td&gt;
&lt;td&gt;Easy/Difficult&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linear/nonlinear&lt;/td&gt;
&lt;td&gt;Some discrete&lt;/td&gt;
&lt;td&gt;Integer Problem or Discrete Optimization Problem&lt;/td&gt;
&lt;td&gt;Difficult&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Problem&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Difficulty&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Linear Programming&lt;/td&gt;
&lt;td&gt;A linear programming problem involves maximizing or minimizing a linear objective function subject to a set of linear constraints&lt;/td&gt;
&lt;td&gt;Easy to moderate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Nonlinear Programming&lt;/td&gt;
&lt;td&gt;A nonlinear programming problem involves optimizing a function that is not linear, subject to a set of nonlinear constraints&lt;/td&gt;
&lt;td&gt;Moderate to hard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Quadratic Programming&lt;/td&gt;
&lt;td&gt;A quadratic programming problem involves optimizing a quadratic objective function subject to a set of linear constraints&lt;/td&gt;
&lt;td&gt;Moderate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Convex Optimization&lt;/td&gt;
&lt;td&gt;A convex optimization problem involves optimizing a convex function subject to a set of linear or convex constraints&lt;/td&gt;
&lt;td&gt;Easy to moderate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Integer Programming&lt;/td&gt;
&lt;td&gt;An integer programming problem involves optimizing a linear or nonlinear objective function subject to a set of linear or nonlinear constraints, where some or all of the variables are restricted to integer values&lt;/td&gt;
&lt;td&gt;Hard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mixed-integer Programming&lt;/td&gt;
&lt;td&gt;A mixed-integer programming problem is a generalization of integer programming where some or all of the variables can be restricted to integer values or continuous values&lt;/td&gt;
&lt;td&gt;Hard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Global Optimization&lt;/td&gt;
&lt;td&gt;A global optimization problem involves finding the global optimum of a function subject to a set of constraints, which may be nonlinear or non-convex&lt;/td&gt;
&lt;td&gt;Hard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Stochastic Optimization&lt;/td&gt;
&lt;td&gt;A stochastic optimization problem involves optimizing an objective function that depends on random variables, subject to a set of constraints&lt;/td&gt;
&lt;td&gt;Hard&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;subclasses-of-nlp-non-linear-problem&#34;&gt;Subclasses of NLP (Non Linear Problem)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Unconstrained optimization&lt;/strong&gt;: No constraints or simple bound constraints on the variables (Box design example above)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quadratic programming&lt;/strong&gt;: Objectives and constraints involve quadratic functions (Data fitting example above), &lt;strong&gt;subset of NLP&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;subclasses-of-ip-integer-programming&#34;&gt;Subclasses of IP (Integer Programming)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mixed Integer Linear Program&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;All linear functions&lt;/li&gt;
&lt;li&gt;Some variables are continuous and some are discrete&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mixed Integer Nonlinear Program (MINLP)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Some nonlinear functions&lt;/li&gt;
&lt;li&gt;Some variables are continuous and some are discrete&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mixed Integer Quadratic Program (MIQLP)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Nonlinear functions are quadratic&lt;/li&gt;
&lt;li&gt;Some variables are continuous and some are discrete&lt;/li&gt;
&lt;li&gt;subset of MINLP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;why-and-how-to-classify&#34;&gt;Why and how to classify?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Important to recognize the type of an optimization problem:
&lt;ul&gt;
&lt;li&gt;to formulate problems to be amenable to certain solution methods&lt;/li&gt;
&lt;li&gt;to anticipate the difficulty of solving the problem&lt;/li&gt;
&lt;li&gt;to know which solution methods to use&lt;/li&gt;
&lt;li&gt;to design customized solution methods&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;how to classify:
&lt;ul&gt;
&lt;li&gt;check domain restriction on variables&lt;/li&gt;
&lt;li&gt;check the structure of the functions involved&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;taylor-approximation&#34;&gt;Taylor Approximation&lt;/h3&gt;
&lt;p&gt;The Taylor series of a real or complex-valued function fâ€‰(x) that is infinitely differentiable at a real or complex number a is the power series.&lt;/p&gt;
&lt;p&gt;Let $f: \mathbb{R}^n \rightarrow \mathbb{R}$ be a differentiable function and $\mathbf{x}^0 \in \mathbb{R}^n$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First order Taylor&amp;rsquo;s approximation of $f$ at $\mathbf{x}^0$ :
$$
f(\mathbf{x}) \approx f\left(\mathbf{x}^0\right)+\nabla f\left(\mathbf{x}^0\right)^{\top}\left(\mathbf{x}-\mathbf{x}^0\right)
$$&lt;/li&gt;
&lt;li&gt;Second order Taylor&amp;rsquo;s approximation of $f$ at $\mathbf{x}^0$ :
$$
f(\mathbf{x}) \approx f\left(\mathbf{x}^0\right)+\nabla f\left(\mathbf{x}^0\right)^{\top}\left(\mathbf{x}-\mathbf{x}^0\right)+\frac{1}{2}\left(\mathbf{x}-\mathbf{x}^0\right)^{\top} \nabla^2 f\left(\mathbf{x}^0\right)\left(\mathbf{x}-\mathbf{x}^0\right)
$$
`&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sets-in-optimization-problems&#34;&gt;Sets in Optimization Problems&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A set is &lt;strong&gt;closed&lt;/strong&gt; if it includes its boundary points.&lt;/li&gt;
&lt;li&gt;Intersection of closed sets is closed.&lt;/li&gt;
&lt;li&gt;Typically, if none of inequalities are strict, then the set is closed.&lt;/li&gt;
&lt;li&gt;A set is convex if a line segment connecting two points in the set lies entirely in the set.&lt;/li&gt;
&lt;li&gt;A set is bounded if it can be enclosed in a large enough (hyper)-sphere or a box.&lt;/li&gt;
&lt;li&gt;A set that is both bounded and closed is called compact.
&lt;ul&gt;
&lt;li&gt;$R^2$ is closed but not bounded&lt;/li&gt;
&lt;li&gt;$x^2+y^2&amp;lt;1$ is bounded but not closed&lt;/li&gt;
&lt;li&gt;$x+y&amp;gt;=1$ is closed but not bounded&lt;/li&gt;
&lt;li&gt;$x^2+y^2&amp;lt;=1$ is closed and bounded (compact)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An optimal solution of maximizing a convex function over a compact set lies on the boundary
of the set.&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe src=&#34;https://www.desmos.com/calculator/49e59msg7u?embed&#34; width=&#34;100%&#34; height=&#34;500&#34; style=&#34;border: 1px solid #ccc&#34; frameborder=0&gt;&lt;/iframe&gt;
&lt;h3 id=&#34;convex-function&#34;&gt;Convex Function&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/ConvexFunction.svg/1280px-ConvexFunction.svg.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A function $f: \mathbb{R}^n \rightarrow \mathbb{R}$ is convex if
$$
f(\lambda \mathbf{x}+(1-\lambda) \mathbf{y}) \leq \lambda f(\mathbf{x})+(1-\lambda) f(\mathbf{y}) \quad \forall \mathbf{x}, \mathbf{y} \in \mathbb{R}^n \text { and } \lambda \in[0,1]
$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;ldquo;Function value at the average is less than the average of the function values&amp;rdquo;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;This also implies that $a^Tx+b$ is convex (and concave)&lt;/li&gt;
&lt;li&gt;For a convex function the first order Taylor&amp;rsquo;s approximation is a global under estimator&lt;/li&gt;
&lt;li&gt;A convex optimization problem has a convex objective and convex set of solutions.&lt;/li&gt;
&lt;li&gt;Linear programs (LPs) can be seen as a special case of convex optimization problems. In an LP, the objective function and constraints are linear, which means that the feasible region defined by the constraints is a convex set. As a result, the optimal solution to an LP is guaranteed to be at a vertex (corner) of the feasible region, which makes it a convex optimization problem.&lt;/li&gt;
&lt;li&gt;A twice differentiable univariate function is convex if $f^{&amp;rsquo;&amp;rsquo;}(x)&amp;gt;=0$ for all $x \in R$&lt;/li&gt;
&lt;li&gt;To generalize, a twice differentiable function is convex if and only if the Hessian matrix is positive semi definite.&lt;/li&gt;
&lt;li&gt;A positive semi-definite (PSD) matrix is a matrix that is symmetric and has non-negative eigenvalues. In the context of a Hessian matrix, it represents the second-order partial derivatives of a multivariate function and reflects the curvature of the function. If the Hessian is PSD, it indicates that the function is locally convex, meaning that it has a minimum value in the vicinity of that point. On the other hand, if the Hessian is not PSD, the function may have a saddle point or be locally non-convex. The PSD property of a Hessian matrix is important in optimization, as it guarantees the existence of a minimum value for the function.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sylvester&amp;rsquo;s criterion&lt;/strong&gt; is a method for determining if a matrix is positive definite or positive semi-definite. The criterion states that a real symmetric matrix is positive definite if and only if all of its leading principal minors (i.e. determinants of the submatrices formed by taking the first few rows and columns of the matrix) are positive. If all the leading principal minors are non-negative, then the matrix is positive semi-definite.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;first-order-methods&#34;&gt;First Order Methods&lt;/h2&gt;
&lt;h3 id=&#34;gradient-descent&#34;&gt;Gradient descent&lt;/h3&gt;
&lt;p&gt;Gradient descent is an iterative optimization algorithm used to find the minimum of a function, typically used in machine learning and deep learning to update the parameters of a model during training. The basic idea behind gradient descent is to adjust the parameters in the direction of steepest descent (negative gradient) to minimize a cost or loss function. Here&amp;rsquo;s a detailed explanation of gradient descent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Objective Function&lt;/strong&gt; : Gradient descent begins with an objective function (also called a cost or loss function) that you want to minimize. In machine learning, this function typically represents the error between the model&amp;rsquo;s predictions and the actual data.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let&amp;rsquo;s denote the objective function as $J(Î¸)$, where $Î¸$ represents a vector of parameters that we want to optimize.&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Initialization&lt;/strong&gt; : You start by initializing the parameter vector Î¸ with some arbitrary values or often with random values. This is the starting point of the optimization process.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Gradient Calculation&lt;/strong&gt; : Calculate the gradient of the objective function with respect to the parameters. The gradient is a vector that points in the direction of the steepest increase in the function. Mathematically, the gradient is represented as:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$(\nabla J(\theta) = \left[\frac{\partial J(\theta)}{\partial \theta_1}, \frac{\partial J(\theta)}{\partial \theta_2}, \ldots, \frac{\partial J(\theta)}{\partial \theta_n}\right])
$&lt;/p&gt;
&lt;p&gt;Here, $âˆ‚J(Î¸)/âˆ‚Î¸_i$ represents the partial derivative of $J(Î¸)$ with respect to the i-th parameter $Î¸_i$.&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Update Parameters&lt;/strong&gt; : Update the parameters Î¸ using the gradient. The update rule is as follows:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$Î¸_{new} = Î¸_{old} - Î± * âˆ‡J(Î¸_{old})$&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Î¸_{new}$ is the updated parameter vector.&lt;/li&gt;
&lt;li&gt;$Î¸_{old}$ is the current parameter vector.&lt;/li&gt;
&lt;li&gt;$Î±$ (alpha) is the learning rate, a hyperparameter that controls the step size or how much to move in the direction of the gradient. It&amp;rsquo;s a small positive value typically chosen in advance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This step is performed iteratively until a stopping criterion is met.&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Stopping Criterion&lt;/strong&gt; : The algorithm continues to update the parameters and compute the gradient until a stopping criterion is satisfied. Common stopping criteria include a maximum number of iterations, a minimum change in the objective function, or when the gradient becomes close to zero.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Convergence&lt;/strong&gt; : Gradient descent converges when it reaches a local or global minimum of the objective function, or when it satisfies the stopping criterion. The choice of learning rate (Î±) and the convergence behavior are important aspects to consider when using gradient descent.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There are variations of gradient descent, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Batch Gradient Descent&lt;/strong&gt; : In each iteration, it computes the gradient using the entire dataset. This can be computationally expensive for large datasets.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stochastic Gradient Descent (SGD)&lt;/strong&gt; : In each iteration, it computes the gradient using only one random data point from the dataset. It&amp;rsquo;s faster but has more noise in its updates.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mini-batch Gradient Descent&lt;/strong&gt; : It uses a small random subset (mini-batch) of the dataset in each iteration, striking a balance between the computational efficiency of SGD and the stability of batch gradient descent.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Momentum, Adagrad, RMSprop, and Adam&lt;/strong&gt; : These are advanced optimization techniques that incorporate additional mechanisms to improve convergence speed and stability.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The choice of the specific gradient descent variant and its hyperparameters depends on the problem at hand, the dataset, and computational resources. Proper tuning of the learning rate and monitoring convergence is crucial for successful optimization.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gradient_descent&lt;/span&gt;(obj_func, gradient_func, initial_theta, learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;, max_iterations&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, tolerance&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-5&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; initial_theta
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; iteration &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(max_iterations):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        gradient &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gradient_func(theta)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; theta &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; learning_rate &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; gradient
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Calculate the magnitude of the gradient for convergence check&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        gradient_magnitude &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(gradient)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; gradient_magnitude &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; tolerance:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Converged after &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;iteration&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; iterations.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;break&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; theta
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;objective_function&lt;/span&gt;(theta):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; theta[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; theta[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gradient_function&lt;/span&gt;(theta):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; theta[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; theta[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Initial parameters&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;initial_theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;3.0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4.0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Call gradient descent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;final_theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gradient_descent(objective_function, gradient_function, initial_theta)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Optimal parameters:&amp;#34;&lt;/span&gt;, final_theta)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Minimum value of the objective function:&amp;#34;&lt;/span&gt;, objective_function(final_theta))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;accelerated-gradient-descent&#34;&gt;Accelerated Gradient Descent&lt;/h3&gt;
&lt;p&gt;Accelerated Gradient Descent, also known as Nesterov Accelerated Gradient (NAG) or simply Nesterov momentum, is an optimization algorithm that improves upon the standard gradient descent by adding momentum to the updates. This momentum helps the algorithm converge faster and provides better stability, especially in the presence of noisy gradients. Here&amp;rsquo;s how it works:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Initialization&lt;/strong&gt; : Initialize the parameter vector Î¸ with some arbitrary values, and initialize the momentum vector &lt;code&gt;v&lt;/code&gt; to zero.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update Momentum (v)&lt;/strong&gt; : In each iteration, before computing the gradient, update the momentum vector &lt;code&gt;v&lt;/code&gt; using the previous momentum and the gradient from the previous iteration. This is the key difference between NAG and traditional momentum.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$v_t = Î³ * v_{t-1} + Î± * âˆ‡J(Î¸_{t-1} - Î³ * v_{t-1})$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Î³$ is the momentum coefficient (typically a value close to 0.9).&lt;/li&gt;
&lt;li&gt;$Î±$ is the learning rate.&lt;/li&gt;
&lt;li&gt;$âˆ‡J(Î¸_{t-1} - Î³ * v_{t-1})$ is the gradient of the loss function evaluated at the updated position using the momentum.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Update Parameters (Î¸)&lt;/strong&gt; : Update the parameters Î¸ using the momentum &lt;code&gt;v&lt;/code&gt; computed in the previous step.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$Î¸_t = Î¸_{t-1} - v_t$&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Repeat&lt;/strong&gt; : Repeat steps 2 and 3 until a stopping criterion is met, such as a maximum number of iterations or a small gradient magnitude.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The key insight in Nesterov Accelerated Gradient Descent is that it calculates the gradient at a &amp;ldquo;lookahead&amp;rdquo; position by subtracting the previous momentum-scaled update from the current parameters before computing the gradient. This lookahead helps in achieving smoother convergence by reducing oscillations.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a Python implementation of Nesterov Accelerated Gradient Descent:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;nesterov_accelerated_gradient_descent&lt;/span&gt;(obj_func, gradient_func, initial_theta, learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;, momentum&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;, max_iterations&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, tolerance&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-5&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; initial_theta
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    v &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(initial_theta)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; iteration &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(max_iterations):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        gradient &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gradient_func(theta &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; momentum &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; v)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        v &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; momentum &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; v &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; learning_rate &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; gradient
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; theta &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; v
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Calculate the magnitude of the gradient for convergence check&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        gradient_magnitude &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(gradient)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; gradient_magnitude &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; tolerance:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Converged after &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;iteration&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; iterations.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;break&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; theta
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Example usage:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Define your objective function and gradient function&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;objective_function&lt;/span&gt;(theta):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; theta[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; theta[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gradient_function&lt;/span&gt;(theta):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; theta[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; theta[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Initial parameters&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;initial_theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;3.0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4.0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Call Nesterov Accelerated Gradient Descent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;final_theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nesterov_accelerated_gradient_descent(objective_function, gradient_function, initial_theta)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Optimal parameters:&amp;#34;&lt;/span&gt;, final_theta)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Minimum value of the objective function:&amp;#34;&lt;/span&gt;, objective_function(final_theta))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this implementation, &lt;code&gt;momentum&lt;/code&gt; is the momentum coefficient (typically close to 0.9), and &lt;code&gt;learning_rate&lt;/code&gt; is the step size. The rest of the algorithm follows the Nesterov Accelerated Gradient Descent procedure described earlier.&lt;/p&gt;
&lt;h3 id=&#34;stochastic-gradient-descent-sgd&#34;&gt;Stochastic Gradient Descent (SGD)&lt;/h3&gt;
&lt;p&gt;Stochastic Gradient Descent (SGD) is an optimization algorithm used for training machine learning models, particularly in cases where you have a large dataset. Unlike traditional gradient descent, which computes the gradient of the cost function using the entire dataset in each iteration, SGD updates the model&amp;rsquo;s parameters by considering only a single randomly chosen data point (or a small batch of data points) in each iteration. This makes it much faster and enables it to handle large datasets.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s how Stochastic Gradient Descent works:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Initialization&lt;/strong&gt; : Start with an initial guess for the model&amp;rsquo;s parameters, often set to small random values.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shuffling&lt;/strong&gt; : Shuffle the training dataset randomly. This step ensures that the data points are processed in a random order in each epoch (a complete pass through the dataset).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Iterative Update&lt;/strong&gt; : For each iteration:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Select a random data point (or a small mini-batch) from the shuffled dataset.&lt;/li&gt;
&lt;li&gt;Compute the gradient of the loss function with respect to the model&amp;rsquo;s parameters using only the selected data point (or mini-batch).&lt;/li&gt;
&lt;li&gt;Update the model&amp;rsquo;s parameters in the opposite direction of the gradient:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$Î¸ = Î¸ - learningrate * gradient$&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Î¸&lt;/code&gt; represents the model&amp;rsquo;s parameters.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;learningrate&lt;/code&gt; is a positive scalar called the learning rate, which controls the step size in the parameter update.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gradient&lt;/code&gt; is the gradient of the loss function with respect to the parameters computed using the selected data point (or mini-batch).&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Repeat&lt;/strong&gt; : Continue this process for a fixed number of iterations (epochs) or until a stopping criterion is met.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;SGD has several advantages, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Efficiency: It&amp;rsquo;s computationally efficient because it uses only one or a few data points at a time, making it suitable for large datasets.&lt;/li&gt;
&lt;li&gt;Regularization: The inherent randomness in SGD acts as a form of regularization, which can help prevent overfitting.&lt;/li&gt;
&lt;li&gt;Escape Local Minima: The noise introduced by using individual data points can help the algorithm escape local minima in the loss landscape.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, SGD can have high variance in its parameter updates because of the noisy gradient estimates, which can lead to oscillations and slow convergence. To address this, variations of SGD have been developed, including Mini-batch Gradient Descent, which uses small random mini-batches of data, and techniques like learning rate schedules and momentum to stabilize and accelerate convergence.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a simple Python implementation of Stochastic Gradient Descent:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;stochastic_gradient_descent&lt;/span&gt;(obj_func, gradient_func, initial_theta, learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;, max_epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, tolerance&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-5&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; initial_theta
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    num_examples &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(obj_func)  &lt;span style=&#34;color:#75715e&#34;&gt;# Number of data points&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(max_epochs):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Shuffle the data for each epoch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        shuffled_indices &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;permutation(num_examples)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; shuffled_indices:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            gradient &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gradient_func(theta, i)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; theta &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; learning_rate &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; gradient
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#75715e&#34;&gt;# Calculate the magnitude of the gradient for convergence check&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            gradient_magnitude &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(gradient)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; gradient_magnitude &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; tolerance:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Converged after &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;epoch&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; epochs.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; theta
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Did not converge.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; theta
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Initial parameters&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;initial_theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;3.0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4.0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Call Stochastic Gradient Descent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;final_theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stochastic_gradient_descent(obj_func, gradient_func, initial_theta)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Optimal parameters:&amp;#34;&lt;/span&gt;, final_theta)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Minimum value of the objective function:&amp;#34;&lt;/span&gt;, obj_func(final_theta))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this implementation, &lt;code&gt;obj_func&lt;/code&gt; represents the objective function you want to minimize, and &lt;code&gt;gradient_func&lt;/code&gt; computes the gradient of the loss function with respect to the model&amp;rsquo;s parameters for a specific data point &lt;code&gt;i&lt;/code&gt;. The rest of the algorithm follows the SGD procedure described earlier.&lt;/p&gt;
&lt;h2 id=&#34;second-order-methods&#34;&gt;Second order Methods&lt;/h2&gt;
&lt;h3 id=&#34;newton-method&#34;&gt;Newton method&lt;/h3&gt;
&lt;p&gt;Newton-Raphson method, often referred to as the Newton method, is an iterative numerical technique used to find the approximate roots (or solutions) of real-valued functions. It is particularly effective for finding the roots of nonlinear equations, optimizing functions, and solving systems of nonlinear equations. The method is named after Sir Isaac Newton and Joseph Raphson, who contributed to its development.&lt;/p&gt;
&lt;p&gt;The basic idea behind the Newton method is to iteratively refine an initial guess for the root by approximating the function with a linear equation (a tangent line) near the current guess. Mathematically, the algorithm can be summarized as follows:&lt;/p&gt;
&lt;p&gt;Given a function $f(x)$ and an initial guess $x_0$â€‹, repeat the following steps until a convergence criterion is met:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Compute the value of the function $f(x_n)$ and its derivative $fâ€²(x_n)$ at the current guess $x_n$â€‹.&lt;/li&gt;
&lt;li&gt;Update the guess for the root using the formula:
$(x_{n+1} = x_{n} - \frac{f&amp;rsquo;(x_{n})}{f(x_{n})})$&lt;/li&gt;
&lt;li&gt;Repeat steps 1 and 2 until $âˆ£f(xn+1)âˆ£$ is sufficiently close to zero or until a maximum number of iterations is reached.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The method converges rapidly if the initial guess is reasonably close to the actual root and if the function is well-behaved (continuous and with a well-defined derivative).&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a Python implementation of the Newton method to find the root of a single-variable function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newton_method&lt;/span&gt;(f, df, x0, tol&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-6&lt;/span&gt;, max_iter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; iteration &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(max_iter):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        fx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; f(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        dfx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Check for small derivatives to avoid division by zero&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; abs(dfx) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-6&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;raise&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ValueError&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Derivative is too small.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x_new &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; fx &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; dfx
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; abs(x_new &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; x) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; tol:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Converged after &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;iteration&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; iterations.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x_new
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x_new
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Did not converge.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Example usage:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Define your function f(x) and its derivative df(x)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt;(x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;df&lt;/span&gt;(x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Initial guess&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Call Newton&amp;#39;s method&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newton_method(f, df, x0)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Approximate root:&amp;#34;&lt;/span&gt;, root)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this example, &lt;code&gt;f(x)&lt;/code&gt; represents the function you want to find the root of, and &lt;code&gt;df(x)&lt;/code&gt; is its derivative. The algorithm iteratively refines the estimate of the root (&lt;code&gt;x&lt;/code&gt;) until it converges within a specified tolerance (&lt;code&gt;tol&lt;/code&gt;) or until a maximum number of iterations (&lt;code&gt;max_iter&lt;/code&gt;) is reached.&lt;/p&gt;
&lt;h3 id=&#34;gauss-newton-method&#34;&gt;Gauss-Newton method&lt;/h3&gt;
&lt;p&gt;Gauss-Newton method iteratively updates the parameter vector ppp to minimize the objective function. In each iteration, it approximates the objective function using a linearization around the current estimate of ppp, which is why it&amp;rsquo;s often considered an extension of the Newton-Raphson method for nonlinear optimization.&lt;/p&gt;
&lt;p&gt;Here are the main steps of the Gauss-Newton method:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Initialization&lt;/strong&gt; : Start with an initial guess for the parameter vector ppp.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Iterative Update&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;For each iteration:
&lt;ul&gt;
&lt;li&gt;Calculate the Jacobian matrix $J(p)$, which contains the partial derivatives of the model predictions $f_i(p)$ with respect to each parameter.&lt;/li&gt;
&lt;li&gt;Calculate the residual vector $r(p)$, which is the difference between the observed data $y_i$ and the model predictions $f_i(p)$ for all data points.&lt;/li&gt;
&lt;li&gt;Update the parameter vector $p$ using the following formula:
$p_{\text{new}} = p_{\text{old}} + \Delta p$
where
$\Delta p = (J^T J)^{-1} J^T r$
$J^T$ is the transpose of the Jacobian matrix, and $(J^T J)^{-1}$ is the pseudoinverse of the Jacobian matrix.&lt;/li&gt;
&lt;li&gt;Repeat the iterative update until a convergence criterion is met, such as small changes in the parameter estimates or a maximum number of iterations.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Convergence&lt;/strong&gt;: The algorithm converges when the parameter estimates $p$ stabilize or when a predefined stopping criterion is satisfied.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here&amp;rsquo;s a Python example demonstrating the Gauss-Newton method for nonlinear regression:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.optimize &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; least_squares
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Define the model function and its Jacobian&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt;(p, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; p[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;p[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; x)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;jacobian&lt;/span&gt;(p, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vstack((&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;p[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; x), x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;p[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; x)))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Generate synthetic data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;seed(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linspace(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;true_params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;2.0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(true_params, x_data) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(len(x_data))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Define the objective function (residuals)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;objective&lt;/span&gt;(p):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; y_data &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; model(p, x_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Initial guess for parameters&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;initial_guess &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Use SciPy&amp;#39;s least_squares function to perform Gauss-Newton optimization&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; least_squares(objective, initial_guess, jac&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;jacobian, method&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lm&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Extract the estimated parameters&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;estimated_params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; result&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;True parameters:&amp;#34;&lt;/span&gt;, true_params)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Estimated parameters:&amp;#34;&lt;/span&gt;, estimated_params)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this example, we define a simple exponential model and generate synthetic data with added noise. Then, we use SciPy&amp;rsquo;s &lt;code&gt;least_squares&lt;/code&gt; function to perform the Gauss-Newton optimization to estimate the parameters of the model. The estimated parameters are compared to the true parameters to assess the quality of the fit.&lt;/p&gt;
&lt;h3 id=&#34;quasi-newton-methods&#34;&gt;Quasi-Newton methods&lt;/h3&gt;
&lt;p&gt;Quasi-Newton methods are a class of optimization algorithms used for finding the minimum of a scalar function of several variables. These methods belong to the broader category of gradient-based optimization techniques and are particularly useful when it&amp;rsquo;s computationally expensive to compute the exact Hessian matrix (the matrix of second derivatives) of the objective function. Instead of calculating the Hessian directly, quasi-Newton methods approximate it using updates based on gradient information, making them more efficient for many practical optimization problems.&lt;/p&gt;
&lt;p&gt;The most well-known quasi-Newton method is the Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno (BFGS) algorithm, but there are other variants like the Limited-memory BFGS (L-BFGS) that are suitable for large-scale problems. Here&amp;rsquo;s an overview of how quasi-Newton methods work:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Initialization&lt;/strong&gt; : Start with an initial guess for the parameters (variables) you want to optimize.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Initialization of the Approximate Hessian&lt;/strong&gt; : Initialize an approximation of the Hessian matrix. In BFGS, for example, this is usually done with the identity matrix or a scaled version of it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Iterative Update&lt;/strong&gt; : Quasi-Newton methods iteratively update the parameter vector and the approximation of the Hessian matrix until convergence is achieved. The main steps in each iteration are as follows:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Calculate the Gradient&lt;/strong&gt; : Compute the gradient of the objective function with respect to the parameters at the current parameter values.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Solve the Quasi-Newton Equation&lt;/strong&gt; : Quasi-Newton methods update the approximation of the Hessian matrix using information from the gradient and parameter changes. The update formula depends on the specific quasi-Newton method (e.g., BFGS or L-BFGS). The objective is to construct an approximation of the Hessian that preserves important curvature information of the objective function.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update Parameters&lt;/strong&gt; : Update the parameter vector using the approximate Hessian matrix. This update step usually involves solving a linear system of equations that is determined by the approximation of the Hessian.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Convergence Check&lt;/strong&gt; : Check for convergence criteria, such as the magnitude of the gradient, small changes in the parameters, or a predefined number of iterations.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Convergence&lt;/strong&gt; : The optimization process terminates when one or more convergence criteria are met.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Quasi-Newton methods are efficient and widely used because they can handle large-scale optimization problems without explicitly computing and storing the full Hessian matrix, which can be computationally expensive and memory-intensive. Instead, they maintain an approximation of the Hessian using a limited amount of memory.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s an example of how to use the L-BFGS-B variant of the L-BFGS quasi-Newton method in Python using SciPy&amp;rsquo;s optimization module:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.optimize &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; minimize
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Define the objective function to minimize&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;objective_function&lt;/span&gt;(x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (x[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Initial guess for the parameters&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;initial_guess &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Use L-BFGS-B for optimization&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; minimize(objective_function, initial_guess, method&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;L-BFGS-B&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Extract the optimized parameters&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;optimized_parameters &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; result&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Optimized parameters:&amp;#34;&lt;/span&gt;, optimized_parameters)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Minimum value of the objective function:&amp;#34;&lt;/span&gt;, result&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fun)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this example, we define a simple quadratic objective function to minimize, and we use the &lt;code&gt;minimize&lt;/code&gt; function from SciPy&amp;rsquo;s optimization module with the L-BFGS-B method to find the minimum. The &lt;code&gt;result&lt;/code&gt; object contains the optimized parameters and the minimum value of the objective function.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deterministic Optimization</title>
      <link>https://ayushsubedi.github.io/posts/deterministic_optimization/</link>
      <pubDate>Tue, 02 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/deterministic_optimization/</guid>
      <description>&lt;h1 id=&#34;general-overview-and-key-concepts&#34;&gt;General overview and key concepts&lt;/h1&gt;
&lt;iframe width=&#34;100%&#34; height=&#34;480&#34; src=&#34;https://www.youtube.com/embed/ijD2KSXWDyo&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;In plain English, &lt;strong&gt;optimization&lt;/strong&gt; is the action of making the best or most effective use of a situation or resource. Optimization problems are of great practical interest. For example, in manufacturing, how should one cut plates of a material so that the waste is minimized? In business, how should a company allocate the available resources that its profit is maximized? Some of the first optimization problems have been solved in ancient Greece and are regarded among the most significant discoveries of that time. In the first century A.D., the Alexandrian mathematician Heron solved the problem of finding the shortest path between two points by way of the mirror.&lt;/p&gt;
&lt;p&gt;This result, also known as Heronâ€™s theorem of the light ray, can be viewed as the origin of the theory of geometrical optics. The problem of finding extreme values gained special importance in the seventeenth century, when it served as one of the motivations in the invention of differential calculus, which is the foundation of the modern theory of mathematical optimization.&lt;/p&gt;
&lt;h2 id=&#34;generic-form-of-optimization-problem&#34;&gt;Generic form of optimization problem:&lt;/h2&gt;
&lt;p&gt;$min$ $f(x)$ $s.t.$ $x \in X $&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The vector $x = (x_1, . . . , x_n)$ is the optimization variable (or decision variable) of the problem&lt;/li&gt;
&lt;li&gt;The function $f$ is the objective function&lt;/li&gt;
&lt;li&gt;A vector $x$ is called optimal, or a solution (not optimal solution) of the problem, if it has the smallest objective value among all vectors that satisfy the constraints&lt;/li&gt;
&lt;li&gt;$X$ is the set of inequality constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mathematical-ingredients&#34;&gt;Mathematical ingredients:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Encode decisions/actions as &lt;strong&gt;decision variables&lt;/strong&gt; whose values we are seeking&lt;/li&gt;
&lt;li&gt;Identify the relevant &lt;strong&gt;problem data&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Express &lt;strong&gt;constraints&lt;/strong&gt; on the values of the decision variables as mathematical relationships (inequalities) between the variables and problem data&lt;/li&gt;
&lt;li&gt;Express the &lt;strong&gt;objective function&lt;/strong&gt; as a function of the decision variables and the problem data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Minimize or Maximize an objective function of decision variable subject to constraints on the values of the decision variables.&lt;/strong&gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;min or max f(x1, x2, .... , xn)
subject to gi(x1, x2, ...., ) &amp;lt;= bi     i = 1,....,m 
        xj is continuous or discrete    j = 1,....,n
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;the-problem-setting&#34;&gt;The problem setting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Finite number of decision variables&lt;/li&gt;
&lt;li&gt;A single objective function of decision variables and problem data
&lt;ul&gt;
&lt;li&gt;Multiple objective functions are handled by either taking a weighted combination of them or by optimizing one of the objectives while ensuring the other objectives meet target requirements.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The constraints are defined by a finite number of inequalities or equalities involving functions of the decision variables and problem data&lt;/li&gt;
&lt;li&gt;There may be domain restrictions (continuous or discrete) on some of the variables&lt;/li&gt;
&lt;li&gt;The functions defining the objective and constraints are algebraic (typically with rational coefficients)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;minimization-vs-maximization&#34;&gt;Minimization vs Maximization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Without the loss of generality, it is sufficient to consider a minimization objective since maximization of objective function is minimization of the negation of the objective function&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;program-vs-optimization&#34;&gt;Program vs Optimization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A program or mathematical program is an optimization problem with a finite number of variables and constraints written out using explicit mathematical (algebraic) expressions&lt;/li&gt;
&lt;li&gt;The word program means plan/planning&lt;/li&gt;
&lt;li&gt;Early application of optimization arose in planning resource allocations and gave rise to programming to mean optimization (predates computer programming)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;example-designing-a-box&#34;&gt;Example: Designing a box:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Given a $1$ feet by $1$ feet piece of cardboard, cut out corners and fold to make a box of maximum volume:&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;Decision:&lt;/strong&gt; $x$ = how much to cut from each of the corners?&lt;br/&gt;
&lt;strong&gt;Alternatives:&lt;/strong&gt; $0&amp;lt;=x&amp;lt;=1/2$&lt;br/&gt;
&lt;strong&gt;Best:&lt;/strong&gt; Maximize volume: $V(x) = x(1-2x)^2$ ($x$ is the height and $(1-2x)^2$ is the base, and their product is the volume)&lt;br/&gt;
&lt;strong&gt;Optimization formulation:&lt;/strong&gt; $max$ $x(1-2x)^2$ subject to $0&amp;lt;=x&amp;lt;=1/2$ (which are the constraints in this case)&lt;br/&gt;&lt;/p&gt;
&lt;iframe src=&#34;https://www.desmos.com/calculator/ily45jyfsv?embed&#34; width=&#34;100%&#34; height=&#34;500&#34; style=&#34;border: 1px solid #ccc&#34; frameborder=0&gt;&lt;/iframe&gt;
&lt;p&gt;This is an unconstrained optimization problem since the constraint is a simple bound based.&lt;/p&gt;
&lt;h3 id=&#34;example-data-fitting&#34;&gt;Example: Data Fitting:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Given $N$ data points $(y_1, x_1)&amp;hellip;(y_N, x_N)$ where $y_i$ belongs to $\mathbb{R}$ and $x_i$ belongs to $\mathbb{R}^n$, for all $i = 1..N$, find a line $y = a^Tx+b$ that best fits the data.&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;Decision&lt;/strong&gt;: A vector $a$ that belongs to $\mathbb{R}^n$ and a scalar $b$ that belongs to $\mathbb{R}$&lt;br/&gt;
&lt;strong&gt;Alternatives&lt;/strong&gt;: All $n$-dimensional vectors and scalars&lt;br/&gt;
&lt;strong&gt;Best&lt;/strong&gt;: Minimize the sum of squared errors&lt;br/&gt;
&lt;strong&gt;Optimization formulation&lt;/strong&gt;:
$\begin{array}{ll}\min &amp;amp; \sum_{i=1}^N\left(y_i-a^{\top} x_i-b\right)^2 \ \text { s.t. } &amp;amp; a \in \mathbb{R}^n, b \in \mathbb{R}\end{array}$&lt;/p&gt;
&lt;p&gt;This is also an unconstrained optimization problem.&lt;/p&gt;
&lt;h3 id=&#34;example-product-mix&#34;&gt;Example: Product Mix:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A firm make $n$ different products using $m$ types of resources. Each unit of product $i$ generates $p_i$ dollars of profit, and requires $r_{ij}$ units of resource $j$. The firm has $u_j$ units of resource $j$ available. How much of each product should the firm make to maximize profits?&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;Decision&lt;/strong&gt;: how much of each product to make&lt;br/&gt;
&lt;strong&gt;Alternatives&lt;/strong&gt;: defined by the resource limits&lt;br/&gt;
&lt;strong&gt;Best&lt;/strong&gt;: Maximize profits&lt;br/&gt;
&lt;strong&gt;Optimization formulation:&lt;/strong&gt; &lt;br/&gt;
Sum notation: $\begin{array}{lll}\max &amp;amp; \sum_{i=1}^n p_i x_i \ \text { s.t. } &amp;amp; \sum_{i=1}^n r_{i j} x_i \leq u_j &amp;amp; \forall j=1, \ldots, m \ &amp;amp; x_i \geq 0 &amp;amp; \forall i=1, \ldots, n\end{array}$ &lt;br/&gt;
Matrix notation: $\begin{array}{cl}\max &amp;amp; p^{\top} x \ \text { s.t. } &amp;amp; R x \leq u \ &amp;amp; x \geq 0\end{array}$&lt;/p&gt;
&lt;h3 id=&#34;example-project-investment&#34;&gt;Example: Project investment&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt; A firm is considering investing in $n$ different R&amp;amp;D projects. Project $j$ requires an investment of $c_j$ dollars and promises a return of $r_j$ dollars. The firm has a budget of $B$ dollars. Which projects should the firm invest in?&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;Decision&lt;/strong&gt;: Whether or not to invest in project&lt;br/&gt;
&lt;strong&gt;Alternatives&lt;/strong&gt;: Defined by budget&lt;br/&gt;
&lt;strong&gt;Best&lt;/strong&gt;: Maximize return on investment&lt;br/&gt;
Sum notation: $\begin{aligned} \max &amp;amp; \sum_{j=1}^n r_j x_j \ \text { s.t. } &amp;amp; \sum_{j=1}^n c_j x_j \leq B \ &amp;amp; x_j \in{0,1} \forall j=1, \ldots, n\end{aligned}$ &lt;br/&gt;
Matrix notation: $\begin{aligned} \max  &amp;amp; r^{\top} x \ \text { s.t. } &amp;amp; c^{\top} x \leq B \ &amp;amp; x \in{0,1}^n\end{aligned}$&lt;/p&gt;
&lt;p&gt;This is not an unconstrained problem.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify basic portfolio optimization and associated issues&lt;/li&gt;
&lt;li&gt;Examine the Markowitz Portfolio Optimization approach
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Markowitz Principle&lt;/strong&gt;: Select a portfolio that attempts to maximize the expected return and minimize the variance of returns (risk)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For multi objective problem (like defined by the Markowitz Principle), two objectives can be combined:
&lt;ul&gt;
&lt;li&gt;Maximize Expected Return - $\lambda$*risk&lt;/li&gt;
&lt;li&gt;Maximize Expected Return subject to risk &amp;lt;= s_max (constraint on risk)&lt;/li&gt;
&lt;li&gt;Minimize Risk subject to return &amp;gt;= r_min (threshold on expected returns)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Optimization Problem Statement&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Given $1000, how much should we invest in each of the three stocks MSFT, V and WMT so as to :
- have a one month expected return of at least a given threshold
- minimize the risk(variance) of the portfolio return
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Decision&lt;/strong&gt;: investment in each stock&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;alternatives&lt;/strong&gt;: any investment that meets the budget and the minimum expected return requirement&lt;/li&gt;
&lt;li&gt;best: minimize variance&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key trade-off&lt;/strong&gt;: How much of the detail of the actual problem to consider while maintaining computational tractability of the mathematical model?&lt;/li&gt;
&lt;li&gt;Requires making simplifying assumptions, either because some of the problem characteristics are not well-defined mathematically, or because we wish to develop a model that can actually be solved&lt;/li&gt;
&lt;li&gt;Need to exercise great caution in these assumptions and not loose sight of the true underlying problem&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Assumptions&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;No transaction cost&lt;/li&gt;
&lt;li&gt;Stocks does not need to be bought in blocks (any amount &amp;gt;=0 is fine)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optimization Process&lt;/strong&gt;: Decision Problem -&amp;gt; Model -&amp;gt; Data Collection -&amp;gt; Model Solution -&amp;gt; Analysis -&amp;gt; Problem solution&lt;/li&gt;
&lt;li&gt;No clear cut recipe&lt;/li&gt;
&lt;li&gt;Lots of feedbacks and iterations&lt;/li&gt;
&lt;li&gt;Approximations and assumptions involved in each stage&lt;/li&gt;
&lt;li&gt;Success requires good understanding of the actual problem (domain knowledge is important)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;classification-of-optimization-problems&#34;&gt;Classification of optimization problems&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The tractability of a large scale optimization problem depends on the structure of the functions that make up the objective and constraints, and the domain restrictions on the variables.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Functions&lt;/th&gt;
&lt;th&gt;Variable domains&lt;/th&gt;
&lt;th&gt;Problem Type&lt;/th&gt;
&lt;th&gt;Difficulty&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;All linear&lt;/td&gt;
&lt;td&gt;Continuous variables&lt;/td&gt;
&lt;td&gt;Linear Program&lt;/td&gt;
&lt;td&gt;Easy&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Some nonlinear&lt;/td&gt;
&lt;td&gt;Continuous variables&lt;/td&gt;
&lt;td&gt;Nonlinear Program or Nonlinear Optimization Problem&lt;/td&gt;
&lt;td&gt;Easy/Difficult&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linear/nonlinear&lt;/td&gt;
&lt;td&gt;Some discrete&lt;/td&gt;
&lt;td&gt;Integer Problem or Discrete Optimization Problem&lt;/td&gt;
&lt;td&gt;Difficult&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Problem&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Difficulty&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Linear Programming&lt;/td&gt;
&lt;td&gt;A linear programming problem involves maximizing or minimizing a linear objective function subject to a set of linear constraints&lt;/td&gt;
&lt;td&gt;Easy to moderate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Nonlinear Programming&lt;/td&gt;
&lt;td&gt;A nonlinear programming problem involves optimizing a function that is not linear, subject to a set of nonlinear constraints&lt;/td&gt;
&lt;td&gt;Moderate to hard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Quadratic Programming&lt;/td&gt;
&lt;td&gt;A quadratic programming problem involves optimizing a quadratic objective function subject to a set of linear constraints&lt;/td&gt;
&lt;td&gt;Moderate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Convex Optimization&lt;/td&gt;
&lt;td&gt;A convex optimization problem involves optimizing a convex function subject to a set of linear or convex constraints&lt;/td&gt;
&lt;td&gt;Easy to moderate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Integer Programming&lt;/td&gt;
&lt;td&gt;An integer programming problem involves optimizing a linear or nonlinear objective function subject to a set of linear or nonlinear constraints, where some or all of the variables are restricted to integer values&lt;/td&gt;
&lt;td&gt;Hard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mixed-integer Programming&lt;/td&gt;
&lt;td&gt;A mixed-integer programming problem is a generalization of integer programming where some or all of the variables can be restricted to integer values or continuous values&lt;/td&gt;
&lt;td&gt;Hard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Global Optimization&lt;/td&gt;
&lt;td&gt;A global optimization problem involves finding the global optimum of a function subject to a set of constraints, which may be nonlinear or non-convex&lt;/td&gt;
&lt;td&gt;Hard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Stochastic Optimization&lt;/td&gt;
&lt;td&gt;A stochastic optimization problem involves optimizing an objective function that depends on random variables, subject to a set of constraints&lt;/td&gt;
&lt;td&gt;Hard&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;subclasses-of-nlp-non-linear-problem&#34;&gt;Subclasses of NLP (Non Linear Problem)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Unconstrained optimization&lt;/strong&gt;: No constraints or simple bound constraints on the variables (Box design example above)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quadratic programming&lt;/strong&gt;: Objectives and constraints involve quadratic functions (Data fitting example above), &lt;strong&gt;subset of NLP&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;subclasses-of-ip-integer-programming&#34;&gt;Subclasses of IP (Integer Programming)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mixed Integer Linear Program&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;All linear functions&lt;/li&gt;
&lt;li&gt;Some variables are continuous and some are discrete&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mixed Integer Nonlinear Program (MINLP)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Some nonlinear functions&lt;/li&gt;
&lt;li&gt;Some variables are continuous and some are discrete&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mixed Integer Quadratic Program (MIQLP)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Nonlinear functions are quadratic&lt;/li&gt;
&lt;li&gt;Some variables are continuous and some are discrete&lt;/li&gt;
&lt;li&gt;subset of MINLP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;why-and-how-to-classify&#34;&gt;Why and how to classify?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Important to recognize the type of an optimization problem:
&lt;ul&gt;
&lt;li&gt;to formulate problems to be amenable to certain solution methods&lt;/li&gt;
&lt;li&gt;to anticipate the difficulty of solving the problem&lt;/li&gt;
&lt;li&gt;to know which solution methods to use&lt;/li&gt;
&lt;li&gt;to design customized solution methods&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;how to classify:
&lt;ul&gt;
&lt;li&gt;check domain restriction on variables&lt;/li&gt;
&lt;li&gt;check the structure of the functions involved&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;linear-algebra-primer&#34;&gt;Linear Algebra Primer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Vectors&lt;/strong&gt;: Vectors are mathematical objects that have both magnitude and direction. They can be represented as ordered lists of numbers or as arrows in space.  Vectors are often used to represent physical quantities such as velocity or force. In two-dimensional space, a vector is represented by an ordered pair of numbers (x, y), and in three-dimensional space, it is represented by an ordered triple (x, y, z). Vectors can be added and subtracted, and multiplied by a scalar (a single number). They also have properties such as the dot product and cross product. In computer science and programming, a vector is also a data structure that can store multiple values of the same type.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Matrices&lt;/strong&gt;: Matrices are rectangular arrays of numbers that can be used to represent linear transformations and systems of linear equations. They are also used to represent data in statistics and machine learning.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linear equations&lt;/strong&gt;: Linear equations are equations that involve only linear terms, such as x and y, rather than more complex functions like sin(x) or e^x. They can be represented using matrices and solved using techniques like Gaussian elimination.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eigenvectors and eigenvalues&lt;/strong&gt;: Eigenvectors are special vectors that are unchanged by a linear transformation, except for a scaling factor. Eigenvalues are the corresponding scaling factors. They are useful in many applications, such as analyzing networks and modeling physical systems.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vector spaces&lt;/strong&gt;: Vector spaces are sets of vectors that satisfy certain properties, such as closure under addition and scalar multiplication. They are used to represent many mathematical objects, such as functions and polynomials.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inner products&lt;/strong&gt;: An inner product is a function that takes two vectors as input and produces a scalar as output. It is used to measure the angle between vectors and the length of a vector.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Orthogonality&lt;/strong&gt;: Two vectors are orthogonal if they are perpendicular to each other. Orthogonal vectors have many important applications, such as in least squares regression and in the Gram-Schmidt process for orthonormalizing a set of vectors.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;second derivative test&lt;/strong&gt; is a method used in calculus to determine the nature of the critical points of a function, which can be either a maximum, minimum, or saddle point.&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;critical point&lt;/strong&gt; is a point on the graph of a function where the derivative is either zero or undefined.&lt;/li&gt;
&lt;li&gt;To apply the second derivative test, we need to find the critical points of the function by setting its first derivative equal to zero and solving for the variables. Then, we can determine the nature of these critical points by examining the sign of the second derivative of the function evaluated at the critical points. Specifically:
&lt;ul&gt;
&lt;li&gt;If the second derivative is positive at a critical point, then the function has a local minimum at that point.&lt;/li&gt;
&lt;li&gt;If the second derivative is negative at a critical point, then the function has a local maximum at that point.&lt;/li&gt;
&lt;li&gt;If the second derivative is zero at a critical point, then the second derivative test is inconclusive, and we need to use other methods to determine the nature of the critical point.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The vectors $x$ and $y$ are orthogonal if $x^Ty=0$, they make an acute angle if $x^Ty&amp;gt;0$ and an obtuse angle if $x^Ty&amp;lt;0$&lt;/li&gt;
&lt;li&gt;Also, $x^Ty=||x||.||y||cos\theta$&lt;/li&gt;
&lt;li&gt;A set of vectors are &lt;strong&gt;linearly independent&lt;/strong&gt; if none of the vectors can be written as a linear combination of the others. That is the unique solution to the system of equations. There can be at most $n$ linearly independent vectors in $R^n$&lt;/li&gt;
&lt;li&gt;Any collection of $n$ linearly independent vectors in $R$ defines a &lt;strong&gt;basis&lt;/strong&gt; (or a coordinate system) of $R^n$, any vector in $R^n$ can be written as a linear combination of the basis vectors  The unit vectors $e^1= [1, 0, &amp;hellip;0]^T$, $e^2= [0, 1, &amp;hellip;0]^T$,&amp;hellip;,$e^n= [0, 0, &amp;hellip;1]^T$, define the standard basis for $R^n$&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;rank&lt;/strong&gt; of a matrix is a measure of the &amp;ldquo;nondegeneracy&amp;rdquo; of the matrix and it is one of the most important concepts in linear algebra. It is defined as the dimension of the vector space spanned by its columns or rows. Intuitively, it represents the number of linearly independent columns or rows in the matrix.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;row rank = column rank = rank($A$). $A$ is full rank if rank($A$) = min($m$, $n$)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;A system of equations has a solution when the equations are consistent, meaning that there is at least one set of values for the variables that satisfies all of the equations. If the equations are inconsistent, meaning that there is no set of values that satisfies all of the equations, then the system of equations has no solution.&lt;/li&gt;
&lt;li&gt;An &lt;strong&gt;affine function&lt;/strong&gt; is a function that is defined as a linear combination of variables, with the addition of a constant term. An affine function can be written as:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;f(x) = a_1x_1 + a_2x_2 + ... + a_nx_n + b
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Where x_1, x_2, &amp;hellip;, x_n are the input variables, a_1, a_2, &amp;hellip;, a_n are the coefficients, and b is a constant term. An affine function is a generalization of a linear function, which does not have the constant term.&lt;/p&gt;
&lt;iframe width=&#34;100%&#34; height =&#34;1024&#34; src=&#34;https://ayushsubedi.github.io/pdfs/la.pdf#toolbar=0&#34;&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;multivariate-calculus-primer&#34;&gt;Multivariate Calculus Primer&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://i.pinimg.com/736x/03/1e/73/031e73d364d35daf9ec479909c966505--systems-of-equations-maths-algebra.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;hessian-matrix&#34;&gt;Hessian matrix&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The Hessian matrix is a square matrix of second-order partial derivatives of a scalar-valued function of multiple variables.&lt;/li&gt;
&lt;li&gt;The Hessian matrix of a scalar-valued function f(x) of n variables x = (x1, x2, &amp;hellip;, xn) is defined as the matrix of second-order partial derivatives of f with respect to x, with the i-th row and j-th column containing the second partial derivative of f with respect to xi and xj.&lt;/li&gt;
&lt;li&gt;The Hessian matrix is often used in optimization, for example, to find the local minima or maxima of a function. A point where the Hessian is positive definite is a local minimum, while a point where the Hessian is negative definite is a local maximum. If the Hessian is positive semi-definite, it&amp;rsquo;s a saddle point.&lt;/li&gt;
&lt;li&gt;It is important to notice that the Hessian Matrix is symmetric, therefore it has real eigenvalues and it is diagonalisable.&lt;/li&gt;
&lt;li&gt;$H(f)_{i,j}=\frac{\partial^2f}{\partial x_i \partial x_j}$&lt;/li&gt;
&lt;li&gt;The symmetry of second derivatives (also called the equality of mixed partials) refers to the possibility of interchanging the order of taking partial derivatives of a function. The symmetry is the assertion that the second-order partial derivatives satisfy the identity. In the context of partial differential equations it is called the &lt;strong&gt;Schwarz integrability condition&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;$\frac{\partial^2f}{\partial x_i \partial x_j} = \frac{\partial^2f}{\partial x_j \partial x_i}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;taylor-approximation&#34;&gt;Taylor Approximation&lt;/h3&gt;
&lt;p&gt;The Taylor series of a real or complex-valued function fâ€‰(x) that is infinitely differentiable at a real or complex number a is the power series.&lt;/p&gt;
&lt;p&gt;Let $f: \mathbb{R}^n \rightarrow \mathbb{R}$ be a differentiable function and $\mathbf{x}^0 \in \mathbb{R}^n$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First order Taylor&amp;rsquo;s approximation of $f$ at $\mathbf{x}^0$ :
$$
f(\mathbf{x}) \approx f\left(\mathbf{x}^0\right)+\nabla f\left(\mathbf{x}^0\right)^{\top}\left(\mathbf{x}-\mathbf{x}^0\right)
$$&lt;/li&gt;
&lt;li&gt;Second order Taylor&amp;rsquo;s approximation of $f$ at $\mathbf{x}^0$ :
$$
f(\mathbf{x}) \approx f\left(\mathbf{x}^0\right)+\nabla f\left(\mathbf{x}^0\right)^{\top}\left(\mathbf{x}-\mathbf{x}^0\right)+\frac{1}{2}\left(\mathbf{x}-\mathbf{x}^0\right)^{\top} \nabla^2 f\left(\mathbf{x}^0\right)\left(\mathbf{x}-\mathbf{x}^0\right)
$$
`&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sets-in-optimization-problems&#34;&gt;Sets in Optimization Problems&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A set is &lt;strong&gt;closed&lt;/strong&gt; if it includes its boundary points.&lt;/li&gt;
&lt;li&gt;Intersection of closed sets is closed.&lt;/li&gt;
&lt;li&gt;Typically, if none of inequalities are strict, then the set is closed.&lt;/li&gt;
&lt;li&gt;A set is convex if a line segment connecting two points in the set lies entirely in the set.&lt;/li&gt;
&lt;li&gt;A set is bounded if it can be enclosed in a large enough (hyper)-sphere or a box.&lt;/li&gt;
&lt;li&gt;A set that is both bounded and closed is called compact.
&lt;ul&gt;
&lt;li&gt;$R^2$ is closed but not bounded&lt;/li&gt;
&lt;li&gt;$x^2+y^2&amp;lt;1$ is bounded but not closed&lt;/li&gt;
&lt;li&gt;$x+y&amp;gt;=1$ is closed but not bounded&lt;/li&gt;
&lt;li&gt;$x^2+y^2&amp;lt;=1$ is closed and bounded (compact)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An optimal solution of maximizing a convex function over a compact set lies on the boundary
of the set.&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe src=&#34;https://www.desmos.com/calculator/49e59msg7u?embed&#34; width=&#34;100%&#34; height=&#34;500&#34; style=&#34;border: 1px solid #ccc&#34; frameborder=0&gt;&lt;/iframe&gt;
&lt;h3 id=&#34;convex-function&#34;&gt;Convex Function&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/ConvexFunction.svg/1280px-ConvexFunction.svg.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A function $f: \mathbb{R}^n \rightarrow \mathbb{R}$ is convex if
$$
f(\lambda \mathbf{x}+(1-\lambda) \mathbf{y}) \leq \lambda f(\mathbf{x})+(1-\lambda) f(\mathbf{y}) \quad \forall \mathbf{x}, \mathbf{y} \in \mathbb{R}^n \text { and } \lambda \in[0,1]
$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;ldquo;Function value at the average is less than the average of the function values&amp;rdquo;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;This also implies that $a^Tx+b$ is convex (and concave)&lt;/li&gt;
&lt;li&gt;For a convex function the first order Taylor&amp;rsquo;s approximation is a global under estimator&lt;/li&gt;
&lt;li&gt;A convex optimization problem has a convex objective and convex set of solutions.&lt;/li&gt;
&lt;li&gt;Linear programs (LPs) can be seen as a special case of convex optimization problems. In an LP, the objective function and constraints are linear, which means that the feasible region defined by the constraints is a convex set. As a result, the optimal solution to an LP is guaranteed to be at a vertex (corner) of the feasible region, which makes it a convex optimization problem.&lt;/li&gt;
&lt;li&gt;A twice differentiable univariate function is convex if $f^{&amp;rsquo;&amp;rsquo;}(x)&amp;gt;=0$ for all $x \in R$&lt;/li&gt;
&lt;li&gt;To generalize, a twice differentiable function is convex if and only if the Hessian matrix is positive semi definite.&lt;/li&gt;
&lt;li&gt;A positive semi-definite (PSD) matrix is a matrix that is symmetric and has non-negative eigenvalues. In the context of a Hessian matrix, it represents the second-order partial derivatives of a multivariate function and reflects the curvature of the function. If the Hessian is PSD, it indicates that the function is locally convex, meaning that it has a minimum value in the vicinity of that point. On the other hand, if the Hessian is not PSD, the function may have a saddle point or be locally non-convex. The PSD property of a Hessian matrix is important in optimization, as it guarantees the existence of a minimum value for the function.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sylvester&amp;rsquo;s criterion&lt;/strong&gt; is a method for determining if a matrix is positive definite or positive semi-definite. The criterion states that a real symmetric matrix is positive definite if and only if all of its leading principal minors (i.e. determinants of the submatrices formed by taking the first few rows and columns of the matrix) are positive. If all the leading principal minors are non-negative, then the matrix is positive semi-definite.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;operations-preserving-convexity&#34;&gt;Operations preserving convexity&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Nonnegative weighted sum of convex functions is convex&lt;/strong&gt;, i.e. if $f_i$ is convex and $\alpha_i \geq 0$ for all $i=1, \ldots, m$, then $g(\mathbf{x})=\sum_{i=1}^m \alpha_i f_i(\mathbf{x})$ is convex.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Maximum of convex functions is convex.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Composition&lt;/strong&gt;: Let $f: \mathbb{R}^m \rightarrow \mathbb{R}$ be a convex function, and $g_i: \mathbb{R}^n \rightarrow \mathbb{R}$ be convex for all $i=1, \ldots, m$. Then the composite function
$$
h(\mathbf{x})=f\left(g_1(\mathbf{x}), g_2(\mathbf{x}), \ldots, g_m(\mathbf{x})\right)
$$
is convex if either $f$ is &lt;strong&gt;nondecreasing or if each $q_i$ is a linear&lt;/strong&gt; function.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convexity-preserving-set-operations&#34;&gt;Convexity Preserving Set Operations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Intersection of convex sets is a convex set&lt;/li&gt;
&lt;li&gt;Intersection of non convex sets might be a convex set&lt;/li&gt;
&lt;li&gt;Union of two convex set might not be a convex set&lt;/li&gt;
&lt;li&gt;Sum of convex set is a convex set&lt;/li&gt;
&lt;li&gt;Product of convex set is a convex set&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convex-optimization-problem&#34;&gt;Convex Optimization Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;An optimization problem (in minimization) form is a convex optimization problem, if the objective function is a convex function and constraint set is a convex set.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;The problem $min$ ${f(x) :  x \in X}$ is a convex optimization problem if $f$ is a convex function and $X$ is a convex set.&lt;/li&gt;
&lt;li&gt;To check if a given problem is convex, we can check convexity of each constraint separately. (This is a sufficient test, not necessary).&lt;/li&gt;
&lt;li&gt;$\begin{array}{cl}\min &amp;amp; f(\mathbf{x}) \ \text { s.t. } \end{array}$
$\begin{array}{cl} g_i(\mathbf{x}) \leq b_i \quad i=1, \ldots, m \ &amp;amp; h_j(\mathbf{x})=d_j \quad j=1, \ldots, \ell \ &amp;amp; \mathbf{x} \in \mathbb{R}^n\end{array}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sufficient-and-necessary&#34;&gt;Sufficient and necessary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In mathematical logic, the terms &amp;ldquo;sufficient&amp;rdquo; and &amp;ldquo;necessary&amp;rdquo; are used to describe the relationship between two conditions.&lt;/li&gt;
&lt;li&gt;A condition A is considered &amp;ldquo;sufficient&amp;rdquo; for a condition B if whenever condition A is true, condition B is also guaranteed to be true. In other words, if A is sufficient for B, then having A implies having B.&lt;/li&gt;
&lt;li&gt;A condition B is considered &amp;ldquo;necessary&amp;rdquo; for a condition A if whenever condition B is false, condition A is also guaranteed to be false. In other words, if B is necessary for A, then not having B implies not having A.&lt;/li&gt;
&lt;li&gt;Together, &amp;ldquo;necessary and sufficient&amp;rdquo; means that the two conditions are equivalent, in the sense that if one is true, then the other must also be true, and if one is false, then the other must also be false. In mathematical terms, A is necessary and sufficient for B if and only if (A if and only if B).&lt;/li&gt;
&lt;li&gt;&amp;ldquo;being a male is a necessary condition for being a brother, but it is not sufficient â€” while being a male sibling is a necessary and sufficient condition for being a brother&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;epigraph-of-a-function&#34;&gt;Epigraph of a function&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Epigraph_convex.svg/660px-Epigraph_convex.svg.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An epigraph of a function is a graphical representation of the function&amp;rsquo;s domain and range. It is formed by the region above the graph of the function and the line x = a for some value of a. The epigraph represents all possible values of the function for all values of x greater than or equal to a. It is used in optimization problems to visualize the feasible region for the optimization variable.&lt;/li&gt;
&lt;li&gt;A function (in black) is convex if and only if the region above its graph (in green) is a convex set. This region is the function&amp;rsquo;s epigraph.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The epigraph and the $\alpha$ level set, of a convex function are convex sets.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;outcomes-of-optimization&#34;&gt;Outcomes of Optimization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Any $x \in X$ is a feasible solution of the optimization problem (P)&lt;/li&gt;
&lt;li&gt;Feasible solution = A solution that satisfies all the constraints&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;An unbounded problem must be feasible&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;An optimization problem is unbounded, if there are feasible solutions with arbitrarily small objective values.(limits to negative infinity for minimization problem)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;If $X=\emptyset$ then no feasible solutions exist, and the problem (P) is said to be infeasible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;If $X$ is a bounded set, then P cannot be unbounded&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;The problem $\min {3x+ 2y: x+ y&amp;lt;=1,x&amp;gt;=2,y&amp;gt;=2}$ is infeasible&lt;/li&gt;
&lt;li&gt;An optimization problem can have 4 possible outcomes. The outcome can be infeasible, unbounded (but feasible), have no optimal solution, have one optimal solution, or have multiple optimal solutions&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;existence-of-optimal-solutions&#34;&gt;Existence of Optimal Solutions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The Weierstrass extreme value theorem asserts that if you minimize a continuous function over a closed and bounded set in $R_n$, then the minimum will be achieved at some point in the set.&lt;/li&gt;
&lt;li&gt;Sufficient conditions: if the constraint set is bounded and non empty (feasible), then continuity and closedness guarantees an optimal solution exist.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;local-and-global-optimal-solutions&#34;&gt;Local and Global Optimal Solutions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Local optimal solutions are also global optimal solutions for convex optimization problems&lt;/li&gt;
&lt;li&gt;Every global optimal solution is a local optimal solution, but not vice versa&lt;/li&gt;
&lt;li&gt;The objective function value at different local optimal solutions may be different&lt;/li&gt;
&lt;li&gt;The objective function value at all global solutions must be the same&lt;/li&gt;
&lt;li&gt;If the problem is convex, since any local solution is a global solution, we can be sure that if we find a local solution, that is also a global solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/go.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;idea-of-improving-search&#34;&gt;Idea of Improving Search&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Most optimization algorithms are based on the paradigm of improving search:
&lt;ul&gt;
&lt;li&gt;Start from a feasible solution&lt;/li&gt;
&lt;li&gt;Move to a new feasible solution with a better objective value, Stop if not possible&lt;/li&gt;
&lt;li&gt;Repeat step 2&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In general, we are only able to look in the &amp;ldquo;neighborhood&amp;rdquo; of the current solution in search of a better feasible solution (solutions that are within a small positive distance from the current solution)&lt;/li&gt;
&lt;li&gt;The move direction and step size should ensure that the new point is feasible and has an improved objective function value&lt;/li&gt;
&lt;li&gt;The improving search is better for local solutions, but for convex, in principal it can be used to find global solutions (by definition)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;optimality-certificates&#34;&gt;Optimality Certificates&lt;/h2&gt;
&lt;h3 id=&#34;optimality-certificates-and-relaxations&#34;&gt;Optimality Certificates and Relaxations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;A certificate or a stopping condition is an easily checkable condition such that if the current solution satisfies this condition then it is guaranteed to be optimal or near optimal&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Lower bound (a Priori) that the objective value of any solution cannot be lower than.&lt;/li&gt;
&lt;li&gt;Suppose we have a feasible solution $x&amp;rsquo;$ to an optimization problem with an objective value of $f(x&amp;rsquo;)$. Suppose the optimal objective value of the problem is $v*$. Then the absolute optimality gap of the solution is $gap(x&amp;rsquo;)$ = $f(x&amp;rsquo;) - v*$. And, the relative gap is $(f(x&amp;rsquo;) - v*)$/$v*$. The gap and rgap are always non negative.&lt;/li&gt;
&lt;li&gt;We do not know $v*$ but we do know the lower bound $L$. From definition, $L&amp;lt;=v*&amp;lt;=f(x&amp;rsquo;)$&lt;/li&gt;
&lt;li&gt;A lower bound allows us to get an upper bound on the solution.&lt;/li&gt;
&lt;li&gt;For two optimization problem (P) $min$ $f(x)$ $s.t.$ $x \in X $ and (Q) $min$ $g(x)$ $s.t.$ $x \in Y $, Problem (Q) is a relaxation of P
&lt;ul&gt;
&lt;li&gt;if $X \subseteq Y$ (problem Q admits more solution than P) and/or&lt;/li&gt;
&lt;li&gt;$f(x) &amp;gt;= g(x) \forall x \in X $&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Obtained by enlarging the feasible region and underapproximating the objective function&lt;/strong&gt;. We do not have to do both of those (see equals to sign)&lt;/li&gt;
&lt;li&gt;Relaxation should be easier to solve.&lt;/li&gt;
&lt;li&gt;Optimal value of the relaxation provides a lower bound on the original problem. (This provides the optimality certificate.)&lt;/li&gt;
&lt;li&gt;If the relaxation is infeasible then the original problem is also infeasible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Suppose only the constraints are relaxed, then if a solution to the relaxation is feasible to the original problem then it must be an optimal solution to the original problem.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;A lower bound on the optimal value provides a way to certify the quality of a given solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lagrangian-relaxation-and-duality&#34;&gt;Lagrangian Relaxation and Duality&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Very specific type of relaxation&lt;/li&gt;
&lt;li&gt;Lagrangian relaxation is a method used in optimization to solve a difficult problem by relaxing some of its constraints and instead optimizing a modified objective function known as the Lagrangian function. The Lagrangian function is constructed by adding a penalty term for each constraint to the original objective function. The penalty term is multiplied by a non-negative Lagrange multiplier that represents the slack in the constraint. By choosing appropriate values for the multipliers, the relaxed problem can be made to approximate the original problem.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The dual problem attempts to find the relaxation with the tightest bound (or the largest lower bound)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Weak duality: dual optimal value &amp;lt;= original optimal value&lt;/li&gt;
&lt;li&gt;Some times we get strong duality (for LP)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/lag_duality.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;unconstrained-optimization-derivative-based&#34;&gt;Unconstrained Optimization: Derivative Based&lt;/h2&gt;
&lt;h3 id=&#34;optimality-conditions&#34;&gt;Optimality Conditions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Unconstrained, that is the constraints are only $x \in R^n$ and twice differentiable&lt;/li&gt;
&lt;li&gt;If a solution is a local optimal solution of an unconstrained problem, then the gradient vanishes at the point (First order optimality condition)&lt;/li&gt;
&lt;li&gt;Hessian is a positive semidefinite (Second order optimality condition)&lt;/li&gt;
&lt;li&gt;The conditions are &lt;strong&gt;necessary but not sufficient&lt;/strong&gt;. Example: $f(x_$)$&lt;/li&gt;
&lt;li&gt;For example for, $f(x)=x^3$, at point 0, both of the conditions are satisfied. However, it is neither a local min or max.&lt;/li&gt;
&lt;li&gt;A sufficient (but not necessary) condition would be the gradient vanishing at the point, and is the Hessian is positive definite.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;gradient-descent&#34;&gt;Gradient Descent&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The gradient descent method moves from one iteration to the next by moving along the negative of the gradient direction in order to minimize the function.&lt;/li&gt;
&lt;li&gt;Gradient descent is a optimization algorithm used to minimize the error of a machine learning model. It is an iterative method that updates the model parameters in the direction of the negative gradient of the cost function with respect to the parameters. The gradient indicates the direction of steepest increase in the cost function and the descent refers to moving in the direction of negative gradient to find the minimum of the cost function. The learning rate determines the size of the steps taken to reach the minimum and the algorithm stops when the change in cost is below a certain threshold or when a maximum number of iterations is reached.&lt;/li&gt;
&lt;li&gt;Let $x^k$ be the current iterate, and we want to chose a downhill direction $d^k$ and a step size $a$ such that $f(x^k+ad^k)&amp;lt;f(x^k)$&lt;/li&gt;
&lt;li&gt;By Taylor&amp;rsquo;s expansion, $f(x^k+ad^k) \approx f(x^k) + a \nabla f(x^k)^Td_k$&lt;/li&gt;
&lt;li&gt;So we want $\nabla f(x^k)^Td_k &amp;lt; 0$. The steepest descent direction is $d^k = - \nabla f(x^k) $&lt;/li&gt;
&lt;li&gt;Step size can be identified using a line search. That is, define a function $g(a) := f(x^k + ad^k)$. Choose $a$ to minimize $g$. It can also be a small fixed step size.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;newtons-method&#34;&gt;Newton&amp;rsquo;s Method&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Newton&amp;rsquo;s Method is a second-order optimization algorithm that is used to find the minimum of a function. It is an iterative method that updates the parameters by using the gradient of the function (first derivative) and the Hessian matrix (second derivative) to find the direction of the local minimum. The algorithm starts with an initial guess for the parameters and iteratively updates them using the Newton-Raphson formula until the change in the parameters is below a certain threshold or a maximum number of iterations is reached. Newton&amp;rsquo;s Method is faster and more precise than gradient descent for well-behaved functions, but it can be sensitive to poor initialization and can get stuck in local minima.&lt;/li&gt;
&lt;li&gt;$x^{k+1} $ = $x^k$ - $[\nabla^2$ $f(x_k)]^{-1}$ $ \nabla f(x^k)$&lt;/li&gt;
&lt;li&gt;If started close enough to local minimum and the Hessian is positive definite, then the method has quadratic convergence&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Not guaranteed to converge. The Newton direction may not be improving at all.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;If the Hessian is singular (or close to singular) at some iteration, we cannot proceed.&lt;/li&gt;
&lt;li&gt;Computing gradient as well as the Hessian and its inverse is expensive.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;quasi-newton-methods&#34;&gt;Quasi-Newton Methods&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Blend of gradient descent and Newton&amp;rsquo;s method.&lt;/li&gt;
&lt;li&gt;Avoids computation of Hessian and its inverse&lt;/li&gt;
&lt;li&gt;$x^{k+1} $ = $x^k$ - $a_k H_k$ $ \nabla f(x^k)$, where $H_k$ is an approximation of $[\nabla^2$ $f(x_k)]^{-1}$ and $a_k$ is determined by line search&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;unconstrained-optimization-derivative-free&#34;&gt;Unconstrained Optimization: Derivative Free&lt;/h2&gt;
&lt;h3 id=&#34;methods-for-univariate-functions&#34;&gt;Methods for Univariate Functions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Golden Section Search: Start with an initial interval $[x_l, x_u]$ containing the minima, and successively narrow this interval&lt;/li&gt;
&lt;li&gt;Golden Section Search is an optimization algorithm used to find the minimum of a unimodal function, i.e., a function with a single minimum. The method is based on the idea of dividing an interval that contains the minimum into three sections, with the middle section being proportional to the golden ratio. The algorithm iteratively narrows down the interval by selecting the section that contains the minimum and discards the other sections. The process continues until the interval is sufficiently small and the minimum can be approximated with a desired accuracy. Golden Section Search is a bracketing method, which means it only requires the function to be unimodal and does not require the derivative or any other information about the function. It is a simple and efficient method for finding the minimum of unimodal functions, but it is slower than more sophisticated optimization methods for functions with multiple minima or more complex structures.&lt;/li&gt;
&lt;li&gt;Step 0: Set $x_1 = x_u - a(x_u-x_l)$ and $x_2=x_l+a(x_u-x_l)$&lt;/li&gt;
&lt;li&gt;Step 1: If $(x_u-x_l) &amp;lt;= \epsilon$ stop and return $x^* = 0.5(x_l+x_u)$ as the minima&lt;/li&gt;
&lt;li&gt;Example of how to use scipy.optimize.minimize to minimize a scalar function:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;import numpy as np
from scipy.optimize import minimize

def objective_function(x):
    return x**2 + 5*np.sin(x)

x0 = np.array([1.0]) # Initial guess
result = minimize(objective_function, x0, method=&amp;#39;BFGS&amp;#39;)
print(&amp;#34;Minimum at:&amp;#34;, result.x)
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;methods-for-multivariate-function&#34;&gt;Methods for Multivariate Function&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/d/de/Nelder-Mead_Himmelblau.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Nelder-Mead method is a optimization algorithm used to minimize a scalar function of several variables. It is a derivative-free method, meaning that it does not require the gradient of the objective function to be calculated. It works by constructing a simplex (a set of vertices) in the high-dimensional space defined by the input variables, and then iteratively modifying the vertices to find the minimum.&lt;/li&gt;
&lt;li&gt;Here&amp;rsquo;s an example of how to use scipy.optimize.minimize with the Nelder-Mead method:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;import numpy as np
from scipy.optimize import minimize

def objective_function(x):
    return x**2 + 5*np.sin(x)

x0 = np.array([1.0]) # Initial guess
result = minimize(objective_function, x0, method=&amp;#39;Nelder-Mead&amp;#39;)
print(&amp;#34;Minimum at:&amp;#34;, result.x)
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Nelder-Mead method is a numerical algorithm for minimizing a multivariate function using only function evaluations&lt;/li&gt;
&lt;li&gt;It is not guaranteed to converge but often works well.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;linear-optimization&#34;&gt;Linear optimization&lt;/h1&gt;
&lt;h2 id=&#34;linear-optimization-modeling---network-flow-problems&#34;&gt;Linear Optimization Modeling - Network Flow Problems&lt;/h2&gt;
&lt;h3 id=&#34;introduction-to-lp-modeling&#34;&gt;Introduction to LP Modeling&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A linear program is composed of:
&lt;ul&gt;
&lt;li&gt;Variables $x=(x_1,x_2,x_3&amp;hellip;,x_n)$&lt;/li&gt;
&lt;li&gt;Linear objective function $f(x_1,x_2,x_3&amp;hellip;,x_n)=\sum_{i=1}^n c_i x_i = c^Tx$&lt;/li&gt;
&lt;li&gt;Linear constraints: $&amp;gt;=, &amp;lt;= or =$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;All linear problems can be written as a inner product of two vectors.&lt;/li&gt;
&lt;li&gt;The objective function must be a linear function of the variables.&lt;/li&gt;
&lt;li&gt;The constraints must be linear inequality or equality constraints.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;optimal-transportation-problem&#34;&gt;Optimal Transportation Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The transportation problem is a type of linear programming problem that deals with finding the optimal assignment of resources to meet a set of demands. The problem is typically framed as a network flow problem, where the goal is to find the maximum flow from a set of sources to a set of destinations.&lt;/li&gt;
&lt;li&gt;In a transportation problem, the goal is to find the least cost way to transport a given amount of goods from a set of sources (e.g. factories) to a set of destinations (e.g. warehouses) subject to certain constraints such as limited supply at the sources and limited demand at the destinations. The cost of transporting a unit of goods from a source to a destination is represented by a cost matrix, which is usually obtained through market research or historical data.&lt;/li&gt;
&lt;li&gt;There are various algorithms that can be used to solve transportation problems, including the North-West Corner Method, the Minimum Cost Method (also known as the Vogel&amp;rsquo;s Approximation Method), and the Modified Distribution Method. The most popular algorithm for solving transportation problems is the Iterative Proportional Fitting (IPF) algorithm, also known as the MODI (Modified Distribution) method.&lt;/li&gt;
&lt;li&gt;The transportation problem is an important optimization problem with numerous real-world applications, including supply chain management, distribution systems, and logistics planning.&lt;/li&gt;
&lt;li&gt;There are $m$ suppliers, $n$ customers. Supplier $i$ can supply up to $s_i$ units of supply, and customer $j$ has $d_j$ units of demand. It costs $c_{ij}$ to transport a unit of product from supplier $i$ to customer $j$. We want to find a transportation schedule to satisfy all the demand within minimum transportation cost.&lt;/li&gt;
&lt;li&gt;Formulation 1: $\begin{array}{ll}\min &amp;amp; \sum_{i=1}^m \sum_{j=1}^n c_{i j} x_{i j} \ \text { s.t. } &amp;amp; \sum_{i=1}^m x_{i j}=d_j, \quad \forall j \ &amp;amp; \sum_{j=1}^n x_{i j} \leq s_i, \quad \forall i \ &amp;amp; x_{i j} \geq 0, \quad \forall i, j .\end{array}$&lt;/li&gt;
&lt;li&gt;Formulation 2: $\begin{array}{ll}\min &amp;amp; \sum_{i=1}^m \sum_{j=1}^n c_{i j} x_{i j} \ \text { s.t. } &amp;amp; \sum_{i=1}^m x_{i j}&amp;gt;=d_j, \quad \forall j \ &amp;amp; \sum_{j=1}^n x_{i j} \leq s_i, \quad \forall i \ &amp;amp; x_{i j} \geq 0, \quad \forall i, j .\end{array}$&lt;/li&gt;
&lt;li&gt;But &amp;gt;= inequality in the second formulation will be satisfied as = at optimal solution, thus, the two formulations are equivalent&lt;/li&gt;
&lt;li&gt;The graphs here are bipartite.&lt;/li&gt;
&lt;li&gt;The total supply is greater than or equal to the total demand.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;maximum-flow-problem&#34;&gt;Maximum Flow Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The maximum flow problem is a classical problem in network flow theory that aims to find the maximum amount of flow that can be sent from a source node to a sink node in a network, subject to capacity constraints on the edges. The maximum flow problem is a special case of the more general minimum cut problem, which aims to find the minimum capacity of a cut that separates the source and the sink in the network.&lt;/li&gt;
&lt;li&gt;A network in this context is represented as a graph, where the nodes represent the vertices and the edges represent the capacities of the arcs. The source node is where the flow originates, and the sink node is where the flow terminates. The capacity constraints on the edges determine the maximum amount of flow that can be sent through a particular edge.&lt;/li&gt;
&lt;li&gt;There are several algorithms that can be used to solve the maximum flow problem, including the Ford-Fulkerson algorithm, the Edmonds-Karp algorithm, and the push-relabel algorithm. These algorithms work by finding augmenting paths in the residual network, which is a network derived from the original network that represents the remaining capacities of the edges after some flow has already been sent. The algorithms continue to find augmenting paths until no more can be found, at which point the maximum flow has been found.&lt;/li&gt;
&lt;li&gt;The maximum flow problem has many real-world applications, including traffic flow in transportation networks, the allocation of bandwidth in communication networks, and the distribution of resources in supply chain networks.&lt;/li&gt;
&lt;li&gt;The graphs here are directed&lt;/li&gt;
&lt;li&gt;$\begin{array}{ll}\max &amp;amp; b_s \ \end{array}$&lt;/li&gt;
&lt;li&gt;$\begin{array}{ll} \text { s.t. } &amp;amp; \sum_{k \in O(i)} x_{i k}-\sum_{j \in I(i)} x_{j i}=b_i \quad \forall i \ &amp;amp; b_t=-b_s \ &amp;amp; b_i=0, \quad \forall i \neq s, t \ &amp;amp; 0 \leq x_{i j} \leq u_{i j}, \quad \forall(i, j) \in \mathcal{A} .\end{array}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;minimum-cut-problem&#34;&gt;Minimum Cut Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The Maximum Cut Problem is a well-known optimization problem in computer science and mathematics. The goal of the problem is to divide a given graph into two sets of vertices such that the sum of the weights of the edges between the two sets is as large as possible.&lt;/li&gt;
&lt;li&gt;Formally, given a graph G = (V,E) with a weight function w : E â†’ R, the maximum cut problem is to find a partition of the vertices into two sets S and T such that the sum of the weights of the edges between S and T is maximized.&lt;/li&gt;
&lt;li&gt;The problem is NP-hard, meaning that finding the optimal solution is computationally infeasible for large graphs. However, there are approximate algorithms that can find near-optimal solutions, such as semidefinite programming, spectral methods, and local search algorithms.&lt;/li&gt;
&lt;li&gt;The maximum cut problem has a wide range of applications, including network design, image and signal processing, and machine learning.&lt;/li&gt;
&lt;li&gt;Minimum cut = Maximum flow&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;shortest-path-problem&#34;&gt;Shortest Path Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The Maximum Cut Problem is a well-known optimization problem in computer science and mathematics. The goal of the problem is to divide a given graph into two sets of vertices such that the sum of the weights of the edges between the two sets is as large as possible.&lt;/li&gt;
&lt;li&gt;Formally, given a graph G = (V,E) with a weight function w : E â†’ R, the maximum cut problem is to find a partition of the vertices into two sets S and T such that the sum of the weights of the edges between S and T is maximized.&lt;/li&gt;
&lt;li&gt;The problem is NP-hard, meaning that finding the optimal solution is computationally infeasible for large graphs. However, there are approximate algorithms that can find near-optimal solutions, such as semidefinite programming, spectral methods, and local search algorithms.&lt;/li&gt;
&lt;li&gt;The maximum cut problem has a wide range of applications, including network design, image and signal processing, and machine learning.&lt;/li&gt;
&lt;li&gt;Shortest Path Problem is a Flow problem if we are shipping 1 unit of flow from $s$ to all other nodes&lt;/li&gt;
&lt;li&gt;$\begin{array}{ll}\min &amp;amp; \sum_{(i, j) \in \mathcal{A}} c_{i j} x_{i j} \ \end{array}$&lt;/li&gt;
&lt;li&gt;$\begin{array}{ll}{ s.t. } &amp;amp; \sum_{k \in O(i)} x_{i k}-\sum_{j \in I(i)} x_{j i}=-1 \forall i \neq s \ &amp;amp; \sum_{k \in O(s)} x_{s k}-\sum_{j \in I(s)} x_{j s}=n-1 \ &amp;amp; x_{i j} \geq 0, \quad \forall(i, j) \in \mathcal{A} .\end{array}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lp-model-for-market-clearing&#34;&gt;LP model for market clearing:&lt;/h3&gt;
&lt;img src=&#34;https://ayushsubedi.github.io/img/op.png&#34; width=&#34;300&#34; height=&#34;200&#34;&gt;
&lt;h3 id=&#34;rosenbrock-function&#34;&gt;Rosenbrock function&lt;/h3&gt;
&lt;p&gt;The Rosenbrock function is a widely used test function in optimization and is often used as a performance test for optimization algorithms. Here&amp;rsquo;s a simple code to plot the Rosenbrock function in Python using Matplotlib:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;import numpy as np
import matplotlib.pyplot as plt

def rosenbrock(x, y):
    return (1-x)**2 + 100*(y-x**2)**2

x = np.linspace(-2, 2, 400)
y = np.linspace(-1, 3, 400)
X, Y = np.meshgrid(x, y)
Z = rosenbrock(X, Y)

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection=&amp;#39;3d&amp;#39;)
ax.plot_surface(X, Y, Z, cmap=&amp;#39;viridis&amp;#39;)
ax.set_xlabel(&amp;#39;X axis&amp;#39;)
ax.set_ylabel(&amp;#39;Y axis&amp;#39;)
ax.set_zlabel(&amp;#39;Z axis&amp;#39;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/rosenbrock.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;lp-model-for-electricity-markets&#34;&gt;LP model for Electricity Markets&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Decision variables
&lt;ul&gt;
&lt;li&gt;Generator output: $p_i$ for each generator $i \in G$&lt;/li&gt;
&lt;li&gt;Power flow: $f_{ij}$ on each edge $(i,j) \in E$&lt;/li&gt;
&lt;li&gt;Nodal potential $\theta_i$ on each node $i \in N$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Objective function:
&lt;ul&gt;
&lt;li&gt;minimize the cost of production, $\sum_{i=1}^{G} c_ip_i$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Constraints:
&lt;ul&gt;
&lt;li&gt;Flow conservation (input=output)
&lt;ul&gt;
&lt;li&gt;for source node $p$ we have: (&amp;ldquo;sum of everything going out&amp;rdquo;) - (&amp;ldquo;sum of everything going in&amp;rdquo;) = $p$&lt;/li&gt;
&lt;li&gt;for demand node $d$ we have: (&amp;ldquo;sum of everything going out&amp;rdquo;) - (&amp;ldquo;sum of everything going in&amp;rdquo; ) = $-d$&lt;/li&gt;
&lt;li&gt;for node which is neither source nor demand we have: (&amp;ldquo;sum of everything going out&amp;rdquo;) - (&amp;ldquo;sum of everything going in&amp;rdquo;) = $0$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nodal potential&lt;/li&gt;
&lt;li&gt;Flow limit constraint&lt;/li&gt;
&lt;li&gt;Generator physical limit constraint&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;inventory-control-problem&#34;&gt;Inventory Control Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;a company must commit to specific production quantity x before knowing the exact demand $d$&lt;/li&gt;
&lt;li&gt;after seeing the demand, the company decides how many to sell and how many to sell at a discounted price of $v$&lt;/li&gt;
&lt;li&gt;This is an example of Decision Making under Uncertainty&lt;/li&gt;
&lt;li&gt;Here and Now decision: production quantity $x$&lt;/li&gt;
&lt;li&gt;Wait and See decision: sell quantity $y$, discount quantity $z$&lt;/li&gt;
&lt;li&gt;Objective: minimize production cost and expected future cost&lt;/li&gt;
&lt;li&gt;Stochastic program:&lt;/li&gt;
&lt;li&gt;$min_{x} cx + E_d[Q(x,d)]$ s.t $0&amp;lt;=x&amp;lt;=\hat{x}$&lt;/li&gt;
&lt;li&gt;$Q(x,d) = min_{y,z} -r.y-s.z$ s.t $y&amp;lt;=d, y+z&amp;lt;=x, y&amp;gt;=0, z&amp;gt;=0$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;generation-capacity-expansion&#34;&gt;Generation Capacity Expansion&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;An electric utility company plans to build new generation stations to serve growing demand, called generation capacity expansion.&lt;/li&gt;
&lt;li&gt;New generation capacity has to be decided before demand and future fuel price are known&lt;/li&gt;
&lt;li&gt;Future demand and fuel prices are not known at the moment of making capacity decision, but can be estimated as random variables.&lt;/li&gt;
&lt;li&gt;After demand is realized, the utility company schedules existing and new generators based on capacity expansion decision.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;financial-planning&#34;&gt;Financial Planning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A family wishes to provide for a child&amp;rsquo;s college education 12 years later.&lt;/li&gt;
&lt;li&gt;The family currently has 100k and decides how to invest in any of 5 investments&lt;/li&gt;
&lt;li&gt;Investment can be adjusted every 4 years. So there are 3 periods&lt;/li&gt;
&lt;li&gt;The returns of investments are unknown and modeled as random variables&lt;/li&gt;
&lt;li&gt;The family wants to maximize the total expected return&lt;/li&gt;
&lt;li&gt;A problem of decision making under uncertainty&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;decision-types&#34;&gt;Decision Types&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Here-and-Now: decision made before knowing uncertain parameters&lt;/li&gt;
&lt;li&gt;Wait-and-See: decision made after knowing uncertain parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;basic-geometric-objects&#34;&gt;Basic Geometric Objects&lt;/h2&gt;
&lt;h3 id=&#34;points-and-vectors&#34;&gt;Points and vectors&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Point: geometric object in space&lt;/li&gt;
&lt;li&gt;Algebraically, a point in n-dimensional space is given by its coordinates: $x = (x_1, &amp;hellip;, x_n)^T \in R^n$&lt;/li&gt;
&lt;li&gt;We always write a vector as a column vector&lt;/li&gt;
&lt;li&gt;A point is also called a vector&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;rays-lines-and-their-parametric-forms&#34;&gt;Rays, lines, and their parametric forms&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A ray consists of a starting point $a$ and all the points in a direction $d$&lt;/li&gt;
&lt;li&gt;Algebraically it is a set: {$x$ $\in R^n | x = a + \theta d$, $\forall$ $\theta &amp;gt;=0 $}&lt;/li&gt;
&lt;li&gt;A line consists of two rays starting at a point pointing two opposite directions.&lt;/li&gt;
&lt;li&gt;Algebraically it is a set: {$x$ $\in R^n | x = a + \theta d$, $\forall$ $\theta \isin R $}&lt;/li&gt;
&lt;li&gt;For ray and line, it is parametric because a and d are known, and $\theta$ is the parameter&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;plane-and-solutions-of-linear-equations&#34;&gt;Plane and solutions of linear equations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A plane in $R^2$ is just a line. $a_1x_1+a_2x_2=c$&lt;/li&gt;
&lt;li&gt;This plane is a line but it is not a parametric representation of a line.&lt;/li&gt;
&lt;li&gt;A plane in $R^3$ is $a_1x_1+a_2x_2+a_3x_3=c$&lt;/li&gt;
&lt;li&gt;If c is 0, plane passes through the origin.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;hyperplane-and-a-linear-equation&#34;&gt;Hyperplane and a Linear equation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The concept of plane can be extended to any dimension R^n&lt;/li&gt;
&lt;li&gt;Algebraically, $a_1x_1+a_2x_2+&amp;hellip;+a_nx_n=c$&lt;/li&gt;
&lt;li&gt;can be written as $a^Tx=c$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;halfspace-and-a-linear-inequality&#34;&gt;Halfspace and a linear inequality&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In $R^2$, a halfspace is half of the whole space&lt;/li&gt;
&lt;li&gt;A halfspace also consists of the line dividing the space&lt;/li&gt;
&lt;li&gt;There are two halfspace in $R^2$, but both include the dividing line&lt;/li&gt;
&lt;li&gt;Same definition can be extended to a halfspace&lt;/li&gt;
&lt;li&gt;$H_1$ = {$x \in R^n: a^Tx&amp;gt;=c$}&lt;/li&gt;
&lt;li&gt;$H_2$ = {$x \in R^n: a^Tx&amp;lt;=c$}&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;polyhedron-and-serveral-hyperspaces&#34;&gt;Polyhedron and serveral hyperspaces&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A polyhedron is the intersection of a finite number of halfspaces&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://i.stack.imgur.com/rmUm7.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;geometric-aspects-of-linear-optimization&#34;&gt;Geometric Aspects of Linear Optimization&lt;/h2&gt;
&lt;h3 id=&#34;corner-points&#34;&gt;Corner Points&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Instead of edges, look at Corner Points&lt;/li&gt;
&lt;li&gt;Corner points are responsible for generating the set&lt;/li&gt;
&lt;li&gt;Convex combination of two points in the action of generating it&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convex-combination-of-two-points&#34;&gt;Convex Combination of Two Points&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Given two points, $a$, $b$ $\in R^n$, a convex combination of $a, b$ is given by
&lt;ul&gt;
&lt;li&gt;$x = \lambda a + (1- \lambda)b$ for some $\lambda \in [0, 1]$&lt;/li&gt;
&lt;li&gt;Geometrically, x is on the line segment connecting a and b&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Given a point $x$ is a convex combination of $a_1, &amp;hellip; a_m$ if $x$ can be written as
&lt;ul&gt;
&lt;li&gt;$x = \sum_{i=1}^m \lambda_ia_i$&lt;/li&gt;
&lt;li&gt;And, $\sum_{i=1}^m \lambda_i = 1, \lambda_i&amp;gt;=0$ for $i = 1, &amp;hellip; , m$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Corner points are special points, and therefore we give them a special name: Extreme Point&lt;/li&gt;
&lt;li&gt;A point x in a polyhedron P is an extreme point if and only if x is not a convex combination of other two different points in P.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convex-hull&#34;&gt;Convex Hull&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A convex hull of $m$ points $a_1, &amp;hellip;., a_m$ is the set of all convex combinations of $a_1, .., a_m$ denoted as $conv$ $x{a_1,.., a_n}$&lt;/li&gt;
&lt;li&gt;Theorem: A nonempty and bounded polyhedron is the convex hull of its extreme points.&lt;/li&gt;
&lt;li&gt;A bounded polyhedron is a polyhedron that does not extend to infinity in any direction.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conic-hull&#34;&gt;Conic Hull&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A polyhedron is unbounded iff there are directions to move to infinity without leaving the polyhedron.&lt;/li&gt;
&lt;li&gt;Recession direction: a ray that we never leave in the direction of the polyhedron&lt;/li&gt;
&lt;li&gt;However, there are special rays on the edge which can be used to generate all other rays&lt;/li&gt;
&lt;li&gt;A ray $d$ is a conic combination of two rays, $e_1$, $e_2$ if d is a nonnegative weighted sum of $e_1$, $e_2$&lt;/li&gt;
&lt;li&gt;The set of all conic combination of rays $r_1, &amp;hellip;, r_m$ is called the conic hull of $r_1, &amp;hellip;, r_m$&lt;/li&gt;
&lt;li&gt;The sum of $\lambda$ does not have to equal to 1 here.&lt;/li&gt;
&lt;li&gt;A ray $e$ in a cone C is called an extreme ray, if $e$ is a conic combination of other two different rays in the cone C&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;extreme-ray-and-extreme-point&#34;&gt;Extreme Ray and Extreme Point&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;If a polyhedron is bounded, there is no extreme ray&lt;/li&gt;
&lt;li&gt;If a polyhedron is bounded, there must be an extreme point&lt;/li&gt;
&lt;li&gt;If a polyhedron is unbounded, it must have an extreme point&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;polyhedron-representations&#34;&gt;Polyhedron Representations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Halfspace representation&lt;/li&gt;
&lt;li&gt;Extreme Point representation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;weyl-caratheodory-theorem&#34;&gt;Weyl-Caratheodory Theorem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Any point $x$ in a polyhedron can be written as a sum of two vectors $x = x^&amp;rsquo; + d$ where $x^&amp;rsquo;$ is in the convex hull of its extreme points and d is in the conic hull of its extreme rays.&lt;/li&gt;
&lt;li&gt;$P =$ $conv$ ${x_1, &amp;hellip;, x^m} + $ $conic$ ${e^1, &amp;hellip;, e^k}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;algebraic-aspect-of-linear-optimization&#34;&gt;Algebraic Aspect of Linear Optimization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Active constraints&lt;/strong&gt;: A linear constraint that is satisfied as equality at a given point is said to be active or binding at that point. Otherwise, if an inequality constraint is satisfied as strict inequality at a point, it is called inactive.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linear independent constraints&lt;/strong&gt;: If the normal directions of two or more linear constraints are linearly independent, then these constraints are called linearly independent&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linearly independent active constraints&lt;/strong&gt;: Active constraints that are linearly independent&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Basic solution&lt;/strong&gt;: The unique solution of $n$ linearly independent active constraints in $R^n$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Basic feasible solution (BFS)&lt;/strong&gt;: Basic solution that is feasible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Basic Feasible Solution = Extreme Point&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;standard-form-of-writing-an-lp&#34;&gt;Standard Form of writing an LP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A standard form linear program is written as $min$ $ c^Tx$ $s.t.$ $Ax=b, x&amp;gt;=0 \in X $&lt;/li&gt;
&lt;li&gt;$x \in R^n$ that is, there are $n$ variables&lt;/li&gt;
&lt;li&gt;$A \in R^{m*n}$, ie there are m equality constraints&lt;/li&gt;
&lt;li&gt;We always assume all the $m$ equality constraints are linearly independent&lt;/li&gt;
&lt;li&gt;Equality constraints and Nonnegative constraints on all variables&lt;/li&gt;
&lt;li&gt;The first constraint is data dependent, whereas the second one is not&lt;/li&gt;
&lt;li&gt;Any linear program can be transformed into LP&lt;/li&gt;
&lt;li&gt;Advantage of standard form LP:
&lt;ul&gt;
&lt;li&gt;Complicating constraints are all equality&lt;/li&gt;
&lt;li&gt;Only inequality constraints are simple, no negativity constraints, which do not depend on data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;basic-solution-to-standard-form-lp&#34;&gt;Basic Solution to standard form LP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A basic solution is the unique solution to $n$ linearly independent active constraints.&lt;/li&gt;
&lt;li&gt;For a standard form LP, we already have $m$ linearly independent active constraints.&lt;/li&gt;
&lt;li&gt;Need $n-m$ additional linearly independent active constraints&lt;/li&gt;
&lt;li&gt;Where to find them?&lt;/li&gt;
&lt;li&gt;Only from nonnegative constraints: $x_i &amp;gt;= 0$&lt;/li&gt;
&lt;li&gt;But which to choose to make active?&lt;/li&gt;
&lt;li&gt;Choose $m$ such linearly independent columns, denote the corresponding $m*m$ matrix as B, called basis matrix. The corresponding $(n-m)$ $x_i$s are denoted as $x_N$, non basic variables&lt;/li&gt;
&lt;li&gt;Choose $x_i=0$ for all $i$ corresponds to the columns in $N$, $x_N$ = 0&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;why-do-we-care&#34;&gt;Why do we care?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Not every LP has a BFS, not every polyhedron has an extreme point (Think about a line or a halfspace)&lt;/li&gt;
&lt;li&gt;So which LP has a BFS?
&lt;ul&gt;
&lt;li&gt;A polyhedron P has an extreme point iff it does not contain a line&lt;/li&gt;
&lt;li&gt;Corollary: A feasible standard form LP always has a BFS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If an LP has a finite optimal solution, then an optimal solution is a BFS&lt;/li&gt;
&lt;li&gt;That does not mean all optimal solution must be BFS&lt;/li&gt;
&lt;li&gt;Because feasible standard form LP must have a BFS&lt;/li&gt;
&lt;li&gt;And because an optimal solution must be a BFS&lt;/li&gt;
&lt;li&gt;Then, an optimal solution of standard for LP must be a BFS&lt;/li&gt;
&lt;li&gt;So we only need to look at BFSs, and select the one BFS with the minimum obj cost&lt;/li&gt;
&lt;li&gt;This is why BFS is very important for linear programming.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;local-search&#34;&gt;Local Search&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;In a feasible region&lt;/li&gt;
&lt;li&gt;General idea (does not have to be a LP)&lt;/li&gt;
&lt;li&gt;Start from some solution, and move to certain direction to a new point, but stay in feasible region.&lt;/li&gt;
&lt;li&gt;Algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/local_search.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generic algorithmic idea&lt;/li&gt;
&lt;li&gt;Gradient Descent and Newton Method uses local search&lt;/li&gt;
&lt;li&gt;Step size should be chosen properly, and the position should be feasible&lt;/li&gt;
&lt;li&gt;Local Search works well for convex optimization (A local minimum of a convex program is also a global minimum)&lt;/li&gt;
&lt;li&gt;Not in general for non convex optimization problems (Local search can get stuck)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;local-search-for-lp&#34;&gt;Local Search for LP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We only need to look at basic feasible solution.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The key step is to find a direction $d$ and step size $\theta$ so that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$d$ points from a BFS to one of its adjacent BFS&lt;/li&gt;
&lt;li&gt;That adjacent BFS should reduce objective value&lt;/li&gt;
&lt;li&gt;Move along the favorable direction as much as possible to maintain feasibility and to reduce objective&lt;/li&gt;
&lt;li&gt;Stop when optimal solution is fount (or cannot be found)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Two BFS are adjacent if they share the same $n-1$ linearly independent active constraints.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Two adjacent BFSs must share the same set of $n-m-1$ nonbasic variables as n-m-1 active constraints, and differ in one nonbasic variable.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example, if $x=(x_1, &amp;hellip;, x_5)$ has nonbasic variables $x_3 = x_4 = x_5 = 0 $, then its adjacent BFS must share two of these three nonbasic variables, i.e. $x_3=x_4=x_2=0$ may be nonbasic variable in an adjacent BFS.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;simplex-method&#34;&gt;Simplex Method&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The simplex method is a linear programming algorithm that is used to solve optimization problems with linear constraints and a linear objective function. It involves iteratively constructing a sequence of feasible solutions that converge to an optimal solution.&lt;/li&gt;
&lt;li&gt;At each iteration, the simplex method selects a non-basic variable to become basic and then computes a feasible solution by solving a set of linear equations. If the solution is not optimal, the method determines a new non-basic variable to become basic and repeats the process until an optimal solution is found.&lt;/li&gt;
&lt;li&gt;The method is based on the fact that a linear programming problem can be represented graphically as a polyhedron in high-dimensional space, and the optimal solution lies at one of the extreme points of the polyhedron. The simplex method works by traversing the edges of the polyhedron until the optimal extreme point is reached.&lt;/li&gt;
&lt;li&gt;The simplex method is a powerful tool for solving large-scale linear programming problems and is widely used in industry, finance, and other fields. However, it has some limitations, such as its inability to handle nonlinear constraints and its susceptibility to numerical instability when dealing with ill-conditioned matrices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;degeneracy&#34;&gt;Degeneracy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Degeneracy in the simplex method refers to a situation where the simplex algorithm encounters multiple optimal solutions or cycles in the iteration process. In other words, a degenerate linear programming problem has more than one basic feasible solution with the same objective function value.&lt;/li&gt;
&lt;li&gt;Degeneracy can occur when one or more constraints in the linear programming problem are redundant or when there is a linear dependence among the constraints. This leads to a reduced dimensionality in the space of feasible solutions, resulting in more than one optimal solution or cycle in the iteration process.&lt;/li&gt;
&lt;li&gt;Degeneracy can pose challenges for the simplex method since it can lead to slow convergence, cycling, or termination of the algorithm before finding an optimal solution. This is because the simplex method relies on selecting non-basic variables to become basic and constructing a feasible solution by solving a set of linear equations. In a degenerate case, some of the variables may become redundant, leading to cycles in the iteration process.&lt;/li&gt;
&lt;li&gt;To address degeneracy, various modifications to the simplex method have been proposed, such as the use of anti-cycling rules, perturbation techniques, or alternative algorithms such as interior-point methods. These modifications aim to reduce or eliminate the effects of degeneracy on the convergence of the algorithm and ensure finding an optimal solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;blands-rule-for-degeneracy&#34;&gt;Bland&amp;rsquo;s rule for degeneracy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Bland&amp;rsquo;s rule ensures that the simplex method always chooses the variable with the smallest index as the entering variable and the variable with the smallest subscript as the leaving variable. In other words, Bland&amp;rsquo;s rule breaks ties in the selection of entering and leaving variables in favor of the variable with the smallest index or subscript.&lt;/li&gt;
&lt;li&gt;By always selecting the variable with the smallest index or subscript, Bland&amp;rsquo;s rule guarantees that the simplex method cycles through all basic feasible solutions before returning to a previous solution. This eliminates the possibility of the algorithm getting stuck in a cycle and ensures that it converges to an optimal solution eventually.&lt;/li&gt;
&lt;li&gt;Although Bland&amp;rsquo;s rule can increase the number of iterations required to solve a degenerate linear programming problem, it provides a provably optimal solution and eliminates the possibility of cycling or termination before finding an optimal solution. Bland&amp;rsquo;s rule is widely used in software implementations of the simplex method and has been shown to be effective in practice.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;h2 id=&#34;linear-program-duality&#34;&gt;Linear Program Duality&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;LP duality is at the core of linear programming theory.&lt;/li&gt;
&lt;li&gt;Provides new perspective on understanding LP, is important for designing algorithms, and has many applications (pricing, game theory, robust optimization, and many more).&lt;/li&gt;
&lt;li&gt;Linear Program (LP) duality is a powerful concept in optimization theory that establishes a relationship between the primal and dual LP problems. The duality principle provides insights into the structure of optimization problems, helps in understanding the solutions and provides a tool for solving LP problems.&lt;/li&gt;
&lt;li&gt;In LP duality, there are two LP problems, known as the primal problem and the dual problem. The primal problem is the original LP problem that seeks to minimize or maximize a linear objective function subject to a set of linear constraints. The dual problem is constructed from the primal problem, and it seeks to maximize or minimize a function subject to a set of constraints.&lt;/li&gt;
&lt;li&gt;The duality principle states that the optimal value of the primal problem is equal to the optimal value of the dual problem. Furthermore, the optimal solutions of both problems are related in a specific way. This relationship is known as the duality gap, which is the difference between the optimal values of the primal and dual problems.&lt;/li&gt;
&lt;li&gt;There are two forms of LP duality: weak duality and strong duality. Weak duality states that the optimal value of the dual problem is always greater than or equal to the optimal value of the primal problem. In contrast, strong duality states that if the primal problem has an optimal solution, then the dual problem also has an optimal solution, and the duality gap is zero.&lt;/li&gt;
&lt;li&gt;The dual LP problem provides useful information about the primal LP problem. For example, the dual problem provides a lower bound on the optimal value of the primal problem, and it can be used to derive sensitivity analysis and shadow prices. Additionally, the dual problem can be used to reformulate the primal problem and generate alternative solutions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A fundamental motivation of LP duality is to find a systematic way to construct a lower bound to the original LP&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Original LP (Primal LP) $Z_p =  min \lbrace c^Tx:Ax=b,x \ge 0 \rbrace $&lt;/li&gt;
&lt;li&gt;Any feasible solution $x$ provides an upper bound on $Z_p$, ie, $Z_p \le c^Tx$&lt;/li&gt;
&lt;li&gt;What about a lower bound, i.e $Z_D \le Z_p$?&lt;/li&gt;
&lt;li&gt;This lower bound is useful because if the lower bound is very close to an upper bound, we have a good estimate of the true optimal.&lt;/li&gt;
&lt;li&gt;However, to get a lower bound, we need to modify the original LP&lt;/li&gt;
&lt;li&gt;In particular, we need to relax the problem.&lt;/li&gt;
&lt;li&gt;Principles of relaxation works for general optimization problems, far beyond LP&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;principle-of-relaxation&#34;&gt;Principle of Relaxation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Relaxation:
&lt;ul&gt;
&lt;li&gt;Find a new objective function that is always smaller or equal to the original objective function at any feasible point&lt;/li&gt;
&lt;li&gt;Find a feasible region that is larger than the feasible region of the original problem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Minimize a function &lt;em&gt;lower&lt;/em&gt; than the original objective over a region that is &lt;em&gt;larger&lt;/em&gt; than the original one. The optimal objective of the new problem will be a lower bound to the original one.&lt;/li&gt;
&lt;li&gt;Among all possible relaxations and lower bounds, find the best lower bound.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/relaxation.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;systematic-way-to-carry-out-relaxation&#34;&gt;Systematic way to carry out relaxation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Step 1&lt;/strong&gt;: Relax the objective function&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Step 2&lt;/strong&gt;: Relax the feasible region by ignoring constraints
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Separability&lt;/strong&gt; refers to the property that the objective function of the Lagrangian dual problem can be expressed as the sum of separate functions, each of which depends only on a subset of the variables of the primal problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Step 3&lt;/strong&gt; Find the best lower bound.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;primal-and-dual-pair&#34;&gt;Primal and Dual Pair&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/panddpair1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.stack.imgur.com/3hQEH.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;is-lagrangian-relaxation-a-dual-problem-to-the-primal&#34;&gt;Is Lagrangian relaxation a dual problem to the primal?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Yes, Lagrangian relaxation is a way of obtaining a lower bound on the optimal value of the primal problem by constructing a dual problem.&lt;/li&gt;
&lt;li&gt;In Lagrangian relaxation, the primal problem is first converted into its Lagrangian dual problem by introducing Lagrange multipliers, which are used to form a penalty term that is added to the original objective function. The resulting Lagrangian function is then minimized subject to the constraints, resulting in a lower bound on the optimal value of the primal problem.&lt;/li&gt;
&lt;li&gt;The Lagrangian dual problem is formulated by taking the infimum (minimum) of the Lagrangian over all possible values of the Lagrange multipliers. The dual problem is a maximization problem that seeks to find the maximum value of the infimum, subject to certain constraints that are derived from the original primal problem.&lt;/li&gt;
&lt;li&gt;The duality theorem states that the optimal value of the primal problem is equal to the optimal value of the dual problem, and that any feasible solution to one problem gives a lower bound or upper bound for the other problem. Therefore, Lagrangian relaxation can be seen as a way of constructing the dual problem to the primal problem, and finding a lower bound on the optimal value of the primal problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;important&#34;&gt;Important&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;If a linear program has an unbounded feasible region, then it can either be unbounded or have a finite optimal solution.&lt;/li&gt;
&lt;li&gt;If it has finite optimal solution than its dual must also have finite optimal solution.&lt;/li&gt;
&lt;li&gt;If it is unbounded, then its dual must be infeasible.&lt;/li&gt;
&lt;li&gt;If a linear program has an unbounded feasible region, then its dual problem cannot have an unbounded optimal solution.&lt;/li&gt;
&lt;li&gt;If a linear program has an unbounded feasible region, then its dual may be infeasible or have a finite optimal solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;linear-programming-weak-duality&#34;&gt;Linear Programming weak duality&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Given a primal LP in minimization, by the construction of the dual, the objective value of any feasible solution of the dual problem provides a lower bound to the primal objective cost&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Theorem 1 (Linear programming weak duality)&lt;/strong&gt;: If $x$ is any feasible solution to the primal minimization LP, and y is any feasible solution to the dual maximization LP, then $c^Tx \ge b^Ty$&lt;/li&gt;
&lt;li&gt;This implies:
&lt;ul&gt;
&lt;li&gt;If the optimal cost of the primal minimization problem is $-\inf$ then the dual maximization problem must be infeasible.&lt;/li&gt;
&lt;li&gt;If the optimal cost of the dual maximization problem is $+\inf$ then the primal minimization problem must be infeasible.&lt;/li&gt;
&lt;li&gt;Let $x^*$ be feasible to the primal problem and $y*$ be feasible to the dual problem, and suppose $c^Tx^*=b^Ty^*$, then $x^*$ and $y^*$ are optimal solutions to the primal and dual problems, respectively.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Weak duality does not hold if problem is infeasible.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;strong-duality&#34;&gt;Strong Duality&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Theorem 1 (Linear programming strong duality)&lt;/strong&gt;: If a primal linear program has a finite optimal solution $x^*$, then its dual linear program must also have a finite optimal solution $y^*$, and the respective optimal objective values are equal, ie, $c^Tx = b^Ty$&lt;/li&gt;
&lt;li&gt;Strong duality is the single most important theorem in LP. Its proof is very illuminating.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tables-of-possibilities&#34;&gt;Tables of possibilities&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/duality.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/primal_dual_combinations.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;sob-method-for-creating-dual-of-a-lp&#34;&gt;SOB method for creating dual of a LP&lt;/h2&gt;
&lt;iframe width=&#34;100%&#34; height =&#34;1024&#34; src=&#34;https://ayushsubedi.github.io/pdfs/tut6.pdf#toolbar=0&#34;&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;complementarity-slackness&#34;&gt;Complementarity Slackness&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Complementarity slackness is a fundamental concept in optimization theory that arises in the context of solving optimization problems with inequality constraints. It provides insights into the structure of the solutions and helps in understanding the behavior of the constraints in the optimization process.&lt;/li&gt;
&lt;li&gt;In an optimization problem with inequality constraints, the optimal solution typically satisfies the constraints with equality or with some slackness. Complementarity slackness is the condition that ensures that a constraint is either binding (i.e., satisfied with equality) or non-binding (i.e., satisfied with strict inequality) in the optimal solution.&lt;/li&gt;
&lt;li&gt;More formally, let x be a feasible solution to an optimization problem with inequality constraints, and let s be the slack variables associated with the constraints. The complementarity slackness condition requires that the product of the slack variables and the dual variables associated with the constraints is equal to zero.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;robust-optimization&#34;&gt;Robust Optimization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Making decision during uncertainty&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Robust optimization is a mathematical optimization technique that seeks to find a solution that is optimal under a set of possible scenarios, often in the presence of uncertain or varying parameters. It is particularly useful when dealing with systems that are subject to variability, such as financial or transportation systems, where decisions need to be made under uncertain conditions.&lt;/li&gt;
&lt;li&gt;In robust optimization, instead of trying to find a single optimal solution, a set of feasible solutions is identified that can perform well across a range of possible scenarios. The objective function is typically defined as a worst-case scenario, which ensures that the selected solution is optimal under all possible scenarios.&lt;/li&gt;
&lt;li&gt;Robust optimization can be used in a variety of applications, including portfolio optimization, supply chain management, and resource allocation. It has become increasingly popular in recent years due to its ability to provide robust solutions that can withstand unpredictable changes in the environment.&lt;/li&gt;
&lt;li&gt;We need to formulate constraint in such a way that solution we obtain will allow production to survive all possible realizations of the coefficients.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;large-scale-optimization&#34;&gt;Large Scale Optimization&lt;/h2&gt;
&lt;h3 id=&#34;cutting-stock-problem&#34;&gt;Cutting Stock Problem&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://www.researchgate.net/publication/228428085/figure/fig1/AS:301993223573505@1449012203611/One-dimensional-cutting-stock-problem-with-one-stock-type.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The cutting stock problem is a combinatorial optimization problem that involves cutting large sheets of material, such as paper or metal, into smaller pieces of specific sizes in order to minimize waste. The objective is to determine the most efficient cutting pattern that can be used to produce a given number of smaller pieces of the desired sizes, while minimizing the amount of leftover material.&lt;/li&gt;
&lt;li&gt;The cutting stock problem is a common problem in the manufacturing industry, where it is used to optimize the use of raw materials and minimize production costs. It can be formulated as a linear programming problem, where the decision variables are the number of cuts made in each direction, and the objective function is to minimize the amount of leftover material.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;gilmore-gomory-formulation&#34;&gt;Gilmore-Gomory Formulation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$min \sum_{i=1}^N x_i$, s.t $Ax=b, x \gt 0$&lt;/li&gt;
&lt;li&gt;the coefficients are 1&lt;/li&gt;
&lt;li&gt;where the columns of A are the patterns to cut one large roll&lt;/li&gt;
&lt;li&gt;$b$ is the amount of demand of each size of smaller rolls&lt;/li&gt;
&lt;li&gt;The number of ways to cut a large roll into smaller ones is usually astronomical&lt;/li&gt;
&lt;li&gt;very large number of variables&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;column-generation&#34;&gt;Column Generation&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/column_generation.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pick a subset&lt;/li&gt;
&lt;li&gt;Solve the restricted master problem (RMP)&lt;/li&gt;
&lt;li&gt;A feasible solution of RMP can be made into a feasible solution of MP. This is because RMP has all the constraints in MP.&lt;/li&gt;
&lt;li&gt;A &lt;em&gt;basic&lt;/em&gt; feasible solution of RMP can made into a &lt;em&gt;basic&lt;/em&gt; feasible solution of MP&lt;/li&gt;
&lt;li&gt;For an optimal BFS of RMP we can compute reduced cost of all nonbasis variables, if any reduced cost is negative, then we know the optimal solution of RMP if not optimal for MP&lt;/li&gt;
&lt;li&gt;We can add the new variable with negative reduced cost to RMP solve the new RMP and repeat the process.&lt;/li&gt;
&lt;li&gt;The procedure of finding a variable with negative reduced cost is called the Pricing Problem. Pricing Problem: Compute all the reduced costs of $x$. If all reduced costs are nonnegative, then $x$ is optimal for MP. Otherwise, we find a new column to add to RMP.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;important-1&#34;&gt;Important&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The features of the cutting stock problem that make column generation a feasible approach to solve:
&lt;ul&gt;
&lt;li&gt;The cutting stock problem formulation has objective coefficients all equal to 1.&lt;/li&gt;
&lt;li&gt;The cutting stock problem has columns with special structures which can be generated by another optimization problem that is easy to solve.&lt;/li&gt;
&lt;li&gt;The cutting stock problem has a small number of rows&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The column generation algorithm will terminate if all columns have been added or if no column can further reduce the number of big rolls used to satisfy demand.&lt;/li&gt;
&lt;li&gt;Constraint generation can be used when problems have too many constraints, but not many variables, &lt;strong&gt;or&lt;/strong&gt; with too many rows and not many columns.&lt;/li&gt;
&lt;li&gt;The constraint generation algorithm will terminate if all the constraints are satisfied by the current solution, &lt;strong&gt;or&lt;/strong&gt; if all the contraints are added.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;correctness-and-convergence&#34;&gt;Correctness and Convergence&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The algorithm is correct because of the key properties of RMP&lt;/li&gt;
&lt;li&gt;Does the algorithm converge?
&lt;ul&gt;
&lt;li&gt;Yes, because the algorithm always adds new columns and never disregards any.&lt;/li&gt;
&lt;li&gt;The worst case is all the columns of MP are used.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dantzig-wolfe&#34;&gt;Dantzig-Wolfe&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The Dantzig-Wolfe decomposition (also known as the column generation method) is a technique for solving large-scale linear programming problems that have a special structure. It is named after George Dantzig and Philip Wolfe, who first proposed the method in the 1960s.&lt;/li&gt;
&lt;li&gt;The Dantzig-Wolfe decomposition method decomposes a large linear programming problem into smaller sub-problems, each of which can be solved independently. The method is particularly useful when the original problem has a large number of constraints, but only a small number of variables are involved in each constraint.&lt;/li&gt;
&lt;li&gt;The basic idea of the method is to introduce new variables (known as columns) into the problem gradually, one at a time, and to solve the resulting sub-problem using standard linear programming techniques. The optimal solution to the sub-problem is then used to generate a new column, which is added to the problem and the process is repeated until the optimal solution to the original problem is found.&lt;/li&gt;
&lt;li&gt;The Dantzig-Wolfe decomposition method can be used to solve a wide range of linear programming problems, including those with integer variables and those with non-linear objective functions. It is particularly useful for problems that involve complex constraints or require the solution of large-scale optimization problems.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;important-2&#34;&gt;Important&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;To use Dantzig-Wolfe decomposition algorithm, the problem must have a special structure where:
&lt;ul&gt;
&lt;li&gt;all constraints are linear and have a block angular structure&lt;/li&gt;
&lt;li&gt;the objective funciton is a linear function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;We solve Dantzig-Wolfe decomposition by using column generation because:
&lt;ul&gt;
&lt;li&gt;the number of extreme points can be huge&lt;/li&gt;
&lt;li&gt;there are not many constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The pricing problem is relatively easy to solve because:
&lt;ul&gt;
&lt;li&gt;We can use simplex method instead of enumeration over all the extreme points&lt;/li&gt;
&lt;li&gt;There are no complicating constraint so that we can solve those pricing problems with angular structures in a distributed manner.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;moore-penrose-pseudoinverse&#34;&gt;Moore Penrose Pseudoinverse&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://www.researchgate.net/publication/278627426/figure/fig1/AS:360884149997586@1463052894718/Geometrical-interpretation-of-the-Moore-Penrose-pseudoinverse-In-the-leftmost-picture.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Moore-Penrose pseudoinverse, also known as the Moore-Penrose inverse or simply the pseudoinverse, is a generalization of the matrix inverse for non-square matrices. It is named after Elisha L. Moore and Roger Penrose, who independently introduced the concept in the mid-20th century.&lt;/li&gt;
&lt;li&gt;The pseudoinverse is defined for any m-by-n matrix A, where m and n need not be equal, and it is denoted by A+. The pseudoinverse has several important properties, including:
&lt;ul&gt;
&lt;li&gt;A+AA+A=A+&lt;/li&gt;
&lt;li&gt;AA+A=AA+&lt;/li&gt;
&lt;li&gt;(AA+)&amp;rsquo;=AA+&lt;/li&gt;
&lt;li&gt;(A+A)A=A&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;where A&amp;rsquo; denotes the transpose of A.&lt;/li&gt;
&lt;li&gt;The pseudoinverse is useful in a variety of applications, including linear regression, least-squares approximation, and control theory. In particular, if A has linearly independent columns, then A+A is the unique solution to the linear system Ax=b that minimizes the Euclidean norm of the error vector Ax-b.&lt;/li&gt;
&lt;li&gt;The pseudoinverse can be computed using singular value decomposition (SVD) or the QR decomposition. In particular, if A has full column rank, then its pseudoinverse can be computed as A+(A&amp;rsquo;A)^(-1) where A&amp;rsquo; denotes the transpose of A.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;convex-conic-optimization&#34;&gt;Convex Conic Optimization&lt;/h1&gt;
&lt;h3 id=&#34;nonnegative-orthant-cone&#34;&gt;Nonnegative Orthant cone&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The nonnegative orthant cone is a special type of cone in linear algebra and convex analysis. It is defined as the set of all nonnegative vectors in n-dimensional Euclidean space, denoted as R^n_+, where R^+ denotes the set of nonnegative real numbers.&lt;/li&gt;
&lt;li&gt;Generalizations of linear programming to nonlinear programming through convex cones and generalized inequalities&lt;/li&gt;
&lt;li&gt;A set K is called convex cone if K is convex and $ax \in K$ for all $a \ge 0$ whenever $x \in K$&lt;/li&gt;
&lt;li&gt;What is the relation between order and cone?
&lt;ul&gt;
&lt;li&gt;Order is a comparison relationship between two elements $a$ and $b$, usually written as $a \gt b$&lt;/li&gt;
&lt;li&gt;An order $\succeq_K$ is defined by an underlying convex cone K as
&lt;ul&gt;
&lt;li&gt;$a \succeq_K b$ iff $a-b \in K$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A standard form LP can be viewed as
&lt;ul&gt;
&lt;li&gt;$min$ ${c^Tx: Ax=b, x \gt_{R_+^n}0}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An elegant way to generalize linear programming is to generalize $R_+^n$ to a general convex cone $K$&lt;/li&gt;
&lt;li&gt;Linear Conic Programming: $min$ $c^T x: Ax=b, x \ge_K 0$&lt;/li&gt;
&lt;li&gt;Linear Conic Programming is a type of optimization problem that involves finding the best solution to a linear objective function subject to a set of linear constraints and the requirement that certain variables lie in a cone. A cone is a set of vectors that satisfies certain properties, such as being non-negative or having a fixed norm.&lt;/li&gt;
&lt;li&gt;In Linear Conic Programming, the constraints are expressed in the form of linear equations or inequalities, while the requirement that certain variables lie in a cone is expressed using conic constraints. Common types of cones include the non-negative orthant, the second-order cone, the semi-definite cone, and the exponential cone.&lt;/li&gt;
&lt;li&gt;The goal of Linear Conic Programming is to find a feasible solution that satisfies all the constraints and optimizes the objective function. This type of optimization problem arises in a variety of applications, such as portfolio optimization, transportation planning, and engineering design. Linear Conic Programming is a powerful tool that can be solved efficiently using specialized algorithms, such as interior-point methods.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;second-order-cone&#34;&gt;Second order cone&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$L^3 = \lbrace (x,y,z) : \sqrt{x^2-y^2} \le z \rbrace$ = $\lbrace(x,y,z):||[x;y]||_2 \le z \rbrace$&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;integer-optimization&#34;&gt;Integer optimization&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Integer optimization is a type of optimization problem where the decision variables are required to take integer values. This is in contrast to continuous optimization, where the decision variables can take any real value.&lt;/li&gt;
&lt;li&gt;Integer optimization problems arise in a variety of fields, including operations research, computer science, engineering, and economics. Examples of integer optimization problems include finding the optimal assignment of workers to shifts, determining the best routes for vehicles to travel, and selecting the optimal set of investments to make.&lt;/li&gt;
&lt;li&gt;Integer optimization is often more difficult than continuous optimization, because the feasible set of integer solutions is typically discrete and non-convex. This means that traditional optimization techniques, such as gradient descent, cannot be used. Instead, specialized algorithms, such as branch and bound or cutting plane methods, are used to find optimal or near-optimal solutions.&lt;/li&gt;
&lt;li&gt;Integer optimization is also sometimes referred to as mixed-integer optimization, when the problem includes both integer and continuous decision variables.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;binary-optimization-models&#34;&gt;Binary Optimization Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A special and important class of discrete optimization models are those where the discrete variables and required to be binary, that is, they are required to take values of 0 and 1.&lt;/li&gt;
&lt;li&gt;$min$ $f(x)$ $s.t.$ $g_i(x) \le b_i, x \in R^{n-p} \times \lbrace 0,1 \rbrace^p$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;set-packing-covering-and-partitioning&#34;&gt;Set Packing, Covering and Partitioning&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.researchgate.net/publication/354791763/figure/fig1/AS:1071429466456066@1632460099978/Set-covering-set-partitioning-and-set-packing-problems.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Set Packing&lt;/strong&gt;: A set packing is a collection of sets in which no two sets share a common element. In other words, a set packing is a collection of non-overlapping sets. The objective in set packing is to find the largest possible subset of the sets that do not overlap.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set Covering&lt;/strong&gt;: A set covering is a collection of sets that together contain every element in a given universe. In other words, a set covering is a collection of sets that covers all the elements of a universe. The objective in set covering is to find the smallest possible subset of the sets that covers all the elements.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set Partitioning&lt;/strong&gt;: Set partitioning is a way to divide a set into non-empty subsets such that each element belongs to exactly one subset. In other words, set partitioning is a way to divide a set into mutually exclusive and exhaustive subsets. The objective in set partitioning is to find a partition that satisfies some given criteria.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;The set packing problem arises when each set element must appear in at most one subset. In this case, the constraints are of the less-than-or-equal form. The set partitioning problem arises when each set element must appear in exactly one subset, and the constraints in this problem are equality constraints.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;store-location-example&#34;&gt;Store Location Example&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Where should store be located so that it can maximize the number of customers?&lt;/li&gt;
&lt;li&gt;maximize total customers, constrained to among the locations same location cannot attract more than one city&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pupl&lt;/code&gt; is the python package that can be used to model this&lt;/li&gt;
&lt;li&gt;Set Packing: Given $m$ elements and a collection of subsets $S_1, &amp;hellip;. , S_n \belongs {1,..,m} with associated nonnegative weights $w_1, &amp;hellip;, w_n$ pick sets from this collection such that they are disjoint and the sum of the weights is maximized.&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe width=&#34;100%&#34; height =&#34;1024&#34; src=&#34;https://www.dam.brown.edu/people/huiwang/classes/am121/Archive/ip_121.pdf#toolbar=0&#34;&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;linear-programming-relaxation&#34;&gt;Linear Programming Relaxation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Decision variable is only taking continuous value to generate the relaxation (drop the integer constraints).&lt;/li&gt;
&lt;li&gt;If LP relaxation is infeasible, so it the IP&lt;/li&gt;
&lt;li&gt;If LP relaxation is unbounded, then the IP can either be infeasible or unbounded.&lt;/li&gt;
&lt;li&gt;If LP relaxation has an optimal solution, then the IP could be infeasible or have an optimal solution&lt;/li&gt;
&lt;li&gt;It always holds that $v_{LP} \le v_{IP}$&lt;/li&gt;
&lt;li&gt;If an optimal solution to the LP is an integer, then it is an optimal solution to the IP.&lt;/li&gt;
&lt;li&gt;It&amp;rsquo;s solution can sometimes be rounded to get a good solution to the IP&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ideal-formulations&#34;&gt;Ideal Formulations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Stronger Formulation: Stronger formulation lead to stronger LP relaxations, and so better LP relaxation  better bounds, and sometimes LP relaxations solutions that are feasible to the MLP&lt;/li&gt;
&lt;li&gt;The formulation of an MLP can be strengthened
&lt;ul&gt;
&lt;li&gt;by adding constraints (valid inequalities)&lt;/li&gt;
&lt;li&gt;by tightening constraint coefficients&lt;/li&gt;
&lt;li&gt;by introducing new variables and constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An ideal formulation of a MILP is one whose LP relaxation solves the MLP&lt;/li&gt;
&lt;li&gt;Ideal formulations are hard to obtain, so we strive to obtain strong formulation that approximate the ideal formulation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;branch-bound-algorithm&#34;&gt;Branch Bound Algorithm&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Branch and bound is a popular algorithm used for solving mixed-integer linear programming (MILP) problems. The basic idea behind branch and bound is to divide the problem into smaller subproblems, solve each subproblem separately, and then combine the solutions to obtain an overall solution to the original problem.&lt;/li&gt;
&lt;li&gt;Here are the steps involved in the branch and bound algorithm for MILP:
&lt;ul&gt;
&lt;li&gt;Solve the relaxed linear programming (LP) problem, which is the MILP problem with the integer constraints removed. This provides an initial solution to the MILP problem.&lt;/li&gt;
&lt;li&gt;If the LP solution satisfies all the integer constraints, then we have found an optimal solution to the MILP problem. Otherwise, select one of the integer variables with a non-integer value in the LP solution.&lt;/li&gt;
&lt;li&gt;Create two new subproblems by branching on the selected variable: one subproblem where the variable is fixed to its integer floor, and another subproblem where the variable is fixed to its integer ceiling.&lt;/li&gt;
&lt;li&gt;Solve each of the subproblems using the LP solver. If a subproblem has an integer solution that is worse than the current best solution, we can prune that branch of the search tree. Otherwise, continue branching until we have found an optimal integer solution or all branches have been pruned.&lt;/li&gt;
&lt;li&gt;Once all branches have been pruned, the best integer solution found during the search is the optimal solution to the MILP problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Analytics for Ride Hailing Services</title>
      <link>https://ayushsubedi.github.io/posts/ride_hailing_analytics/</link>
      <pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/ride_hailing_analytics/</guid>
      <description>&lt;h2 id=&#34;analytics-for-ride-hailing-services&#34;&gt;Analytics for Ride Hailing Services&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.sanity.io/images/6xsct86j/production/e8fc0f789129b17cc8ae2e05b91e93d0752bef67-3840x2160.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;introduction-to-ride-hailing&#34;&gt;Introduction to Ride Hailing&lt;/h2&gt;
&lt;p&gt;At present, it is pretty common to hail a ride to get from one place to the other at a tap of a button. Almost all major cities in the world have some sort of ride-hailing service. Uber, Lyft, Didi, Ola, Gojek, etc. are some examples of service providers that come to mind. Additionally, the service is also proliferating to smaller cities and has become commonplace in many parts of the world. Analytics is a key component in making sure the service is provided efficiently. All of the aforementioned companies invest heavily in data science and analytics to be competitive and to provide better services.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For this post, I will focus on Ride-Hailing services (not Ride Sharing services). See the difference &lt;a href=&#34;https://www.ecolane.com/blog/ride-hailing-vs.-ride-sharing-the-key-difference-and-why-it-matters&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Predominantly, ride-hailing functions as a &lt;em&gt;Gig Economy&lt;/em&gt;. The drivers (sometimes referred to as partners, captains, etc.) are mostly independent contractors who bring their own vehicle and work at their own time and are paid based on their time commitment. This variability requires monitoring, sophisticated algorithms, good incentives, competitive pricing to passengers, etc. which is also common in other gig economy jobs. In most cases, the analytics models that will be built for one gig economy can be tweaked to fit another one as well.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at a few components of Ride-hailing that will be relevant for how we frame our models and the data we use.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For this post, &amp;ldquo;passengers&amp;rdquo; are referred to as service requesters/receivers and &amp;ldquo;drivers&amp;rdquo; are referred to as service providers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;components-of-the-problem&#34;&gt;Components of the problem&lt;/h2&gt;
&lt;hr&gt;
&lt;h3 id=&#34;balancing-act-supply-and-demand-and-chicken-and-egg-problem&#34;&gt;Balancing act: Supply and Demand, and Chicken and Egg Problem&lt;/h3&gt;
&lt;p&gt;There is a balancing act that all of these ride-sharing platforms need to perform to be efficient. A healthy ratio between driver and passenger (to go more granular, for a segment of geographic area at a given time) is very important.  The balancing act is even crucial when a ride-hailing service decides to introduce itself to a new city (especially one that is new to ride-hailing).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If an area has more drivers than demand from passengers, the drivers might not get ride requests causing them to lose interest and find a different job or move to a different competition.&lt;/li&gt;
&lt;li&gt;If an area has more passengers than a supply of drivers, the passengers might not get their ride requests accepted causing them to move onto another (direct/indirect) competition.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From an analytics perspective, this is a difficult problem to solve. However, good analytics can also be a competitive advantage here.&lt;/p&gt;
&lt;h3 id=&#34;pricing&#34;&gt;Pricing&lt;/h3&gt;
&lt;p&gt;Pricing is a by-product of the balancing act described above. The pricing must be competitive enough to lure the supply and the demand pool. The driver should feel like the pricing justifies the time, effort, and resources supplied. The passenger should feel the amount paid for the service justifies the service received.&lt;/p&gt;
&lt;p&gt;Few ride-hailing services opt-out for transparent and fixed payment (i.e the price is only dictated by the distance to destination), while some have complex pricing strategies to stand out, lure passengers or drivers, and manage supply and demand effectively.&lt;/p&gt;
&lt;h3 id=&#34;dynamic-pricing&#34;&gt;Dynamic Pricing&lt;/h3&gt;
&lt;p&gt;Some ride-hailing services implement dynamic pricing as a way to balance the chicken and egg problem described above. This is a large-scale, complex analytics problem involving several variables. Additionally, driver bonuses, discounts, and referrals might constitute the pricing strategy as well.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://thumbor.forbes.com/thumbor/711x274/https://blogs-images.forbes.com/nicolemartin1/files/2019/03/dynamic-pricing.jpg?width=960&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Credit: Forbes&lt;/p&gt;
&lt;h3 id=&#34;competition-direct-and-indirect&#34;&gt;Competition (Direct and Indirect)&lt;/h3&gt;
&lt;h4 id=&#34;direct-competition-passenger&#34;&gt;Direct Competition (Passenger)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;other ride hailing services&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;direct-competition-driver&#34;&gt;Direct Competition (Driver)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;other ride-hailing services&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;indirect-competition-passenger&#34;&gt;Indirect Competition (Passenger)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;public transportation&lt;/li&gt;
&lt;li&gt;taxi/cab&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;indirect-competition-driver&#34;&gt;Indirect Competition (Driver)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;other employment opportunities&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://thumbor.forbes.com/thumbor/fit-in/1200x0/filters%3Aformat%28jpg%29/https%3A%2F%2Fblogs-images.forbes.com%2Fliyanchen%2Ffiles%2F2015%2F09%2F0908_uber-map2_2000-1940x1487.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Credit: Forbes&lt;/p&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;h2 id=&#34;descriptive-analysis&#34;&gt;Descriptive analysis&lt;/h2&gt;
&lt;p&gt;Before we build complex models, it is essential to understand how the business/service is performing. These descriptive analyses will lay the foundation for us when we build complex and combined models later on.&lt;/p&gt;
&lt;h3 id=&#34;ride-completioncancellation-rate&#34;&gt;Ride Completion/Cancellation rate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the ride completion rate?&lt;/li&gt;
&lt;li&gt;To be more granular, what is the ride completion rate at a geographic segment of the city at a particular time?&lt;/li&gt;
&lt;li&gt;What is the ride cancellation rate?&lt;/li&gt;
&lt;li&gt;Similar to before, what is the ride cancellation rate at a geographic segment of the city at a particular time?&lt;/li&gt;
&lt;li&gt;Why do passengers cancel rides?&lt;/li&gt;
&lt;li&gt;Is cancellation more prominent in one area compared to the other?&lt;/li&gt;
&lt;li&gt;Is this dependent on the time of the day?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;passenger_id&lt;/li&gt;
&lt;li&gt;driver_id&lt;/li&gt;
&lt;li&gt;latitude (pickup, drop)&lt;/li&gt;
&lt;li&gt;longitude (pickup, drop)&lt;/li&gt;
&lt;li&gt;timestamps (requested, accepted, picked up, dropped, canceled)&lt;/li&gt;
&lt;li&gt;completion_status&lt;/li&gt;
&lt;li&gt;cancellation_reason&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;late-arrival-rate&#34;&gt;Late arrival rate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the late arrival rate?&lt;/li&gt;
&lt;li&gt;what is the late arrival rate at a geographic segment of the city at a particular time?&lt;/li&gt;
&lt;li&gt;Is the late arrival rate prominent for some time of the day or for a particular geographical area?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;passenger_id&lt;/li&gt;
&lt;li&gt;driver_id&lt;/li&gt;
&lt;li&gt;latitude (pickup, drop)&lt;/li&gt;
&lt;li&gt;longitude (pickup, drop)&lt;/li&gt;
&lt;li&gt;timestamps (requested, accepted, picked up, dropped, canceled)&lt;/li&gt;
&lt;li&gt;completion_status&lt;/li&gt;
&lt;li&gt;cancellation_reason&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;activation-acquisition-retention-referral-revenue&#34;&gt;Activation, Acquisition, Retention, Referral, Revenue&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What does the pirate metric funnel look like?&lt;/li&gt;
&lt;li&gt;Is there a specific area where the business should focus to improve business/efficiency?&lt;/li&gt;
&lt;li&gt;Is the funnel leaking somewhere?&lt;/li&gt;
&lt;li&gt;What is the passenger/driver churn rate?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;passenger_id/driver_id&lt;/li&gt;
&lt;li&gt;timestamps (created_date, last_ride_date)&lt;/li&gt;
&lt;li&gt;total_amount_spent_on_platform / total_money_made&lt;/li&gt;
&lt;li&gt;total_rides&lt;/li&gt;
&lt;li&gt;num_of_referrals&lt;/li&gt;
&lt;li&gt;acquisition_channel&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://hygger.io/wp-content/uploads/2018/01/Main-EN.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Credit: hygger.io&lt;/p&gt;
&lt;h3 id=&#34;channels&#34;&gt;Channels&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the acquisition rate from different marketing channels for drivers or for passengers?&lt;/li&gt;
&lt;li&gt;What marketing channel is more apt/effective for different demography/user segments?&lt;/li&gt;
&lt;li&gt;Can we use the multi-arm bandits model to identify a balance between exploration and exploitation to test on different channels?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;passenger_id/driver_id&lt;/li&gt;
&lt;li&gt;timestamps (created_date)&lt;/li&gt;
&lt;li&gt;acquisition_channel&lt;/li&gt;
&lt;li&gt;total_amount_spent_on_platform / total_money_made&lt;/li&gt;
&lt;li&gt;passenger/driver demographic information (age, gender, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;user-analysis&#34;&gt;User Analysis&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What does the demography (social, cultural, economic) of the driver look like?&lt;/li&gt;
&lt;li&gt;What does the demography (social, cultural, economic) of the passenger look like?&lt;/li&gt;
&lt;li&gt;What does the demography of the city look like?&lt;/li&gt;
&lt;li&gt;What does the demography of the segment that uses the service the most look like?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;passenger_id/driver_id&lt;/li&gt;
&lt;li&gt;timestamps (created_date)&lt;/li&gt;
&lt;li&gt;acquisition_channel&lt;/li&gt;
&lt;li&gt;total_amount_spent_on_platform / total_money_made&lt;/li&gt;
&lt;li&gt;passenger/driver/city demographic information (age, gender etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;driver-rankingdriver-performance&#34;&gt;Driver Ranking/Driver Performance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;How is a driver performing? (this could be based on multiple factors including customer rating, and other factors)&lt;/li&gt;
&lt;li&gt;Based on the index for performance, what is the rank of a driver?&lt;/li&gt;
&lt;li&gt;What is the rank of a driver among a segment of drivers? (this will be useful for priority queue for driver dispatching)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;driver_id&lt;/li&gt;
&lt;li&gt;timestamps&lt;/li&gt;
&lt;li&gt;average_rating&lt;/li&gt;
&lt;li&gt;rides_complete_rate&lt;/li&gt;
&lt;li&gt;last_ride_date&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;h2 id=&#34;predictive-analysis&#34;&gt;Predictive analysis&lt;/h2&gt;
&lt;p&gt;If we are looking to make the system more efficient, it is also very important to understand what the future holds.&lt;/p&gt;
&lt;h3 id=&#34;growth-in-rides&#34;&gt;Growth in rides&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the number of expected daily rides next day/week/month/year?&lt;/li&gt;
&lt;li&gt;What is the expected revenue for the next day/week/month/year?&lt;/li&gt;
&lt;li&gt;Is there a daily/weekly/monthly seasonality?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;timestamp (daily)&lt;/li&gt;
&lt;li&gt;num_of_ride (completed rides or ride requests)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;passenger-growth&#34;&gt;Passenger growth&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the number of expected passenger growth next day/week/month/year?&lt;/li&gt;
&lt;li&gt;Is there a daily/weekly/monthly seasonality?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;timestamp (daily)&lt;/li&gt;
&lt;li&gt;num_of_unique_passengers (acquisition or ride request)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;driver-growth&#34;&gt;Driver growth&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the number of expected driver growth next day/week/month/year?&lt;/li&gt;
&lt;li&gt;Is there a daily/weekly/monthly seasonality?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;timestamp (daily)&lt;/li&gt;
&lt;li&gt;num_of_unique_drivers (acquisition or ride request)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;churn-over-the-period-of-time&#34;&gt;Churn over the period of time&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is the expected churn in the next day/week/month/year?&lt;/li&gt;
&lt;li&gt;Is there a daily/weekly/monthly seasonality?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DATA&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;timestamp (passenger acquisition)&lt;/li&gt;
&lt;li&gt;passenger&amp;rsquo;s number of rides each month (grouped acquisition to present)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;h2 id=&#34;prescriptive-analysis&#34;&gt;Prescriptive analysis&lt;/h2&gt;
&lt;p&gt;Descriptive and Predictive analysis will help us move towards prescriptive analysis, especially for optimization models. These models will help the service provider in decision making, especially with regards to an increase in efficiency for drivers and passengers.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;ratio-of-drivers-to-passengers&#34;&gt;Ratio of drivers to passengers&lt;/h3&gt;
&lt;h4 id=&#34;what-is-the-ideal-ratio-of-the-passenger-to-the-driver-to-maximize-rides-completion-rate&#34;&gt;What is the ideal ratio of the passenger to the driver to maximize rides completion rate?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Given&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Voronoi clustering for geographic indexing based on geographic hotspots (other indexing methods are more efficient like h3 developed by Uber, but Voronoi can be used to build something similar as well.)&lt;/li&gt;
&lt;li&gt;rides data (requested, canceled, completed)&lt;/li&gt;
&lt;li&gt;passenger data (raw data and data after descriptive analysis performed: Pirate metrics etc.)&lt;/li&gt;
&lt;li&gt;driver data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Optimization
&lt;ul&gt;
&lt;li&gt;with constraints: num_of_rides should be greater than a threshold (comes from future rides data)&lt;/li&gt;
&lt;li&gt;with objective functions: maximize rides completion rate for each geographic segment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;to find an optimal driver to passenger ratio&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Regression (or logistic regression if we only care about a healthy/unhealthy ratio) can also be used to do something similar as well.&lt;/li&gt;
&lt;li&gt;Additionally, the result from the model can also be used to model advertisement campaigns for the future if we find the number of driver or passenger (in a particular geographic area) need to be increased for a stable ratio.&lt;/li&gt;
&lt;li&gt;This is an important indicator because it allows the service provider to focus on growth while keeping this indicator at a healthy level.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;dynamic-pricing-1&#34;&gt;Dynamic pricing&lt;/h3&gt;
&lt;h4 id=&#34;what-should-the-dynamicsurge-pricing-be-at-a-given-time&#34;&gt;What should the dynamic/surge pricing be at a given time?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Given&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;ratio of the driver to passenger&lt;/li&gt;
&lt;li&gt;paying capacity of passengers (based on descriptive analysis of users, useful for capping at some multiplier so that it does not go wild)&lt;/li&gt;
&lt;li&gt;number of requests in the queue in a geographic segment&lt;/li&gt;
&lt;li&gt;competition surge at the moment&lt;/li&gt;
&lt;li&gt;number of requests completed in the geographic segment (and neighboring segment) in last x minutes (arbitrary but can be defined by waiting for time analysis from descriptive analysis)&lt;/li&gt;
&lt;li&gt;geographic location information (grid-based on Voronoi for the availability of drivers in other cells)&lt;/li&gt;
&lt;li&gt;number of drivers that will be free (complete a ride soon or are predicted to come online soon) in the grid or neighboring grids&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Linear regression&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;to find ideal dynamic pricing multiplier&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The cap might/might not be necessary, and that might be another analytics problem altogether. There have been some cases where a natural disaster/terrorist attack increased surge multiplier to an exorbitant number causing massive backlash.&lt;/li&gt;
&lt;li&gt;grid above refers to one unit of Voronoi based geographic segmentation&lt;/li&gt;
&lt;li&gt;It is necessary to study the correlation of some of the predictors mentioned above.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;ride-dispatching&#34;&gt;Ride Dispatching&lt;/h3&gt;
&lt;h4 id=&#34;what-is-a-robust-ride-dispatching-mechanism-that-will-increase-passengers-and-drivers&#34;&gt;What is a robust ride dispatching mechanism that will increase passengers and drivers?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Given&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Drivers in Geographic Grid (and neighboring Grid)&lt;/li&gt;
&lt;li&gt;Driver Rating/Driver Ranking&lt;/li&gt;
&lt;li&gt;Geographic Grid&lt;/li&gt;
&lt;li&gt;Pickup/Drop location (distance and Grid)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Optimization
&lt;ul&gt;
&lt;li&gt;with constraints: the probability of each driver getting ride should be close to 1, waiting time should be less than some threshold for the request to be accepted  or not accepted (which comes from descriptive analysis), the time between request dispatching (time window a driver gets before the request is passed on to a different driver, also comes from descriptive analysis) should be equal to the acceptable waiting time divided by some constant (integer)&lt;/li&gt;
&lt;li&gt;with objective functions: maximize rides completion rate for each geographic segment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;** Notes **&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Queuing models can also be here to identify correct values for the dispatching system (waiting time, dynamic geographic grid, etc.). However, there is a need to check the distribution of different events (booking created, booking accepted, waiting time, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;It seems analytics is extremely relevant in all aspects of ride-hailing. In this project, I merely covered a few use cases, with one or two relevant models. Even with this brief exploration, I can conclude that analytics can lead to better outcomes for both drivers and passengers.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>