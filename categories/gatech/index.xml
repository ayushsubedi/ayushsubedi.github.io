<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>gatech on Ayush Subedi</title>
    <link>https://ayushsubedi.github.io/categories/gatech/</link>
    <description>Recent content in gatech on Ayush Subedi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 10 Sep 2023 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://ayushsubedi.github.io/categories/gatech/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Topics on High-Dimensional Data Analytics (Machine Learning 2)</title>
      <link>https://ayushsubedi.github.io/posts/topics_on_high_dimensional_data_analytics/</link>
      <pubDate>Sun, 10 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/topics_on_high_dimensional_data_analytics/</guid>
      <description>&lt;h1 id=&#34;topics-on-high-dimensional-data-analytics&#34;&gt;Topics on High-Dimensional Data Analytics&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#functional-data-analysis&#34;&gt;Functional Data Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#image-analysis&#34;&gt;Image Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tensor-data-analysis&#34;&gt;Tensor Data Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#optimization-application&#34;&gt;Optimization and Application&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#regularization&#34;&gt;Regularization&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;tensor-data-analysis&#34;&gt;Tensor Data Analysis&lt;/h1&gt;
&lt;h2 id=&#34;tensor-introduction&#34;&gt;Tensor Introduction&lt;/h2&gt;
&lt;p&gt;A tensor is an algebraic object that describes a multi-linear relationship between sets of algebraic objects related to a vector space. Tensors may map between different objects such as vectors, scalars, and even other tensors.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hkilter.com/images/7/7a/Tensors.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;terminologies&#34;&gt;Terminologies:&lt;/h3&gt;
&lt;h4 id=&#34;order&#34;&gt;Order&lt;/h4&gt;
&lt;p&gt;The order of a tensor refers to the number of indices or subscripts needed to specify its components in a given coordinate system. Tensors can have different orders, and the order determines their mathematical properties and how they transform under coordinate transformations. Here&amp;rsquo;s a brief overview of tensor orders:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zeroth-Order Tensor (Scalar)&lt;/strong&gt;: A zeroth-order tensor is also known as a scalar. It has no indices and represents a single numerical value. Scalars are invariant under coordinate transformations.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example: Temperature at a point in space.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;First-Order Tensor (Vector)&lt;/strong&gt;: A first-order tensor, also known as a vector, has one index. Vectors represent quantities with both magnitude and direction and transform linearly under coordinate transformations.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example: Velocity, force, displacement.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Second-Order Tensor (Matrix)&lt;/strong&gt;: A second-order tensor has two indices. It represents a linear transformation that maps one vector to another. Matrices are used to represent various physical quantities, such as stress tensors, moment of inertia tensors, and more.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example: Stress tensor, moment of inertia tensor.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Third-Order Tensor:&lt;/strong&gt; A third-order tensor has three indices, and it is used to represent more complex relationships between vectors and matrices. These tensors are less common but can arise in various physical and mathematical contexts.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example: Piezoelectric tensor in materials science.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/tensor_order.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;fibers&#34;&gt;Fibers&lt;/h4&gt;
&lt;p&gt;A fiber, the higher order analogue of matrix row and column, is defined by fixing every index but one, e.g.,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A matrix column is a mode-1 fiber and a matrix row is a mode-2 fiber&lt;/li&gt;
&lt;li&gt;Third-order tensors have column, row, and tube fibers&lt;/li&gt;
&lt;li&gt;Extracted fibers from a tensor are assumed to be oriented as column vectors.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/fibers.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;slices&#34;&gt;Slices&lt;/h4&gt;
&lt;p&gt;Two-dimensional sections of a tensor, defined by fixing all but two indices.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/slices.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;norm&#34;&gt;Norm&lt;/h4&gt;
&lt;p&gt;Norm of a tensor $X \in \R^{I_1 \times I_2 \times &amp;hellip;. \times I_N}$ is the square root of the sum of the squares of all its elements.&lt;/p&gt;
&lt;p&gt;This is analogous to the matrix Frobenius norm, which is denoted $||A||_F$ for matrix $A$&lt;/p&gt;
&lt;h4 id=&#34;outer-product&#34;&gt;Outer Product&lt;/h4&gt;
&lt;p&gt;A multi-way vector outer product is a tensor where each element is the product of corresponding elements in vectors&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/outer_product.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;inner-product&#34;&gt;Inner Product&lt;/h4&gt;
&lt;p&gt;The inner product of two tensors is a generalization of the dot product operation for vectors as calculated by dot. A dot product operation (multiply and sum) is performed on all corresponding dimensions in the tensors, so the operation returns a scalar value. For this operation, the tensors must have the same size.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/innter_product.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;using-tensorly-for-inner-and-outer-product&#34;&gt;Using Tensorly for inner and outer product&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorly &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Define the shape of the random tensors&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Generate random data for X and Y using NumPy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;X_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;shape)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Y_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;shape)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Convert the NumPy arrays to TensorLy tensors&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(X_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(Y_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Calculate the inner product of X and Y&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;inner_product &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tenalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner(X, Y)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Calculate the outer product of X and Y&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;outer_product &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tenalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;outer(X, Y)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the results&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Inner Product:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(inner_product)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Outer Product:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(outer_product)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;using-tensorly-for-unfolding-and-flattening&#34;&gt;Using Tensorly for unfolding, and flattening&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Unfold an N-way tensor into a matrix&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorly &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a random 2x2x2 tensor&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;random_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tensor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(random_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Mode-1 matricization (unfold along the first mode)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mode1_matricization &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unfold(tensor, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Mode-2 matricization (unfold along the second mode)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mode2_matricization &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unfold(tensor, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Mode-3 matricization (unfold along the third mode)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mode3_matricization &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unfold(tensor, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the results&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Mode-1 Matricization:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(mode1_matricization)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Mode-2 Matricization:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(mode2_matricization)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Mode-3 Matricization:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(mode3_matricization)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/matrixization.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;tensor-multiplication&#34;&gt;Tensor Multiplication&lt;/h2&gt;
&lt;p&gt;The n-mode product is referred to as multiplying a tensor by a matrix (or a vector) in mode n.&lt;/p&gt;
&lt;p&gt;The n-mode (matrix) product of a tensor $X \in \R^{I_1 \times I_2 \times &amp;hellip;. \times I_N}$ with a matrix $U \in R^{J \times I_n}$ is denoted by $X \times_n U$ and is of size $I_1 \times I_2 \times &amp;hellip;. \times I_{n-1} \times J \times J_{n+1} \times &amp;hellip;\times I_N $&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorly &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a random 3x2x4 tensor&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;random_tensor_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tensor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(random_tensor_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a random matrix compatible with mode-1 multiplication&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;random_matrix_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(random_matrix_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Multiply the tensor and matrix in mode-1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tenalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mode_dot(tensor, matrix, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the result&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Random Tensor:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(tensor)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Random Matrix:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(matrix)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Result of Mode-1 Multiplication:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(result)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;n-mode-vector-product&#34;&gt;n-Mode Vector Product&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorly &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a random 3x2x4 tensor&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;random_tensor_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tensor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(random_tensor_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a random vector compatible with mode-1 multiplication&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;random_vector_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(random_vector_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Multiply the tensor and vector in mode-1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tenalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mode_dot(tensor, vector, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the random tensor, random vector, and the result of Mode-1 multiplication&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Random Tensor:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(tensor)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Random Vector:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(vector)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Result of Mode-1 Multiplication:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(result)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;kronecker-product&#34;&gt;Kronecker Product&lt;/h4&gt;
&lt;p&gt;The Kronecker product, denoted by ⊗, is a mathematical operation that combines two matrices to create a larger matrix. It is a tensor product of two matrices and results in a block matrix where each block is a scalar multiple of one of the elements of the first matrix, multiplied by the second matrix.&lt;/p&gt;
&lt;p&gt;The Kronecker Product of matrices $A \in R^{I \times J}$ and $B \in R^{K \times L}$ is denoted by $A \bigotimes B$. The result is a matrix size ($IK) \times (JL)$ and defined by&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/kronecker.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;examples&#34;&gt;Examples&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://wikimedia.org/api/rest_v1/media/math/render/svg/74fc4867467d053ae700ebb040ddfbe42600288c&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wikimedia.org/api/rest_v1/media/math/render/svg/1d5453c59a261174eb2458c21ff9bdd30dc2c87d&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create two matrices&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;A &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;B &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Compute the Kronecker product&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kronecker_product &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kron(A, B)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the result&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Kronecker Product:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(kronecker_product)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;khatri-rao-product&#34;&gt;Khatri-Rao Product&lt;/h4&gt;
&lt;p&gt;The Khatri-Rao product, also known as the column-wise Kronecker product or simply the Khatri-Rao product, is an operation on two matrices that results in a matrix. It&amp;rsquo;s used in various applications in signal processing and linear algebra, especially in multilinear models and factorization problems. The Khatri-Rao product is denoted by ⊙.&lt;/p&gt;
&lt;p&gt;Given two matrices, A of size m x n and B of size p x n, the Khatri-Rao product of A and B results in a matrix C of size (m * p) x n, where each column of C is formed by taking the Kronecker product of the corresponding columns of A and B.&lt;/p&gt;
&lt;h4 id=&#34;example&#34;&gt;Example&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://wikimedia.org/api/rest_v1/media/math/render/svg/311fb96a2459096ea05d8f0461e67a8b49f5ee43&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;so that:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wikimedia.org/api/rest_v1/media/math/render/svg/1e951f306d0dd52a9a56a35d767f2117db8a5ee6&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create two matrices A and B&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;A &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;B &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Compute the Khatri-Rao product&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;C &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kron(A, B)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the result&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Khatri-Rao Product:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(C)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;If a and b are vectors, then the Khatri-Rao and Kronecker products are identical&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;hadamard-product&#34;&gt;Hadamard Product&lt;/h4&gt;
&lt;p&gt;The Hadamard product, also known as the element-wise product or Schur product, is an operation between two matrices or vectors of the same size, resulting in another matrix or vector of the same size. In this operation, each element of the resulting matrix is the product of the corresponding elements of the input matrices. It is denoted by ⊙.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create two matrices or vectors of the same size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;A &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;B &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Compute the Hadamard product&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;C &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; B
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the result&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hadamard Product:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(C)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;tensor-decomposition&#34;&gt;Tensor Decomposition&lt;/h2&gt;
&lt;!-- ## Tensor Decomposition Methods - CP Decomposition
## Tensor Decomposition Methods - Tucker Decomposition
## Tensor Analysis Applications I
## Tensor Analysis Application II --&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;h3 id=&#34;big-data&#34;&gt;Big Data&lt;/h3&gt;
&lt;p&gt;Big data is a term used to describe extremely large and complex datasets that traditional data processing applications are not well-equipped to handle. The concept of &amp;ldquo;big data&amp;rdquo; is often associated with what is referred to as the &amp;ldquo;4V&amp;rdquo; framework, which describes the key characteristics of big data:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Volume:&lt;/strong&gt;  This refers to the sheer scale of data generated and collected. Big data involves datasets that are too large to be managed and processed using traditional databases and tools. This massive volume can range from terabytes to petabytes and beyond.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Velocity:&lt;/strong&gt;  This characteristic pertains to the speed at which data is generated, collected, and processed. In today&amp;rsquo;s fast-paced digital world, data is generated at an unprecedented rate, often in real-time or near-real-time. Examples include social media interactions, sensor data from IoT devices, financial transactions, and more.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Variety:&lt;/strong&gt;  Big data comes in various formats and types, such as structured, semi-structured, and unstructured data. Structured data is organized into a well-defined format (e.g., tables in a relational database), whereas unstructured data lacks a specific structure (e.g., text documents, images, videos, social media posts). Semi-structured data lies somewhere in between, having a partial structure but not fitting neatly into traditional databases.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Veracity:&lt;/strong&gt;  Veracity refers to the quality and reliability of the data. With the proliferation of data sources, there&amp;rsquo;s an increased potential for data to be incomplete, inaccurate, or inconsistent. Ensuring the accuracy and trustworthiness of big data is a significant challenge, and data quality management is crucial for meaningful insights.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;high-dimensional-data&#34;&gt;High Dimensional Data&lt;/h3&gt;
&lt;p&gt;High-dimensional data refers to datasets where the number of features or variables (dimensions) is significantly larger than the number of observations or samples. In other words, the data has a high number of attributes compared to the number of data points available. This kind of data is prevalent in various fields such as genomics, image analysis, social networks, and more.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/high_dimensional_.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;difference-between-high-dimensional-data-and-big-data&#34;&gt;Difference between High Dimensional Data and Big Data&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/diff_bet_high_and_low.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;p = dimension
n = samples&lt;/p&gt;
&lt;h3 id=&#34;the-curse-of-dimensionality&#34;&gt;The Curse of Dimensionality&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;As the number of features or dimensions grows, the amount of data we need to generalize accurately grows exponentially!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/distance_dimension.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;As distance between observations increases with the dimensions, the sample size required for learning a model drastically increases.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Increased Sparsity:&lt;/strong&gt;  In higher dimensions, the available data points are spread out more thinly across the space. This means that data points become farther apart from each other, making it challenging to find meaningful clusters or patterns. It&amp;rsquo;s like having a lot of points scattered in a large, high-dimensional space, and they&amp;rsquo;re so spread out that it&amp;rsquo;s difficult to identify any consistent relationships.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;More Data Needed:&lt;/strong&gt;  With higher-dimensional data, you need a disproportionately larger amount of data to capture the underlying patterns accurately. When the data is sparse, it&amp;rsquo;s harder to generalize from the observed points to make accurate predictions or draw conclusions. As the dimensionality increases, you might need exponentially more data to maintain the same level of accuracy in your models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Impact on Complexity:&lt;/strong&gt;  The complexity of machine learning models increases with dimensionality. More dimensions mean more parameters to estimate, which can lead to overfitting – a situation where a model fits the training data too closely and fails to generalize well to new data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Increased Computational Demands:&lt;/strong&gt;  Processing and analyzing high-dimensional data require more computational resources and time. Many algorithms become slower and more memory-intensive as the number of dimensions grows. This can make experimentation and model training more challenging and time-consuming.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Difficulties in Visualization:&lt;/strong&gt;  Our ability to visualize data effectively diminishes as the number of dimensions increases. We are accustomed to thinking in 2D and 3D space, but visualizing data in, say, 10 dimensions is practically impossible. This can make it hard to understand the structure of the data and the relationships between variables.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;low-dimensional-learning-from-high-dimensional-data&#34;&gt;Low Dimensional Learning From High Dimensional Data&lt;/h3&gt;
&lt;p&gt;High dimensional data usually have low dimensional structure.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.mathworks.com/help/examples/stats/win64/ChangeTsneSettingsExample_01.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;This can be achieved through Functional Data Analysis, Tensor Analysis, Rank Deficient Methods among others.&lt;/p&gt;
&lt;h3 id=&#34;solutions-for-the-curse-of-dimensionality&#34;&gt;Solutions for the curse of dimensionality&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Feature extraction&lt;/li&gt;
&lt;li&gt;Dimensionality reduction&lt;/li&gt;
&lt;li&gt;Collecting much more observations&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;functional-data-analysis&#34;&gt;Functional Data Analysis&lt;/h1&gt;
&lt;p&gt;A fluctuating quantity or impulse whose variations represent information and is often represented as a function of time or space.&lt;/p&gt;
&lt;p&gt;From Wikipedia&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Functional data analysis (FDA)&lt;/strong&gt; is a branch of statistics that analyses data providing information about curves, surfaces or anything else varying over a continuum. In its most general form, under an FDA framework, each sample element of functional data is considered to be a random function. The physical continuum over which these functions are defined is often time, but may also be spatial location, wavelength, probability, etc. Intrinsically, functional data are infinite dimensional. The high intrinsic dimensionality of these data brings challenges for theory as well as computation, where these challenges vary with how the functional data were sampled. However, the high or infinite dimensional structure of the data is a rich source of information and there are many interesting challenges for research and data analysis.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://lands.let.ru.nl/FDA/images/FDA_pic4website.bmp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;regression---least-square-estimates&#34;&gt;Regression - Least square Estimates&lt;/h2&gt;
&lt;p&gt;A linear regression model assumes that the regression function $E(Y|X)$ is linear in the inputs $X_1, &amp;hellip;, X_p$. They were developed in the pre-computer age of statistics, but even in today&amp;rsquo;s computer era there are still good reasons to study and use them. They are simple and often provide an adequate and interpretable description of how the inputs affect the output.&lt;/p&gt;
&lt;p&gt;The linear regression model has the form:&lt;/p&gt;
&lt;p&gt;$f(X) = \beta_0 + \sum_{j=1}^p X_j\beta_j$&lt;/p&gt;
&lt;p&gt;Typically we have a set of training data $(x_1, y_1)&amp;hellip;(x_N, y_N)$ from which to estimate the parameters $\beta$. Each $x_i = (x_{i1}, x_{i2} &amp;hellip; x_{ip})^T$ is a vector of feature measurements for the $i$th case. The most popular estimation method is the least squares, in which we pick the coefficients $\beta = (\beta_0, \beta_1,&amp;hellip;.\beta_p)^T$ to minimize the residual sum of squares.&lt;/p&gt;
&lt;p&gt;$\sum_{i=1}^N (y_i - f(x))^2 = \sum_{i=1}^N (y_i - \beta_0 - \sum_{j=1}^p X_j\beta_j)^2$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/lr.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Denote $X$ by the $N \times (p+1)$ matrix with each row an input vector (with a 1 in the first position, to represent the intercept), and similarity let $y$ be the $N$ vector of outputs in the training set. Then we can write the residual sum-of-squares as :&lt;/p&gt;
&lt;p&gt;$RSS(\beta) = (y-X\beta)^T(y-X\beta)$&lt;/p&gt;
&lt;p&gt;Differentiating with respect to $\beta$, &amp;hellip;.&lt;/p&gt;
&lt;p&gt;$\hat{\beta} = (X^TX)^{-1}X^Ty$&lt;/p&gt;
&lt;h2 id=&#34;geometric-interpretation&#34;&gt;Geometric Interpretation&lt;/h2&gt;
&lt;p&gt;$\hat{y} = X\hat{\beta} = X(X^TX)^{-1}X^Ty = Hy $&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Projection Matrix&lt;/strong&gt; (or Hat matrix): The outcome vector $y$ is orthogonally projected onto the hyperplane spanned by the input vectors $x_1$ and $x_2$. The Projection $\hat{y}$ represents the vector of predictions obtained by the least square method.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/ols_projection.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;properties-of-ols&#34;&gt;Properties of OLS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;They are unbiased estimators. That is the expected value of estimators and actual parameters are the same $E(\hat{\beta}) = \beta$&lt;/li&gt;
&lt;li&gt;The covariance can be obtained by $cov(\hat{\beta}) = \sigma^2 (X^TX)^{-1}$, where $\sigma^2 = SSE/(n-p)$&lt;/li&gt;
&lt;li&gt;According to the &lt;strong&gt;Gauss-Markov Theorem&lt;/strong&gt;, &lt;em&gt;among all unbiased linear estimates&lt;/em&gt;, the least square estimate (LSE) has the minimum variance and it is unique.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Regression can be used for Feature Extraction&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;splines&#34;&gt;Splines&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Polynomial Regression&lt;/strong&gt; is a type of regression analysis where the relationship between the independent variable (input) and the dependent variable (output) is modeled as an nth-degree polynomial. In other words, instead of fitting a straight line (linear regression), a polynomial regression can fit curves of various degrees, allowing for more flexibility in capturing complex relationships. For example, a quadratic polynomial regression (degree 2) can model a parabolic relationship, and a cubic polynomial regression (degree 3) can model more intricate curves.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Polynomial regression is still considered a type of linear regression&lt;/strong&gt; because the relationship between the input and output variables is linear with respect to the coefficients, even though the input variables may be raised to different powers. The model equation for polynomial regression of degree n is:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$y = \beta_0 + \beta_1x + \beta_2x^2 + \beta_3x^3 + &amp;hellip; + \beta_mx^m + \epsilon$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nonlinear Regression&lt;/strong&gt;, on the other hand, refers to a broader class of regression models where the relationship between the independent and dependent variables is not a linear function. Nonlinear regression can encompass a wide range of functional forms, including exponential, logarithmic, sigmoidal, and other complex shapes. The main characteristic of nonlinear regression is that the model parameters are estimated in a way that best fits the chosen nonlinear function to the data.&lt;/p&gt;
&lt;p&gt;Unlike polynomial regression, nonlinear regression models can&amp;rsquo;t be expressed in terms of a simple equation with polynomial terms. The specific form of the nonlinear function needs to be determined based on the problem&amp;rsquo;s nature and domain knowledge.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disadvantages of Polynomial Regression&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Remote part of the function is very sensitive to outliers&lt;/li&gt;
&lt;li&gt;Less flexibility due to global function structure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/dis_pr.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The global function structure causes underfitting or overfitting.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The solution is to move from global to local structure -&amp;gt; Splines.&lt;/p&gt;
&lt;h3 id=&#34;splines-1&#34;&gt;Splines&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Linear combination of Piecewise Polynomial Function &lt;strong&gt;under continuity assumption&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Partition the domain of x into continuous intervals and fit polynomials in each interval separately&lt;/li&gt;
&lt;li&gt;Provides flexibility and local fitting&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Suppose $x \in [a,b]$. Partition the x domain using the following points (a.k.a knots):&lt;/p&gt;
&lt;p&gt;$a&amp;lt;\xi_1&amp;lt;\xi_2&amp;hellip;&amp;lt;\xi_k&amp;lt;b, &amp;lt;\xi_0=a, &amp;lt;\xi_{k+1}=b$&lt;/p&gt;
&lt;p&gt;Fit a polynomial in each interval under the continuity conditions and integrate them by&lt;/p&gt;
&lt;p&gt;$f(X) = \sum_{m=1}^K \beta_mh_m(X)$&lt;/p&gt;
&lt;h3 id=&#34;simple-example&#34;&gt;Simple Example&lt;/h3&gt;
&lt;h3 id=&#34;piecewise-constant&#34;&gt;Piecewise Constant&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/pwc.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here we are using a zero order polynomial. A zero order polynomial can be defined by an indicator function. If we use OLS, the beta would be the average of point in each local region.&lt;/p&gt;
&lt;p&gt;$f(X) = \sum_{m=1}^3 \beta_mh_m(X)$&lt;/p&gt;
&lt;h3 id=&#34;piecewise-linear&#34;&gt;Piecewise Linear&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/pwl.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here we are using a first order polynomial. A first order polynomial includes slopes and intercept (and therefore $K=6$ here.)&lt;/p&gt;
&lt;p&gt;$f(X) = \sum_{m=1}^6 \beta_mh_m(X)$&lt;/p&gt;
&lt;p&gt;There are two issues here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Discontinuity&lt;/li&gt;
&lt;li&gt;Underfitting&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;solving-for-discontinuity&#34;&gt;Solving for Discontinuity&lt;/h2&gt;
&lt;p&gt;We can impose continuity constraint for each knot:&lt;/p&gt;
&lt;p&gt;$f{\xi^-_1}=f(\xi^+_1)$&lt;/p&gt;
&lt;p&gt;This can be translated to $\beta_1+\xi_1\beta_4 = \beta_2 + \xi_1\beta_5$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Not sure how&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;By adding constraints we are losing some degrees of freedom.
The total number of free parameters (degree of freedom) = 6 (total number of parameters -2 (total number of constraints) = 4&lt;/p&gt;
&lt;p&gt;Alternatively, once could incorporate the constraints into the basis functions:&lt;/p&gt;
&lt;p&gt;$h_1(X) = 1$,&lt;/p&gt;
&lt;p&gt;$h_2(X) = X$,&lt;/p&gt;
&lt;p&gt;$h_3(X) = (X-\xi_1)_+$,&lt;/p&gt;
&lt;p&gt;$h_4(X) = (X-\xi_2)_+$&lt;/p&gt;
&lt;p&gt;This basis is known as truncated power basis&lt;/p&gt;
&lt;p&gt;$(X-\xi_k)_+ = (X-\xi_k)$ if $x \ge xi_k$ $0$ if $x&amp;lt;xi_k$&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/790G152GYz4?si=PIkkurtDgaioUCMu&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;solving-for-underfitting&#34;&gt;Solving for Underfitting&lt;/h2&gt;
&lt;p&gt;Splines with Higher Order of Continuity can be used to tackle underfitting.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/cp.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Continuity constraints for smoothness&lt;/p&gt;
&lt;p&gt;$f{\xi^-_1}=f(\xi^+_1)$&lt;/p&gt;
&lt;p&gt;$f^&amp;rsquo;{\xi^-_1}=f^&amp;rsquo;(\xi^+_1)$&lt;/p&gt;
&lt;p&gt;$f^{&amp;rsquo;&amp;rsquo;}{\xi^-_1}=f^{&amp;rsquo;&amp;rsquo;}(\xi^+_1)$&lt;/p&gt;
&lt;p&gt;$h_1(X) = 1$,&lt;/p&gt;
&lt;p&gt;$h_2(X) = X$,&lt;/p&gt;
&lt;p&gt;$h_3(X) = X^2$,&lt;/p&gt;
&lt;p&gt;$h_4(X) = X^3$,&lt;/p&gt;
&lt;p&gt;$h_5(X) = (X-\xi_1)^3_+$,&lt;/p&gt;
&lt;p&gt;$h_6(X) = (X-\xi_2)^3_+$&lt;/p&gt;
&lt;p&gt;The degree of freedom is calculated by:
Number of regions * Number of parameters in each region) - (Number of knots)*(Number of constraints per knot)&lt;/p&gt;
&lt;h2 id=&#34;order-m-splines&#34;&gt;Order-M Splines&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;M=1 piecewise-constant splines&lt;/li&gt;
&lt;li&gt;M=2 linear splines&lt;/li&gt;
&lt;li&gt;M=3 quadratic splines&lt;/li&gt;
&lt;li&gt;M=4 cubic splines&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For Truncated power basis functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Total degree of freedom is K+M&lt;/li&gt;
&lt;li&gt;Cubic spline is the lowest order spline for which the knot discontinuity is not visible to human eyes&lt;/li&gt;
&lt;li&gt;Knots selection: a simple method is to use x quantiles. However, the choice of knots is a variable/model selection problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;estimation&#34;&gt;Estimation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;After creating the basis function, we can use OLS to estimate parameters $\beta$&lt;/li&gt;
&lt;li&gt;First of all, create a basis matrix by concatinating basis vectors. For example if we have cubic splines with two knots, we will have six basis vectors.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$H = [h_1(x) \quad h_2(x) \quad h_3(x) \quad h_4(x) \quad h_5(x) \quad h_6(x)]$&lt;/p&gt;
&lt;p&gt;gives $\hat\beta = (H^TH)^-1H^Ty$&lt;/p&gt;
&lt;p&gt;Linear Smoother: $\hat y= H\hat\beta = H(H^TH)^{-1}H^Ty = Sy$&lt;/p&gt;
&lt;p&gt;Degrees of Freedom $df=trace S$&lt;/p&gt;
&lt;p&gt;Although truncated power basis functions are simple and algebraically appealing, it is not efficient for computation and ill-posed and numerically unstable. The matrix is close to singular (because of correlations among themselves, and determinant being very close to zero), and inverting it becomes challenging.&lt;/p&gt;
&lt;p&gt;The solution is to user Bsplines.&lt;/p&gt;
&lt;h2 id=&#34;bsplines&#34;&gt;Bsplines&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Alternative basis vectors for piecewise polynomials that are computationally more efficient&lt;/li&gt;
&lt;li&gt;Each basis function has a local support, that is, it is nonzero over at most M (spline order) consecutive intervals&lt;/li&gt;
&lt;li&gt;The basis matrix is banded&lt;/li&gt;
&lt;li&gt;The low bandwidth of the matrix reduces the linear dependency of the columns, and therefore, removes the numeric column stability.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/bspline.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;bspline-basis&#34;&gt;Bspline Basis&lt;/h2&gt;
&lt;p&gt;Let $B_{j,m}(x)$ be the $j^{th}$ B-spline basis function of order $m(m \le M)$ for the knot sequence $\tau$&lt;/p&gt;
&lt;p&gt;$a &amp;lt; \xi_1 &amp;lt; \xi_2 &amp;lt; &amp;hellip; &amp;lt; \xi_k &amp;lt; b$&lt;/p&gt;
&lt;p&gt;Define the augmented knots sequence $\tau$&lt;/p&gt;
&lt;p&gt;$\tau_1 \le \tau_2 &amp;hellip;\le \tau_M \le \xi_0$ (before the lower bound)&lt;/p&gt;
&lt;p&gt;$\tau_{M+j} = \xi_j, j = 1, &amp;hellip; , K$&lt;/p&gt;
&lt;p&gt;$\xi_{K+1} \le \tau_{M+K+1} \le \tau_{M+K+2} \le &amp;hellip; \le \tau_{2M+K}$ (after the lower bound)&lt;/p&gt;
&lt;h3 id=&#34;smoother-matrix&#34;&gt;Smoother Matrix&lt;/h3&gt;
&lt;p&gt;Consider a regression Spline basis B&lt;/p&gt;
&lt;p&gt;$\hat f = B(B^TB)^{-1}B^Ty = Hy$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;H is the smoother matrix (projection matrix)&lt;/li&gt;
&lt;li&gt;H is idempotent ($H \times H = H$)&lt;/li&gt;
&lt;li&gt;H is symmetric&lt;/li&gt;
&lt;li&gt;Degrees of freedom trace (H)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;smoothing-splines&#34;&gt;Smoothing Splines&lt;/h2&gt;
&lt;h3 id=&#34;bspline-basis-boundary-issue&#34;&gt;Bspline basis boundary issue&lt;/h3&gt;
&lt;p&gt;Consider the following setting with the fixed training data&lt;/p&gt;
&lt;p&gt;$y_i = f(x_i) + \epsilon_i$&lt;/p&gt;
&lt;p&gt;$\epsilon_i \approx iid(0, \sigma^2)$&lt;/p&gt;
&lt;p&gt;$Var(\hat f(x)) = h(x)^T(H^TH)^{-1}h(x)\sigma^2$ (variance of estimated function using spline)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Behavior of splines tends to be sporadic near the boundaries, and extrapolation can be problematic. The main reason is that the complexity of Cubic Spline is more than the complexity of Global Cubic Polynomial, due to the large number of parameters (less bias, more variance). The solution is to use linear splines instead of cubic splines (Natural Cubic Splines).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;natural-cubic-splines&#34;&gt;Natural Cubic Splines&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Additional constraints are added to make the function linear beyond the boundary knots&lt;/li&gt;
&lt;li&gt;Assuming the function is linear near the boundaries (where there is less information) is often reasonable&lt;/li&gt;
&lt;li&gt;Cubic spline; linear on $[-\inf, \xi_1]$ and $[\xi_k , \inf]$&lt;/li&gt;
&lt;li&gt;Prediction variance decreases&lt;/li&gt;
&lt;li&gt;The price is the bias near the boundaries&lt;/li&gt;
&lt;li&gt;Degrees of freedom is K, the number of knots&lt;/li&gt;
&lt;li&gt;Each of these basis functions has zero second and third derivative in the linear region.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;penalized-residual-sum-of-squares&#34;&gt;Penalized residual sum of squares&lt;/h2&gt;
&lt;p&gt;$\min_f \frac{1}{n}\sum_{i-1}^n[y_i - f(x_i)]^2+\lambda \int^a_b[f^{&amp;quot;}(x)^2dx]$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first term measures the closeness of the model to the data (related to bias)&lt;/li&gt;
&lt;li&gt;The second term penalizes curvature of the function (related to variance)&lt;/li&gt;
&lt;li&gt;$\lambda$ is the smoothing parameter controlling the trade between bias and variance&lt;/li&gt;
&lt;li&gt;$\lambda = 0$ interpolate the data (overfitting)&lt;/li&gt;
&lt;li&gt;$\lambda = \inf$ linear least-square regression (underfitting)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It can be shown that the minimizer is a natural cubic spline.&lt;/p&gt;
&lt;p&gt;Solution: $\hat \theta = (N^TN + \lambda\Omega)^{-1}N^Ty$
, $\Omega$ represents the second derivative&lt;/p&gt;
&lt;p&gt;$ f = (N^TN + \lambda\Omega)^{-1}N^Ty = S_\lambda y$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Smoothing spline estimator is a linear smoother&lt;/li&gt;
&lt;li&gt;$S_\lambda$ is the smoother matrix&lt;/li&gt;
&lt;li&gt;$S_\lambda$ is NOT idempotent&lt;/li&gt;
&lt;li&gt;$S_\lambda$ is symmetric&lt;/li&gt;
&lt;li&gt;$S_\lambda$ is positive definite&lt;/li&gt;
&lt;li&gt;Degrees of freedom: trace($S_\lambda$)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;choice-of-tuning-parameters&#34;&gt;Choice of Tuning Parameters&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Train Test Validation
&lt;img src=&#34;https://ayushsubedi.github.io/img/pt.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cross Validation
If an independent validation dataset is not affordable, the K-fold cross validation or leave-one-out CV can be useful&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Akaike Information Criteria (AIC)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bayesian Information Criteria (BIC)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generalized Cross-validation&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kernel-smoothers&#34;&gt;Kernel Smoothers&lt;/h2&gt;
&lt;h3 id=&#34;k-nearest-neighbor-knn&#34;&gt;K-Nearest Neighbor (KNN)&lt;/h3&gt;
&lt;p&gt;KNN Average $\hat f(x_0) = \sum_{i=1}^nw(x_0, x_i)y_i$&lt;/p&gt;
&lt;p&gt;where $\sum_{i=1}^nw(x_0, x_i)$ = $\frac{1}{K}$ if $x_i \in N_k(x_0)$ else $0$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple average of the k nearest observations to $x_0$ (local averaging)&lt;/li&gt;
&lt;li&gt;Equal weights are assigned to all neighbors&lt;/li&gt;
&lt;li&gt;However, the fitted function is in the form of a step function (non-smooth function)&lt;/li&gt;
&lt;li&gt;Also, the bias is quite high&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kernel-function&#34;&gt;Kernel Function&lt;/h3&gt;
&lt;p&gt;Any non-negative real-valued integrable function that satisfies the following conditions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\int_{-\inf}^{\inf}K(u)du=1$&lt;/li&gt;
&lt;li&gt;K is an even function; $K(-u) = K(u)$&lt;/li&gt;
&lt;li&gt;It has a finite second moment; $u^2\int_{-\inf}^{\inf}K(u)du &amp;lt; \inf$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kernel-smoother-regression&#34;&gt;Kernel Smoother Regression&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Kernel Regression&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is weighted local averaging that fits a simple model separately at each query point $x_0$&lt;/li&gt;
&lt;li&gt;More weights are assigned to closer observation&lt;/li&gt;
&lt;li&gt;Localization is defined by the weighting function&lt;/li&gt;
&lt;li&gt;Kernel regression requires little training, all calculations get done at the evaluation time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/kregression.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;choice-of-lambda&#34;&gt;Choice of $\lambda$&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$\lambda$ defines the width of the neighbourhood&lt;/li&gt;
&lt;li&gt;Only points withing $[x_0-\lambda, x_0+\lambda]$ receive positive weights&lt;/li&gt;
&lt;li&gt;Smaller $\lambda$: rough estimate, larger bias, smaller variance&lt;/li&gt;
&lt;li&gt;Larger $\lambda$: smoother estimate, smaller bias, larger variance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cross-validation can be used for determining of $\lambda$:&lt;/p&gt;
&lt;h3 id=&#34;drawbacks-of-local-averaging&#34;&gt;Drawbacks of Local Averaging&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The local averaging can be biased on the boundaries of the domain due to the asymmetry of the kernel in that region.&lt;/li&gt;
&lt;li&gt;This can be solved by local linear regression&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/nw_kernel.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Local linear regression corrects the bias on the boundaries&lt;/li&gt;
&lt;li&gt;Local polynomial regression corrects the bias in the curvature region&lt;/li&gt;
&lt;li&gt;However, local polynomial regression is complex due to higher order of polynomials, therefore, it increases the prediction variance.&lt;/li&gt;
&lt;li&gt;A good solution would be to use local linear model for points in the boundaries, and local quadratic regression in the interior regions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;functional-principal-component&#34;&gt;Functional Principal Component&lt;/h2&gt;
&lt;p&gt;Similar to PCA, FPCA aims to reduce the dimension of functional data by extracting a small set of uncorrelated features, which capture the most of the variation.&lt;/p&gt;
&lt;p&gt;Functional data (observed signals) are comprised of two main components. The first component is the continuous functional mean, and the second component is the error term, that is, the realizations from a stochastic process with mean function 0 and covariance function $C(t, t^&amp;rsquo;)$. It includes both random noise and signal-to-signal variations&lt;/p&gt;
&lt;p&gt;$s_i(t) = \mu(t) + \epsilon_i(t)$&lt;/p&gt;
&lt;p&gt;The mean function is common across all signals (notice that it does not have the $i$ subscript)&lt;/p&gt;
&lt;p&gt;Since signal variance comes from the noise function, we first focus on this for dimensionality reduction using the Karhunen-Loeve Theorem.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/kl.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The variance of $\xi_{ik}$ quickly decays with k. Therefore, only a few $\xi_{ik}$ also known as FPC-scores, would be enough to accurately approximate the noise function. That is,&lt;/p&gt;
&lt;p&gt;$\epsilon_i(t) \approx \sum_{k=1}^K \xi_{ik}\phi_{k}(t)$&lt;/p&gt;
&lt;p&gt;Signals decomposition is given by&lt;/p&gt;
&lt;p&gt;$s_i(t) = \mu(t) + \epsilon_i(t) \implies \mu(t) + \sum_{k=1}^K \xi_{ik}\phi_{k}(t)$&lt;/p&gt;
&lt;h2 id=&#34;model-estimation&#34;&gt;Model Estimation&lt;/h2&gt;
&lt;p&gt;Both the mean and covariance is unknown, and should be measured using training data. In practice, we have two types of signals/data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complete signals: Sampled regularly&lt;/li&gt;
&lt;li&gt;Incomplete signals: Sampled irregularly, sparse, fragmented&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;steps-for-fpca-when-the-signals-are-incomplete&#34;&gt;Steps for FPCA when the signals are incomplete:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Estimate the mean function using local linear regression&lt;/li&gt;
&lt;li&gt;Estimate the raw covariance function using the estimated mean function&lt;/li&gt;
&lt;li&gt;Estimate the covariance surface using local quadratic regression&lt;/li&gt;
&lt;li&gt;Compute the Eigen functions&lt;/li&gt;
&lt;li&gt;Compute the FPC scores&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;image-analysis&#34;&gt;Image Analysis&lt;/h1&gt;
&lt;h2 id=&#34;introduction-to-image-processing&#34;&gt;Introduction to Image Processing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The process of processing raw images and extracting useful information for decision making.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Level 0:&lt;/strong&gt; Image representation (acquisition, sampling, quantization, compression)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Level 1:&lt;/strong&gt; Image to Image transformations (enhancement, filtering, restoration, smoothing, segmentation)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Level 2:&lt;/strong&gt; Image to vector transformation (feature extraction and dimension reduction)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Level 3:&lt;/strong&gt; Feature to decision mapping&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/image_analysis.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-an-image&#34;&gt;What is an Image?&lt;/h2&gt;
&lt;p&gt;A gray (color-RGB) image is a 2-D (3-D) light intensity function, $f (x_1, x_2)$, where $f$ measures brightness at position $f(x_1, x_2)$ . A digital gray (color) image is a representation of an image by a 2-D (3-D) array of discrete samples. &lt;strong&gt;Pixel&lt;/strong&gt; is referred to an element of the array.&lt;/p&gt;
&lt;p&gt;Possible values each pixel can have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Black and white image: 2&lt;/li&gt;
&lt;li&gt;8-bit Gray image: 256&lt;/li&gt;
&lt;li&gt;RGB: 256 x 256 x 256 = 16777216&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;basic-manipulation-in-python&#34;&gt;Basic Manipulation in Python&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Load the image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;your_image.jpg&amp;#39;&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# Replace with the path to your image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;original_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(image_path)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Check if the image was loaded successfully&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; original_image &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Error: Could not open or find the image.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Convert the image to grayscale&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    gray_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cvtColor(original_image, cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;COLOR_BGR2GRAY)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Convert the grayscale image to black and white using thresholding&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    _, binary_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;threshold(gray_image, &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;, cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;THRESH_BINARY)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Resize the image (e.g., to a width of 800 pixels while maintaining aspect ratio)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_width &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;800&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    aspect_ratio &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; original_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; original_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_height &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(new_width &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; aspect_ratio)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    resized_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(binary_image, (new_width, new_height))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Save the processed images to disk&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray_image.jpg&amp;#39;&lt;/span&gt;, gray_image)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;black_and_white_image.jpg&amp;#39;&lt;/span&gt;, binary_image)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imwrite(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;resized_image.jpg&amp;#39;&lt;/span&gt;, resized_image)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Images processed and saved successfully.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;image-transformation&#34;&gt;Image Transformation&lt;/h2&gt;
&lt;h3 id=&#34;image-histogram&#34;&gt;Image Histogram&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Histogram represents the distribution of gray levels.&lt;/li&gt;
&lt;li&gt;It is an estimate of the probability density function (pdf) of the underlying random process.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Image can be transformed by applying a function on the image matrix.&lt;/p&gt;
&lt;p&gt;$g(x,y) = T(f(x,y))$&lt;/p&gt;
&lt;p&gt;For example if a threshold function is sued as the transformation function a gray-scale image can be converted to a BW image.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/step_function.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The brightness of an image can be changed by shifting its histogram.&lt;/li&gt;
&lt;li&gt;The contrast of an image is defined by the difference in maximum and minimum pixel intensity.&lt;/li&gt;
&lt;li&gt;Gray level resolution refers to change in the shades or levels of gray in an image.&lt;/li&gt;
&lt;li&gt;The number of different colors in an image depends on bits per pixel (bpp).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$L = 2^{bpp}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gray level transformation is often used for image enchantment.&lt;/li&gt;
&lt;li&gt;Three typical transformation functions are:
&lt;ul&gt;
&lt;li&gt;Linear (negative image)&lt;/li&gt;
&lt;li&gt;Log&lt;/li&gt;
&lt;li&gt;Power-Law&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convolution-and-image-filtering&#34;&gt;Convolution and image filtering&lt;/h3&gt;
&lt;p&gt;The convolution of functions $f$ and $g$ is defined by:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/convolutions.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Convolution is widely used in image processing for denoising, blurring, sharpening, embossing, and edge detection.&lt;/li&gt;
&lt;li&gt;Image filter is a convolution of a mask (aka kernel, and convolution matrix) with an image that can be used for blurring, sharpening, edge detection, etc.&lt;/li&gt;
&lt;li&gt;A mask is a matrix convolved with an image.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;image-convolution-with-a-mask&#34;&gt;Image Convolution with a Mask&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Flip the mask (kernel) both horizontally and vertically.&lt;/li&gt;
&lt;li&gt;Put the center element of the mask at every pixel of the image. Multiply the corresponding elements and then add them up. Replace the pixel value corresponding to the center of the mask with the resulting sum.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/convolution.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For pixels on the border of image matrix, some elements of the mask might fall out of the image matrix. In this case, we can extend the image by adding zeros. This is known as padding.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/padding.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;denoising-of-smooth-images-using-splines&#34;&gt;Denoising of Smooth Images using Splines&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Another approach for denoising smooth images is to use local regression with smooth basis (eg. splines)&lt;/li&gt;
&lt;li&gt;Using Kronecker product, a 2D-spline basis can be generated from 1D basis matrices&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;image-segmentation&#34;&gt;Image Segmentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The main goal of image segmentation is to partition an image into multiple sets of pixels (segments)&lt;/li&gt;
&lt;li&gt;Image segmentation has been widely used for object detection, face and fingerprint recognition, medical imaging, video surveillance, etc.&lt;/li&gt;
&lt;li&gt;Various methods exist for image segmentation including:
&lt;ul&gt;
&lt;li&gt;Local and global thresholding&lt;/li&gt;
&lt;li&gt;Otsu&amp;rsquo;s method&lt;/li&gt;
&lt;li&gt;K-means clustering&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Thresholding is a simple segmentation approach that converts grayscale image to binary image by applying the thresholding function on histogram.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;otsus-method&#34;&gt;Otsu&amp;rsquo;s Method&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The goal is to automatically determine the threshold $t$ given an image histogram.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Otsu%27s_Method_Visualization.gif/440px-Otsu%27s_Method_Visualization.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get the histogram of the image&lt;/li&gt;
&lt;li&gt;Calculate group mean and variance&lt;/li&gt;
&lt;li&gt;Find the maximum value for the variance&lt;/li&gt;
&lt;li&gt;Threshold the image&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compute_otsu_criteria&lt;/span&gt;(im, th):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Otsu&amp;#39;s method to compute criteria.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# create the thresholded image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    thresholded_im &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(im&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    thresholded_im[im &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; th] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# compute weights&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    nb_pixels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; im&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;size
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    nb_pixels1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;count_nonzero(thresholded_im)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    weight1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nb_pixels1 &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; nb_pixels
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    weight0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; weight1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# if one of the classes is empty, eg all pixels are below or above the threshold, that threshold will not be considered&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# in the search for the best threshold&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; weight1 &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; weight0 &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# find all pixels belonging to each class&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    val_pixels1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; im[thresholded_im &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    val_pixels0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; im[thresholded_im &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# compute variance of these classes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    var1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;var(val_pixels1) &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(val_pixels1) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    var0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;var(val_pixels0) &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(val_pixels0) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; weight0 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; var0 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; weight1 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; var1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;im &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# load your image as a numpy array.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# For testing purposes, one can use for example im = np.random.randint(0,255, size = (50,50))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# testing all thresholds from 0 to the maximum of the image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;threshold_range &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max(im)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;criterias &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [compute_otsu_criteria(im, th) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; th &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; threshold_range]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# best threshold is the one minimizing the Otsu criteria&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;best_threshold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; threshold_range[np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmin(criterias)]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;k-means-clustering-method&#34;&gt;K-Means Clustering Method&lt;/h3&gt;
&lt;p&gt;K-means clustering is a method for partitioning a set of observations to K clusters, such that the within-cluster variation is minimized.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rearrange the image pixels such that the number of rows in the resulting matrix is equal to the number of pixels and the number of columns is the same as the number of color channels&lt;/li&gt;
&lt;li&gt;Randomly select K centers&lt;/li&gt;
&lt;li&gt;Assign each pixel to the closest cluster&lt;/li&gt;
&lt;li&gt;Update the cluster mean&lt;/li&gt;
&lt;li&gt;Repeat the last two process until convergence&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;The objective of K-means is to minimize the within cluster variation, and maximize the inter-class variation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;edge-detection&#34;&gt;Edge Detection&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Edges are significant local changes of intensity in an image.&lt;/li&gt;
&lt;li&gt;Edge Detection: Detect pixel with sudden intensity change&lt;/li&gt;
&lt;li&gt;Often points that lie on an edge are detected by:
&lt;ul&gt;
&lt;li&gt;Detecting the local &lt;strong&gt;maxima&lt;/strong&gt; or &lt;strong&gt;minima&lt;/strong&gt; of the first derivative.&lt;/li&gt;
&lt;li&gt;Detecting the &lt;strong&gt;zero-crossings&lt;/strong&gt; of the second derivative.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/edge.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;sobel-operator&#34;&gt;Sobel Operator&lt;/h3&gt;
&lt;p&gt;The Sobel operator works by convolving an image with a pair of 3x3 kernels or filters, one for detecting edges in the horizontal direction (often referred to as the Sobel-X operator) and the other for detecting edges in the vertical direction (often referred to as the Sobel-Y operator). These kernels are as follows:&lt;/p&gt;
&lt;p&gt;Sobel-X Kernel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Sobel-Y Kernel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;krisch-operator&#34;&gt;Krisch Operator&lt;/h3&gt;
&lt;p&gt;Krisch is another derivative mask that finds the maximum edge strength in eight directions of a compass.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/kirsh.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It is more time consuming compare to Sobel&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;prewitt-mask&#34;&gt;Prewitt Mask&lt;/h3&gt;
&lt;p&gt;The Prewitt operator, like the Sobel operator, employs a pair of 3x3 convolution kernels, one for detecting edges in the horizontal direction and the other for detecting edges in the vertical direction.&lt;/p&gt;
&lt;p&gt;Here are the two Prewitt kernels:&lt;/p&gt;
&lt;p&gt;Prewitt-X Kernel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Prewitt-Y Kernel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;laplacian-and-laplacian-of-gaussian-mask&#34;&gt;Laplacian and Laplacian of Gaussian Mask&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Laplacian mask is a second order derivative mask.&lt;/li&gt;
&lt;li&gt;For noisy images, is combined with a Gaussian mask to reduce the noise&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Laplacian, Sobel, and Prewitt are masks used for edge detection. Gaussian is not a mask for edge detection.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Machine Learning for Trading</title>
      <link>https://ayushsubedi.github.io/posts/machine_learning_for_trading/</link>
      <pubDate>Sun, 04 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/machine_learning_for_trading/</guid>
      <description>&lt;h1 id=&#34;machine-learning-for-trading&#34;&gt;Machine Learning for Trading&lt;/h1&gt;
&lt;p&gt;Machine learning plays a vital role in trading by enabling the analysis of vast amounts of financial data and the development of predictive models. It leverages algorithms and statistical techniques to identify patterns, make predictions, and generate insights for informed trading decisions. Machine learning algorithms can be applied to various aspects of trading, including price prediction, risk management, portfolio optimization, market analysis, and automated trading. By leveraging machine learning, traders can uncover hidden patterns in data, adapt to changing market conditions, and improve decision-making processes, ultimately aiming to achieve better trading performance and profitability.&lt;/p&gt;
&lt;h1 id=&#34;sections&#34;&gt;Sections&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#manipulating-financial-data&#34;&gt;Manipulating Financial Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#computational-investing&#34;&gt;Computational Investing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#learning-algorithms-for-trading&#34;&gt;Learning algorithms for Trading&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;manipulating-financial-data&#34;&gt;Manipulating Financial Data&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://i.ytimg.com/vi/_z6I9K6Sy6A/maxresdefault.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;pandas&#34;&gt;Pandas&lt;/h2&gt;
&lt;p&gt;Pandas is a popular Python library that provides powerful data manipulation and analysis tools. It&amp;rsquo;s widely used for working with various types of data, including stock data analysis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Importing Pandas:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Loading Data:&lt;/strong&gt; Load the stock data into a Pandas DataFrame. There are various ways to load data, such as reading from a CSV file or querying an API. Here&amp;rsquo;s an example of loading data from a CSV file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;stock_data.csv&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Exploring Data:&lt;/strong&gt; Use various Pandas functions to explore and understand the data. Some commonly used functions include &lt;code&gt;head()&lt;/code&gt;, &lt;code&gt;tail()&lt;/code&gt;, &lt;code&gt;info()&lt;/code&gt;, &lt;code&gt;describe()&lt;/code&gt;, and &lt;code&gt;shape&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()  &lt;span style=&#34;color:#75715e&#34;&gt;# Display the first few rows of the DataFrame&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info()  &lt;span style=&#34;color:#75715e&#34;&gt;# Get information about the DataFrame&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe()  &lt;span style=&#34;color:#75715e&#34;&gt;# Statistical summary of the data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape  &lt;span style=&#34;color:#75715e&#34;&gt;# Get the number of rows and columns in the DataFrame&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Data Cleaning:&lt;/strong&gt; Perform any necessary data cleaning steps, such as handling missing values, removing duplicates, and converting data types.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dropna()  &lt;span style=&#34;color:#75715e&#34;&gt;# Drop rows with missing values&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop_duplicates()  &lt;span style=&#34;color:#75715e&#34;&gt;# Remove duplicate rows&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_datetime(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;])  &lt;span style=&#34;color:#75715e&#34;&gt;# Convert the &amp;#39;date&amp;#39; column to datetime&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Data Manipulation:&lt;/strong&gt; Pandas functions can be used to manipulate the data according to any analysis requirements. It can be used to filter rows, select specific columns, create new columns, apply mathematical operations, and more.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Selecting specific columns&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;close_price&amp;#39;&lt;/span&gt;]]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Filtering rows&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;volume&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000000&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Creating new columns&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;returns&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;close_price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pct_change()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Applying mathematical operations&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;moving_average&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;close_price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rolling(window&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Data Visualization:&lt;/strong&gt; Pandas can work well with other libraries like Matplotlib or Seaborn to create visualizations of the stock data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; plt
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;close_price&amp;#39;&lt;/span&gt;, title&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Stock Price&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;These are just a few examples of how Pandas can be used for stock data analysis. Pandas provides a wide range of functions and methods that can be used to manipulate, analyze, and visualize stock data effectively.&lt;/p&gt;
&lt;h3 id=&#34;slicing-and-indexing&#34;&gt;Slicing and indexing&lt;/h3&gt;
&lt;p&gt;Pandas provides several methods for slicing and indexing data in a DataFrame. Here are some commonly used techniques for slicing data with Pandas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Column Selection:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;To select a single column, the square bracket notation with the column name as a string can be used:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;column_name&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;To select multiple columns, provide a list of column names within the square brackets:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;column_name1&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;column_name2&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;]]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Row Selection:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;To select rows based on a specific condition, use boolean indexing:&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[condition]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;For example, to select rows where the &amp;lsquo;price&amp;rsquo; column is greater than 100:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Slicing Rows:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;To slice rows based on their position, use the &lt;code&gt;loc&lt;/code&gt; or &lt;code&gt;iloc&lt;/code&gt; accessor:&lt;/li&gt;
&lt;li&gt;&lt;code&gt;loc&lt;/code&gt; is label-based and inclusive of the endpoints.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;iloc&lt;/code&gt; is index-based and exclusive of the endpoints.&lt;/li&gt;
&lt;li&gt;For example, to slice the first five rows:&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]  &lt;span style=&#34;color:#75715e&#34;&gt;# Exclusive of the endpoint&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;To slice rows by labels, use:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[start_label:end_label]  &lt;span style=&#34;color:#75715e&#34;&gt;# Inclusive of the endpoints&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Slicing Rows and Columns:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;To slice both rows and columns simultaneously, use the &lt;code&gt;loc&lt;/code&gt; or &lt;code&gt;iloc&lt;/code&gt; accessor with row and column selections separated by a comma:&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[start_label:end_label, [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;column_name1&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;column_name2&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;]]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[start_index:end_index, [column_index1, column_index2, &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;]]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For example, to slice the first five rows and select columns &amp;lsquo;price&amp;rsquo; and &amp;lsquo;volume&amp;rsquo;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;volume&amp;#39;&lt;/span&gt;]]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;numpy&#34;&gt;Numpy&lt;/h2&gt;
&lt;p&gt;Numpy is a fundamental Python library that provides efficient numerical computing capabilities. It offers a powerful array data structure and a wide range of mathematical functions, making it useful for financial research and analysis. Here are some key points about Numpy focused on its application in financial research:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Numerical Data Handling:&lt;/strong&gt; Numpy provides the &lt;code&gt;ndarray&lt;/code&gt; (N-dimensional array) data structure, which is highly efficient for handling large volumes of numerical data. It allows for fast element-wise operations and supports various numerical data types, including integers, floating-point numbers, and complex numbers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Array Creation and Manipulation:&lt;/strong&gt; Numpy offers functions to create and manipulate arrays, such as &lt;code&gt;np.array()&lt;/code&gt;, &lt;code&gt;np.zeros()&lt;/code&gt;, &lt;code&gt;np.ones()&lt;/code&gt;, &lt;code&gt;np.arange()&lt;/code&gt;, and &lt;code&gt;np.linspace()&lt;/code&gt;. These functions are beneficial for creating arrays representing financial data, such as price series, returns, or volume data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mathematical Operations:&lt;/strong&gt; Numpy provides a comprehensive set of mathematical functions and operators that can be applied to arrays. These include basic arithmetic operations, statistical functions (&lt;code&gt;mean()&lt;/code&gt;, &lt;code&gt;std()&lt;/code&gt;, &lt;code&gt;min()&lt;/code&gt;, &lt;code&gt;max()&lt;/code&gt;, etc.), linear algebra functions (&lt;code&gt;dot()&lt;/code&gt;, &lt;code&gt;inv()&lt;/code&gt;, &lt;code&gt;eig()&lt;/code&gt;, etc.), and more advanced functions for trigonometry, exponentials, logarithms, and random number generation. These operations can be leveraged to perform calculations on financial data efficiently.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Aggregation and Summary Statistics:&lt;/strong&gt; Numpy functions are helpful for calculating summary statistics on financial data. Functions like &lt;code&gt;np.sum()&lt;/code&gt;, &lt;code&gt;np.mean()&lt;/code&gt;, &lt;code&gt;np.std()&lt;/code&gt;, &lt;code&gt;np.median()&lt;/code&gt;, and &lt;code&gt;np.percentile()&lt;/code&gt; allow you to calculate aggregate measures, central tendency, dispersion, and percentiles on arrays or subsets of data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Time Series Analysis:&lt;/strong&gt; Numpy provides tools for working with time series data, including date and time handling. The &lt;code&gt;np.datetime64&lt;/code&gt; data type enables storing and manipulating date and time values, allowing for easy handling of temporal aspects in financial research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Broadcasting and Vectorization:&lt;/strong&gt; Numpy&amp;rsquo;s broadcasting feature allows for performing element-wise operations between arrays of different shapes and sizes, making it efficient for vectorized calculations. This feature is particularly useful when working with arrays representing financial data, as it enables applying operations across entire arrays without explicit looping.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integration with Other Libraries:&lt;/strong&gt; Numpy plays a vital role in the scientific Python ecosystem and integrates well with other libraries commonly used in financial research. For example, Numpy arrays can be seamlessly used with Pandas DataFrames, providing efficient data processing and analysis capabilities.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By leveraging Numpy&amp;rsquo;s capabilities, financial researchers can efficiently handle and analyze large datasets, perform mathematical computations, calculate summary statistics, and conduct time series analysis. Its fast execution and integration with other libraries make it a valuable tool for financial research and analysis.&lt;/p&gt;
&lt;h2 id=&#34;global-statistics&#34;&gt;Global Statistics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;To calculate global statistics of stock prices in Python, you can use the Pandas library to load and manipulate stock price data. Here&amp;rsquo;s an example of how you can calculate common statistics such as mean, standard deviation, minimum, maximum, and percentiles for stock prices:
-Import the necessary libraries:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Load the stock price data into a Pandas DataFrame. Assuming you have a CSV file named &amp;lsquo;stock_prices.csv&amp;rsquo; with a &amp;lsquo;price&amp;rsquo; column containing the stock prices, you can use the following code:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;stock_prices.csv&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Calculate the desired statistics using Numpy functions on the &amp;lsquo;price&amp;rsquo; column:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mean_price &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;std_price &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;std(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;min_price &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;max_price &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;percentiles &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;percentile(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;75&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Print or use the calculated statistics as needed:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Mean price:&amp;#34;&lt;/span&gt;, mean_price)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Standard deviation:&amp;#34;&lt;/span&gt;, std_price)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Minimum price:&amp;#34;&lt;/span&gt;, min_price)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Maximum price:&amp;#34;&lt;/span&gt;, max_price)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;25th, 50th, and 75th percentiles:&amp;#34;&lt;/span&gt;, percentiles)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;rolling-statistics&#34;&gt;Rolling Statistics&lt;/h2&gt;
&lt;p&gt;To calculate rolling statistics for stock prices in Python, you can use the rolling window functionality provided by Pandas. Here&amp;rsquo;s an example of how you can calculate rolling mean and standard deviation for stock prices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Import the necessary libraries:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Load the stock price data into a Pandas DataFrame. Assuming you have a CSV file named &amp;lsquo;stock_prices.csv&amp;rsquo; with a &amp;lsquo;price&amp;rsquo; column containing the stock prices, you can use the following code:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;stock_prices.csv&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Convert the date column to a datetime type if it is not already in that format:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_datetime(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Sort the DataFrame by the date column in ascending order:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort_values(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Calculate the rolling mean and standard deviation using the &lt;code&gt;rolling()&lt;/code&gt; function on the &amp;lsquo;price&amp;rsquo; column:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;window_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# Define the rolling window size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rolling_mean&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rolling(window&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;window_size)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rolling_std&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rolling(window&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;window_size)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;std()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the code above, &lt;code&gt;window_size&lt;/code&gt; represents the number of observations to include in each rolling window. You can adjust it based on your specific requirements.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Print or use the rolling statistics as needed:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(df[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rolling_mean&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rolling_std&amp;#39;&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This code will display the &amp;lsquo;date&amp;rsquo;, &amp;lsquo;price&amp;rsquo;, &amp;lsquo;rolling_mean&amp;rsquo;, and &amp;lsquo;rolling_std&amp;rsquo; columns of the DataFrame, showing the calculated rolling statistics.&lt;/p&gt;
&lt;p&gt;By applying these steps, you can calculate rolling statistics, such as the rolling mean and standard deviation, for stock prices using Python and Pandas. Feel free to modify the code to incorporate additional rolling statistics or customize the output to suit your needs.&lt;/p&gt;
&lt;h2 id=&#34;bollinger-bands&#34;&gt;Bollinger bands&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.investopedia.com/thmb/XOTAkeqxe65MifNefOz1vGXiQq0=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/dotdash_Final_Using_Bollinger_Bands_to_Gauge_Trends_Oct_2020-01-73f4b5749a6e445585bc2751d6e39d34.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Bollinger Bands is a popular technical analysis tool used to identify potential price trends and volatility in financial markets. It consists of three lines plotted on a price chart: the middle band (usually a simple moving average), an upper band (typically two standard deviations above the middle band), and a lower band (usually two standard deviations below the middle band). Here&amp;rsquo;s an example of how you can calculate and plot Bollinger Bands using Python and Pandas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Import the necessary libraries:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; plt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Load the stock price data into a Pandas DataFrame. Assuming you have a CSV file named &amp;lsquo;stock_prices.csv&amp;rsquo; with a &amp;lsquo;price&amp;rsquo; column containing the stock prices, you can use the following code:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;stock_prices.csv&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Calculate the middle band, upper band, and lower band using rolling mean and standard deviation:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;window_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# Define the rolling window size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;middle_band&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rolling(window&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;window_size)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;std&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rolling(window&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;window_size)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;std()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;upper_band&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;middle_band&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;std&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lower_band&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;middle_band&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;std&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the code above, the &amp;lsquo;middle_band&amp;rsquo; is calculated as the rolling mean of the &amp;lsquo;price&amp;rsquo; column, while the &amp;lsquo;std&amp;rsquo; represents the rolling standard deviation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plot the Bollinger Bands:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;price&amp;#39;&lt;/span&gt;], label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;middle_band&amp;#39;&lt;/span&gt;], label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Middle Band&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;upper_band&amp;#39;&lt;/span&gt;], label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Upper Band&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lower_band&amp;#39;&lt;/span&gt;], label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Lower Band&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bollinger Bands&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Date&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;The code above will create a line plot with the stock price (&amp;lsquo;price&amp;rsquo;) and the Bollinger Bands: the middle band (&amp;lsquo;middle_band&amp;rsquo;), upper band (&amp;lsquo;upper_band&amp;rsquo;), and lower band (&amp;rsquo;lower_band&amp;rsquo;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;daily-returns&#34;&gt;Daily returns&lt;/h2&gt;
&lt;p&gt;Daily returns refer to the percentage change in the value of an asset from one trading day to the next. It is a commonly used metric to measure the performance and volatility of an asset over time. Daily returns can be calculated using the following mathematical equation:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Daily Return = (Price_today - Price_yesterday) / Price_yesterday
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;where Price_today is the closing price of the asset on the current day, and Price_yesterday is the closing price of the asset on the previous day.&lt;/p&gt;
&lt;p&gt;To calculate daily returns in Python, you can use the Pandas library. Here&amp;rsquo;s an example of Python code that calculates daily returns from a DataFrame containing historical price data:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Assuming you have a DataFrame named &amp;#39;df&amp;#39; with a &amp;#39;closing_price&amp;#39; column&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;daily_return&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;closing_price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pct_change()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the DataFrame with daily returns&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(df[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;closing_price&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;daily_return&amp;#39;&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the code above, the &lt;code&gt;pct_change()&lt;/code&gt; function is used to calculate the percentage change between consecutive values in the &amp;lsquo;closing_price&amp;rsquo; column. The result is stored in a new column named &amp;lsquo;daily_return&amp;rsquo; in the DataFrame.&lt;/p&gt;
&lt;p&gt;The printed DataFrame will display the &amp;lsquo;date&amp;rsquo;, &amp;lsquo;closing_price&amp;rsquo;, and &amp;lsquo;daily_return&amp;rsquo; columns, showing the historical prices and corresponding daily returns.&lt;/p&gt;
&lt;h2 id=&#34;cumulative-returns&#34;&gt;Cumulative returns&lt;/h2&gt;
&lt;p&gt;Cumulative returns, in finance and trading, represent the total percentage change in the value of an asset over a given period. It provides an understanding of the overall performance and growth of an investment over time. Cumulative returns can be calculated by multiplying the daily returns together and then subtracting 1. The mathematical equation for calculating cumulative returns is as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-scss&#34; data-lang=&#34;scss&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;Cumulative&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;Return&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;Daily&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;Return_1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;Daily&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;Return_2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;...&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;Daily&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;Return_n&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;where Daily Return_1, Daily Return_2, &amp;hellip;, Daily Return_n are the daily returns for each respective trading day.&lt;/p&gt;
&lt;p&gt;To calculate cumulative returns in Python, you can use the Pandas library. Here&amp;rsquo;s an example of Python code that calculates cumulative returns from a DataFrame containing daily return data:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Assuming you have a DataFrame named &amp;#39;df&amp;#39; with a &amp;#39;daily_return&amp;#39; column&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cumulative_return&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;daily_return&amp;#39;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cumprod() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the DataFrame with cumulative returns&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(df[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;daily_return&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cumulative_return&amp;#39;&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the code above, the &lt;code&gt;cumprod()&lt;/code&gt; function is used to calculate the cumulative product of the (1 + daily_return) values. The result is then subtracted by 1 to obtain the cumulative return. The cumulative returns are stored in a new column named &amp;lsquo;cumulative_return&amp;rsquo; in the DataFrame.&lt;/p&gt;
&lt;p&gt;The printed DataFrame will display the &amp;lsquo;date&amp;rsquo;, &amp;lsquo;daily_return&amp;rsquo;, and &amp;lsquo;cumulative_return&amp;rsquo; columns, showing the historical daily returns and corresponding cumulative returns.&lt;/p&gt;
&lt;h2 id=&#34;histograms-and-scatter-plots&#34;&gt;Histograms and Scatter Plots&lt;/h2&gt;
&lt;p&gt;Histograms provide a graphical representation of the distribution of a dataset. In the context of market analysis, histograms are often used to visualize the frequency distribution of stock prices, trading volumes, or other relevant financial variables. They display the number of occurrences or the probability of data falling within different intervals, allowing analysts to identify patterns, outliers, and the shape of the distribution. Histograms help in understanding the central tendency, dispersion, and skewness of the data, providing valuable insights into market dynamics.&lt;/p&gt;
&lt;p&gt;Scatter plots, on the other hand, visualize the relationship between two variables. In market analysis, scatter plots are commonly used to explore the correlation or association between two financial variables, such as the relationship between stock prices and trading volumes. Each data point represents a pair of values for the two variables, and their positions on the plot indicate the values of the variables. Scatter plots provide a visual indication of the strength, direction, and pattern of the relationship between the variables. They can help identify trends, patterns, outliers, or potential trading opportunities based on the observed relationships between variables.&lt;/p&gt;
&lt;p&gt;Both histograms and scatter plots facilitate the exploration and analysis of financial data, enabling market analysts to uncover patterns, relationships, and potential insights that can inform trading strategies and decision-making processes.&lt;/p&gt;
&lt;h2 id=&#34;kurtosis&#34;&gt;Kurtosis&lt;/h2&gt;
&lt;p&gt;Kurtosis is a statistical measure that quantifies the shape of a probability distribution. In market analysis, kurtosis helps evaluate the distribution of returns or other financial variables. It measures the tail-heaviness or tail-thinness of the distribution compared to a normal distribution. High kurtosis indicates heavy tails, implying a higher likelihood of extreme values, while low kurtosis suggests lighter tails and a more peaked distribution. Kurtosis analysis aids in understanding the level of risk and potential outliers in the data, which are crucial considerations for assessing investment strategies and managing portfolio risk.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://av-eks-blogoptimized.s3.amazonaws.com/57983kurt1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;beta-vs-correlation&#34;&gt;Beta vs correlation&lt;/h2&gt;
&lt;p&gt;Beta and correlation are both metrics used in finance to measure the relationship between two variables, but they serve different purposes and provide distinct insights.&lt;/p&gt;
&lt;p&gt;Correlation measures the strength and direction of the linear relationship between two variables. It ranges between -1 and +1, where -1 represents a perfect negative correlation, +1 represents a perfect positive correlation, and 0 indicates no correlation. Correlation helps in understanding the degree to which changes in one variable are associated with changes in another variable. In finance, correlation is commonly used to assess the relationship between the returns of different assets or the relationship between an asset&amp;rsquo;s returns and a benchmark index. It helps to identify diversification opportunities and understand how assets move in relation to each other.&lt;/p&gt;
&lt;p&gt;Beta, on the other hand, is a measure of systematic risk or volatility of an asset relative to a benchmark, usually the overall market represented by an index such as the S&amp;amp;P 500. It quantifies the sensitivity of an asset&amp;rsquo;s returns to the movements of the market. A beta of 1 indicates that the asset tends to move in sync with the market, while a beta greater than 1 indicates higher volatility than the market, and a beta less than 1 indicates lower volatility. Beta is used to evaluate the risk-reward tradeoff of an asset and to assess its potential impact on a portfolio&amp;rsquo;s overall risk. Investors often consider beta when constructing portfolios to balance risk exposure and diversify holdings.&lt;/p&gt;
&lt;p&gt;In summary, correlation measures the degree of linear relationship between two variables, while beta measures the relative volatility or risk of an asset compared to a benchmark. Correlation helps identify associations between variables, while beta aids in assessing the systematic risk of an asset and its impact on portfolio performance. Both metrics provide valuable insights in different aspects of financial analysis and decision-making.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://camo.githubusercontent.com/8d963291b8f1c6c5f8f52136f23f73489b5726845b623149fb716d223b0b3555/68747470733a2f2f6173736574732e6f6d7363732e696f2f6e6f7465732f323032302d30312d31352d32322d31352d32342e706e67&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;daily-portfolio-values&#34;&gt;Daily Portfolio values&lt;/h2&gt;
&lt;p&gt;The daily portfolio value can be calculated by normalizing it with the values of the first day, allocating the portfolio based on the desired weights, and then calculating the position values by multiplying the allocated weights with the starting values of each asset. Finally, the portfolio value is obtained by summing the position values.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Normalize the daily portfolio value by dividing it by the value of the portfolio on the first day. This normalization allows for comparison and analysis of the portfolio&amp;rsquo;s performance over time.&lt;/li&gt;
&lt;li&gt;Calculate the allocation of the portfolio by determining the desired weights for each asset. The allocation specifies the proportion of the portfolio&amp;rsquo;s total value that will be invested in each asset. These weights can be based on factors like risk tolerance, investment strategy, or market conditions.&lt;/li&gt;
&lt;li&gt;Compute the position values by multiplying the allocated weights with the starting values of each asset. This step determines the initial value of each asset position in the portfolio.&lt;/li&gt;
&lt;li&gt;Calculate the portfolio value by summing the position values. The portfolio value represents the total worth of the portfolio on a given trading day, taking into account the values of all the assets held in the portfolio.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;portfolio-statistics&#34;&gt;Portfolio statistics&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Daily Returns:&lt;/strong&gt;
Daily Return = (Portfolio Value_today - Portfolio Value_yesterday) / Portfolio Value_yesterday&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cumulative Returns:&lt;/strong&gt;
Cumulative Return = (Portfolio Value_today - Portfolio Value_start) / Portfolio Value_start&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Average Daily Returns:&lt;/strong&gt;
Average Daily Return = mean(Daily Returns)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Standard Deviation of Daily Returns:&lt;/strong&gt;
Standard Deviation = std(Daily Returns)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sharpe Ratio:&lt;/strong&gt;
Sharpe Ratio = (Average Daily Return - Risk-Free Rate) / Standard Deviation of Daily Returns&lt;/p&gt;
&lt;h2 id=&#34;sharpe-ratio&#34;&gt;Sharpe ratio&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Risk adjusted return&lt;/li&gt;
&lt;li&gt;All else being equal
&lt;ul&gt;
&lt;li&gt;lower risk is better&lt;/li&gt;
&lt;li&gt;higher return is better&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SR also considers risk free rate of return (which is 0% for practical purposes)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;parameterized-model&#34;&gt;Parameterized model&lt;/h2&gt;
&lt;p&gt;A parameterized model, in the context of finance and trading, refers to a mathematical or statistical model that includes parameters as variables that can be adjusted or optimized based on specific criteria or data. These models provide a flexible framework for analyzing financial data, making predictions, and generating insights.&lt;/p&gt;
&lt;p&gt;In a parameterized model, the parameters represent various characteristics or assumptions that govern the behavior of the model. These parameters can be estimated, calibrated, or optimized using historical data, statistical techniques, or other methods. By adjusting the values of the parameters, analysts can test different scenarios, evaluate the model&amp;rsquo;s performance, and make informed decisions based on the desired objectives.&lt;/p&gt;
&lt;p&gt;The advantage of parameterized models lies in their ability to adapt to different market conditions, asset classes, or investment strategies. By incorporating parameters, the models can capture specific features or dynamics of the financial markets and provide more accurate predictions or analysis.&lt;/p&gt;
&lt;p&gt;Examples of parameterized models in finance include regression models, time series models like ARIMA or GARCH, option pricing models such as Black-Scholes, and machine learning models like neural networks or random forests. Each of these models contains parameters that can be adjusted or optimized to enhance their performance and align them with the characteristics of the data or the specific requirements of the analysis.&lt;/p&gt;
&lt;p&gt;By utilizing parameterized models, market analysts and researchers can gain deeper insights into financial data, forecast future market trends, manage risk, and optimize investment strategies. The flexibility and adaptability of these models make them valuable tools for decision-making and analysis in the dynamic and complex world of finance.&lt;/p&gt;
&lt;h2 id=&#34;optimizer&#34;&gt;Optimizer&lt;/h2&gt;
&lt;p&gt;An optimizer, in the context of finance and mathematical modeling, refers to a computational algorithm or method used to find the optimal solution for a given problem. It is designed to search through a space of possible solutions and identify the values or configurations that optimize a specific objective or satisfy certain constraints.&lt;/p&gt;
&lt;p&gt;An optimizer typically works by iteratively adjusting the input variables or parameters of a model, evaluating the corresponding output or objective function, and updating the variables based on a defined optimization criterion. The process continues until a satisfactory solution is found, often the one that minimizes or maximizes the objective function within the given constraints.&lt;/p&gt;
&lt;p&gt;In finance, optimizers are extensively used in areas such as portfolio optimization, asset allocation, risk management, and trading strategy development. They enable investors and analysts to find the optimal allocation of assets, determine the optimal weights or positions for a portfolio, or identify the optimal parameters for a trading strategy.&lt;/p&gt;
&lt;p&gt;Various optimization algorithms exist, ranging from simple techniques like grid search and random search to more advanced methods such as gradient-based optimization (e.g., gradient descent), evolutionary algorithms, or convex optimization algorithms. The choice of optimizer depends on the nature of the problem, the complexity of the model, and the desired solution accuracy.&lt;/p&gt;
&lt;h1 id=&#34;computational-investing&#34;&gt;Computational Investing&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Liquidity&lt;/strong&gt; is a measurement of how easy it is to buy or sell shares in a fund. ETFs, or exchange-traded funds are the most liquid of funds. They can be bought and sold easily and near-instantly during the trading day just like individual stocks; ETFs, though, represent some distribution of stocks. The volume of an ETF is just as important to its liquidity: because there are often millions of people trading it, it’s easy to get your buy / sell order filled.&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;large-cap stock&lt;/strong&gt; like Apple refers to a stock with a large market capitalization. Market capitalization is a metric of a stock’s total shares times its price. It’s worth noting that the &lt;em&gt;price of a stock has no relation to the value of a company&lt;/em&gt;; it only describes the cost of owning a single share in that company. If you can afford the market capitalization of a company, you can afford to buy the company in its entirety and take over its ownership.&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;bull market&lt;/strong&gt; or a &lt;strong&gt;bullish position&lt;/strong&gt; on a stock is an optimistic viewpoint that implies that things will continue to grow. On the other hand, a &lt;strong&gt;bear market&lt;/strong&gt; or a &lt;strong&gt;bearish position&lt;/strong&gt; is pessimistic (or cautionary, or realistic, depending on how you see the glass) about the future of an asset.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;types-of-managed-funds&#34;&gt;Types of Managed Funds&lt;/h2&gt;
&lt;h3 id=&#34;etfs-exchange-traded-funds&#34;&gt;ETFs (Exchange Traded Funds)&lt;/h3&gt;
&lt;p&gt;ETFs, or exchange-traded funds, are investment funds that are traded on stock exchanges, similar to individual stocks. They are designed to track the performance of a specific index, sector, commodity, or asset class. ETFs offer investors a way to gain exposure to a diversified portfolio of assets without directly owning the underlying securities.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Structure:&lt;/strong&gt; ETFs are structured as open-end investment companies or unit investment trusts. They issue shares to investors, and these shares represent an ownership interest in the ETF&amp;rsquo;s underlying assets.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Underlying Assets:&lt;/strong&gt; ETFs can track a wide range of underlying assets, including stock indexes (such as the S&amp;amp;P 500), bond indexes, commodity prices, currencies, or a combination of assets. The ETF&amp;rsquo;s performance is designed to closely mirror that of its underlying index or asset class.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Creation and Redemption:&lt;/strong&gt; Authorized Participants (APs) play a crucial role in the creation and redemption of ETF shares. They are typically large institutional investors, such as market makers or authorized broker-dealers. APs create new shares of an ETF by delivering a basket of the underlying assets to the ETF issuer, and in return, they receive ETF shares. Conversely, they can redeem ETF shares by returning them to the issuer in exchange for the underlying assets.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Listing and Trading:&lt;/strong&gt; ETFs are listed on stock exchanges, making them easily tradable throughout the trading day. Investors can buy and sell ETF shares through brokerage accounts, just like they would trade individual stocks. The price of an ETF share is determined by market demand and supply and can sometimes deviate slightly from the net asset value (NAV) of the underlying assets.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Benefits of ETFs:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Diversification:&lt;/strong&gt; ETFs offer investors exposure to a broad range of securities within a single investment. This diversification can help reduce risk compared to investing in individual stocks or bonds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Liquidity:&lt;/strong&gt; ETFs are traded on stock exchanges, providing investors with liquidity. They can be bought or sold throughout the trading day at market prices.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transparency:&lt;/strong&gt; ETFs disclose their holdings on a daily basis, allowing investors to see exactly which securities they own. This transparency helps investors make informed decisions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lower Costs:&lt;/strong&gt; ETFs generally have lower expense ratios compared to mutual funds. They often passively track an index rather than actively managed funds, resulting in lower management fees.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flexibility:&lt;/strong&gt; ETFs can be used for various investment strategies, including long-term investing, short-term trading, or tactical asset allocation.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It&amp;rsquo;s important to note that while ETFs offer many benefits, they also carry risks. The value of an ETF can fluctuate based on the performance of its underlying assets, and there are potential risks associated with market volatility, liquidity, and tracking error.&lt;/p&gt;
&lt;h3 id=&#34;mutual-funds&#34;&gt;Mutual Funds&lt;/h3&gt;
&lt;p&gt;Mutual funds are investment vehicles that pool money from multiple investors to invest in a diversified portfolio of securities, such as stocks, bonds, or a combination of both. They are managed by professional investment firms or asset management companies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Structure:&lt;/strong&gt; Mutual funds are set up as open-end investment companies. This means that the fund continuously issues and redeems shares based on investor demand. Investors purchase shares of the mutual fund at the net asset value (NAV), which is calculated by dividing the total value of the fund&amp;rsquo;s assets by the number of shares outstanding.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Professional Management:&lt;/strong&gt; Mutual funds are managed by professional fund managers or investment teams who make investment decisions on behalf of the fund. The fund manager conducts research, performs security analysis, and selects investments based on the fund&amp;rsquo;s investment objective and strategy.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Investment Objectives and Strategies:&lt;/strong&gt; Mutual funds can have various investment objectives and strategies. For example, a mutual fund may aim to achieve long-term capital appreciation, income generation, or a blend of both. The investment strategy could be actively managed, where the fund manager actively selects and manages the fund&amp;rsquo;s portfolio, or passively managed, where the fund aims to replicate the performance of a specific index.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Diversification:&lt;/strong&gt; Mutual funds provide diversification by investing in a wide range of securities. By pooling money from multiple investors, the fund can hold a diversified portfolio of stocks, bonds, or other assets. This diversification helps spread the investment risk and reduces the impact of any single security&amp;rsquo;s performance on the overall portfolio.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Net Asset Value (NAV):&lt;/strong&gt; The NAV of a mutual fund represents the per-share value of the fund&amp;rsquo;s assets. It is calculated by subtracting the fund&amp;rsquo;s liabilities from its total assets and dividing the result by the number of shares outstanding. The NAV is typically calculated at the end of each trading day.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fees and Expenses:&lt;/strong&gt; Mutual funds charge fees and expenses to cover the costs of managing the fund. These fees may include an expense ratio, which covers management fees, administrative expenses, and other operational costs. Additionally, some funds may charge sales loads, which are fees paid when purchasing or selling shares of the fund.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Liquidity:&lt;/strong&gt; Mutual funds are priced and traded at the NAV at the end of each trading day. Investors can buy or sell shares directly with the fund company or through brokerage accounts. Mutual funds are generally considered to be liquid investments, as they provide investors with the ability to buy or sell shares on any business day.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Benefits of Mutual Funds:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Professional Management:&lt;/strong&gt; Mutual funds are managed by experienced professionals who make investment decisions based on their expertise and research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Diversification:&lt;/strong&gt; Mutual funds offer instant diversification by investing in a broad range of securities, reducing the risk associated with investing in individual stocks or bonds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Accessibility:&lt;/strong&gt; Mutual funds are accessible to a wide range of investors, as they have relatively low minimum investment requirements.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Liquidity:&lt;/strong&gt; Investors can typically buy or sell mutual fund shares on any business day at the NAV, providing liquidity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flexibility:&lt;/strong&gt; Mutual funds offer various investment strategies and asset classes to cater to different investor preferences and goals.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Risks of Mutual Funds:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Market Risk:&lt;/strong&gt; The value of mutual fund shares can fluctuate based on the performance of the underlying securities, and investors may experience losses if the market declines.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fees and Expenses:&lt;/strong&gt; Mutual funds charge fees and expenses, which can affect the overall returns earned by investors.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Management Risk:&lt;/strong&gt; The performance of a mutual fund depends on the investment decisions made by the fund manager. Poor investment choices or ineffective management can negatively impact returns.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No Guarantees:&lt;/strong&gt; Mutual funds do not provide guaranteed returns, and investors may not receive back the full amount of their initial investment.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;hedge-funds&#34;&gt;Hedge Funds&lt;/h2&gt;
&lt;p&gt;Hedge funds are alternative investment vehicles that are designed for wealthy individuals or institutional investors. Unlike mutual funds, hedge funds are typically only available to accredited investors due to their complex nature and higher risk profile. Hedge funds employ a range of investment strategies and techniques to seek higher returns, often through active management and the use of leverage.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Structure:&lt;/strong&gt; Hedge funds are structured as private investment partnerships or limited liability companies. They are managed by professional investment managers or investment firms who act as general partners or managers of the fund.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Investment Strategies:&lt;/strong&gt; Hedge funds employ various investment strategies with the goal of generating higher returns than traditional investments. These strategies can include long and short positions in stocks, bonds, commodities, currencies, derivatives, and other financial instruments. Hedge funds can also utilize leverage (borrowed money) to amplify potential returns.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Limited Regulation:&lt;/strong&gt; Hedge funds often operate with fewer regulatory restrictions compared to mutual funds. This allows them to have more flexibility in their investment strategies, including the ability to engage in short selling, derivative trading, and alternative investments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Performance Fees:&lt;/strong&gt; Hedge funds typically charge performance fees in addition to management fees. The performance fee is a percentage of the fund&amp;rsquo;s profits, usually around 20%. This fee structure aligns the interests of the fund managers with those of the investors, as the managers earn higher fees when they generate positive returns.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Risk Management:&lt;/strong&gt; Hedge funds often employ risk management techniques to mitigate potential losses. This can involve diversifying investments, hedging against market downturns, and implementing risk controls. However, it&amp;rsquo;s important to note that hedge funds can still be subject to substantial risk, and their strategies may not always be successful.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Access and Investor Requirements:&lt;/strong&gt; Hedge funds generally have higher minimum investment requirements compared to mutual funds, often ranging from hundreds of thousands to millions of dollars. They are typically open only to accredited investors, who have higher income or net worth thresholds set by regulatory authorities.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Liquidity and Lock-up Periods:&lt;/strong&gt; Hedge funds often have restrictions on liquidity. Investors may face limited redemption options and longer lock-up periods, where their investment is tied up for a specific period, typically one year or more. This illiquidity is intended to provide fund managers with more flexibility in managing investments and executing strategies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Benefits of Hedge Funds:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Potential Higher Returns:&lt;/strong&gt; Hedge funds aim to generate higher returns by using sophisticated investment strategies, including short selling, leverage, and alternative investments.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Diversification:&lt;/strong&gt; Hedge funds often employ a wide range of investment strategies and can invest across multiple asset classes, offering potential diversification benefits to investors.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Active Management:&lt;/strong&gt; Hedge fund managers actively monitor and adjust their investment portfolios, seeking opportunities to capitalize on market inefficiencies and generate alpha (excess returns).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Risks of Hedge Funds:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Higher Risk&lt;/strong&gt;: Hedge funds typically carry higher risk compared to traditional investments. The use of leverage, complex strategies, and alternative investments can amplify potential losses.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Limited Transparency&lt;/strong&gt;: Hedge funds are less regulated than mutual funds, and they often have limited disclosure requirements. Investors may have less visibility into the fund&amp;rsquo;s holdings and investment decisions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Limited Liquidity&lt;/strong&gt;: Hedge funds may have restrictions on withdrawals and longer lock-up periods, limiting investors&amp;rsquo; access to their capital.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Potential for High Fees&lt;/strong&gt;: Hedge funds generally charge higher management and performance fees compared to traditional investment options, which can erode overall returns.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;compensation&#34;&gt;Compensation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Assets under management (AUM):&lt;/strong&gt; The amount of other people&amp;rsquo;s money the fund manager is responsible for.&lt;/li&gt;
&lt;li&gt;Managers of ETFs are paid in expense ratio (0.01% to 1.00% of AUM)&lt;/li&gt;
&lt;li&gt;Mutual Funds are pain in expense ratio (0.5% to 3.00% of AUM)&lt;/li&gt;
&lt;li&gt;Hedge Funds Two and Twenty structure. 2% of AUM and 20% of profits&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;who-are-the-investors-in-hedge-funds&#34;&gt;Who are the investors in Hedge Funds?&lt;/h2&gt;
&lt;p&gt;Hedge fund investors can be a diverse group of individuals, institutions, and organizations. Here are some common types of hedge fund investors:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;High-Net-Worth Individuals (HNWIs):&lt;/strong&gt; These are wealthy individuals who have a substantial amount of investable assets. HNWIs often invest in hedge funds to diversify their portfolios and seek higher returns.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Family Offices:&lt;/strong&gt; Family offices manage the financial affairs and investments of wealthy families. They may allocate a portion of their assets to hedge funds to achieve specific investment goals.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pension Funds:&lt;/strong&gt; Pension funds manage retirement assets on behalf of employees. Some pension funds, especially those with larger assets, invest in hedge funds to diversify their portfolios and potentially enhance returns.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Endowments and Foundations:&lt;/strong&gt; Educational institutions, charitable foundations, and other similar organizations may invest in hedge funds to generate income for their operations or to support their philanthropic activities.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Insurance Companies:&lt;/strong&gt; Some insurance companies allocate a portion of their investment portfolios to hedge funds in order to enhance overall returns and manage risk.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sovereign Wealth Funds:&lt;/strong&gt; These funds are created by governments to manage and invest surplus funds, often derived from commodity exports or foreign exchange reserves. Sovereign wealth funds may invest in hedge funds as part of their overall investment strategy.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Funds of Funds:&lt;/strong&gt; These are investment vehicles that pool capital from multiple investors to invest in a portfolio of hedge funds. Funds of funds provide diversification and professional management for investors who may not have direct access to hedge funds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Institutional Investors:&lt;/strong&gt; This category includes various institutions such as banks, asset management firms, and corporations. Institutional investors often have dedicated teams or departments that manage their investments, which may include hedge fund allocations.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;goals-of-hedge-funds&#34;&gt;Goals of hedge funds&lt;/h2&gt;
&lt;p&gt;The goals of hedge funds can vary depending on their investment strategies and the preferences of their managers. However, there are several common goals that hedge funds typically aim to achieve:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Capital Appreciation:&lt;/strong&gt; Hedge funds often seek to generate positive returns on their investments, aiming for capital appreciation and growth of the fund&amp;rsquo;s assets over time. The primary goal is to outperform traditional investment vehicles, such as stock market indices or mutual funds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Risk Management and Preservation of Capital:&lt;/strong&gt; While hedge funds are known for their potential to generate high returns, they also prioritize risk management. Hedge fund managers employ various strategies to mitigate downside risks and preserve capital, aiming to protect investors&amp;rsquo; assets during market downturns.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Absolute Returns:&lt;/strong&gt; Hedge funds typically pursue absolute returns, aiming to generate positive performance regardless of market conditions. Unlike traditional investment funds that often benchmark their performance against a specific market index, hedge funds aim to generate returns that are not reliant on overall market performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Diversification:&lt;/strong&gt; Hedge funds often use diverse investment strategies across different asset classes, including stocks, bonds, commodities, currencies, and derivatives. By diversifying their investments, hedge funds aim to reduce risk and potentially enhance returns through exposure to various market opportunities.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Active Management and Flexibility:&lt;/strong&gt; Hedge funds have the advantage of flexibility and the ability to implement active investment strategies. They can take both long and short positions, engage in leverage, use derivatives, and employ other sophisticated techniques to exploit market inefficiencies and generate returns.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Capital Preservation in Down Markets:&lt;/strong&gt; Some hedge funds aim to provide downside protection during market downturns. They may use strategies such as hedging, short-selling, or employing market-neutral approaches to reduce correlation with broader market movements and potentially deliver positive returns even in challenging market conditions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alpha Generation:&lt;/strong&gt; Hedge funds often strive to generate alpha, which represents the excess return earned beyond what would be expected based on the risk exposure of their investments. By identifying and exploiting market inefficiencies or mispriced assets, hedge funds aim to generate alpha and deliver superior risk-adjusted returns.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;hedge-funds-metrics&#34;&gt;Hedge funds metrics&lt;/h2&gt;
&lt;p&gt;Hedge funds employ a wide range of metrics and indicators to evaluate investment opportunities, monitor portfolio performance, and make informed decisions. The specific metrics they chase can vary depending on the fund&amp;rsquo;s investment strategy and objectives. Here are some commonly used metrics in the hedge fund industry:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Return on Investment (ROI):&lt;/strong&gt; ROI is a fundamental metric that measures the profitability of an investment. Hedge funds closely track the returns generated by their investments to assess the success of their strategies and compare them against their targets or benchmarks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alpha:&lt;/strong&gt; Alpha represents the excess return generated by a hedge fund compared to its expected return based on its risk exposure. Hedge funds aim to achieve positive alpha, as it indicates that they have outperformed the market or their benchmark, taking into account the level of risk undertaken.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sharpe Ratio:&lt;/strong&gt; The Sharpe ratio measures the risk-adjusted return of an investment by considering the excess return earned relative to its volatility or risk. Hedge funds often strive for higher Sharpe ratios, indicating that they are generating superior returns for the level of risk taken.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Volatility:&lt;/strong&gt; Volatility measures the degree of price fluctuations in an investment or a portfolio. Hedge funds may target specific levels of volatility based on their risk appetite and investment strategies. Some funds may seek to reduce volatility by employing hedging or risk management techniques.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Maximum Drawdown:&lt;/strong&gt; Maximum drawdown refers to the largest peak-to-trough decline in the value of a hedge fund or investment portfolio over a specific period. Hedge funds aim to minimize drawdowns as they can significantly impact investor capital. Lower maximum drawdowns indicate better risk management.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Information Ratio:&lt;/strong&gt; The information ratio measures the excess return generated by a hedge fund relative to a benchmark, considering the level of active risk taken. It assesses the fund manager&amp;rsquo;s ability to generate returns through active management decisions and market insights.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Risk Metrics:&lt;/strong&gt; Hedge funds closely monitor various risk metrics such as Value-at-Risk (VaR), which estimates the potential loss under adverse market conditions, and tracking error, which measures the deviation of a fund&amp;rsquo;s returns from its benchmark. These metrics help hedge funds assess and manage the risks associated with their investment strategies.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Liquidity Metrics:&lt;/strong&gt; Hedge funds may track liquidity metrics to assess the ease of buying or selling assets in their portfolios. Measures such as bid-ask spreads, trading volumes, and market depth can help hedge funds gauge the liquidity of their investments and ensure they can exit positions when necessary.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;computing-in-a-hedge-fund&#34;&gt;Computing in a Hedge Fund&lt;/h2&gt;
&lt;p&gt;Computing plays a crucial role in the operations of hedge funds, enabling efficient data analysis, trading strategies, risk management, and overall portfolio management. Here are some key aspects of computing within a hedge fund:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Data Management:&lt;/strong&gt; Hedge funds handle vast amounts of data from various sources, including market data, economic indicators, company financials, news feeds, and more. Computing systems are used to collect, store, and organize this data for analysis and decision-making. This may involve the use of databases, data warehouses, and data lakes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quantitative Analysis:&lt;/strong&gt; Hedge funds often employ quantitative analysts (quants) who develop mathematical models and algorithms to analyze data, identify patterns, and generate trading signals. These models can range from statistical models and machine learning algorithms to more complex quantitative finance models. High-performance computing systems are often used to perform computationally intensive tasks and backtest strategies.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Algorithmic Trading:&lt;/strong&gt; Hedge funds commonly utilize algorithmic trading, where computer algorithms execute trades based on predefined rules and strategies. These algorithms take into account various factors such as market conditions, pricing data, and order book information. Low-latency computing systems are often employed to execute trades quickly and efficiently.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Risk Management:&lt;/strong&gt; Hedge funds have sophisticated risk management systems to monitor and assess potential risks associated with their portfolios. These systems use computing power to calculate risk metrics, such as Value-at-Risk (VaR), stress tests, and scenario analyses. Risk models are often run on computing clusters to analyze the potential impact of different market conditions on the fund&amp;rsquo;s holdings.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Portfolio Management and Optimization:&lt;/strong&gt; Computing systems are used for portfolio management tasks, including portfolio construction, rebalancing, and optimization. Advanced optimization algorithms help hedge funds determine optimal asset allocations based on desired risk-return trade-offs, constraints, and market conditions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Market Data Analysis:&lt;/strong&gt; Hedge funds analyze market data in real-time to identify trading opportunities, monitor market trends, and make informed investment decisions. This involves processing and analyzing vast amounts of streaming market data using computing systems, often with the help of complex event processing (CEP) techniques.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Infrastructure and Connectivity:&lt;/strong&gt; Hedge funds require robust computing infrastructure to support their operations. This includes servers, data storage systems, network infrastructure, and connectivity to exchanges, brokers, and other trading platforms. Redundancy and high availability are critical to ensure uninterrupted operations and minimize downtime.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Security:&lt;/strong&gt; Hedge funds handle sensitive financial data and must maintain strict data security measures. This includes encryption, access controls, secure networks, and data backup systems to protect against unauthorized access, data breaches, and system failures.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;the-order-book&#34;&gt;The Order Book&lt;/h2&gt;
&lt;p&gt;An order book is a key component of financial markets, particularly in the context of exchanges or trading platforms. It is a record of buy and sell orders for a particular security, such as stocks, bonds, or cryptocurrencies, organized by price and time. The order book provides market participants with transparency regarding the supply and demand dynamics of the security.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s how an order book typically works:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Buy and Sell Orders:&lt;/strong&gt; Market participants can submit buy or sell orders for a specific security. Buy orders represent the demand for the security at a certain price, while sell orders represent the supply of the security at a given price.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Price Levels:&lt;/strong&gt; The order book organizes these buy and sell orders into different price levels. Each price level represents a specific price at which orders are placed. The highest bid price (buy orders) and the lowest ask price (sell orders) are often displayed prominently.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quantity:&lt;/strong&gt; Along with the price, the order book also shows the quantity or volume of shares or contracts being bid or offered at each price level. This provides information about the liquidity available at different price points.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Best Bid and Ask:&lt;/strong&gt; The order book highlights the best bid price and the best ask price, which represent the highest bid and lowest ask prices available in the market at a given moment. The difference between the best bid and ask prices is known as the bid-ask spread.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Market Depth:&lt;/strong&gt; Market depth refers to the cumulative quantity of buy and sell orders available at different price levels. It shows the potential buying and selling pressure in the market and helps market participants assess the level of liquidity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Market Order Execution:&lt;/strong&gt; When a market participant submits a market order to buy or sell a security, it is typically executed against the best available prices in the order book. The market order consumes the available liquidity in the order book until the entire order is filled.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Limit Order Execution:&lt;/strong&gt; Limit orders specify the desired price at which a participant wants to buy or sell a security. These orders are placed in the order book and remain there until they are matched with a counterparty. If a buy limit order matches a sell limit order at the specified price, a trade occurs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Order Book Updates:&lt;/strong&gt; The order book is continuously updated as new orders are submitted or existing orders are modified or canceled. The order book reflects real-time changes in supply and demand dynamics, allowing participants to observe shifts in market sentiment.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The order book is an essential tool for traders, providing them with visibility into market liquidity, price levels, and potential trading opportunities. By analyzing the order book, traders can make informed decisions about when to place orders, at what price, and how much liquidity is available to support their trades.&lt;/p&gt;
&lt;h2 id=&#34;how-orders-get-to-the-exchange&#34;&gt;How orders get to the exchange?&lt;/h2&gt;
&lt;p&gt;Orders can reach exchanges through various channels, including direct connections, brokers, and alternative trading venues. Here&amp;rsquo;s a general overview of how orders reach exchanges and the role of dark pools:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Direct Market Access (DMA)&lt;/strong&gt;: Institutional investors and some high-frequency trading firms have direct market access to exchanges. They establish direct connections to the exchange&amp;rsquo;s trading system, enabling them to send orders directly without intermediaries. DMA allows for faster order execution and greater control over the order routing process.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Brokers and Trading Platforms:&lt;/strong&gt; Most individual investors and some institutional investors route their orders through brokers or trading platforms. These intermediaries receive orders from clients and act as an interface between the client and the exchange. Brokers typically offer access to multiple exchanges, allowing clients to choose the desired trading venue.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Smart Order Routing (SOR):&lt;/strong&gt; When an order is received by a broker or a trading platform, they may use smart order routing technology. SOR algorithms analyze various factors such as price, liquidity, execution speed, and regulatory requirements to determine the optimal destination for the order. SOR aims to maximize the chances of obtaining the best execution possible by routing the order to the most suitable market or venue.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Primary Exchanges:&lt;/strong&gt; The primary exchanges, such as the New York Stock Exchange (NYSE) or NASDAQ, are the most widely known trading venues. Orders sent directly to these exchanges or routed through brokers are executed on their centralized order books. These exchanges provide transparent markets where orders are visible to all participants, allowing for price discovery and liquidity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dark Pools:&lt;/strong&gt; Dark pools are alternative trading venues that offer a level of anonymity and reduced market impact for large institutional orders. Dark pools operate differently from primary exchanges as they do not display order details in the public order book. Instead, they match buy and sell orders internally, away from public view. Dark pools are designed to facilitate large block trades with reduced information leakage and minimize market impact.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Crossing Networks:&lt;/strong&gt; Some brokers operate crossing networks, which are internal matching engines that facilitate the execution of orders from their own clients. These orders are not routed to external exchanges. Crossing networks aim to match buy and sell orders within the broker&amp;rsquo;s client base, providing potential price improvement and confidentiality.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Electronic Communication Networks (ECNs):&lt;/strong&gt; ECNs are electronic platforms that connect buyers and sellers directly. They provide a venue for trading securities and can be accessed by market participants, including institutional investors and retail traders. ECNs often offer fast order matching, access to multiple markets, and display order information for transparency.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;geographic-arbitrage&#34;&gt;Geographic arbitrage&lt;/h2&gt;
&lt;p&gt;Geographic arbitrage refers to the practice of taking advantage of price or valuation discrepancies between different geographic regions or markets. It involves exploiting the differences in prices, costs, or economic conditions across countries or regions to generate profits.&lt;/p&gt;
&lt;h2 id=&#34;stop-loss&#34;&gt;Stop Loss&lt;/h2&gt;
&lt;p&gt;Stop Loss is an order placed by an investor to automatically sell a security if it reaches a specified price, limiting potential losses.&lt;/p&gt;
&lt;h2 id=&#34;stop-gain&#34;&gt;Stop Gain&lt;/h2&gt;
&lt;p&gt;Stop Gain is an order placed by an investor to automatically sell a security if it reaches a specified price, securing profits and preventing potential losses.&lt;/p&gt;
&lt;h2 id=&#34;trailing-stop&#34;&gt;Trailing Stop&lt;/h2&gt;
&lt;p&gt;A trailing stop is a type of stop loss order that adjusts dynamically with the market price, moving in lockstep to protect profits by automatically selling a security if its price drops a certain percentage or amount from its highest point.&lt;/p&gt;
&lt;h2 id=&#34;short-selling&#34;&gt;Short selling&lt;/h2&gt;
&lt;p&gt;Short selling is a trading strategy where an investor borrows a security from a broker and sells it in the market, anticipating that the price of the security will decline. The investor aims to buy back the security at a lower price in the future to return it to the broker, thereby profiting from the price difference. Short selling allows investors to potentially profit from falling prices and is commonly used for speculative purposes, hedging, or market-making activities. However, it carries inherent risks, as there is unlimited potential for loss if the price of the security being shorted rises significantly.&lt;/p&gt;
&lt;h2 id=&#34;evaluating-the-true-value-of-a-company&#34;&gt;Evaluating the &amp;ldquo;true&amp;rdquo; value of a company&lt;/h2&gt;
&lt;h3 id=&#34;intrinsic-value-of-a-company&#34;&gt;Intrinsic value of a company&lt;/h3&gt;
&lt;p&gt;The intrinsic value of a company refers to the estimated underlying worth or fair value of the company&amp;rsquo;s business, assets, and cash flows. It is an assessment of what the company is truly worth based on its fundamental characteristics, financial performance, growth prospects, and other relevant factors.&lt;/p&gt;
&lt;p&gt;Calculating the intrinsic value involves analyzing various aspects of the company, such as its earnings, revenue, cash flow, assets, liabilities, industry trends, competitive position, management quality, and overall economic conditions. Different valuation methods, such as discounted cash flow (DCF) analysis, comparable company analysis, or asset-based valuation, can be used to estimate the intrinsic value.&lt;/p&gt;
&lt;p&gt;The intrinsic value is often compared to the market price of the company&amp;rsquo;s stock to determine if the stock is overvalued or undervalued. If the intrinsic value is higher than the market price, the stock may be considered undervalued and potentially a good investment opportunity. Conversely, if the intrinsic value is lower than the market price, the stock may be considered overvalued, signaling a potential selling opportunity.&lt;/p&gt;
&lt;h3 id=&#34;book-value-of-the-company&#34;&gt;Book value of the company&lt;/h3&gt;
&lt;p&gt;The book value of a company, also known as the net book value or shareholder&amp;rsquo;s equity, represents the value of a company&amp;rsquo;s assets minus its liabilities as reported on the balance sheet. It provides an accounting-based measure of the company&amp;rsquo;s net worth or equity position.&lt;/p&gt;
&lt;h3 id=&#34;market-cap&#34;&gt;Market cap&lt;/h3&gt;
&lt;p&gt;The market capitalization (market cap) of a company is a measure of its total market value, representing the worth of the company as perceived by the market. It is calculated by multiplying the company&amp;rsquo;s current stock price by the total number of outstanding shares.&lt;/p&gt;
&lt;p&gt;The formula for market cap is as follows:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Market Cap = Stock Price x Number of Outstanding Shares
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;rule-of-72&#34;&gt;Rule of 72&lt;/h2&gt;
&lt;p&gt;The Rule of 72 is a simplified mathematical rule used to estimate the time it takes for an investment or a sum of money to double, given a fixed interest rate. It provides a quick approximation of the doubling time based on the concept of compound interest.&lt;/p&gt;
&lt;p&gt;The Rule of 72 is applied as follows:&lt;/p&gt;
&lt;p&gt;Doubling Time ≈ 72 / Interest Rate&lt;/p&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;p&gt;Interest Rate ≈ 72 / Doubling Time&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Doubling Time represents the estimated time it takes for an investment or sum of money to double.&lt;/li&gt;
&lt;li&gt;Interest Rate represents the fixed annual interest rate or rate of return.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, if you have an investment with an annual interest rate of 6%, you can estimate that it will take approximately 12 years (72 / 6) for your investment to double.&lt;/p&gt;
&lt;p&gt;The Rule of 72 is a simple approximation and assumes a constant interest rate and compound interest. It is most accurate for interest rates in the range of 6% to 10%. However, for higher or lower interest rates, the approximation becomes less precise. Additionally, it does not take into account factors such as inflation, taxes, or other variables that may affect investment returns.&lt;/p&gt;
&lt;h2 id=&#34;the-future-value-of-money&#34;&gt;The future value of money&lt;/h2&gt;
&lt;p&gt;The present value (PV) and future value (FV) of money are related through a mathematical formula that takes into account the time period and the interest rate. The formula to calculate the present value (PV) based on a future value (FV) is as follows:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;PV = FV / (1 + r)^n

Where:
PV = Present Value
FV = Future Value
r = Interest rate (expressed as a decimal)
n = Number of periods or time period
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;the-capital-asset-pricing-model&#34;&gt;The Capital Asset Pricing Model&lt;/h2&gt;
&lt;p&gt;The Capital Asset Pricing Model (CAPM) is a financial model used to estimate the expected return on an investment by considering the relationship between its systematic risk and expected return. It provides a framework for pricing risky securities and determining an appropriate required rate of return.&lt;/p&gt;
&lt;p&gt;The CAPM is based on the following formula:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Expected Return = Risk-Free Rate + Beta x (Market Return - Risk-Free Rate)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Expected Return is the anticipated return on the investment.&lt;/li&gt;
&lt;li&gt;Risk-Free Rate is the return on a risk-free investment, typically represented by the yield on government bonds.&lt;/li&gt;
&lt;li&gt;Beta is a measure of the investment&amp;rsquo;s systematic risk or sensitivity to market movements.&lt;/li&gt;
&lt;li&gt;Market Return is the expected return on the overall market.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The CAPM assumes that investors are risk-averse and require compensation for bearing systematic risk beyond the risk-free rate. It suggests that an investment&amp;rsquo;s expected return should increase in proportion to its systematic risk (as measured by beta). The formula calculates the expected return by adding a risk premium (Beta x (Market Return - Risk-Free Rate)) to the risk-free rate.&lt;/p&gt;
&lt;p&gt;Key assumptions of the CAPM include efficient markets, where all relevant information is reflected in asset prices, and a single-period investment horizon. The model also assumes that investors have homogeneous expectations and hold well-diversified portfolios.&lt;/p&gt;
&lt;p&gt;The CAPM is widely used in finance for determining the appropriate discount rate for investment valuation, evaluating the performance of investment portfolios, and estimating the cost of equity capital for companies. However, it has its limitations and critics, as it relies on simplifying assumptions and may not fully capture the complexities of real-world market dynamics.&lt;/p&gt;
&lt;h2 id=&#34;passive-vs-active-investing&#34;&gt;Passive vs Active Investing&lt;/h2&gt;
&lt;p&gt;Passive investing and active investing are two contrasting investment approaches that differ in terms of strategy, management style, and investment philosophy. Here&amp;rsquo;s an overview of each:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Passive Investing:
Passive investing, also known as index investing or passive management, involves constructing a portfolio that aims to replicate the performance of a specific market index, such as the S&amp;amp;P 500. The primary goal is to match the returns of the chosen index rather than trying to outperform it. Passive investors believe that markets are efficient and that it is challenging to consistently beat the market over the long term.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Key characteristics of passive investing include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Index-based approach: Passive investors invest in index funds or exchange-traded funds (ETFs) that hold a diversified portfolio of securities to mimic the performance of a specific index.&lt;/li&gt;
&lt;li&gt;Lower costs: Passive investing generally incurs lower fees and expenses compared to active investing, as it requires minimal research and portfolio management.&lt;/li&gt;
&lt;li&gt;Buy and hold strategy: Passive investors typically maintain a long-term investment approach, avoiding frequent trading or market timing.&lt;/li&gt;
&lt;li&gt;Broad market exposure: Passive strategies offer exposure to an entire market or a specific segment, providing diversification and representing the overall market performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Active Investing:
Active investing involves actively managing a portfolio with the goal of outperforming the market or a specific benchmark. Active investors believe that it is possible to identify undervalued securities or exploit market inefficiencies through research, analysis, and active decision-making.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Key characteristics of active investing include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Individual security selection: Active investors analyze and select specific stocks, bonds, or other securities based on their research and evaluation of company fundamentals, market trends, and other factors.&lt;/li&gt;
&lt;li&gt;Higher costs: Active investing typically involves higher costs compared to passive investing, as it requires more research, analysis, and trading activity.&lt;/li&gt;
&lt;li&gt;Portfolio turnover: Active managers frequently buy and sell securities in an attempt to take advantage of market opportunities or manage risk.&lt;/li&gt;
&lt;li&gt;Flexibility and customization: Active investing allows for a more tailored approach, with the ability to deviate from market indices and adjust the portfolio based on the manager&amp;rsquo;s outlook and investment strategy.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;efficient-market-hypothesis&#34;&gt;Efficient market hypothesis:&lt;/h2&gt;
&lt;p&gt;The Efficient Market Hypothesis (EMH) is a theory in finance that suggests financial markets are efficient in reflecting all available information into security prices. According to the EMH, it is not possible to consistently achieve above-average returns through stock picking or market timing, as stock prices already incorporate all relevant information.&lt;/p&gt;
&lt;p&gt;Key principles of the Efficient Market Hypothesis include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Information Efficiency: The EMH assumes that financial markets efficiently incorporate all publicly available information, including historical data, financial statements, news, and other market-relevant information. In an efficient market, prices adjust quickly and accurately to new information, making it difficult for investors to gain an advantage by acting upon it.&lt;/li&gt;
&lt;li&gt;Three Forms of Market Efficiency: The EMH categorizes market efficiency into three forms:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Weak Form Efficiency: Prices reflect past trading information, such as historical prices and trading volume. Technical analysis techniques based on past price patterns would not consistently generate abnormal returns.&lt;/li&gt;
&lt;li&gt;Semi-Strong Form Efficiency: Prices reflect all publicly available information, including not only past trading data but also fundamental and non-public information, such as earnings reports, news announcements, and analyst recommendations. Neither technical nor fundamental analysis would consistently yield superior returns.&lt;/li&gt;
&lt;li&gt;Strong Form Efficiency: Prices reflect all information, including public and non-public information. This implies that even insider information would not provide an advantage, as it is already factored into prices.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Implications for Investors: The EMH suggests that investors cannot systematically beat the market or consistently identify mispriced securities, as any available information is already incorporated into prices. Therefore, passive investing through strategies like index funds or exchange-traded funds (ETFs) that track broad market indices is considered a rational approach.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While the Efficient Market Hypothesis provides a framework for understanding market efficiency, it has been subject to criticism. Critics argue that markets may not always be fully efficient due to behavioral biases, information asymmetry, or temporary market inefficiencies that can be exploited by skilled investors. As a result, various investment strategies, such as active management or value investing, continue to be pursued by those who believe in the potential to outperform the market.&lt;/p&gt;
&lt;h2 id=&#34;arbitrage-pricing-theory&#34;&gt;Arbitrage Pricing Theory&lt;/h2&gt;
&lt;p&gt;The Arbitrage Pricing Theory (APT) is a financial theory that attempts to explain the relationship between the expected returns of an asset and its risk factors. It is an alternative to the Capital Asset Pricing Model (CAPM) and provides a multi-factor model for asset pricing.&lt;/p&gt;
&lt;p&gt;Key features of the Arbitrage Pricing Theory include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Multi-Factor Model: APT posits that the expected return of an asset is influenced by multiple risk factors, which are systematic influences that affect the asset&amp;rsquo;s returns. These risk factors can be economic variables such as interest rates, inflation, market indices, or industry-specific factors.&lt;/li&gt;
&lt;li&gt;No Arbitrage: APT assumes the absence of arbitrage opportunities, meaning that it is not possible to make riskless profits by exploiting mispriced securities. The theory suggests that market prices adjust quickly to eliminate any potential arbitrage opportunities.&lt;/li&gt;
&lt;li&gt;Linear Relationship: APT assumes a linear relationship between the risk factors and the expected returns of an asset. It suggests that the sensitivity of an asset&amp;rsquo;s returns to each risk factor can be quantified through factor loadings or coefficients.&lt;/li&gt;
&lt;li&gt;Risk Premiums: APT predicts that investors require a risk premium for exposure to each risk factor. The size of the risk premium depends on the perceived riskiness of the factor and its impact on the asset&amp;rsquo;s returns.&lt;/li&gt;
&lt;li&gt;Arbitrage Pricing: APT allows for the identification of mispriced assets by comparing their expected returns, as estimated using the multi-factor model, with their actual market prices. If an asset&amp;rsquo;s expected return does not match the return implied by the APT model, an arbitrage opportunity may exist.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;APT is a more flexible model compared to the CAPM, as it considers multiple risk factors and does not rely on the assumptions of market efficiency or a single market portfolio. However, APT requires identifying and estimating the relevant risk factors specific to a particular asset or market, which can be challenging.&lt;/p&gt;
&lt;p&gt;While APT provides a framework for understanding asset pricing, it is not as widely used as the CAPM in practical applications. Nevertheless, it has contributed to the development of factor-based investing and the understanding of the relationship between risk factors and asset returns.&lt;/p&gt;
&lt;h1 id=&#34;technical-analysis&#34;&gt;Technical Analysis&lt;/h1&gt;
&lt;p&gt;Technical analysis is a methodology used in financial markets to evaluate and forecast future price movements of securities, such as stocks, currencies, commodities, and indices. It relies on the analysis of historical price and volume data, along with various technical indicators and chart patterns, to make investment decisions.&lt;/p&gt;
&lt;p&gt;Key aspects of technical analysis include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Price Patterns:&lt;/strong&gt; Technical analysts study various patterns formed by historical price data, such as trends (uptrends, downtrends, or sideways movements), support and resistance levels, chart patterns (e.g., head and shoulders, double tops/bottoms), and trend lines. These patterns are believed to provide insights into future price movements.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Technical Indicators:&lt;/strong&gt; Technical analysts use a wide range of indicators that mathematically analyze price and volume data to generate trading signals. Examples of popular indicators include moving averages, oscillators (e.g., Relative Strength Index - RSI, Stochastic Oscillator), and momentum indicators (e.g., Moving Average Convergence Divergence - MACD). These indicators help identify overbought or oversold conditions, trend strength, and potential reversals.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Volume Analysis:&lt;/strong&gt; Volume, the number of shares or contracts traded, is considered a significant factor in technical analysis. Changes in trading volume can indicate the strength or weakness of price movements, confirmation or divergence of trends, or the presence of buying or selling pressure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Market Sentiment:&lt;/strong&gt; Technical analysis takes into account market sentiment, which reflects the collective psychological and emotional outlook of market participants. It is believed that market sentiment can influence price movements and can be inferred from indicators like the put/call ratio, investor surveys, or sentiment indicators.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Timeframes:&lt;/strong&gt; Technical analysis can be applied to various timeframes, ranging from intraday charts to long-term charts. Different timeframes may reveal different patterns and trends, catering to traders with different investment horizons.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Technical analysis assumes that historical price patterns, along with associated indicators and patterns, can provide insights into future price movements. Critics argue that technical analysis is based on subjective interpretations and lacks a solid foundation in fundamental analysis or economic factors.&lt;/p&gt;
&lt;p&gt;Traders and investors who use technical analysis aim to identify trading opportunities, determine entry and exit points, manage risk, and assess the probability of price movements. It is often used alongside other forms of analysis, such as fundamental analysis, to make more informed investment decisions.&lt;/p&gt;
&lt;h2 id=&#34;technical-indicator-momentum&#34;&gt;Technical Indicator: Momentum&lt;/h2&gt;
&lt;p&gt;Momentum, in the context of financial markets, refers to the tendency of an asset&amp;rsquo;s price to continue moving in the same direction over a certain period of time. It is a key concept in technical analysis and is based on the belief that assets that have performed well or poorly in the recent past will continue to do so in the near future.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Price Trend:&lt;/strong&gt; Momentum focuses on identifying and capitalizing on existing price trends. It assumes that assets that have been rising in price will continue to rise, while those that have been falling will continue to decline.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relative Strength:&lt;/strong&gt; Momentum analysis often involves comparing the performance of one asset relative to others in the same market or sector. Assets that have demonstrated relatively stronger performance compared to their peers are considered to have positive momentum.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time Frame:&lt;/strong&gt; Momentum analysis can be applied to various timeframes, ranging from short-term intraday movements to longer-term trends. Different traders and investors may use different timeframes to capture momentum opportunities based on their trading strategies and investment goals.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Momentum Indicators:&lt;/strong&gt; Technical analysts use various momentum indicators to identify and quantify the strength of price trends. Examples of momentum indicators include the Relative Strength Index (RSI), Moving Average Convergence Divergence (MACD), and Stochastic Oscillator. These indicators help assess whether an asset is overbought or oversold and whether the momentum is likely to continue or reverse.&lt;/p&gt;
&lt;p&gt;Momentum trading strategies typically involve buying assets that have exhibited positive momentum and selling or short-selling assets that have shown negative momentum. Traders aim to profit from the continuation of trends by entering positions in the direction of the established momentum. Risk management techniques, such as stop-loss orders, are often employed to limit potential losses if the momentum reverses.&lt;/p&gt;
&lt;h2 id=&#34;dealing-with-data&#34;&gt;Dealing with Data&lt;/h2&gt;
&lt;h3 id=&#34;tick&#34;&gt;Tick&lt;/h3&gt;
&lt;p&gt;A &amp;ldquo;tick&amp;rdquo; refers to the smallest possible price movement for a financial instrument, such as a stock, futures contract, or currency pair. The tick size is the minimum price increment that the price can move up or down. It represents the precision with which prices are quoted in the market.&lt;/p&gt;
&lt;p&gt;The tick size varies depending on the specific financial instrument and the exchange where it is traded. For example, in the stock market, the tick size is typically a penny (or a fraction of a penny), while in the futures market, it may be a different amount.&lt;/p&gt;
&lt;h3 id=&#34;stock-split&#34;&gt;Stock Split&lt;/h3&gt;
&lt;p&gt;A stock split is a corporate action taken by a publicly traded company to increase the number of its outstanding shares while simultaneously reducing the share price in order to make the shares more affordable to investors. The overall value of the company remains the same after a stock split.&lt;/p&gt;
&lt;p&gt;Stock splits are usually expressed as a ratio, such as 2-for-1, 3-for-1, or any other combination. Here&amp;rsquo;s how it works:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;2-for-1 Stock Split: In a 2-for-1 stock split, for every one share an investor owns before the split, they receive two shares after the split. For example, if an investor holds 100 shares of a company&amp;rsquo;s stock trading at 100 dollars per share, after the 2-for-1 split, they will have 200 shares priced at 50 dollars per share (100 shares x 2).&lt;/li&gt;
&lt;li&gt;3-for-1 Stock Split: In a 3-for-1 stock split, for every one share an investor owns before the split, they receive three shares after the split. If they held 50 shares priced at 150 dollars per share before the split, they would have 150 shares priced at 50 dollars per share after the 3-for-1 split.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The primary purpose of a stock split is to make the company&amp;rsquo;s stock more accessible to a broader range of investors, especially those with smaller amounts of capital. When the share price is lower, investors with limited funds can participate in the market more easily. Stock splits do not change the total market capitalization of the company or the proportional ownership of shareholders.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s important to note that a stock split is different from a stock dividend. In a stock dividend, the company issues additional shares to its existing shareholders as a way of distributing its profits or retained earnings.&lt;/p&gt;
&lt;p&gt;Stock splits are typically a sign of a company&amp;rsquo;s confidence in its future growth prospects. They are not uncommon for companies that experience significant share price appreciation and want to maintain a reasonable share price for retail investors.&lt;/p&gt;
&lt;h3 id=&#34;dividends&#34;&gt;Dividends&lt;/h3&gt;
&lt;p&gt;Dividends are payments made by a corporation to its shareholders as a distribution of the company&amp;rsquo;s profits or retained earnings. When a company earns a profit, it has several options for using that money, such as reinvesting it back into the business for expansion or paying off debts. Another common option is to return some of the profits to the shareholders in the form of dividends.&lt;/p&gt;
&lt;p&gt;Dividends are typically paid out in cash, but they can also be paid in the form of additional shares of stock or other property. The amount of dividends paid to each shareholder is usually proportional to the number of shares they own. For example, if a company declares a dividend of 0.50 dollars per share and a shareholder owns 100 shares, they would receive 50 dollars in dividends.&lt;/p&gt;
&lt;p&gt;Dividends can be paid on a regular basis, such as quarterly or annually, or the company may decide to pay special or one-time dividends based on its financial performance or specific events. The decision to pay dividends is made by the company&amp;rsquo;s board of directors, and the amount and frequency of dividends can vary depending on the company&amp;rsquo;s profitability, financial health, and growth opportunities.&lt;/p&gt;
&lt;p&gt;Investors often see dividends as a way to generate income from their investments, especially in stable and mature companies with a history of consistent dividend payments. Dividend-paying stocks are popular among income-seeking investors, retirees, and those looking for a steady income stream.&lt;/p&gt;
&lt;h3 id=&#34;efficient-market-hypothesis-1&#34;&gt;Efficient Market Hypothesis&lt;/h3&gt;
&lt;p&gt;The Efficient Market Hypothesis (EMH) is a theory in financial economics that suggests that financial markets are efficient and that asset prices always fully reflect all available information. In other words, according to the EMH, it is impossible to consistently &amp;ldquo;beat the market&amp;rdquo; by identifying undervalued or overvalued assets because all relevant information is already incorporated into the prices.&lt;/p&gt;
&lt;p&gt;The concept of the Efficient Market Hypothesis was developed by economist Eugene Fama in the 1960s and has been a fundamental principle in modern finance theory ever since. The hypothesis is based on three key assumptions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Perfect Competition: The hypothesis assumes that financial markets are characterized by perfect competition, meaning there are many buyers and sellers, and no individual participant can significantly influence prices.&lt;/li&gt;
&lt;li&gt;Rational Investors: It assumes that all market participants are rational and always act in a way to maximize their expected utility, based on all available information.&lt;/li&gt;
&lt;li&gt;Immediate Information Processing: The EMH assumes that all relevant information is available to investors at the same time and that they immediately and accurately process that information to adjust prices accordingly.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The Efficient Market Hypothesis is usually divided into three forms:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Weak Form EMH: This form of the hypothesis asserts that stock prices already reflect all past trading information, including price and volume data. In other words, technical analysis, which relies on historical price patterns, should not be able to consistently predict future price movements.&lt;/li&gt;
&lt;li&gt;Semi-Strong Form EMH: This version of the hypothesis states that stock prices already reflect all publicly available information, including financial statements, news, and other non-confidential information. Thus, fundamental analysis, which involves examining a company&amp;rsquo;s financials and prospects, should not provide an advantage in predicting future prices.&lt;/li&gt;
&lt;li&gt;Strong Form EMH: The strong form asserts that stock prices already reflect all information, whether it is public or private. This includes insider information that is not available to the general public. If the strong form holds, then no individual or entity, not even insiders, can consistently earn above-average returns based on private information.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;the-fundamental-law-of-active-portfolio-management&#34;&gt;The Fundamental Law of Active Portfolio Management&lt;/h2&gt;
&lt;p&gt;The Fundamental Law of Active Portfolio Management, also known as the Fundamental Law of Active Management or simply the Fundamental Law, is a key concept in the field of portfolio management. It was developed by Richard Grinold, a finance professor, and Ronald Kahn, a quantitative analyst, and was first published in their 1999 book &amp;ldquo;Active Portfolio Management.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;The Fundamental Law relates a portfolio&amp;rsquo;s expected excess return to two fundamental components: skill and breadth. It provides a quantitative framework for evaluating the performance of active portfolio managers, helping to distinguish between luck and skill in their investment decisions.&lt;/p&gt;
&lt;p&gt;The formula for the Fundamental Law of Active Portfolio Management is as follows:&lt;/p&gt;
&lt;p&gt;Information Ratio (IR) = IC (Information Coefficient) * √(BR) (Breadth)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Information Ratio (IR): The Information Ratio measures the portfolio manager&amp;rsquo;s ability to generate excess returns relative to a benchmark, adjusted for the level of risk taken. It is calculated as the ratio of the expected excess return (active return) to the tracking error of the portfolio. The higher the Information Ratio, the better the manager&amp;rsquo;s skill in generating consistent excess returns.&lt;/li&gt;
&lt;li&gt;Information Coefficient (IC): The Information Coefficient represents the manager&amp;rsquo;s ability to generate forecasts that are accurate and valuable. It quantifies the correlation between the manager&amp;rsquo;s forecasted returns and the realized returns. A perfect forecast would have an IC of 1, while an IC of 0 indicates that the manager&amp;rsquo;s forecasts are no better than random guesses.&lt;/li&gt;
&lt;li&gt;Breadth (BR): The Breadth component captures the number of independent investment opportunities that the portfolio manager can exploit. It reflects the diversification of the active positions within the portfolio. A larger breadth implies more opportunities to generate excess returns.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The Fundamental Law states that to achieve a higher Information Ratio, a portfolio manager can do one of the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Increase the Information Coefficient (IC): Improve the accuracy of their forecasts and the ability to identify mispriced assets or alpha-generating opportunities.&lt;/li&gt;
&lt;li&gt;Increase the Breadth (BR): Diversify the portfolio to include more independent alpha sources, which reduces the impact of idiosyncratic risk and improves the overall risk-adjusted performance.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The Fundamental Law of Active Portfolio Management is a valuable tool for understanding the relationship between skill, diversification, and the ability to generate alpha in active portfolio management. It helps investors and portfolio managers assess the effectiveness of their investment strategies and identify potential areas for improvement.&lt;/p&gt;
&lt;h2 id=&#34;portfolio-optimization-and-efficient-frontier&#34;&gt;Portfolio Optimization and efficient frontier&lt;/h2&gt;
&lt;p&gt;Mean-Variance Optimization (MVO) is a widely used quantitative approach in finance and portfolio management to construct an optimal portfolio that maximizes expected returns for a given level of risk or minimizes risk for a given level of expected returns. It was first introduced by Harry Markowitz in his seminal paper &amp;ldquo;Portfolio Selection&amp;rdquo; in 1952, which laid the foundation for modern portfolio theory.&lt;/p&gt;
&lt;p&gt;The key idea behind Mean-Variance Optimization is to find the allocation of assets in a portfolio that strikes a balance between the desire for higher returns and the aversion to risk. The process involves the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Expected Returns: Investors first estimate the expected returns of each asset in the portfolio based on historical data, forecasts, or other relevant information. These expected returns represent the mean or average return that investors expect to earn from each asset.&lt;/li&gt;
&lt;li&gt;Risk (Variance or Standard Deviation): The risk of an asset is typically measured by its variance or standard deviation. Variance quantifies the dispersion of an asset&amp;rsquo;s returns from its expected return. Standard deviation is simply the square root of variance. The higher the variance (or standard deviation), the higher the asset&amp;rsquo;s risk.&lt;/li&gt;
&lt;li&gt;Covariance and Correlation: Investors also need to calculate the covariance or correlation between each pair of assets in the portfolio. Covariance measures how two assets move together, while correlation standardizes the covariance to a value between -1 and +1, where -1 indicates a perfect negative relationship, +1 indicates a perfect positive relationship, and 0 indicates no relationship.&lt;/li&gt;
&lt;li&gt;Efficient Frontier: Mean-Variance Optimization seeks to find the combination of assets that generates the highest expected return for a given level of risk or the lowest risk for a given level of expected return. This set of optimal portfolios is referred to as the &amp;ldquo;efficient frontier.&amp;rdquo; It represents the set of portfolios that provides the best risk-reward trade-offs.&lt;/li&gt;
&lt;li&gt;Risk Tolerance: Finally, investors must define their risk tolerance level, which indicates how much risk they are willing to bear in pursuit of higher returns. The choice of portfolio from the efficient frontier will depend on an investor&amp;rsquo;s risk preferences.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Mean-Variance Optimization has been a cornerstone of modern portfolio theory and has greatly influenced the practice of portfolio management. However, critics argue that it makes some simplifying assumptions, such as assuming that returns follow a normal distribution and that investors are solely focused on risk and return, neglecting other aspects like liquidity preferences or behavioral biases. As a result, alternative approaches, like Black-Litterman model and Conditional Value-at-Risk (CVaR) optimization, have been proposed to address some of these limitations.&lt;/p&gt;
&lt;h1 id=&#34;learning-algorithms-for-trading&#34;&gt;Learning Algorithms for Trading&lt;/h1&gt;
&lt;h2 id=&#34;parametric-vs-non-parametric&#34;&gt;Parametric vs non parametric&lt;/h2&gt;
&lt;p&gt;A parametric learner, in the context of machine learning, refers to a model that makes strong assumptions about the underlying data distribution. It assumes a specific functional form or structure for the relationship between the input variables and the output variable. In other words, the model is characterized by a fixed number of parameters that need to be estimated from the training data. Examples of parametric learners include linear regression, logistic regression, and neural networks. Once the parameters are estimated, the model can make predictions or classifications based on new input data. Parametric learners tend to be computationally efficient and require less training data, but their performance heavily depends on the accuracy of the assumed parametric form.&lt;/p&gt;
&lt;p&gt;On the other hand, a non-parametric learner does not make explicit assumptions about the underlying data distribution or functional form. Instead, it seeks to directly learn the relationship between the input variables and the output variable from the training data. Non-parametric learners, such as k-nearest neighbors, decision trees, and support vector machines, can adapt to more complex and flexible relationships in the data. They typically have more parameters and their complexity grows with the size of the training set. Non-parametric learners may require more data for training and can be computationally more expensive, but they offer greater flexibility in capturing intricate patterns in the data.&lt;/p&gt;
&lt;h2 id=&#34;knn&#34;&gt;KNN&lt;/h2&gt;
&lt;p&gt;K-Nearest Neighbors (KNN) is a popular algorithm used in machine learning for both classification and regression tasks. In the context of classification, KNN predicts the class of a new data point based on the classes of its K nearest neighbors in the feature space. The algorithm assumes that similar instances tend to have similar labels.&lt;/p&gt;
&lt;p&gt;Overfitting occurs when a model learns too much from the training data, including noise and irrelevant patterns, which leads to poor generalization on unseen data. KNN can be prone to overfitting when the value of K is too small. With a small K, the model can become overly sensitive to the local characteristics of the training data, potentially causing the model to memorize the training examples and perform poorly on new instances.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;KNNClassifier&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self, k):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;k &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; k
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fit&lt;/span&gt;(self, X, y):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;X_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; X
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;y_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predict&lt;/span&gt;(self, X):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sample &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; X:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            distances &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum((self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;X_train &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; sample)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            nearest_indices &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argsort(distances)[:self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;k]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            nearest_labels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;y_train[nearest_indices]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            unique, counts &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique(nearest_labels, return_counts&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            y_pred&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(unique[np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(counts)])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; y_pred
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;kernel-regression&#34;&gt;Kernel regression&lt;/h2&gt;
&lt;p&gt;In kernel regression, the main idea is to assign weights to nearby data points based on their distance from the point being estimated. These weights, known as kernel weights, determine the influence of each data point on the estimation. The closer a data point is to the target point, the higher its weight and vice versa.&lt;/p&gt;
&lt;h2 id=&#34;rmse&#34;&gt;RMSE&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Root Mean Square Error (RMSE) is a commonly used metric to evaluate the performance of regression models. It measures the average deviation between the predicted and actual values of the target variable. RMSE provides a quantitative measure of the model&amp;rsquo;s accuracy by calculating the square root of the mean of squared differences between the predicted and actual values.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pros-of-rmse&#34;&gt;Pros of RMSE:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;RMSE takes into account both the magnitude and direction of errors, giving a comprehensive assessment of the model&amp;rsquo;s performance.&lt;/li&gt;
&lt;li&gt;It is widely used and easily interpretable, allowing for meaningful comparisons between different models or techniques.&lt;/li&gt;
&lt;li&gt;RMSE penalizes larger errors more heavily than mean absolute error, making it more sensitive to outliers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cons-of-rmse&#34;&gt;Cons of RMSE:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Since RMSE is based on squared differences, it amplifies the impact of large errors, which can be problematic if outliers or extreme values are present in the data.&lt;/li&gt;
&lt;li&gt;RMSE does not have the same unit of measurement as the target variable, making it less interpretable in terms of the original scale.&lt;/li&gt;
&lt;li&gt;It assumes that errors follow a Gaussian distribution and that there is no heteroscedasticity (unequal variance) in the residuals.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s an example of Python code for calculating RMSE from scratch:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rmse&lt;/span&gt;(y_true, y_pred):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    squared_errors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (y_true &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; y_pred) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    mean_squared_error &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(squared_errors)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    rmse &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(mean_squared_error)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; rmse
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the code above, the &lt;code&gt;rmse&lt;/code&gt; function takes the true values (&lt;code&gt;y_true&lt;/code&gt;) and predicted values (&lt;code&gt;y_pred&lt;/code&gt;) as input. It calculates the squared differences between the true and predicted values, computes the mean squared error, and returns the square root of the mean squared error as the RMSE.&lt;/p&gt;
&lt;p&gt;When using this implementation, it&amp;rsquo;s important to ensure that the true and predicted values are in the same format and shape. Additionally, data preprocessing, feature engineering, and model selection should be performed prior to calculating RMSE to ensure accurate evaluation of the model&amp;rsquo;s performance.&lt;/p&gt;
&lt;h2 id=&#34;mae&#34;&gt;MAE&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Mean Absolute Error (MAE) is a widely used metric for evaluating the performance of regression models. It measures the average absolute difference between the predicted and actual values of the target variable. MAE provides a straightforward measure of the model&amp;rsquo;s accuracy without considering the direction of errors.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pros-of-mae&#34;&gt;Pros of MAE:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;MAE is robust to outliers since it does not involve squaring the differences between predicted and actual values. It treats all errors equally regardless of their magnitude.&lt;/li&gt;
&lt;li&gt;It is easily interpretable as it has the same unit of measurement as the target variable, allowing for direct comparison and understanding of the model&amp;rsquo;s performance.&lt;/li&gt;
&lt;li&gt;MAE does not make any assumptions about the underlying distribution of errors and is less sensitive to heteroscedasticity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cons-of-mae&#34;&gt;Cons of MAE:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Since MAE does not square the errors, it may be less sensitive to large errors compared to metrics like RMSE, which can be a disadvantage when outliers need to be given more weight in the evaluation.&lt;/li&gt;
&lt;li&gt;MAE does not provide information on the variance or distribution of errors, making it less informative for certain types of analysis or decision-making.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s an example of Python code for calculating MAE from scratch:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mae&lt;/span&gt;(y_true, y_pred):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    absolute_errors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs(y_true &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; y_pred)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    mean_absolute_error &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(absolute_errors)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; mean_absolute_error
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the code above, the &lt;code&gt;mae&lt;/code&gt; function takes the true values (&lt;code&gt;y_true&lt;/code&gt;) and predicted values (&lt;code&gt;y_pred&lt;/code&gt;) as input. It calculates the absolute differences between the true and predicted values, computes the mean of these absolute differences, and returns it as the MAE.&lt;/p&gt;
&lt;p&gt;When using this implementation, ensure that the true and predicted values are in the same format and shape. Additionally, perform any necessary data preprocessing, feature engineering, and model selection before calculating MAE to ensure accurate evaluation of the model&amp;rsquo;s performance.&lt;/p&gt;
&lt;h2 id=&#34;cross-validation&#34;&gt;Cross validation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Cross-validation is a resampling technique used in machine learning to assess the performance and generalization ability of a model. It involves partitioning the available data into multiple subsets or folds, where each fold is used as both a training set and a validation set in a series of iterations. Cross-validation provides a more reliable estimate of the model&amp;rsquo;s performance by evaluating its consistency across different data subsets.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pros-of-cross-validation&#34;&gt;Pros of Cross-Validation:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cross-validation provides a more robust evaluation of the model&amp;rsquo;s performance compared to a single train-test split, as it utilizes multiple subsets of the data for training and testing.&lt;/li&gt;
&lt;li&gt;It helps to estimate how well the model generalizes to unseen data and provides insights into the model&amp;rsquo;s stability and consistency.&lt;/li&gt;
&lt;li&gt;Cross-validation allows for tuning hyperparameters and selecting the best model configuration by comparing the performance across different folds.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cons-of-cross-validation&#34;&gt;Cons of Cross-Validation:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Implementing cross-validation can be computationally expensive, especially for large datasets or complex models, as it requires fitting and evaluating the model multiple times.&lt;/li&gt;
&lt;li&gt;In some cases, the performance of a model can vary significantly across different folds, leading to a less reliable estimate of its generalization ability.&lt;/li&gt;
&lt;li&gt;Cross-validation may not account for certain types of data dependencies, such as time-series data, where the order of observations is important.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s an example of Python code for implementing k-fold cross-validation from scratch:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;cross_validation&lt;/span&gt;(X, y, model, k):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(X)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    fold_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; k
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    scores &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(k):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; fold_size
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        end &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; start &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; fold_size
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        X_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concatenate((X[:start], X[end:]), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concatenate((y[:start], y[end:]), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        X_val &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; X[start:end]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y_val &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y[start:end]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X_train, y_train)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        score &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(X_val, y_val)  &lt;span style=&#34;color:#75715e&#34;&gt;# Evaluation metric specific to the model&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        scores&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(score)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; scores
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the code above, the &lt;code&gt;cross_validation&lt;/code&gt; function takes the input features (&lt;code&gt;X&lt;/code&gt;), target variable (&lt;code&gt;y&lt;/code&gt;), the model to evaluate, and the number of folds (&lt;code&gt;k&lt;/code&gt;) as input. It iteratively partitions the data into training and validation sets, fits the model on the training data, and evaluates its performance using a specific evaluation metric. The function returns a list of scores obtained from each fold.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s important to note that the code provided is a basic implementation and may need to be modified or extended depending on the specific requirements of the model and evaluation metric. Additionally, the &lt;code&gt;model.fit&lt;/code&gt; and &lt;code&gt;model.evaluate&lt;/code&gt; methods represent placeholder functions and should be replaced with the appropriate methods for the chosen model.&lt;/p&gt;
&lt;h2 id=&#34;ensemble-learners&#34;&gt;Ensemble learners&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ensemble learning is a machine learning technique that combines multiple individual models, called base models or weak learners, to improve predictive performance and generalization ability. The idea behind ensemble learning is to leverage the diversity of the base models and aggregate their predictions to make a final prediction that is often more accurate and robust than that of any individual model.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ensemble learners can be categorized into two main types: bagging and boosting.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Bagging&lt;/strong&gt;: Bagging stands for bootstrap aggregating. It involves training multiple base models independently on different subsets of the training data, created through bootstrap sampling (sampling with replacement). The predictions from these models are then combined, typically through majority voting (for classification) or averaging (for regression), to obtain the final prediction. The goal is to reduce variance and improve generalization by reducing the impact of individual noisy or overfitting models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Boosting&lt;/strong&gt;: Boosting aims to sequentially train a series of base models, where each subsequent model focuses on correcting the mistakes made by the previous models. In boosting, the training data is reweighted, giving higher importance to the instances that were misclassified by previous models. The predictions of the base models are combined by weighted voting or weighted averaging to obtain the final prediction. Boosting methods, such as AdaBoost, Gradient Boosting, and XGBoost, often achieve high accuracy by iteratively building strong models from weak ones.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here&amp;rsquo;s an example of Python code for implementing ensemble learning using the Random Forest algorithm, which is a popular ensemble method based on bagging:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.ensemble &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; RandomForestClassifier
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create an ensemble of 100 decision tree classifiers&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ensemble &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RandomForestClassifier(n_estimators&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Train the ensemble on the training data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ensemble&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X_train, y_train)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Make predictions using the ensemble&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;predictions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ensemble&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X_test)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the code above, the &lt;code&gt;RandomForestClassifier&lt;/code&gt; class from the scikit-learn library is used to create an ensemble of 100 decision tree classifiers. The &lt;code&gt;n_estimators&lt;/code&gt; parameter specifies the number of base models in the ensemble. The ensemble is then trained on the training data (&lt;code&gt;X_train&lt;/code&gt; and &lt;code&gt;y_train&lt;/code&gt;), and predictions are made on the test data (&lt;code&gt;X_test&lt;/code&gt;) using the &lt;code&gt;predict&lt;/code&gt; method.&lt;/p&gt;
&lt;h2 id=&#34;reinforcement-learning&#34;&gt;Reinforcement Learning&lt;/h2&gt;
&lt;p&gt;Reinforcement Learning (RL) is a type of machine learning paradigm where an agent learns to make decisions and take actions in an environment to achieve a specific goal. Unlike supervised learning, where the model is trained on labeled data, or unsupervised learning, where the model finds patterns and structures in unlabeled data, RL focuses on learning through interaction with an environment and receiving feedback in the form of rewards or penalties.&lt;/p&gt;
&lt;p&gt;The basic components of a reinforcement learning system are as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Agent: The agent is the learner or decision-maker that interacts with the environment. It makes observations, takes actions, and learns from the rewards or penalties it receives.&lt;/li&gt;
&lt;li&gt;Environment: The environment is the context or setting in which the agent operates. It can be anything from a virtual environment in a computer simulation to a real-world scenario.&lt;/li&gt;
&lt;li&gt;Actions: At each time step, the agent chooses an action from a set of possible actions based on its current state and the information it has learned from previous interactions.&lt;/li&gt;
&lt;li&gt;State: The state represents the current situation or context of the agent within the environment. It captures the relevant information necessary for the agent to make decisions.&lt;/li&gt;
&lt;li&gt;Rewards: After taking an action, the agent receives feedback in the form of rewards or penalties from the environment. Positive rewards encourage the agent to take actions that lead to the desired goal, while negative rewards discourage undesired actions.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The objective of the agent in reinforcement learning is to learn a policy, which is a mapping from states to actions, that maximizes the cumulative reward over time. The agent employs exploration and exploitation strategies to balance between trying out new actions (exploration) and exploiting the knowledge it has gained so far to make optimal decisions (exploitation).&lt;/p&gt;
&lt;p&gt;Reinforcement learning has been successfully applied in various fields, including robotics, game playing (e.g., AlphaGo), autonomous vehicles, recommendation systems, finance, and more. Deep Reinforcement Learning (DRL), which combines reinforcement learning with deep neural networks, has shown remarkable achievements in complex tasks by utilizing deep learning&amp;rsquo;s ability to handle high-dimensional input data.&lt;/p&gt;
&lt;p&gt;One of the key challenges in reinforcement learning is the trade-off between exploration and exploitation, and the potential for the agent to get stuck in suboptimal solutions (local optima). Researchers continue to develop new algorithms and techniques to address these challenges and further advance the capabilities of reinforcement learning in practical applications.&lt;/p&gt;
&lt;h2 id=&#34;q-learning&#34;&gt;Q Learning&lt;/h2&gt;
&lt;p&gt;Q-learning is a popular model-free reinforcement learning algorithm used to find an optimal policy for an agent to make decisions in an environment. It was developed by Christopher Watkins in his PhD thesis in 1989. Q-learning is a type of Temporal Difference (TD) learning, which means it learns from the difference between its predictions and the observed rewards obtained from the environment.&lt;/p&gt;
&lt;p&gt;The central idea behind Q-learning is to estimate the value of taking a particular action in a given state, called the action-value function or Q-function. The Q-value represents the expected cumulative reward the agent can achieve by starting in a particular state, taking a specific action, and following an optimal policy thereafter.&lt;/p&gt;
&lt;p&gt;The Q-learning algorithm works as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Initialization: Initialize the Q-function arbitrarily for all state-action pairs. Typically, the Q-values are initialized to zero, or a small random value.&lt;/li&gt;
&lt;li&gt;Exploration vs. Exploitation: The agent interacts with the environment by taking actions based on its current policy. Initially, it often explores the environment by selecting random actions (exploration) to discover new strategies. As the learning progresses, the agent starts exploiting the Q-values it has learned to choose the actions with the highest Q-values.&lt;/li&gt;
&lt;li&gt;Update Q-values: After each action, the agent receives a reward from the environment and observes the new state. The Q-value for the (state, action) pair is updated using the Bellman equation:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Q(s, a) = Q(s, a) + α * [r + γ * max Q(s&amp;rsquo;, a&amp;rsquo;) - Q(s, a)]&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Q(s, a): The Q-value for state s and action a.&lt;/li&gt;
&lt;li&gt;α: The learning rate, which determines how much the agent updates its Q-values based on new information.&lt;/li&gt;
&lt;li&gt;r: The reward received by taking action a in state s.&lt;/li&gt;
&lt;li&gt;γ: The discount factor, which balances immediate rewards versus future rewards.&lt;/li&gt;
&lt;li&gt;max Q(s&amp;rsquo;, a&amp;rsquo;): The maximum Q-value for the next state s&amp;rsquo; and all possible actions a&amp;rsquo;.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Continue Exploration and Exploitation: The agent continues to interact with the environment, updating Q-values after each action, and refining its policy to improve performance over time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Q-learning is known to converge to the optimal Q-values and an optimal policy in the limit as the agent explores the environment indefinitely. It is especially effective in situations where the agent has no prior knowledge of the environment, and the transition model and reward function are unknown.&lt;/p&gt;
&lt;p&gt;Q-learning has been widely used in various applications, such as game playing, robotic control, and optimization problems, and has paved the way for more advanced deep reinforcement learning algorithms like Deep Q-Networks (DQNs) that leverage deep neural networks to approximate the Q-function in high-dimensional state spaces.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deterministic Optimization</title>
      <link>https://ayushsubedi.github.io/posts/deterministic_optimization/</link>
      <pubDate>Tue, 02 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/deterministic_optimization/</guid>
      <description>&lt;h1 id=&#34;general-overview-and-key-concepts&#34;&gt;General overview and key concepts&lt;/h1&gt;
&lt;iframe width=&#34;100%&#34; height=&#34;480&#34; src=&#34;https://www.youtube.com/embed/ijD2KSXWDyo&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;In plain English, &lt;strong&gt;optimization&lt;/strong&gt; is the action of making the best or most effective use of a situation or resource. Optimization problems are of great practical interest. For example, in manufacturing, how should one cut plates of a material so that the waste is minimized? In business, how should a company allocate the available resources that its profit is maximized? Some of the first optimization problems have been solved in ancient Greece and are regarded among the most significant discoveries of that time. In the first century A.D., the Alexandrian mathematician Heron solved the problem of finding the shortest path between two points by way of the mirror.&lt;/p&gt;
&lt;p&gt;This result, also known as Heron’s theorem of the light ray, can be viewed as the origin of the theory of geometrical optics. The problem of finding extreme values gained special importance in the seventeenth century, when it served as one of the motivations in the invention of differential calculus, which is the foundation of the modern theory of mathematical optimization.&lt;/p&gt;
&lt;h2 id=&#34;generic-form-of-optimization-problem&#34;&gt;Generic form of optimization problem:&lt;/h2&gt;
&lt;p&gt;$min$ $f(x)$ $s.t.$ $x \in X $&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The vector $x = (x_1, . . . , x_n)$ is the optimization variable (or decision variable) of the problem&lt;/li&gt;
&lt;li&gt;The function $f$ is the objective function&lt;/li&gt;
&lt;li&gt;A vector $x$ is called optimal, or a solution (not optimal solution) of the problem, if it has the smallest objective value among all vectors that satisfy the constraints&lt;/li&gt;
&lt;li&gt;$X$ is the set of inequality constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mathematical-ingredients&#34;&gt;Mathematical ingredients:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Encode decisions/actions as &lt;strong&gt;decision variables&lt;/strong&gt; whose values we are seeking&lt;/li&gt;
&lt;li&gt;Identify the relevant &lt;strong&gt;problem data&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Express &lt;strong&gt;constraints&lt;/strong&gt; on the values of the decision variables as mathematical relationships (inequalities) between the variables and problem data&lt;/li&gt;
&lt;li&gt;Express the &lt;strong&gt;objective function&lt;/strong&gt; as a function of the decision variables and the problem data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Minimize or Maximize an objective function of decision variable subject to constraints on the values of the decision variables.&lt;/strong&gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;min or max f(x1, x2, .... , xn)
subject to gi(x1, x2, ...., ) &amp;lt;= bi     i = 1,....,m 
        xj is continuous or discrete    j = 1,....,n
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;the-problem-setting&#34;&gt;The problem setting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Finite number of decision variables&lt;/li&gt;
&lt;li&gt;A single objective function of decision variables and problem data
&lt;ul&gt;
&lt;li&gt;Multiple objective functions are handled by either taking a weighted combination of them or by optimizing one of the objectives while ensuring the other objectives meet target requirements.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The constraints are defined by a finite number of inequalities or equalities involving functions of the decision variables and problem data&lt;/li&gt;
&lt;li&gt;There may be domain restrictions (continuous or discrete) on some of the variables&lt;/li&gt;
&lt;li&gt;The functions defining the objective and constraints are algebraic (typically with rational coefficients)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;minimization-vs-maximization&#34;&gt;Minimization vs Maximization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Without the loss of generality, it is sufficient to consider a minimization objective since maximization of objective function is minimization of the negation of the objective function&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;program-vs-optimization&#34;&gt;Program vs Optimization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A program or mathematical program is an optimization problem with a finite number of variables and constraints written out using explicit mathematical (algebraic) expressions&lt;/li&gt;
&lt;li&gt;The word program means plan/planning&lt;/li&gt;
&lt;li&gt;Early application of optimization arose in planning resource allocations and gave rise to programming to mean optimization (predates computer programming)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;example-designing-a-box&#34;&gt;Example: Designing a box:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Given a $1$ feet by $1$ feet piece of cardboard, cut out corners and fold to make a box of maximum volume:&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;Decision:&lt;/strong&gt; $x$ = how much to cut from each of the corners?&lt;br/&gt;
&lt;strong&gt;Alternatives:&lt;/strong&gt; $0&amp;lt;=x&amp;lt;=1/2$&lt;br/&gt;
&lt;strong&gt;Best:&lt;/strong&gt; Maximize volume: $V(x) = x(1-2x)^2$ ($x$ is the height and $(1-2x)^2$ is the base, and their product is the volume)&lt;br/&gt;
&lt;strong&gt;Optimization formulation:&lt;/strong&gt; $max$ $x(1-2x)^2$ subject to $0&amp;lt;=x&amp;lt;=1/2$ (which are the constraints in this case)&lt;br/&gt;&lt;/p&gt;
&lt;iframe src=&#34;https://www.desmos.com/calculator/ily45jyfsv?embed&#34; width=&#34;100%&#34; height=&#34;500&#34; style=&#34;border: 1px solid #ccc&#34; frameborder=0&gt;&lt;/iframe&gt;
&lt;p&gt;This is an unconstrained optimization problem since the constraint is a simple bound based.&lt;/p&gt;
&lt;h3 id=&#34;example-data-fitting&#34;&gt;Example: Data Fitting:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Given $N$ data points $(y_1, x_1)&amp;hellip;(y_N, x_N)$ where $y_i$ belongs to $\mathbb{R}$ and $x_i$ belongs to $\mathbb{R}^n$, for all $i = 1..N$, find a line $y = a^Tx+b$ that best fits the data.&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;Decision&lt;/strong&gt;: A vector $a$ that belongs to $\mathbb{R}^n$ and a scalar $b$ that belongs to $\mathbb{R}$&lt;br/&gt;
&lt;strong&gt;Alternatives&lt;/strong&gt;: All $n$-dimensional vectors and scalars&lt;br/&gt;
&lt;strong&gt;Best&lt;/strong&gt;: Minimize the sum of squared errors&lt;br/&gt;
&lt;strong&gt;Optimization formulation&lt;/strong&gt;:
$\begin{array}{ll}\min &amp;amp; \sum_{i=1}^N\left(y_i-a^{\top} x_i-b\right)^2 \ \text { s.t. } &amp;amp; a \in \mathbb{R}^n, b \in \mathbb{R}\end{array}$&lt;/p&gt;
&lt;p&gt;This is also an unconstrained optimization problem.&lt;/p&gt;
&lt;h3 id=&#34;example-product-mix&#34;&gt;Example: Product Mix:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A firm make $n$ different products using $m$ types of resources. Each unit of product $i$ generates $p_i$ dollars of profit, and requires $r_{ij}$ units of resource $j$. The firm has $u_j$ units of resource $j$ available. How much of each product should the firm make to maximize profits?&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;Decision&lt;/strong&gt;: how much of each product to make&lt;br/&gt;
&lt;strong&gt;Alternatives&lt;/strong&gt;: defined by the resource limits&lt;br/&gt;
&lt;strong&gt;Best&lt;/strong&gt;: Maximize profits&lt;br/&gt;
&lt;strong&gt;Optimization formulation:&lt;/strong&gt; &lt;br/&gt;
Sum notation: $\begin{array}{lll}\max &amp;amp; \sum_{i=1}^n p_i x_i \ \text { s.t. } &amp;amp; \sum_{i=1}^n r_{i j} x_i \leq u_j &amp;amp; \forall j=1, \ldots, m \ &amp;amp; x_i \geq 0 &amp;amp; \forall i=1, \ldots, n\end{array}$ &lt;br/&gt;
Matrix notation: $\begin{array}{cl}\max &amp;amp; p^{\top} x \ \text { s.t. } &amp;amp; R x \leq u \ &amp;amp; x \geq 0\end{array}$&lt;/p&gt;
&lt;h3 id=&#34;example-project-investment&#34;&gt;Example: Project investment&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt; A firm is considering investing in $n$ different R&amp;amp;D projects. Project $j$ requires an investment of $c_j$ dollars and promises a return of $r_j$ dollars. The firm has a budget of $B$ dollars. Which projects should the firm invest in?&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;Decision&lt;/strong&gt;: Whether or not to invest in project&lt;br/&gt;
&lt;strong&gt;Alternatives&lt;/strong&gt;: Defined by budget&lt;br/&gt;
&lt;strong&gt;Best&lt;/strong&gt;: Maximize return on investment&lt;br/&gt;
Sum notation: $\begin{aligned} \max &amp;amp; \sum_{j=1}^n r_j x_j \ \text { s.t. } &amp;amp; \sum_{j=1}^n c_j x_j \leq B \ &amp;amp; x_j \in{0,1} \forall j=1, \ldots, n\end{aligned}$ &lt;br/&gt;
Matrix notation: $\begin{aligned} \max  &amp;amp; r^{\top} x \ \text { s.t. } &amp;amp; c^{\top} x \leq B \ &amp;amp; x \in{0,1}^n\end{aligned}$&lt;/p&gt;
&lt;p&gt;This is not an unconstrained problem.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify basic portfolio optimization and associated issues&lt;/li&gt;
&lt;li&gt;Examine the Markowitz Portfolio Optimization approach
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Markowitz Principle&lt;/strong&gt;: Select a portfolio that attempts to maximize the expected return and minimize the variance of returns (risk)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For multi objective problem (like defined by the Markowitz Principle), two objectives can be combined:
&lt;ul&gt;
&lt;li&gt;Maximize Expected Return - $\lambda$*risk&lt;/li&gt;
&lt;li&gt;Maximize Expected Return subject to risk &amp;lt;= s_max (constraint on risk)&lt;/li&gt;
&lt;li&gt;Minimize Risk subject to return &amp;gt;= r_min (threshold on expected returns)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Optimization Problem Statement&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Given $1000, how much should we invest in each of the three stocks MSFT, V and WMT so as to :
- have a one month expected return of at least a given threshold
- minimize the risk(variance) of the portfolio return
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Decision&lt;/strong&gt;: investment in each stock&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;alternatives&lt;/strong&gt;: any investment that meets the budget and the minimum expected return requirement&lt;/li&gt;
&lt;li&gt;best: minimize variance&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key trade-off&lt;/strong&gt;: How much of the detail of the actual problem to consider while maintaining computational tractability of the mathematical model?&lt;/li&gt;
&lt;li&gt;Requires making simplifying assumptions, either because some of the problem characteristics are not well-defined mathematically, or because we wish to develop a model that can actually be solved&lt;/li&gt;
&lt;li&gt;Need to exercise great caution in these assumptions and not loose sight of the true underlying problem&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Assumptions&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;No transaction cost&lt;/li&gt;
&lt;li&gt;Stocks does not need to be bought in blocks (any amount &amp;gt;=0 is fine)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optimization Process&lt;/strong&gt;: Decision Problem -&amp;gt; Model -&amp;gt; Data Collection -&amp;gt; Model Solution -&amp;gt; Analysis -&amp;gt; Problem solution&lt;/li&gt;
&lt;li&gt;No clear cut recipe&lt;/li&gt;
&lt;li&gt;Lots of feedbacks and iterations&lt;/li&gt;
&lt;li&gt;Approximations and assumptions involved in each stage&lt;/li&gt;
&lt;li&gt;Success requires good understanding of the actual problem (domain knowledge is important)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;classification-of-optimization-problems&#34;&gt;Classification of optimization problems&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The tractability of a large scale optimization problem depends on the structure of the functions that make up the objective and constraints, and the domain restrictions on the variables.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Functions&lt;/th&gt;
&lt;th&gt;Variable domains&lt;/th&gt;
&lt;th&gt;Problem Type&lt;/th&gt;
&lt;th&gt;Difficulty&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;All linear&lt;/td&gt;
&lt;td&gt;Continuous variables&lt;/td&gt;
&lt;td&gt;Linear Program&lt;/td&gt;
&lt;td&gt;Easy&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Some nonlinear&lt;/td&gt;
&lt;td&gt;Continuous variables&lt;/td&gt;
&lt;td&gt;Nonlinear Program or Nonlinear Optimization Problem&lt;/td&gt;
&lt;td&gt;Easy/Difficult&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linear/nonlinear&lt;/td&gt;
&lt;td&gt;Some discrete&lt;/td&gt;
&lt;td&gt;Integer Problem or Discrete Optimization Problem&lt;/td&gt;
&lt;td&gt;Difficult&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Optimization Problem&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Difficulty&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Linear Programming&lt;/td&gt;
&lt;td&gt;A linear programming problem involves maximizing or minimizing a linear objective function subject to a set of linear constraints&lt;/td&gt;
&lt;td&gt;Easy to moderate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Nonlinear Programming&lt;/td&gt;
&lt;td&gt;A nonlinear programming problem involves optimizing a function that is not linear, subject to a set of nonlinear constraints&lt;/td&gt;
&lt;td&gt;Moderate to hard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Quadratic Programming&lt;/td&gt;
&lt;td&gt;A quadratic programming problem involves optimizing a quadratic objective function subject to a set of linear constraints&lt;/td&gt;
&lt;td&gt;Moderate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Convex Optimization&lt;/td&gt;
&lt;td&gt;A convex optimization problem involves optimizing a convex function subject to a set of linear or convex constraints&lt;/td&gt;
&lt;td&gt;Easy to moderate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Integer Programming&lt;/td&gt;
&lt;td&gt;An integer programming problem involves optimizing a linear or nonlinear objective function subject to a set of linear or nonlinear constraints, where some or all of the variables are restricted to integer values&lt;/td&gt;
&lt;td&gt;Hard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mixed-integer Programming&lt;/td&gt;
&lt;td&gt;A mixed-integer programming problem is a generalization of integer programming where some or all of the variables can be restricted to integer values or continuous values&lt;/td&gt;
&lt;td&gt;Hard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Global Optimization&lt;/td&gt;
&lt;td&gt;A global optimization problem involves finding the global optimum of a function subject to a set of constraints, which may be nonlinear or non-convex&lt;/td&gt;
&lt;td&gt;Hard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Stochastic Optimization&lt;/td&gt;
&lt;td&gt;A stochastic optimization problem involves optimizing an objective function that depends on random variables, subject to a set of constraints&lt;/td&gt;
&lt;td&gt;Hard&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;subclasses-of-nlp-non-linear-problem&#34;&gt;Subclasses of NLP (Non Linear Problem)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Unconstrained optimization&lt;/strong&gt;: No constraints or simple bound constraints on the variables (Box design example above)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quadratic programming&lt;/strong&gt;: Objectives and constraints involve quadratic functions (Data fitting example above), &lt;strong&gt;subset of NLP&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;subclasses-of-ip-integer-programming&#34;&gt;Subclasses of IP (Integer Programming)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mixed Integer Linear Program&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;All linear functions&lt;/li&gt;
&lt;li&gt;Some variables are continuous and some are discrete&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mixed Integer Nonlinear Program (MINLP)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Some nonlinear functions&lt;/li&gt;
&lt;li&gt;Some variables are continuous and some are discrete&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mixed Integer Quadratic Program (MIQLP)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Nonlinear functions are quadratic&lt;/li&gt;
&lt;li&gt;Some variables are continuous and some are discrete&lt;/li&gt;
&lt;li&gt;subset of MINLP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;why-and-how-to-classify&#34;&gt;Why and how to classify?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Important to recognize the type of an optimization problem:
&lt;ul&gt;
&lt;li&gt;to formulate problems to be amenable to certain solution methods&lt;/li&gt;
&lt;li&gt;to anticipate the difficulty of solving the problem&lt;/li&gt;
&lt;li&gt;to know which solution methods to use&lt;/li&gt;
&lt;li&gt;to design customized solution methods&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;how to classify:
&lt;ul&gt;
&lt;li&gt;check domain restriction on variables&lt;/li&gt;
&lt;li&gt;check the structure of the functions involved&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;linear-algebra-primer&#34;&gt;Linear Algebra Primer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Vectors&lt;/strong&gt;: Vectors are mathematical objects that have both magnitude and direction. They can be represented as ordered lists of numbers or as arrows in space.  Vectors are often used to represent physical quantities such as velocity or force. In two-dimensional space, a vector is represented by an ordered pair of numbers (x, y), and in three-dimensional space, it is represented by an ordered triple (x, y, z). Vectors can be added and subtracted, and multiplied by a scalar (a single number). They also have properties such as the dot product and cross product. In computer science and programming, a vector is also a data structure that can store multiple values of the same type.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Matrices&lt;/strong&gt;: Matrices are rectangular arrays of numbers that can be used to represent linear transformations and systems of linear equations. They are also used to represent data in statistics and machine learning.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linear equations&lt;/strong&gt;: Linear equations are equations that involve only linear terms, such as x and y, rather than more complex functions like sin(x) or e^x. They can be represented using matrices and solved using techniques like Gaussian elimination.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eigenvectors and eigenvalues&lt;/strong&gt;: Eigenvectors are special vectors that are unchanged by a linear transformation, except for a scaling factor. Eigenvalues are the corresponding scaling factors. They are useful in many applications, such as analyzing networks and modeling physical systems.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vector spaces&lt;/strong&gt;: Vector spaces are sets of vectors that satisfy certain properties, such as closure under addition and scalar multiplication. They are used to represent many mathematical objects, such as functions and polynomials.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inner products&lt;/strong&gt;: An inner product is a function that takes two vectors as input and produces a scalar as output. It is used to measure the angle between vectors and the length of a vector.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Orthogonality&lt;/strong&gt;: Two vectors are orthogonal if they are perpendicular to each other. Orthogonal vectors have many important applications, such as in least squares regression and in the Gram-Schmidt process for orthonormalizing a set of vectors.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;second derivative test&lt;/strong&gt; is a method used in calculus to determine the nature of the critical points of a function, which can be either a maximum, minimum, or saddle point.&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;critical point&lt;/strong&gt; is a point on the graph of a function where the derivative is either zero or undefined.&lt;/li&gt;
&lt;li&gt;To apply the second derivative test, we need to find the critical points of the function by setting its first derivative equal to zero and solving for the variables. Then, we can determine the nature of these critical points by examining the sign of the second derivative of the function evaluated at the critical points. Specifically:
&lt;ul&gt;
&lt;li&gt;If the second derivative is positive at a critical point, then the function has a local minimum at that point.&lt;/li&gt;
&lt;li&gt;If the second derivative is negative at a critical point, then the function has a local maximum at that point.&lt;/li&gt;
&lt;li&gt;If the second derivative is zero at a critical point, then the second derivative test is inconclusive, and we need to use other methods to determine the nature of the critical point.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The vectors $x$ and $y$ are orthogonal if $x^Ty=0$, they make an acute angle if $x^Ty&amp;gt;0$ and an obtuse angle if $x^Ty&amp;lt;0$&lt;/li&gt;
&lt;li&gt;Also, $x^Ty=||x||.||y||cos\theta$&lt;/li&gt;
&lt;li&gt;A set of vectors are &lt;strong&gt;linearly independent&lt;/strong&gt; if none of the vectors can be written as a linear combination of the others. That is the unique solution to the system of equations. There can be at most $n$ linearly independent vectors in $R^n$&lt;/li&gt;
&lt;li&gt;Any collection of $n$ linearly independent vectors in $R$ defines a &lt;strong&gt;basis&lt;/strong&gt; (or a coordinate system) of $R^n$, any vector in $R^n$ can be written as a linear combination of the basis vectors  The unit vectors $e^1= [1, 0, &amp;hellip;0]^T$, $e^2= [0, 1, &amp;hellip;0]^T$,&amp;hellip;,$e^n= [0, 0, &amp;hellip;1]^T$, define the standard basis for $R^n$&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;rank&lt;/strong&gt; of a matrix is a measure of the &amp;ldquo;nondegeneracy&amp;rdquo; of the matrix and it is one of the most important concepts in linear algebra. It is defined as the dimension of the vector space spanned by its columns or rows. Intuitively, it represents the number of linearly independent columns or rows in the matrix.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;row rank = column rank = rank($A$). $A$ is full rank if rank($A$) = min($m$, $n$)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;A system of equations has a solution when the equations are consistent, meaning that there is at least one set of values for the variables that satisfies all of the equations. If the equations are inconsistent, meaning that there is no set of values that satisfies all of the equations, then the system of equations has no solution.&lt;/li&gt;
&lt;li&gt;An &lt;strong&gt;affine function&lt;/strong&gt; is a function that is defined as a linear combination of variables, with the addition of a constant term. An affine function can be written as:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;f(x) = a_1x_1 + a_2x_2 + ... + a_nx_n + b
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Where x_1, x_2, &amp;hellip;, x_n are the input variables, a_1, a_2, &amp;hellip;, a_n are the coefficients, and b is a constant term. An affine function is a generalization of a linear function, which does not have the constant term.&lt;/p&gt;
&lt;iframe width=&#34;100%&#34; height =&#34;1024&#34; src=&#34;https://ayushsubedi.github.io/pdfs/la.pdf#toolbar=0&#34;&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;multivariate-calculus-primer&#34;&gt;Multivariate Calculus Primer&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://i.pinimg.com/736x/03/1e/73/031e73d364d35daf9ec479909c966505--systems-of-equations-maths-algebra.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;hessian-matrix&#34;&gt;Hessian matrix&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The Hessian matrix is a square matrix of second-order partial derivatives of a scalar-valued function of multiple variables.&lt;/li&gt;
&lt;li&gt;The Hessian matrix of a scalar-valued function f(x) of n variables x = (x1, x2, &amp;hellip;, xn) is defined as the matrix of second-order partial derivatives of f with respect to x, with the i-th row and j-th column containing the second partial derivative of f with respect to xi and xj.&lt;/li&gt;
&lt;li&gt;The Hessian matrix is often used in optimization, for example, to find the local minima or maxima of a function. A point where the Hessian is positive definite is a local minimum, while a point where the Hessian is negative definite is a local maximum. If the Hessian is positive semi-definite, it&amp;rsquo;s a saddle point.&lt;/li&gt;
&lt;li&gt;It is important to notice that the Hessian Matrix is symmetric, therefore it has real eigenvalues and it is diagonalisable.&lt;/li&gt;
&lt;li&gt;$H(f)_{i,j}=\frac{\partial^2f}{\partial x_i \partial x_j}$&lt;/li&gt;
&lt;li&gt;The symmetry of second derivatives (also called the equality of mixed partials) refers to the possibility of interchanging the order of taking partial derivatives of a function. The symmetry is the assertion that the second-order partial derivatives satisfy the identity. In the context of partial differential equations it is called the &lt;strong&gt;Schwarz integrability condition&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;$\frac{\partial^2f}{\partial x_i \partial x_j} = \frac{\partial^2f}{\partial x_j \partial x_i}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;taylor-approximation&#34;&gt;Taylor Approximation&lt;/h3&gt;
&lt;p&gt;The Taylor series of a real or complex-valued function f (x) that is infinitely differentiable at a real or complex number a is the power series.&lt;/p&gt;
&lt;p&gt;Let $f: \mathbb{R}^n \rightarrow \mathbb{R}$ be a differentiable function and $\mathbf{x}^0 \in \mathbb{R}^n$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First order Taylor&amp;rsquo;s approximation of $f$ at $\mathbf{x}^0$ :
$$
f(\mathbf{x}) \approx f\left(\mathbf{x}^0\right)+\nabla f\left(\mathbf{x}^0\right)^{\top}\left(\mathbf{x}-\mathbf{x}^0\right)
$$&lt;/li&gt;
&lt;li&gt;Second order Taylor&amp;rsquo;s approximation of $f$ at $\mathbf{x}^0$ :
$$
f(\mathbf{x}) \approx f\left(\mathbf{x}^0\right)+\nabla f\left(\mathbf{x}^0\right)^{\top}\left(\mathbf{x}-\mathbf{x}^0\right)+\frac{1}{2}\left(\mathbf{x}-\mathbf{x}^0\right)^{\top} \nabla^2 f\left(\mathbf{x}^0\right)\left(\mathbf{x}-\mathbf{x}^0\right)
$$
`&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sets-in-optimization-problems&#34;&gt;Sets in Optimization Problems&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A set is &lt;strong&gt;closed&lt;/strong&gt; if it includes its boundary points.&lt;/li&gt;
&lt;li&gt;Intersection of closed sets is closed.&lt;/li&gt;
&lt;li&gt;Typically, if none of inequalities are strict, then the set is closed.&lt;/li&gt;
&lt;li&gt;A set is convex if a line segment connecting two points in the set lies entirely in the set.&lt;/li&gt;
&lt;li&gt;A set is bounded if it can be enclosed in a large enough (hyper)-sphere or a box.&lt;/li&gt;
&lt;li&gt;A set that is both bounded and closed is called compact.
&lt;ul&gt;
&lt;li&gt;$R^2$ is closed but not bounded&lt;/li&gt;
&lt;li&gt;$x^2+y^2&amp;lt;1$ is bounded but not closed&lt;/li&gt;
&lt;li&gt;$x+y&amp;gt;=1$ is closed but not bounded&lt;/li&gt;
&lt;li&gt;$x^2+y^2&amp;lt;=1$ is closed and bounded (compact)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An optimal solution of maximizing a convex function over a compact set lies on the boundary
of the set.&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe src=&#34;https://www.desmos.com/calculator/49e59msg7u?embed&#34; width=&#34;100%&#34; height=&#34;500&#34; style=&#34;border: 1px solid #ccc&#34; frameborder=0&gt;&lt;/iframe&gt;
&lt;h3 id=&#34;convex-function&#34;&gt;Convex Function&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/ConvexFunction.svg/1280px-ConvexFunction.svg.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A function $f: \mathbb{R}^n \rightarrow \mathbb{R}$ is convex if
$$
f(\lambda \mathbf{x}+(1-\lambda) \mathbf{y}) \leq \lambda f(\mathbf{x})+(1-\lambda) f(\mathbf{y}) \quad \forall \mathbf{x}, \mathbf{y} \in \mathbb{R}^n \text { and } \lambda \in[0,1]
$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;ldquo;Function value at the average is less than the average of the function values&amp;rdquo;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;This also implies that $a^Tx+b$ is convex (and concave)&lt;/li&gt;
&lt;li&gt;For a convex function the first order Taylor&amp;rsquo;s approximation is a global under estimator&lt;/li&gt;
&lt;li&gt;A convex optimization problem has a convex objective and convex set of solutions.&lt;/li&gt;
&lt;li&gt;Linear programs (LPs) can be seen as a special case of convex optimization problems. In an LP, the objective function and constraints are linear, which means that the feasible region defined by the constraints is a convex set. As a result, the optimal solution to an LP is guaranteed to be at a vertex (corner) of the feasible region, which makes it a convex optimization problem.&lt;/li&gt;
&lt;li&gt;A twice differentiable univariate function is convex if $f^{&amp;rsquo;&amp;rsquo;}(x)&amp;gt;=0$ for all $x \in R$&lt;/li&gt;
&lt;li&gt;To generalize, a twice differentiable function is convex if and only if the Hessian matrix is positive semi definite.&lt;/li&gt;
&lt;li&gt;A positive semi-definite (PSD) matrix is a matrix that is symmetric and has non-negative eigenvalues. In the context of a Hessian matrix, it represents the second-order partial derivatives of a multivariate function and reflects the curvature of the function. If the Hessian is PSD, it indicates that the function is locally convex, meaning that it has a minimum value in the vicinity of that point. On the other hand, if the Hessian is not PSD, the function may have a saddle point or be locally non-convex. The PSD property of a Hessian matrix is important in optimization, as it guarantees the existence of a minimum value for the function.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sylvester&amp;rsquo;s criterion&lt;/strong&gt; is a method for determining if a matrix is positive definite or positive semi-definite. The criterion states that a real symmetric matrix is positive definite if and only if all of its leading principal minors (i.e. determinants of the submatrices formed by taking the first few rows and columns of the matrix) are positive. If all the leading principal minors are non-negative, then the matrix is positive semi-definite.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;operations-preserving-convexity&#34;&gt;Operations preserving convexity&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Nonnegative weighted sum of convex functions is convex&lt;/strong&gt;, i.e. if $f_i$ is convex and $\alpha_i \geq 0$ for all $i=1, \ldots, m$, then $g(\mathbf{x})=\sum_{i=1}^m \alpha_i f_i(\mathbf{x})$ is convex.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Maximum of convex functions is convex.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Composition&lt;/strong&gt;: Let $f: \mathbb{R}^m \rightarrow \mathbb{R}$ be a convex function, and $g_i: \mathbb{R}^n \rightarrow \mathbb{R}$ be convex for all $i=1, \ldots, m$. Then the composite function
$$
h(\mathbf{x})=f\left(g_1(\mathbf{x}), g_2(\mathbf{x}), \ldots, g_m(\mathbf{x})\right)
$$
is convex if either $f$ is &lt;strong&gt;nondecreasing or if each $q_i$ is a linear&lt;/strong&gt; function.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convexity-preserving-set-operations&#34;&gt;Convexity Preserving Set Operations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Intersection of convex sets is a convex set&lt;/li&gt;
&lt;li&gt;Intersection of non convex sets might be a convex set&lt;/li&gt;
&lt;li&gt;Union of two convex set might not be a convex set&lt;/li&gt;
&lt;li&gt;Sum of convex set is a convex set&lt;/li&gt;
&lt;li&gt;Product of convex set is a convex set&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convex-optimization-problem&#34;&gt;Convex Optimization Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;An optimization problem (in minimization) form is a convex optimization problem, if the objective function is a convex function and constraint set is a convex set.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;The problem $min$ ${f(x) :  x \in X}$ is a convex optimization problem if $f$ is a convex function and $X$ is a convex set.&lt;/li&gt;
&lt;li&gt;To check if a given problem is convex, we can check convexity of each constraint separately. (This is a sufficient test, not necessary).&lt;/li&gt;
&lt;li&gt;$\begin{array}{cl}\min &amp;amp; f(\mathbf{x}) \ \text { s.t. } \end{array}$
$\begin{array}{cl} g_i(\mathbf{x}) \leq b_i \quad i=1, \ldots, m \ &amp;amp; h_j(\mathbf{x})=d_j \quad j=1, \ldots, \ell \ &amp;amp; \mathbf{x} \in \mathbb{R}^n\end{array}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sufficient-and-necessary&#34;&gt;Sufficient and necessary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In mathematical logic, the terms &amp;ldquo;sufficient&amp;rdquo; and &amp;ldquo;necessary&amp;rdquo; are used to describe the relationship between two conditions.&lt;/li&gt;
&lt;li&gt;A condition A is considered &amp;ldquo;sufficient&amp;rdquo; for a condition B if whenever condition A is true, condition B is also guaranteed to be true. In other words, if A is sufficient for B, then having A implies having B.&lt;/li&gt;
&lt;li&gt;A condition B is considered &amp;ldquo;necessary&amp;rdquo; for a condition A if whenever condition B is false, condition A is also guaranteed to be false. In other words, if B is necessary for A, then not having B implies not having A.&lt;/li&gt;
&lt;li&gt;Together, &amp;ldquo;necessary and sufficient&amp;rdquo; means that the two conditions are equivalent, in the sense that if one is true, then the other must also be true, and if one is false, then the other must also be false. In mathematical terms, A is necessary and sufficient for B if and only if (A if and only if B).&lt;/li&gt;
&lt;li&gt;&amp;ldquo;being a male is a necessary condition for being a brother, but it is not sufficient — while being a male sibling is a necessary and sufficient condition for being a brother&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;epigraph-of-a-function&#34;&gt;Epigraph of a function&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Epigraph_convex.svg/660px-Epigraph_convex.svg.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An epigraph of a function is a graphical representation of the function&amp;rsquo;s domain and range. It is formed by the region above the graph of the function and the line x = a for some value of a. The epigraph represents all possible values of the function for all values of x greater than or equal to a. It is used in optimization problems to visualize the feasible region for the optimization variable.&lt;/li&gt;
&lt;li&gt;A function (in black) is convex if and only if the region above its graph (in green) is a convex set. This region is the function&amp;rsquo;s epigraph.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The epigraph and the $\alpha$ level set, of a convex function are convex sets.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;outcomes-of-optimization&#34;&gt;Outcomes of Optimization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Any $x \in X$ is a feasible solution of the optimization problem (P)&lt;/li&gt;
&lt;li&gt;Feasible solution = A solution that satisfies all the constraints&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;An unbounded problem must be feasible&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;An optimization problem is unbounded, if there are feasible solutions with arbitrarily small objective values.(limits to negative infinity for minimization problem)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;If $X=\emptyset$ then no feasible solutions exist, and the problem (P) is said to be infeasible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;If $X$ is a bounded set, then P cannot be unbounded&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;The problem $\min {3x+ 2y: x+ y&amp;lt;=1,x&amp;gt;=2,y&amp;gt;=2}$ is infeasible&lt;/li&gt;
&lt;li&gt;An optimization problem can have 4 possible outcomes. The outcome can be infeasible, unbounded (but feasible), have no optimal solution, have one optimal solution, or have multiple optimal solutions&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;existence-of-optimal-solutions&#34;&gt;Existence of Optimal Solutions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The Weierstrass extreme value theorem asserts that if you minimize a continuous function over a closed and bounded set in $R_n$, then the minimum will be achieved at some point in the set.&lt;/li&gt;
&lt;li&gt;Sufficient conditions: if the constraint set is bounded and non empty (feasible), then continuity and closedness guarantees an optimal solution exist.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;local-and-global-optimal-solutions&#34;&gt;Local and Global Optimal Solutions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Local optimal solutions are also global optimal solutions for convex optimization problems&lt;/li&gt;
&lt;li&gt;Every global optimal solution is a local optimal solution, but not vice versa&lt;/li&gt;
&lt;li&gt;The objective function value at different local optimal solutions may be different&lt;/li&gt;
&lt;li&gt;The objective function value at all global solutions must be the same&lt;/li&gt;
&lt;li&gt;If the problem is convex, since any local solution is a global solution, we can be sure that if we find a local solution, that is also a global solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/go.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;idea-of-improving-search&#34;&gt;Idea of Improving Search&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Most optimization algorithms are based on the paradigm of improving search:
&lt;ul&gt;
&lt;li&gt;Start from a feasible solution&lt;/li&gt;
&lt;li&gt;Move to a new feasible solution with a better objective value, Stop if not possible&lt;/li&gt;
&lt;li&gt;Repeat step 2&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In general, we are only able to look in the &amp;ldquo;neighborhood&amp;rdquo; of the current solution in search of a better feasible solution (solutions that are within a small positive distance from the current solution)&lt;/li&gt;
&lt;li&gt;The move direction and step size should ensure that the new point is feasible and has an improved objective function value&lt;/li&gt;
&lt;li&gt;The improving search is better for local solutions, but for convex, in principal it can be used to find global solutions (by definition)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;optimality-certificates&#34;&gt;Optimality Certificates&lt;/h2&gt;
&lt;h3 id=&#34;optimality-certificates-and-relaxations&#34;&gt;Optimality Certificates and Relaxations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;A certificate or a stopping condition is an easily checkable condition such that if the current solution satisfies this condition then it is guaranteed to be optimal or near optimal&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Lower bound (a Priori) that the objective value of any solution cannot be lower than.&lt;/li&gt;
&lt;li&gt;Suppose we have a feasible solution $x&amp;rsquo;$ to an optimization problem with an objective value of $f(x&amp;rsquo;)$. Suppose the optimal objective value of the problem is $v*$. Then the absolute optimality gap of the solution is $gap(x&amp;rsquo;)$ = $f(x&amp;rsquo;) - v*$. And, the relative gap is $(f(x&amp;rsquo;) - v*)$/$v*$. The gap and rgap are always non negative.&lt;/li&gt;
&lt;li&gt;We do not know $v*$ but we do know the lower bound $L$. From definition, $L&amp;lt;=v*&amp;lt;=f(x&amp;rsquo;)$&lt;/li&gt;
&lt;li&gt;A lower bound allows us to get an upper bound on the solution.&lt;/li&gt;
&lt;li&gt;For two optimization problem (P) $min$ $f(x)$ $s.t.$ $x \in X $ and (Q) $min$ $g(x)$ $s.t.$ $x \in Y $, Problem (Q) is a relaxation of P
&lt;ul&gt;
&lt;li&gt;if $X \subseteq Y$ (problem Q admits more solution than P) and/or&lt;/li&gt;
&lt;li&gt;$f(x) &amp;gt;= g(x) \forall x \in X $&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Obtained by enlarging the feasible region and underapproximating the objective function&lt;/strong&gt;. We do not have to do both of those (see equals to sign)&lt;/li&gt;
&lt;li&gt;Relaxation should be easier to solve.&lt;/li&gt;
&lt;li&gt;Optimal value of the relaxation provides a lower bound on the original problem. (This provides the optimality certificate.)&lt;/li&gt;
&lt;li&gt;If the relaxation is infeasible then the original problem is also infeasible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Suppose only the constraints are relaxed, then if a solution to the relaxation is feasible to the original problem then it must be an optimal solution to the original problem.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;A lower bound on the optimal value provides a way to certify the quality of a given solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lagrangian-relaxation-and-duality&#34;&gt;Lagrangian Relaxation and Duality&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Very specific type of relaxation&lt;/li&gt;
&lt;li&gt;Lagrangian relaxation is a method used in optimization to solve a difficult problem by relaxing some of its constraints and instead optimizing a modified objective function known as the Lagrangian function. The Lagrangian function is constructed by adding a penalty term for each constraint to the original objective function. The penalty term is multiplied by a non-negative Lagrange multiplier that represents the slack in the constraint. By choosing appropriate values for the multipliers, the relaxed problem can be made to approximate the original problem.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The dual problem attempts to find the relaxation with the tightest bound (or the largest lower bound)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Weak duality: dual optimal value &amp;lt;= original optimal value&lt;/li&gt;
&lt;li&gt;Some times we get strong duality (for LP)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/lag_duality.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;unconstrained-optimization-derivative-based&#34;&gt;Unconstrained Optimization: Derivative Based&lt;/h2&gt;
&lt;h3 id=&#34;optimality-conditions&#34;&gt;Optimality Conditions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Unconstrained, that is the constraints are only $x \in R^n$ and twice differentiable&lt;/li&gt;
&lt;li&gt;If a solution is a local optimal solution of an unconstrained problem, then the gradient vanishes at the point (First order optimality condition)&lt;/li&gt;
&lt;li&gt;Hessian is a positive semidefinite (Second order optimality condition)&lt;/li&gt;
&lt;li&gt;The conditions are &lt;strong&gt;necessary but not sufficient&lt;/strong&gt;. Example: $f(x_$)$&lt;/li&gt;
&lt;li&gt;For example for, $f(x)=x^3$, at point 0, both of the conditions are satisfied. However, it is neither a local min or max.&lt;/li&gt;
&lt;li&gt;A sufficient (but not necessary) condition would be the gradient vanishing at the point, and is the Hessian is positive definite.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;gradient-descent&#34;&gt;Gradient Descent&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The gradient descent method moves from one iteration to the next by moving along the negative of the gradient direction in order to minimize the function.&lt;/li&gt;
&lt;li&gt;Gradient descent is a optimization algorithm used to minimize the error of a machine learning model. It is an iterative method that updates the model parameters in the direction of the negative gradient of the cost function with respect to the parameters. The gradient indicates the direction of steepest increase in the cost function and the descent refers to moving in the direction of negative gradient to find the minimum of the cost function. The learning rate determines the size of the steps taken to reach the minimum and the algorithm stops when the change in cost is below a certain threshold or when a maximum number of iterations is reached.&lt;/li&gt;
&lt;li&gt;Let $x^k$ be the current iterate, and we want to chose a downhill direction $d^k$ and a step size $a$ such that $f(x^k+ad^k)&amp;lt;f(x^k)$&lt;/li&gt;
&lt;li&gt;By Taylor&amp;rsquo;s expansion, $f(x^k+ad^k) \approx f(x^k) + a \nabla f(x^k)^Td_k$&lt;/li&gt;
&lt;li&gt;So we want $\nabla f(x^k)^Td_k &amp;lt; 0$. The steepest descent direction is $d^k = - \nabla f(x^k) $&lt;/li&gt;
&lt;li&gt;Step size can be identified using a line search. That is, define a function $g(a) := f(x^k + ad^k)$. Choose $a$ to minimize $g$. It can also be a small fixed step size.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;newtons-method&#34;&gt;Newton&amp;rsquo;s Method&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Newton&amp;rsquo;s Method is a second-order optimization algorithm that is used to find the minimum of a function. It is an iterative method that updates the parameters by using the gradient of the function (first derivative) and the Hessian matrix (second derivative) to find the direction of the local minimum. The algorithm starts with an initial guess for the parameters and iteratively updates them using the Newton-Raphson formula until the change in the parameters is below a certain threshold or a maximum number of iterations is reached. Newton&amp;rsquo;s Method is faster and more precise than gradient descent for well-behaved functions, but it can be sensitive to poor initialization and can get stuck in local minima.&lt;/li&gt;
&lt;li&gt;$x^{k+1} $ = $x^k$ - $[\nabla^2$ $f(x_k)]^{-1}$ $ \nabla f(x^k)$&lt;/li&gt;
&lt;li&gt;If started close enough to local minimum and the Hessian is positive definite, then the method has quadratic convergence&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Not guaranteed to converge. The Newton direction may not be improving at all.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;If the Hessian is singular (or close to singular) at some iteration, we cannot proceed.&lt;/li&gt;
&lt;li&gt;Computing gradient as well as the Hessian and its inverse is expensive.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;quasi-newton-methods&#34;&gt;Quasi-Newton Methods&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Blend of gradient descent and Newton&amp;rsquo;s method.&lt;/li&gt;
&lt;li&gt;Avoids computation of Hessian and its inverse&lt;/li&gt;
&lt;li&gt;$x^{k+1} $ = $x^k$ - $a_k H_k$ $ \nabla f(x^k)$, where $H_k$ is an approximation of $[\nabla^2$ $f(x_k)]^{-1}$ and $a_k$ is determined by line search&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;unconstrained-optimization-derivative-free&#34;&gt;Unconstrained Optimization: Derivative Free&lt;/h2&gt;
&lt;h3 id=&#34;methods-for-univariate-functions&#34;&gt;Methods for Univariate Functions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Golden Section Search: Start with an initial interval $[x_l, x_u]$ containing the minima, and successively narrow this interval&lt;/li&gt;
&lt;li&gt;Golden Section Search is an optimization algorithm used to find the minimum of a unimodal function, i.e., a function with a single minimum. The method is based on the idea of dividing an interval that contains the minimum into three sections, with the middle section being proportional to the golden ratio. The algorithm iteratively narrows down the interval by selecting the section that contains the minimum and discards the other sections. The process continues until the interval is sufficiently small and the minimum can be approximated with a desired accuracy. Golden Section Search is a bracketing method, which means it only requires the function to be unimodal and does not require the derivative or any other information about the function. It is a simple and efficient method for finding the minimum of unimodal functions, but it is slower than more sophisticated optimization methods for functions with multiple minima or more complex structures.&lt;/li&gt;
&lt;li&gt;Step 0: Set $x_1 = x_u - a(x_u-x_l)$ and $x_2=x_l+a(x_u-x_l)$&lt;/li&gt;
&lt;li&gt;Step 1: If $(x_u-x_l) &amp;lt;= \epsilon$ stop and return $x^* = 0.5(x_l+x_u)$ as the minima&lt;/li&gt;
&lt;li&gt;Example of how to use scipy.optimize.minimize to minimize a scalar function:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;import numpy as np
from scipy.optimize import minimize

def objective_function(x):
    return x**2 + 5*np.sin(x)

x0 = np.array([1.0]) # Initial guess
result = minimize(objective_function, x0, method=&amp;#39;BFGS&amp;#39;)
print(&amp;#34;Minimum at:&amp;#34;, result.x)
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;methods-for-multivariate-function&#34;&gt;Methods for Multivariate Function&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/d/de/Nelder-Mead_Himmelblau.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Nelder-Mead method is a optimization algorithm used to minimize a scalar function of several variables. It is a derivative-free method, meaning that it does not require the gradient of the objective function to be calculated. It works by constructing a simplex (a set of vertices) in the high-dimensional space defined by the input variables, and then iteratively modifying the vertices to find the minimum.&lt;/li&gt;
&lt;li&gt;Here&amp;rsquo;s an example of how to use scipy.optimize.minimize with the Nelder-Mead method:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;import numpy as np
from scipy.optimize import minimize

def objective_function(x):
    return x**2 + 5*np.sin(x)

x0 = np.array([1.0]) # Initial guess
result = minimize(objective_function, x0, method=&amp;#39;Nelder-Mead&amp;#39;)
print(&amp;#34;Minimum at:&amp;#34;, result.x)
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Nelder-Mead method is a numerical algorithm for minimizing a multivariate function using only function evaluations&lt;/li&gt;
&lt;li&gt;It is not guaranteed to converge but often works well.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;linear-optimization&#34;&gt;Linear optimization&lt;/h1&gt;
&lt;h2 id=&#34;linear-optimization-modeling---network-flow-problems&#34;&gt;Linear Optimization Modeling - Network Flow Problems&lt;/h2&gt;
&lt;h3 id=&#34;introduction-to-lp-modeling&#34;&gt;Introduction to LP Modeling&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A linear program is composed of:
&lt;ul&gt;
&lt;li&gt;Variables $x=(x_1,x_2,x_3&amp;hellip;,x_n)$&lt;/li&gt;
&lt;li&gt;Linear objective function $f(x_1,x_2,x_3&amp;hellip;,x_n)=\sum_{i=1}^n c_i x_i = c^Tx$&lt;/li&gt;
&lt;li&gt;Linear constraints: $&amp;gt;=, &amp;lt;= or =$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;All linear problems can be written as a inner product of two vectors.&lt;/li&gt;
&lt;li&gt;The objective function must be a linear function of the variables.&lt;/li&gt;
&lt;li&gt;The constraints must be linear inequality or equality constraints.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;optimal-transportation-problem&#34;&gt;Optimal Transportation Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The transportation problem is a type of linear programming problem that deals with finding the optimal assignment of resources to meet a set of demands. The problem is typically framed as a network flow problem, where the goal is to find the maximum flow from a set of sources to a set of destinations.&lt;/li&gt;
&lt;li&gt;In a transportation problem, the goal is to find the least cost way to transport a given amount of goods from a set of sources (e.g. factories) to a set of destinations (e.g. warehouses) subject to certain constraints such as limited supply at the sources and limited demand at the destinations. The cost of transporting a unit of goods from a source to a destination is represented by a cost matrix, which is usually obtained through market research or historical data.&lt;/li&gt;
&lt;li&gt;There are various algorithms that can be used to solve transportation problems, including the North-West Corner Method, the Minimum Cost Method (also known as the Vogel&amp;rsquo;s Approximation Method), and the Modified Distribution Method. The most popular algorithm for solving transportation problems is the Iterative Proportional Fitting (IPF) algorithm, also known as the MODI (Modified Distribution) method.&lt;/li&gt;
&lt;li&gt;The transportation problem is an important optimization problem with numerous real-world applications, including supply chain management, distribution systems, and logistics planning.&lt;/li&gt;
&lt;li&gt;There are $m$ suppliers, $n$ customers. Supplier $i$ can supply up to $s_i$ units of supply, and customer $j$ has $d_j$ units of demand. It costs $c_{ij}$ to transport a unit of product from supplier $i$ to customer $j$. We want to find a transportation schedule to satisfy all the demand within minimum transportation cost.&lt;/li&gt;
&lt;li&gt;Formulation 1: $\begin{array}{ll}\min &amp;amp; \sum_{i=1}^m \sum_{j=1}^n c_{i j} x_{i j} \ \text { s.t. } &amp;amp; \sum_{i=1}^m x_{i j}=d_j, \quad \forall j \ &amp;amp; \sum_{j=1}^n x_{i j} \leq s_i, \quad \forall i \ &amp;amp; x_{i j} \geq 0, \quad \forall i, j .\end{array}$&lt;/li&gt;
&lt;li&gt;Formulation 2: $\begin{array}{ll}\min &amp;amp; \sum_{i=1}^m \sum_{j=1}^n c_{i j} x_{i j} \ \text { s.t. } &amp;amp; \sum_{i=1}^m x_{i j}&amp;gt;=d_j, \quad \forall j \ &amp;amp; \sum_{j=1}^n x_{i j} \leq s_i, \quad \forall i \ &amp;amp; x_{i j} \geq 0, \quad \forall i, j .\end{array}$&lt;/li&gt;
&lt;li&gt;But &amp;gt;= inequality in the second formulation will be satisfied as = at optimal solution, thus, the two formulations are equivalent&lt;/li&gt;
&lt;li&gt;The graphs here are bipartite.&lt;/li&gt;
&lt;li&gt;The total supply is greater than or equal to the total demand.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;maximum-flow-problem&#34;&gt;Maximum Flow Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The maximum flow problem is a classical problem in network flow theory that aims to find the maximum amount of flow that can be sent from a source node to a sink node in a network, subject to capacity constraints on the edges. The maximum flow problem is a special case of the more general minimum cut problem, which aims to find the minimum capacity of a cut that separates the source and the sink in the network.&lt;/li&gt;
&lt;li&gt;A network in this context is represented as a graph, where the nodes represent the vertices and the edges represent the capacities of the arcs. The source node is where the flow originates, and the sink node is where the flow terminates. The capacity constraints on the edges determine the maximum amount of flow that can be sent through a particular edge.&lt;/li&gt;
&lt;li&gt;There are several algorithms that can be used to solve the maximum flow problem, including the Ford-Fulkerson algorithm, the Edmonds-Karp algorithm, and the push-relabel algorithm. These algorithms work by finding augmenting paths in the residual network, which is a network derived from the original network that represents the remaining capacities of the edges after some flow has already been sent. The algorithms continue to find augmenting paths until no more can be found, at which point the maximum flow has been found.&lt;/li&gt;
&lt;li&gt;The maximum flow problem has many real-world applications, including traffic flow in transportation networks, the allocation of bandwidth in communication networks, and the distribution of resources in supply chain networks.&lt;/li&gt;
&lt;li&gt;The graphs here are directed&lt;/li&gt;
&lt;li&gt;$\begin{array}{ll}\max &amp;amp; b_s \ \end{array}$&lt;/li&gt;
&lt;li&gt;$\begin{array}{ll} \text { s.t. } &amp;amp; \sum_{k \in O(i)} x_{i k}-\sum_{j \in I(i)} x_{j i}=b_i \quad \forall i \ &amp;amp; b_t=-b_s \ &amp;amp; b_i=0, \quad \forall i \neq s, t \ &amp;amp; 0 \leq x_{i j} \leq u_{i j}, \quad \forall(i, j) \in \mathcal{A} .\end{array}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;minimum-cut-problem&#34;&gt;Minimum Cut Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The Maximum Cut Problem is a well-known optimization problem in computer science and mathematics. The goal of the problem is to divide a given graph into two sets of vertices such that the sum of the weights of the edges between the two sets is as large as possible.&lt;/li&gt;
&lt;li&gt;Formally, given a graph G = (V,E) with a weight function w : E → R, the maximum cut problem is to find a partition of the vertices into two sets S and T such that the sum of the weights of the edges between S and T is maximized.&lt;/li&gt;
&lt;li&gt;The problem is NP-hard, meaning that finding the optimal solution is computationally infeasible for large graphs. However, there are approximate algorithms that can find near-optimal solutions, such as semidefinite programming, spectral methods, and local search algorithms.&lt;/li&gt;
&lt;li&gt;The maximum cut problem has a wide range of applications, including network design, image and signal processing, and machine learning.&lt;/li&gt;
&lt;li&gt;Minimum cut = Maximum flow&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;shortest-path-problem&#34;&gt;Shortest Path Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The Maximum Cut Problem is a well-known optimization problem in computer science and mathematics. The goal of the problem is to divide a given graph into two sets of vertices such that the sum of the weights of the edges between the two sets is as large as possible.&lt;/li&gt;
&lt;li&gt;Formally, given a graph G = (V,E) with a weight function w : E → R, the maximum cut problem is to find a partition of the vertices into two sets S and T such that the sum of the weights of the edges between S and T is maximized.&lt;/li&gt;
&lt;li&gt;The problem is NP-hard, meaning that finding the optimal solution is computationally infeasible for large graphs. However, there are approximate algorithms that can find near-optimal solutions, such as semidefinite programming, spectral methods, and local search algorithms.&lt;/li&gt;
&lt;li&gt;The maximum cut problem has a wide range of applications, including network design, image and signal processing, and machine learning.&lt;/li&gt;
&lt;li&gt;Shortest Path Problem is a Flow problem if we are shipping 1 unit of flow from $s$ to all other nodes&lt;/li&gt;
&lt;li&gt;$\begin{array}{ll}\min &amp;amp; \sum_{(i, j) \in \mathcal{A}} c_{i j} x_{i j} \ \end{array}$&lt;/li&gt;
&lt;li&gt;$\begin{array}{ll}{ s.t. } &amp;amp; \sum_{k \in O(i)} x_{i k}-\sum_{j \in I(i)} x_{j i}=-1 \forall i \neq s \ &amp;amp; \sum_{k \in O(s)} x_{s k}-\sum_{j \in I(s)} x_{j s}=n-1 \ &amp;amp; x_{i j} \geq 0, \quad \forall(i, j) \in \mathcal{A} .\end{array}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lp-model-for-market-clearing&#34;&gt;LP model for market clearing:&lt;/h3&gt;
&lt;img src=&#34;https://ayushsubedi.github.io/img/op.png&#34; width=&#34;300&#34; height=&#34;200&#34;&gt;
&lt;h3 id=&#34;rosenbrock-function&#34;&gt;Rosenbrock function&lt;/h3&gt;
&lt;p&gt;The Rosenbrock function is a widely used test function in optimization and is often used as a performance test for optimization algorithms. Here&amp;rsquo;s a simple code to plot the Rosenbrock function in Python using Matplotlib:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;import numpy as np
import matplotlib.pyplot as plt

def rosenbrock(x, y):
    return (1-x)**2 + 100*(y-x**2)**2

x = np.linspace(-2, 2, 400)
y = np.linspace(-1, 3, 400)
X, Y = np.meshgrid(x, y)
Z = rosenbrock(X, Y)

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection=&amp;#39;3d&amp;#39;)
ax.plot_surface(X, Y, Z, cmap=&amp;#39;viridis&amp;#39;)
ax.set_xlabel(&amp;#39;X axis&amp;#39;)
ax.set_ylabel(&amp;#39;Y axis&amp;#39;)
ax.set_zlabel(&amp;#39;Z axis&amp;#39;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/rosenbrock.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;lp-model-for-electricity-markets&#34;&gt;LP model for Electricity Markets&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Decision variables
&lt;ul&gt;
&lt;li&gt;Generator output: $p_i$ for each generator $i \in G$&lt;/li&gt;
&lt;li&gt;Power flow: $f_{ij}$ on each edge $(i,j) \in E$&lt;/li&gt;
&lt;li&gt;Nodal potential $\theta_i$ on each node $i \in N$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Objective function:
&lt;ul&gt;
&lt;li&gt;minimize the cost of production, $\sum_{i=1}^{G} c_ip_i$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Constraints:
&lt;ul&gt;
&lt;li&gt;Flow conservation (input=output)
&lt;ul&gt;
&lt;li&gt;for source node $p$ we have: (&amp;ldquo;sum of everything going out&amp;rdquo;) - (&amp;ldquo;sum of everything going in&amp;rdquo;) = $p$&lt;/li&gt;
&lt;li&gt;for demand node $d$ we have: (&amp;ldquo;sum of everything going out&amp;rdquo;) - (&amp;ldquo;sum of everything going in&amp;rdquo; ) = $-d$&lt;/li&gt;
&lt;li&gt;for node which is neither source nor demand we have: (&amp;ldquo;sum of everything going out&amp;rdquo;) - (&amp;ldquo;sum of everything going in&amp;rdquo;) = $0$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nodal potential&lt;/li&gt;
&lt;li&gt;Flow limit constraint&lt;/li&gt;
&lt;li&gt;Generator physical limit constraint&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;inventory-control-problem&#34;&gt;Inventory Control Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;a company must commit to specific production quantity x before knowing the exact demand $d$&lt;/li&gt;
&lt;li&gt;after seeing the demand, the company decides how many to sell and how many to sell at a discounted price of $v$&lt;/li&gt;
&lt;li&gt;This is an example of Decision Making under Uncertainty&lt;/li&gt;
&lt;li&gt;Here and Now decision: production quantity $x$&lt;/li&gt;
&lt;li&gt;Wait and See decision: sell quantity $y$, discount quantity $z$&lt;/li&gt;
&lt;li&gt;Objective: minimize production cost and expected future cost&lt;/li&gt;
&lt;li&gt;Stochastic program:&lt;/li&gt;
&lt;li&gt;$min_{x} cx + E_d[Q(x,d)]$ s.t $0&amp;lt;=x&amp;lt;=\hat{x}$&lt;/li&gt;
&lt;li&gt;$Q(x,d) = min_{y,z} -r.y-s.z$ s.t $y&amp;lt;=d, y+z&amp;lt;=x, y&amp;gt;=0, z&amp;gt;=0$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;generation-capacity-expansion&#34;&gt;Generation Capacity Expansion&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;An electric utility company plans to build new generation stations to serve growing demand, called generation capacity expansion.&lt;/li&gt;
&lt;li&gt;New generation capacity has to be decided before demand and future fuel price are known&lt;/li&gt;
&lt;li&gt;Future demand and fuel prices are not known at the moment of making capacity decision, but can be estimated as random variables.&lt;/li&gt;
&lt;li&gt;After demand is realized, the utility company schedules existing and new generators based on capacity expansion decision.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;financial-planning&#34;&gt;Financial Planning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A family wishes to provide for a child&amp;rsquo;s college education 12 years later.&lt;/li&gt;
&lt;li&gt;The family currently has 100k and decides how to invest in any of 5 investments&lt;/li&gt;
&lt;li&gt;Investment can be adjusted every 4 years. So there are 3 periods&lt;/li&gt;
&lt;li&gt;The returns of investments are unknown and modeled as random variables&lt;/li&gt;
&lt;li&gt;The family wants to maximize the total expected return&lt;/li&gt;
&lt;li&gt;A problem of decision making under uncertainty&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;decision-types&#34;&gt;Decision Types&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Here-and-Now: decision made before knowing uncertain parameters&lt;/li&gt;
&lt;li&gt;Wait-and-See: decision made after knowing uncertain parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;basic-geometric-objects&#34;&gt;Basic Geometric Objects&lt;/h2&gt;
&lt;h3 id=&#34;points-and-vectors&#34;&gt;Points and vectors&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Point: geometric object in space&lt;/li&gt;
&lt;li&gt;Algebraically, a point in n-dimensional space is given by its coordinates: $x = (x_1, &amp;hellip;, x_n)^T \in R^n$&lt;/li&gt;
&lt;li&gt;We always write a vector as a column vector&lt;/li&gt;
&lt;li&gt;A point is also called a vector&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;rays-lines-and-their-parametric-forms&#34;&gt;Rays, lines, and their parametric forms&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A ray consists of a starting point $a$ and all the points in a direction $d$&lt;/li&gt;
&lt;li&gt;Algebraically it is a set: {$x$ $\in R^n | x = a + \theta d$, $\forall$ $\theta &amp;gt;=0 $}&lt;/li&gt;
&lt;li&gt;A line consists of two rays starting at a point pointing two opposite directions.&lt;/li&gt;
&lt;li&gt;Algebraically it is a set: {$x$ $\in R^n | x = a + \theta d$, $\forall$ $\theta \isin R $}&lt;/li&gt;
&lt;li&gt;For ray and line, it is parametric because a and d are known, and $\theta$ is the parameter&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;plane-and-solutions-of-linear-equations&#34;&gt;Plane and solutions of linear equations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A plane in $R^2$ is just a line. $a_1x_1+a_2x_2=c$&lt;/li&gt;
&lt;li&gt;This plane is a line but it is not a parametric representation of a line.&lt;/li&gt;
&lt;li&gt;A plane in $R^3$ is $a_1x_1+a_2x_2+a_3x_3=c$&lt;/li&gt;
&lt;li&gt;If c is 0, plane passes through the origin.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;hyperplane-and-a-linear-equation&#34;&gt;Hyperplane and a Linear equation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The concept of plane can be extended to any dimension R^n&lt;/li&gt;
&lt;li&gt;Algebraically, $a_1x_1+a_2x_2+&amp;hellip;+a_nx_n=c$&lt;/li&gt;
&lt;li&gt;can be written as $a^Tx=c$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;halfspace-and-a-linear-inequality&#34;&gt;Halfspace and a linear inequality&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In $R^2$, a halfspace is half of the whole space&lt;/li&gt;
&lt;li&gt;A halfspace also consists of the line dividing the space&lt;/li&gt;
&lt;li&gt;There are two halfspace in $R^2$, but both include the dividing line&lt;/li&gt;
&lt;li&gt;Same definition can be extended to a halfspace&lt;/li&gt;
&lt;li&gt;$H_1$ = {$x \in R^n: a^Tx&amp;gt;=c$}&lt;/li&gt;
&lt;li&gt;$H_2$ = {$x \in R^n: a^Tx&amp;lt;=c$}&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;polyhedron-and-serveral-hyperspaces&#34;&gt;Polyhedron and serveral hyperspaces&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A polyhedron is the intersection of a finite number of halfspaces&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://i.stack.imgur.com/rmUm7.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;geometric-aspects-of-linear-optimization&#34;&gt;Geometric Aspects of Linear Optimization&lt;/h2&gt;
&lt;h3 id=&#34;corner-points&#34;&gt;Corner Points&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Instead of edges, look at Corner Points&lt;/li&gt;
&lt;li&gt;Corner points are responsible for generating the set&lt;/li&gt;
&lt;li&gt;Convex combination of two points in the action of generating it&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convex-combination-of-two-points&#34;&gt;Convex Combination of Two Points&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Given two points, $a$, $b$ $\in R^n$, a convex combination of $a, b$ is given by
&lt;ul&gt;
&lt;li&gt;$x = \lambda a + (1- \lambda)b$ for some $\lambda \in [0, 1]$&lt;/li&gt;
&lt;li&gt;Geometrically, x is on the line segment connecting a and b&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Given a point $x$ is a convex combination of $a_1, &amp;hellip; a_m$ if $x$ can be written as
&lt;ul&gt;
&lt;li&gt;$x = \sum_{i=1}^m \lambda_ia_i$&lt;/li&gt;
&lt;li&gt;And, $\sum_{i=1}^m \lambda_i = 1, \lambda_i&amp;gt;=0$ for $i = 1, &amp;hellip; , m$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Corner points are special points, and therefore we give them a special name: Extreme Point&lt;/li&gt;
&lt;li&gt;A point x in a polyhedron P is an extreme point if and only if x is not a convex combination of other two different points in P.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convex-hull&#34;&gt;Convex Hull&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A convex hull of $m$ points $a_1, &amp;hellip;., a_m$ is the set of all convex combinations of $a_1, .., a_m$ denoted as $conv$ $x{a_1,.., a_n}$&lt;/li&gt;
&lt;li&gt;Theorem: A nonempty and bounded polyhedron is the convex hull of its extreme points.&lt;/li&gt;
&lt;li&gt;A bounded polyhedron is a polyhedron that does not extend to infinity in any direction.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conic-hull&#34;&gt;Conic Hull&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A polyhedron is unbounded iff there are directions to move to infinity without leaving the polyhedron.&lt;/li&gt;
&lt;li&gt;Recession direction: a ray that we never leave in the direction of the polyhedron&lt;/li&gt;
&lt;li&gt;However, there are special rays on the edge which can be used to generate all other rays&lt;/li&gt;
&lt;li&gt;A ray $d$ is a conic combination of two rays, $e_1$, $e_2$ if d is a nonnegative weighted sum of $e_1$, $e_2$&lt;/li&gt;
&lt;li&gt;The set of all conic combination of rays $r_1, &amp;hellip;, r_m$ is called the conic hull of $r_1, &amp;hellip;, r_m$&lt;/li&gt;
&lt;li&gt;The sum of $\lambda$ does not have to equal to 1 here.&lt;/li&gt;
&lt;li&gt;A ray $e$ in a cone C is called an extreme ray, if $e$ is a conic combination of other two different rays in the cone C&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;extreme-ray-and-extreme-point&#34;&gt;Extreme Ray and Extreme Point&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;If a polyhedron is bounded, there is no extreme ray&lt;/li&gt;
&lt;li&gt;If a polyhedron is bounded, there must be an extreme point&lt;/li&gt;
&lt;li&gt;If a polyhedron is unbounded, it must have an extreme point&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;polyhedron-representations&#34;&gt;Polyhedron Representations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Halfspace representation&lt;/li&gt;
&lt;li&gt;Extreme Point representation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;weyl-caratheodory-theorem&#34;&gt;Weyl-Caratheodory Theorem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Any point $x$ in a polyhedron can be written as a sum of two vectors $x = x^&amp;rsquo; + d$ where $x^&amp;rsquo;$ is in the convex hull of its extreme points and d is in the conic hull of its extreme rays.&lt;/li&gt;
&lt;li&gt;$P =$ $conv$ ${x_1, &amp;hellip;, x^m} + $ $conic$ ${e^1, &amp;hellip;, e^k}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;algebraic-aspect-of-linear-optimization&#34;&gt;Algebraic Aspect of Linear Optimization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Active constraints&lt;/strong&gt;: A linear constraint that is satisfied as equality at a given point is said to be active or binding at that point. Otherwise, if an inequality constraint is satisfied as strict inequality at a point, it is called inactive.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linear independent constraints&lt;/strong&gt;: If the normal directions of two or more linear constraints are linearly independent, then these constraints are called linearly independent&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linearly independent active constraints&lt;/strong&gt;: Active constraints that are linearly independent&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Basic solution&lt;/strong&gt;: The unique solution of $n$ linearly independent active constraints in $R^n$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Basic feasible solution (BFS)&lt;/strong&gt;: Basic solution that is feasible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Basic Feasible Solution = Extreme Point&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;standard-form-of-writing-an-lp&#34;&gt;Standard Form of writing an LP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A standard form linear program is written as $min$ $ c^Tx$ $s.t.$ $Ax=b, x&amp;gt;=0 \in X $&lt;/li&gt;
&lt;li&gt;$x \in R^n$ that is, there are $n$ variables&lt;/li&gt;
&lt;li&gt;$A \in R^{m*n}$, ie there are m equality constraints&lt;/li&gt;
&lt;li&gt;We always assume all the $m$ equality constraints are linearly independent&lt;/li&gt;
&lt;li&gt;Equality constraints and Nonnegative constraints on all variables&lt;/li&gt;
&lt;li&gt;The first constraint is data dependent, whereas the second one is not&lt;/li&gt;
&lt;li&gt;Any linear program can be transformed into LP&lt;/li&gt;
&lt;li&gt;Advantage of standard form LP:
&lt;ul&gt;
&lt;li&gt;Complicating constraints are all equality&lt;/li&gt;
&lt;li&gt;Only inequality constraints are simple, no negativity constraints, which do not depend on data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;basic-solution-to-standard-form-lp&#34;&gt;Basic Solution to standard form LP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A basic solution is the unique solution to $n$ linearly independent active constraints.&lt;/li&gt;
&lt;li&gt;For a standard form LP, we already have $m$ linearly independent active constraints.&lt;/li&gt;
&lt;li&gt;Need $n-m$ additional linearly independent active constraints&lt;/li&gt;
&lt;li&gt;Where to find them?&lt;/li&gt;
&lt;li&gt;Only from nonnegative constraints: $x_i &amp;gt;= 0$&lt;/li&gt;
&lt;li&gt;But which to choose to make active?&lt;/li&gt;
&lt;li&gt;Choose $m$ such linearly independent columns, denote the corresponding $m*m$ matrix as B, called basis matrix. The corresponding $(n-m)$ $x_i$s are denoted as $x_N$, non basic variables&lt;/li&gt;
&lt;li&gt;Choose $x_i=0$ for all $i$ corresponds to the columns in $N$, $x_N$ = 0&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;why-do-we-care&#34;&gt;Why do we care?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Not every LP has a BFS, not every polyhedron has an extreme point (Think about a line or a halfspace)&lt;/li&gt;
&lt;li&gt;So which LP has a BFS?
&lt;ul&gt;
&lt;li&gt;A polyhedron P has an extreme point iff it does not contain a line&lt;/li&gt;
&lt;li&gt;Corollary: A feasible standard form LP always has a BFS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If an LP has a finite optimal solution, then an optimal solution is a BFS&lt;/li&gt;
&lt;li&gt;That does not mean all optimal solution must be BFS&lt;/li&gt;
&lt;li&gt;Because feasible standard form LP must have a BFS&lt;/li&gt;
&lt;li&gt;And because an optimal solution must be a BFS&lt;/li&gt;
&lt;li&gt;Then, an optimal solution of standard for LP must be a BFS&lt;/li&gt;
&lt;li&gt;So we only need to look at BFSs, and select the one BFS with the minimum obj cost&lt;/li&gt;
&lt;li&gt;This is why BFS is very important for linear programming.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;local-search&#34;&gt;Local Search&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;In a feasible region&lt;/li&gt;
&lt;li&gt;General idea (does not have to be a LP)&lt;/li&gt;
&lt;li&gt;Start from some solution, and move to certain direction to a new point, but stay in feasible region.&lt;/li&gt;
&lt;li&gt;Algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/local_search.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generic algorithmic idea&lt;/li&gt;
&lt;li&gt;Gradient Descent and Newton Method uses local search&lt;/li&gt;
&lt;li&gt;Step size should be chosen properly, and the position should be feasible&lt;/li&gt;
&lt;li&gt;Local Search works well for convex optimization (A local minimum of a convex program is also a global minimum)&lt;/li&gt;
&lt;li&gt;Not in general for non convex optimization problems (Local search can get stuck)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;local-search-for-lp&#34;&gt;Local Search for LP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We only need to look at basic feasible solution.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The key step is to find a direction $d$ and step size $\theta$ so that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$d$ points from a BFS to one of its adjacent BFS&lt;/li&gt;
&lt;li&gt;That adjacent BFS should reduce objective value&lt;/li&gt;
&lt;li&gt;Move along the favorable direction as much as possible to maintain feasibility and to reduce objective&lt;/li&gt;
&lt;li&gt;Stop when optimal solution is fount (or cannot be found)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Two BFS are adjacent if they share the same $n-1$ linearly independent active constraints.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Two adjacent BFSs must share the same set of $n-m-1$ nonbasic variables as n-m-1 active constraints, and differ in one nonbasic variable.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example, if $x=(x_1, &amp;hellip;, x_5)$ has nonbasic variables $x_3 = x_4 = x_5 = 0 $, then its adjacent BFS must share two of these three nonbasic variables, i.e. $x_3=x_4=x_2=0$ may be nonbasic variable in an adjacent BFS.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;simplex-method&#34;&gt;Simplex Method&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The simplex method is a linear programming algorithm that is used to solve optimization problems with linear constraints and a linear objective function. It involves iteratively constructing a sequence of feasible solutions that converge to an optimal solution.&lt;/li&gt;
&lt;li&gt;At each iteration, the simplex method selects a non-basic variable to become basic and then computes a feasible solution by solving a set of linear equations. If the solution is not optimal, the method determines a new non-basic variable to become basic and repeats the process until an optimal solution is found.&lt;/li&gt;
&lt;li&gt;The method is based on the fact that a linear programming problem can be represented graphically as a polyhedron in high-dimensional space, and the optimal solution lies at one of the extreme points of the polyhedron. The simplex method works by traversing the edges of the polyhedron until the optimal extreme point is reached.&lt;/li&gt;
&lt;li&gt;The simplex method is a powerful tool for solving large-scale linear programming problems and is widely used in industry, finance, and other fields. However, it has some limitations, such as its inability to handle nonlinear constraints and its susceptibility to numerical instability when dealing with ill-conditioned matrices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;degeneracy&#34;&gt;Degeneracy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Degeneracy in the simplex method refers to a situation where the simplex algorithm encounters multiple optimal solutions or cycles in the iteration process. In other words, a degenerate linear programming problem has more than one basic feasible solution with the same objective function value.&lt;/li&gt;
&lt;li&gt;Degeneracy can occur when one or more constraints in the linear programming problem are redundant or when there is a linear dependence among the constraints. This leads to a reduced dimensionality in the space of feasible solutions, resulting in more than one optimal solution or cycle in the iteration process.&lt;/li&gt;
&lt;li&gt;Degeneracy can pose challenges for the simplex method since it can lead to slow convergence, cycling, or termination of the algorithm before finding an optimal solution. This is because the simplex method relies on selecting non-basic variables to become basic and constructing a feasible solution by solving a set of linear equations. In a degenerate case, some of the variables may become redundant, leading to cycles in the iteration process.&lt;/li&gt;
&lt;li&gt;To address degeneracy, various modifications to the simplex method have been proposed, such as the use of anti-cycling rules, perturbation techniques, or alternative algorithms such as interior-point methods. These modifications aim to reduce or eliminate the effects of degeneracy on the convergence of the algorithm and ensure finding an optimal solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;blands-rule-for-degeneracy&#34;&gt;Bland&amp;rsquo;s rule for degeneracy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Bland&amp;rsquo;s rule ensures that the simplex method always chooses the variable with the smallest index as the entering variable and the variable with the smallest subscript as the leaving variable. In other words, Bland&amp;rsquo;s rule breaks ties in the selection of entering and leaving variables in favor of the variable with the smallest index or subscript.&lt;/li&gt;
&lt;li&gt;By always selecting the variable with the smallest index or subscript, Bland&amp;rsquo;s rule guarantees that the simplex method cycles through all basic feasible solutions before returning to a previous solution. This eliminates the possibility of the algorithm getting stuck in a cycle and ensures that it converges to an optimal solution eventually.&lt;/li&gt;
&lt;li&gt;Although Bland&amp;rsquo;s rule can increase the number of iterations required to solve a degenerate linear programming problem, it provides a provably optimal solution and eliminates the possibility of cycling or termination before finding an optimal solution. Bland&amp;rsquo;s rule is widely used in software implementations of the simplex method and has been shown to be effective in practice.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;h2 id=&#34;linear-program-duality&#34;&gt;Linear Program Duality&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;LP duality is at the core of linear programming theory.&lt;/li&gt;
&lt;li&gt;Provides new perspective on understanding LP, is important for designing algorithms, and has many applications (pricing, game theory, robust optimization, and many more).&lt;/li&gt;
&lt;li&gt;Linear Program (LP) duality is a powerful concept in optimization theory that establishes a relationship between the primal and dual LP problems. The duality principle provides insights into the structure of optimization problems, helps in understanding the solutions and provides a tool for solving LP problems.&lt;/li&gt;
&lt;li&gt;In LP duality, there are two LP problems, known as the primal problem and the dual problem. The primal problem is the original LP problem that seeks to minimize or maximize a linear objective function subject to a set of linear constraints. The dual problem is constructed from the primal problem, and it seeks to maximize or minimize a function subject to a set of constraints.&lt;/li&gt;
&lt;li&gt;The duality principle states that the optimal value of the primal problem is equal to the optimal value of the dual problem. Furthermore, the optimal solutions of both problems are related in a specific way. This relationship is known as the duality gap, which is the difference between the optimal values of the primal and dual problems.&lt;/li&gt;
&lt;li&gt;There are two forms of LP duality: weak duality and strong duality. Weak duality states that the optimal value of the dual problem is always greater than or equal to the optimal value of the primal problem. In contrast, strong duality states that if the primal problem has an optimal solution, then the dual problem also has an optimal solution, and the duality gap is zero.&lt;/li&gt;
&lt;li&gt;The dual LP problem provides useful information about the primal LP problem. For example, the dual problem provides a lower bound on the optimal value of the primal problem, and it can be used to derive sensitivity analysis and shadow prices. Additionally, the dual problem can be used to reformulate the primal problem and generate alternative solutions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A fundamental motivation of LP duality is to find a systematic way to construct a lower bound to the original LP&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Original LP (Primal LP) $Z_p =  min \lbrace c^Tx:Ax=b,x \ge 0 \rbrace $&lt;/li&gt;
&lt;li&gt;Any feasible solution $x$ provides an upper bound on $Z_p$, ie, $Z_p \le c^Tx$&lt;/li&gt;
&lt;li&gt;What about a lower bound, i.e $Z_D \le Z_p$?&lt;/li&gt;
&lt;li&gt;This lower bound is useful because if the lower bound is very close to an upper bound, we have a good estimate of the true optimal.&lt;/li&gt;
&lt;li&gt;However, to get a lower bound, we need to modify the original LP&lt;/li&gt;
&lt;li&gt;In particular, we need to relax the problem.&lt;/li&gt;
&lt;li&gt;Principles of relaxation works for general optimization problems, far beyond LP&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;principle-of-relaxation&#34;&gt;Principle of Relaxation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Relaxation:
&lt;ul&gt;
&lt;li&gt;Find a new objective function that is always smaller or equal to the original objective function at any feasible point&lt;/li&gt;
&lt;li&gt;Find a feasible region that is larger than the feasible region of the original problem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Minimize a function &lt;em&gt;lower&lt;/em&gt; than the original objective over a region that is &lt;em&gt;larger&lt;/em&gt; than the original one. The optimal objective of the new problem will be a lower bound to the original one.&lt;/li&gt;
&lt;li&gt;Among all possible relaxations and lower bounds, find the best lower bound.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/relaxation.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;systematic-way-to-carry-out-relaxation&#34;&gt;Systematic way to carry out relaxation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Step 1&lt;/strong&gt;: Relax the objective function&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Step 2&lt;/strong&gt;: Relax the feasible region by ignoring constraints
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Separability&lt;/strong&gt; refers to the property that the objective function of the Lagrangian dual problem can be expressed as the sum of separate functions, each of which depends only on a subset of the variables of the primal problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Step 3&lt;/strong&gt; Find the best lower bound.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;primal-and-dual-pair&#34;&gt;Primal and Dual Pair&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/panddpair1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.stack.imgur.com/3hQEH.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;is-lagrangian-relaxation-a-dual-problem-to-the-primal&#34;&gt;Is Lagrangian relaxation a dual problem to the primal?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Yes, Lagrangian relaxation is a way of obtaining a lower bound on the optimal value of the primal problem by constructing a dual problem.&lt;/li&gt;
&lt;li&gt;In Lagrangian relaxation, the primal problem is first converted into its Lagrangian dual problem by introducing Lagrange multipliers, which are used to form a penalty term that is added to the original objective function. The resulting Lagrangian function is then minimized subject to the constraints, resulting in a lower bound on the optimal value of the primal problem.&lt;/li&gt;
&lt;li&gt;The Lagrangian dual problem is formulated by taking the infimum (minimum) of the Lagrangian over all possible values of the Lagrange multipliers. The dual problem is a maximization problem that seeks to find the maximum value of the infimum, subject to certain constraints that are derived from the original primal problem.&lt;/li&gt;
&lt;li&gt;The duality theorem states that the optimal value of the primal problem is equal to the optimal value of the dual problem, and that any feasible solution to one problem gives a lower bound or upper bound for the other problem. Therefore, Lagrangian relaxation can be seen as a way of constructing the dual problem to the primal problem, and finding a lower bound on the optimal value of the primal problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;important&#34;&gt;Important&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;If a linear program has an unbounded feasible region, then it can either be unbounded or have a finite optimal solution.&lt;/li&gt;
&lt;li&gt;If it has finite optimal solution than its dual must also have finite optimal solution.&lt;/li&gt;
&lt;li&gt;If it is unbounded, then its dual must be infeasible.&lt;/li&gt;
&lt;li&gt;If a linear program has an unbounded feasible region, then its dual problem cannot have an unbounded optimal solution.&lt;/li&gt;
&lt;li&gt;If a linear program has an unbounded feasible region, then its dual may be infeasible or have a finite optimal solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;linear-programming-weak-duality&#34;&gt;Linear Programming weak duality&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Given a primal LP in minimization, by the construction of the dual, the objective value of any feasible solution of the dual problem provides a lower bound to the primal objective cost&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Theorem 1 (Linear programming weak duality)&lt;/strong&gt;: If $x$ is any feasible solution to the primal minimization LP, and y is any feasible solution to the dual maximization LP, then $c^Tx \ge b^Ty$&lt;/li&gt;
&lt;li&gt;This implies:
&lt;ul&gt;
&lt;li&gt;If the optimal cost of the primal minimization problem is $-\inf$ then the dual maximization problem must be infeasible.&lt;/li&gt;
&lt;li&gt;If the optimal cost of the dual maximization problem is $+\inf$ then the primal minimization problem must be infeasible.&lt;/li&gt;
&lt;li&gt;Let $x^*$ be feasible to the primal problem and $y*$ be feasible to the dual problem, and suppose $c^Tx^*=b^Ty^*$, then $x^*$ and $y^*$ are optimal solutions to the primal and dual problems, respectively.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Weak duality does not hold if problem is infeasible.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;strong-duality&#34;&gt;Strong Duality&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Theorem 1 (Linear programming strong duality)&lt;/strong&gt;: If a primal linear program has a finite optimal solution $x^*$, then its dual linear program must also have a finite optimal solution $y^*$, and the respective optimal objective values are equal, ie, $c^Tx = b^Ty$&lt;/li&gt;
&lt;li&gt;Strong duality is the single most important theorem in LP. Its proof is very illuminating.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tables-of-possibilities&#34;&gt;Tables of possibilities&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/duality.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/primal_dual_combinations.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;sob-method-for-creating-dual-of-a-lp&#34;&gt;SOB method for creating dual of a LP&lt;/h2&gt;
&lt;iframe width=&#34;100%&#34; height =&#34;1024&#34; src=&#34;https://ayushsubedi.github.io/pdfs/tut6.pdf#toolbar=0&#34;&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;complementarity-slackness&#34;&gt;Complementarity Slackness&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Complementarity slackness is a fundamental concept in optimization theory that arises in the context of solving optimization problems with inequality constraints. It provides insights into the structure of the solutions and helps in understanding the behavior of the constraints in the optimization process.&lt;/li&gt;
&lt;li&gt;In an optimization problem with inequality constraints, the optimal solution typically satisfies the constraints with equality or with some slackness. Complementarity slackness is the condition that ensures that a constraint is either binding (i.e., satisfied with equality) or non-binding (i.e., satisfied with strict inequality) in the optimal solution.&lt;/li&gt;
&lt;li&gt;More formally, let x be a feasible solution to an optimization problem with inequality constraints, and let s be the slack variables associated with the constraints. The complementarity slackness condition requires that the product of the slack variables and the dual variables associated with the constraints is equal to zero.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;robust-optimization&#34;&gt;Robust Optimization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Making decision during uncertainty&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Robust optimization is a mathematical optimization technique that seeks to find a solution that is optimal under a set of possible scenarios, often in the presence of uncertain or varying parameters. It is particularly useful when dealing with systems that are subject to variability, such as financial or transportation systems, where decisions need to be made under uncertain conditions.&lt;/li&gt;
&lt;li&gt;In robust optimization, instead of trying to find a single optimal solution, a set of feasible solutions is identified that can perform well across a range of possible scenarios. The objective function is typically defined as a worst-case scenario, which ensures that the selected solution is optimal under all possible scenarios.&lt;/li&gt;
&lt;li&gt;Robust optimization can be used in a variety of applications, including portfolio optimization, supply chain management, and resource allocation. It has become increasingly popular in recent years due to its ability to provide robust solutions that can withstand unpredictable changes in the environment.&lt;/li&gt;
&lt;li&gt;We need to formulate constraint in such a way that solution we obtain will allow production to survive all possible realizations of the coefficients.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;large-scale-optimization&#34;&gt;Large Scale Optimization&lt;/h2&gt;
&lt;h3 id=&#34;cutting-stock-problem&#34;&gt;Cutting Stock Problem&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://www.researchgate.net/publication/228428085/figure/fig1/AS:301993223573505@1449012203611/One-dimensional-cutting-stock-problem-with-one-stock-type.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The cutting stock problem is a combinatorial optimization problem that involves cutting large sheets of material, such as paper or metal, into smaller pieces of specific sizes in order to minimize waste. The objective is to determine the most efficient cutting pattern that can be used to produce a given number of smaller pieces of the desired sizes, while minimizing the amount of leftover material.&lt;/li&gt;
&lt;li&gt;The cutting stock problem is a common problem in the manufacturing industry, where it is used to optimize the use of raw materials and minimize production costs. It can be formulated as a linear programming problem, where the decision variables are the number of cuts made in each direction, and the objective function is to minimize the amount of leftover material.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;gilmore-gomory-formulation&#34;&gt;Gilmore-Gomory Formulation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$min \sum_{i=1}^N x_i$, s.t $Ax=b, x \gt 0$&lt;/li&gt;
&lt;li&gt;the coefficients are 1&lt;/li&gt;
&lt;li&gt;where the columns of A are the patterns to cut one large roll&lt;/li&gt;
&lt;li&gt;$b$ is the amount of demand of each size of smaller rolls&lt;/li&gt;
&lt;li&gt;The number of ways to cut a large roll into smaller ones is usually astronomical&lt;/li&gt;
&lt;li&gt;very large number of variables&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;column-generation&#34;&gt;Column Generation&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/column_generation.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pick a subset&lt;/li&gt;
&lt;li&gt;Solve the restricted master problem (RMP)&lt;/li&gt;
&lt;li&gt;A feasible solution of RMP can be made into a feasible solution of MP. This is because RMP has all the constraints in MP.&lt;/li&gt;
&lt;li&gt;A &lt;em&gt;basic&lt;/em&gt; feasible solution of RMP can made into a &lt;em&gt;basic&lt;/em&gt; feasible solution of MP&lt;/li&gt;
&lt;li&gt;For an optimal BFS of RMP we can compute reduced cost of all nonbasis variables, if any reduced cost is negative, then we know the optimal solution of RMP if not optimal for MP&lt;/li&gt;
&lt;li&gt;We can add the new variable with negative reduced cost to RMP solve the new RMP and repeat the process.&lt;/li&gt;
&lt;li&gt;The procedure of finding a variable with negative reduced cost is called the Pricing Problem. Pricing Problem: Compute all the reduced costs of $x$. If all reduced costs are nonnegative, then $x$ is optimal for MP. Otherwise, we find a new column to add to RMP.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;important-1&#34;&gt;Important&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The features of the cutting stock problem that make column generation a feasible approach to solve:
&lt;ul&gt;
&lt;li&gt;The cutting stock problem formulation has objective coefficients all equal to 1.&lt;/li&gt;
&lt;li&gt;The cutting stock problem has columns with special structures which can be generated by another optimization problem that is easy to solve.&lt;/li&gt;
&lt;li&gt;The cutting stock problem has a small number of rows&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The column generation algorithm will terminate if all columns have been added or if no column can further reduce the number of big rolls used to satisfy demand.&lt;/li&gt;
&lt;li&gt;Constraint generation can be used when problems have too many constraints, but not many variables, &lt;strong&gt;or&lt;/strong&gt; with too many rows and not many columns.&lt;/li&gt;
&lt;li&gt;The constraint generation algorithm will terminate if all the constraints are satisfied by the current solution, &lt;strong&gt;or&lt;/strong&gt; if all the contraints are added.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;correctness-and-convergence&#34;&gt;Correctness and Convergence&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The algorithm is correct because of the key properties of RMP&lt;/li&gt;
&lt;li&gt;Does the algorithm converge?
&lt;ul&gt;
&lt;li&gt;Yes, because the algorithm always adds new columns and never disregards any.&lt;/li&gt;
&lt;li&gt;The worst case is all the columns of MP are used.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dantzig-wolfe&#34;&gt;Dantzig-Wolfe&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The Dantzig-Wolfe decomposition (also known as the column generation method) is a technique for solving large-scale linear programming problems that have a special structure. It is named after George Dantzig and Philip Wolfe, who first proposed the method in the 1960s.&lt;/li&gt;
&lt;li&gt;The Dantzig-Wolfe decomposition method decomposes a large linear programming problem into smaller sub-problems, each of which can be solved independently. The method is particularly useful when the original problem has a large number of constraints, but only a small number of variables are involved in each constraint.&lt;/li&gt;
&lt;li&gt;The basic idea of the method is to introduce new variables (known as columns) into the problem gradually, one at a time, and to solve the resulting sub-problem using standard linear programming techniques. The optimal solution to the sub-problem is then used to generate a new column, which is added to the problem and the process is repeated until the optimal solution to the original problem is found.&lt;/li&gt;
&lt;li&gt;The Dantzig-Wolfe decomposition method can be used to solve a wide range of linear programming problems, including those with integer variables and those with non-linear objective functions. It is particularly useful for problems that involve complex constraints or require the solution of large-scale optimization problems.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;important-2&#34;&gt;Important&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;To use Dantzig-Wolfe decomposition algorithm, the problem must have a special structure where:
&lt;ul&gt;
&lt;li&gt;all constraints are linear and have a block angular structure&lt;/li&gt;
&lt;li&gt;the objective funciton is a linear function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;We solve Dantzig-Wolfe decomposition by using column generation because:
&lt;ul&gt;
&lt;li&gt;the number of extreme points can be huge&lt;/li&gt;
&lt;li&gt;there are not many constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The pricing problem is relatively easy to solve because:
&lt;ul&gt;
&lt;li&gt;We can use simplex method instead of enumeration over all the extreme points&lt;/li&gt;
&lt;li&gt;There are no complicating constraint so that we can solve those pricing problems with angular structures in a distributed manner.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;moore-penrose-pseudoinverse&#34;&gt;Moore Penrose Pseudoinverse&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://www.researchgate.net/publication/278627426/figure/fig1/AS:360884149997586@1463052894718/Geometrical-interpretation-of-the-Moore-Penrose-pseudoinverse-In-the-leftmost-picture.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Moore-Penrose pseudoinverse, also known as the Moore-Penrose inverse or simply the pseudoinverse, is a generalization of the matrix inverse for non-square matrices. It is named after Elisha L. Moore and Roger Penrose, who independently introduced the concept in the mid-20th century.&lt;/li&gt;
&lt;li&gt;The pseudoinverse is defined for any m-by-n matrix A, where m and n need not be equal, and it is denoted by A+. The pseudoinverse has several important properties, including:
&lt;ul&gt;
&lt;li&gt;A+AA+A=A+&lt;/li&gt;
&lt;li&gt;AA+A=AA+&lt;/li&gt;
&lt;li&gt;(AA+)&amp;rsquo;=AA+&lt;/li&gt;
&lt;li&gt;(A+A)A=A&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;where A&amp;rsquo; denotes the transpose of A.&lt;/li&gt;
&lt;li&gt;The pseudoinverse is useful in a variety of applications, including linear regression, least-squares approximation, and control theory. In particular, if A has linearly independent columns, then A+A is the unique solution to the linear system Ax=b that minimizes the Euclidean norm of the error vector Ax-b.&lt;/li&gt;
&lt;li&gt;The pseudoinverse can be computed using singular value decomposition (SVD) or the QR decomposition. In particular, if A has full column rank, then its pseudoinverse can be computed as A+(A&amp;rsquo;A)^(-1) where A&amp;rsquo; denotes the transpose of A.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;convex-conic-optimization&#34;&gt;Convex Conic Optimization&lt;/h1&gt;
&lt;h3 id=&#34;nonnegative-orthant-cone&#34;&gt;Nonnegative Orthant cone&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The nonnegative orthant cone is a special type of cone in linear algebra and convex analysis. It is defined as the set of all nonnegative vectors in n-dimensional Euclidean space, denoted as R^n_+, where R^+ denotes the set of nonnegative real numbers.&lt;/li&gt;
&lt;li&gt;Generalizations of linear programming to nonlinear programming through convex cones and generalized inequalities&lt;/li&gt;
&lt;li&gt;A set K is called convex cone if K is convex and $ax \in K$ for all $a \ge 0$ whenever $x \in K$&lt;/li&gt;
&lt;li&gt;What is the relation between order and cone?
&lt;ul&gt;
&lt;li&gt;Order is a comparison relationship between two elements $a$ and $b$, usually written as $a \gt b$&lt;/li&gt;
&lt;li&gt;An order $\succeq_K$ is defined by an underlying convex cone K as
&lt;ul&gt;
&lt;li&gt;$a \succeq_K b$ iff $a-b \in K$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A standard form LP can be viewed as
&lt;ul&gt;
&lt;li&gt;$min$ ${c^Tx: Ax=b, x \gt_{R_+^n}0}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An elegant way to generalize linear programming is to generalize $R_+^n$ to a general convex cone $K$&lt;/li&gt;
&lt;li&gt;Linear Conic Programming: $min$ $c^T x: Ax=b, x \ge_K 0$&lt;/li&gt;
&lt;li&gt;Linear Conic Programming is a type of optimization problem that involves finding the best solution to a linear objective function subject to a set of linear constraints and the requirement that certain variables lie in a cone. A cone is a set of vectors that satisfies certain properties, such as being non-negative or having a fixed norm.&lt;/li&gt;
&lt;li&gt;In Linear Conic Programming, the constraints are expressed in the form of linear equations or inequalities, while the requirement that certain variables lie in a cone is expressed using conic constraints. Common types of cones include the non-negative orthant, the second-order cone, the semi-definite cone, and the exponential cone.&lt;/li&gt;
&lt;li&gt;The goal of Linear Conic Programming is to find a feasible solution that satisfies all the constraints and optimizes the objective function. This type of optimization problem arises in a variety of applications, such as portfolio optimization, transportation planning, and engineering design. Linear Conic Programming is a powerful tool that can be solved efficiently using specialized algorithms, such as interior-point methods.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;second-order-cone&#34;&gt;Second order cone&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$L^3 = \lbrace (x,y,z) : \sqrt{x^2-y^2} \le z \rbrace$ = $\lbrace(x,y,z):||[x;y]||_2 \le z \rbrace$&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;integer-optimization&#34;&gt;Integer optimization&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Integer optimization is a type of optimization problem where the decision variables are required to take integer values. This is in contrast to continuous optimization, where the decision variables can take any real value.&lt;/li&gt;
&lt;li&gt;Integer optimization problems arise in a variety of fields, including operations research, computer science, engineering, and economics. Examples of integer optimization problems include finding the optimal assignment of workers to shifts, determining the best routes for vehicles to travel, and selecting the optimal set of investments to make.&lt;/li&gt;
&lt;li&gt;Integer optimization is often more difficult than continuous optimization, because the feasible set of integer solutions is typically discrete and non-convex. This means that traditional optimization techniques, such as gradient descent, cannot be used. Instead, specialized algorithms, such as branch and bound or cutting plane methods, are used to find optimal or near-optimal solutions.&lt;/li&gt;
&lt;li&gt;Integer optimization is also sometimes referred to as mixed-integer optimization, when the problem includes both integer and continuous decision variables.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;binary-optimization-models&#34;&gt;Binary Optimization Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A special and important class of discrete optimization models are those where the discrete variables and required to be binary, that is, they are required to take values of 0 and 1.&lt;/li&gt;
&lt;li&gt;$min$ $f(x)$ $s.t.$ $g_i(x) \le b_i, x \in R^{n-p} \times \lbrace 0,1 \rbrace^p$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;set-packing-covering-and-partitioning&#34;&gt;Set Packing, Covering and Partitioning&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.researchgate.net/publication/354791763/figure/fig1/AS:1071429466456066@1632460099978/Set-covering-set-partitioning-and-set-packing-problems.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Set Packing&lt;/strong&gt;: A set packing is a collection of sets in which no two sets share a common element. In other words, a set packing is a collection of non-overlapping sets. The objective in set packing is to find the largest possible subset of the sets that do not overlap.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set Covering&lt;/strong&gt;: A set covering is a collection of sets that together contain every element in a given universe. In other words, a set covering is a collection of sets that covers all the elements of a universe. The objective in set covering is to find the smallest possible subset of the sets that covers all the elements.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set Partitioning&lt;/strong&gt;: Set partitioning is a way to divide a set into non-empty subsets such that each element belongs to exactly one subset. In other words, set partitioning is a way to divide a set into mutually exclusive and exhaustive subsets. The objective in set partitioning is to find a partition that satisfies some given criteria.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;The set packing problem arises when each set element must appear in at most one subset. In this case, the constraints are of the less-than-or-equal form. The set partitioning problem arises when each set element must appear in exactly one subset, and the constraints in this problem are equality constraints.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;store-location-example&#34;&gt;Store Location Example&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Where should store be located so that it can maximize the number of customers?&lt;/li&gt;
&lt;li&gt;maximize total customers, constrained to among the locations same location cannot attract more than one city&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pupl&lt;/code&gt; is the python package that can be used to model this&lt;/li&gt;
&lt;li&gt;Set Packing: Given $m$ elements and a collection of subsets $S_1, &amp;hellip;. , S_n \belongs {1,..,m} with associated nonnegative weights $w_1, &amp;hellip;, w_n$ pick sets from this collection such that they are disjoint and the sum of the weights is maximized.&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe width=&#34;100%&#34; height =&#34;1024&#34; src=&#34;https://www.dam.brown.edu/people/huiwang/classes/am121/Archive/ip_121.pdf#toolbar=0&#34;&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;linear-programming-relaxation&#34;&gt;Linear Programming Relaxation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Decision variable is only taking continuous value to generate the relaxation (drop the integer constraints).&lt;/li&gt;
&lt;li&gt;If LP relaxation is infeasible, so it the IP&lt;/li&gt;
&lt;li&gt;If LP relaxation is unbounded, then the IP can either be infeasible or unbounded.&lt;/li&gt;
&lt;li&gt;If LP relaxation has an optimal solution, then the IP could be infeasible or have an optimal solution&lt;/li&gt;
&lt;li&gt;It always holds that $v_{LP} \le v_{IP}$&lt;/li&gt;
&lt;li&gt;If an optimal solution to the LP is an integer, then it is an optimal solution to the IP.&lt;/li&gt;
&lt;li&gt;It&amp;rsquo;s solution can sometimes be rounded to get a good solution to the IP&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ideal-formulations&#34;&gt;Ideal Formulations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Stronger Formulation: Stronger formulation lead to stronger LP relaxations, and so better LP relaxation  better bounds, and sometimes LP relaxations solutions that are feasible to the MLP&lt;/li&gt;
&lt;li&gt;The formulation of an MLP can be strengthened
&lt;ul&gt;
&lt;li&gt;by adding constraints (valid inequalities)&lt;/li&gt;
&lt;li&gt;by tightening constraint coefficients&lt;/li&gt;
&lt;li&gt;by introducing new variables and constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An ideal formulation of a MILP is one whose LP relaxation solves the MLP&lt;/li&gt;
&lt;li&gt;Ideal formulations are hard to obtain, so we strive to obtain strong formulation that approximate the ideal formulation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;branch-bound-algorithm&#34;&gt;Branch Bound Algorithm&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Branch and bound is a popular algorithm used for solving mixed-integer linear programming (MILP) problems. The basic idea behind branch and bound is to divide the problem into smaller subproblems, solve each subproblem separately, and then combine the solutions to obtain an overall solution to the original problem.&lt;/li&gt;
&lt;li&gt;Here are the steps involved in the branch and bound algorithm for MILP:
&lt;ul&gt;
&lt;li&gt;Solve the relaxed linear programming (LP) problem, which is the MILP problem with the integer constraints removed. This provides an initial solution to the MILP problem.&lt;/li&gt;
&lt;li&gt;If the LP solution satisfies all the integer constraints, then we have found an optimal solution to the MILP problem. Otherwise, select one of the integer variables with a non-integer value in the LP solution.&lt;/li&gt;
&lt;li&gt;Create two new subproblems by branching on the selected variable: one subproblem where the variable is fixed to its integer floor, and another subproblem where the variable is fixed to its integer ceiling.&lt;/li&gt;
&lt;li&gt;Solve each of the subproblems using the LP solver. If a subproblem has an integer solution that is worse than the current best solution, we can prune that branch of the search tree. Otherwise, continue branching until we have found an optimal integer solution or all branches have been pruned.&lt;/li&gt;
&lt;li&gt;Once all branches have been pruned, the best integer solution found during the search is the optimal solution to the MILP problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Human-Computer Interaction</title>
      <link>https://ayushsubedi.github.io/posts/human_computer_interaction/</link>
      <pubDate>Tue, 25 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/human_computer_interaction/</guid>
      <description>&lt;h1 id=&#34;human-computer-interaction&#34;&gt;Human-Computer Interaction&lt;/h1&gt;
&lt;h1 id=&#34;introduction-to-hci&#34;&gt;Introduction to HCI&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The goal is to create a scenario where user spends as much time as possible to accomplish the task, while the interface kind of vanishes during that interaction.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;A video game, as an example gives the user an experience of being in the game, not tinkering with the controller.&lt;/li&gt;
&lt;li&gt;We might be experts at interacting with computers, but that does not make us experts at designing interactions between other humans and computers.&lt;/li&gt;
&lt;li&gt;HCI is a subset of Human Factors Engineering (Industrial Design, HCI, Product Design).&lt;/li&gt;
&lt;li&gt;UI Design and UX Design and Interaction Design are a subset of HCI.&lt;/li&gt;
&lt;li&gt;Many principle of HCI come from Human Factors Engineering applied to computers.&lt;/li&gt;
&lt;li&gt;Tha gap between HCI and Interaction Design is shrinking (as computers become ubiquitous).&lt;/li&gt;
&lt;li&gt;HCI is about understanding the interaction between users and computers, and UX design is about dictating the interaction between users and computer. The relationship is however, deeply symbiotic.&lt;/li&gt;
&lt;li&gt;Human Factors Engineering is a merger of Engineering and Psychology.&lt;/li&gt;
&lt;li&gt;Psychology and HCI are also deeply symbiotic.&lt;/li&gt;
&lt;li&gt;HCI is about research (needfinding, prototyping, evaluation) and design (distributed cognition, mental models, universal design).&lt;/li&gt;
&lt;li&gt;HCI at its core: Research informs Design and Design informs Research.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;exploring-hci&#34;&gt;Exploring HCI&lt;/h1&gt;
&lt;p&gt;Three main application areas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Technologies&lt;/strong&gt;: Virtual Reality, Augmented Reality, UbiComp and Wearables, Robotics, Mobile&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ideas&lt;/strong&gt;: Context-Sensitive Computing (equipping user interfaces with historical, geographical, or other forms of contextual knowledge), Gesture-Based Interaction (interacting with interfaces using hand or body gestures), Pen-and Touch-Based Interaction, Information Visualization (representing abstract data visually to help humans understand it), CSCW (Computer Supported Cooperative Work) Interaction (Distributed Team, Distributed Work, Temporal and Geographical dimension): Example: Slack, Online course, etc., Social Computing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Domain&lt;/strong&gt;: Special Needs (example: communicating data using sound for visually impaired people), Education (you might not always want to make something super easy), Healthcare (fitbit, virtual
reality), Security (for security to be useful, it has to be usable). Captcha has become easy now with a checkbox, Games (topics of HCI are super salient here)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;h1 id=&#34;introduction-to-principles&#34;&gt;Introduction to Principles&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;User uses interfaces to accomplish a task&lt;/li&gt;
&lt;li&gt;Need to understand the user goals and the task&lt;/li&gt;
&lt;li&gt;Focusing on task and not the interface, allows us to come up with something amazing (nest instead of iteration on thermostat)&lt;/li&gt;
&lt;li&gt;How to identify a task?
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Watch real users&lt;/strong&gt; - get people and ask them to work with you&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Talk to them&lt;/strong&gt; - talk through the user&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Start small&lt;/strong&gt; - find small task which user performs&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Abstract up&lt;/strong&gt; - keep asking why till you reach beyond scope of design (small + small + big - series of why)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;You are not your user&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Goals of HCI:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Useful&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Usable&lt;/strong&gt; (the big concern)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If we were focusing on building better maps, we would not add navigation (think about what the user wants)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ex situ&lt;/strong&gt; - in a controlled or otherwise inauthentic environment&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;In situ&lt;/strong&gt; - within the authentic context&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;viewrole-of-a-human-within-a-system&#34;&gt;View/Role of a human within a system&lt;/h2&gt;
&lt;h2 id=&#34;processor&#34;&gt;Processor&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Nothing more than Sensory processor, take input and spit output out, like another computer in the system, interface must fit within known human limits: (what humans can sense, what they can store in memory, and what they can physically do in the world)&lt;/li&gt;
&lt;li&gt;usability: interface is physically usable (users can see colors, touch the buttons etc.)&lt;/li&gt;
&lt;li&gt;evaluated by quantitative methods/experiments. - - &amp;ldquo;Behaviorism&amp;rdquo; from psychology&lt;/li&gt;
&lt;li&gt;how quickly can the user complete the task?, how quickly can they react to incoming stimulus?&lt;/li&gt;
&lt;li&gt;not the one generally taken when talking about good design.&lt;/li&gt;
&lt;li&gt;The processor model is concerned with objective, measurable outcomes, so noting the efficiency with which you can accomplish different tasks is relevant here.&lt;/li&gt;
&lt;li&gt;Control study&lt;/li&gt;
&lt;li&gt;interfaces and get the timing&lt;/li&gt;
&lt;li&gt;Pros
&lt;ul&gt;
&lt;li&gt;Use existing data.&lt;/li&gt;
&lt;li&gt;Objective comparison (text v/s voice).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cons
&lt;ul&gt;
&lt;li&gt;Reason is not visible&lt;/li&gt;
&lt;li&gt;why text is not better than voice.&lt;/li&gt;
&lt;li&gt;cannot differentiate by expertise.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Suitable for only evaluation and optimization, not redesign.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;predictor&#34;&gt;Predictor&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ask interviews and focus groups&lt;/li&gt;
&lt;li&gt;Get full details on textual description&lt;/li&gt;
&lt;li&gt;Why use different interfaces at different time&lt;/li&gt;
&lt;li&gt;why choice, why particular option&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Cognitivism&amp;rdquo; from psychology&lt;/li&gt;
&lt;li&gt;here we care about the users knowledge, experience, expectation and thought process, we want users to predict what will happen, what are they thinking, interface must fit with knowledge, evaluated by qualitative studies.&lt;/li&gt;
&lt;li&gt;The predictor model is concerned with what you predict will be the outcome of your action, and whether you can interpret whether the outcome matched your prediction, so focus on how the user perceives and interprets what they should do and whether it was successful.&lt;/li&gt;
&lt;li&gt;The predictor model is not about interfaces predicting users intentions. The predictor model is about paying attention to what the user predicts the outcome of their action will be, and how they will interpret what they see after their action is complete.&lt;/li&gt;
&lt;li&gt;Pros
&lt;ul&gt;
&lt;li&gt;More complete picture of interaction&lt;/li&gt;
&lt;li&gt;Caters for experts and novices&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cons
&lt;ul&gt;
&lt;li&gt;Analysis is costly&lt;/li&gt;
&lt;li&gt;Bias in analysis. Focus on specific set of data points.&lt;/li&gt;
&lt;li&gt;Ignore broader context. Example: Only person and interface. Example maps in driving vs map in labs. *5 sec disappearance of search bar&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;participant&#34;&gt;Participant&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Consider broader activity&lt;/li&gt;
&lt;li&gt;not just inside their head but outside world, interface must fit with context, evaluated by in-situ studies (evaluated in the real world).&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Functionalism/Systems Psychology&amp;rdquo; from psychology&lt;/li&gt;
&lt;li&gt;Pros
&lt;ul&gt;
&lt;li&gt;Evaluates interaction in context&lt;/li&gt;
&lt;li&gt;Capture authentic user attentions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cons
&lt;ul&gt;
&lt;li&gt;Expensive to perform and analyze both&lt;/li&gt;
&lt;li&gt;Requires real functional interfaces, no prototypes&lt;/li&gt;
&lt;li&gt;Hard to use when starting fresh&lt;/li&gt;
&lt;li&gt;Lots of uncontrollable variables&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Each design informs one another&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/difference_models.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;user-experience-sans-design&#34;&gt;User experience, Sans Design&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;There is always user experience&lt;/li&gt;
&lt;li&gt;UX design focuses on dictating users experience&lt;/li&gt;
&lt;li&gt;It comes due to humans and tasks&lt;/li&gt;
&lt;li&gt;Scope of user experience:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Individual&lt;/strong&gt; - Feels of design like vs dislike&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Group&lt;/strong&gt; - FB keeps people in touch&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Societal&lt;/strong&gt; - Twitter and Arab Spring&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;feedback-cycles&#34;&gt;Feedback Cycles&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Way in which people interact with the world and get feedback on the results of those interactions&lt;/li&gt;
&lt;li&gt;Feedback cycles are hallmark of AI&lt;/li&gt;
&lt;li&gt;All of HCI can be interpreted as an application of feedback cycles&lt;/li&gt;
&lt;li&gt;The Gulf of Execution is a term used in the field of human-computer interaction to describe the gap between a user&amp;rsquo;s goals or
intentions and the actions they must take in order to achieve those goals using a computer system.&lt;/li&gt;
&lt;li&gt;The Gulf of Execution refers to the difficulty or complexity a user may experience in understanding and using the system to accomplish their task.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;gulf-of-execution&#34;&gt;Gulf of Execution&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The distance between user&amp;rsquo;s goals and the execution of the actions required to realize those goals
&lt;ul&gt;
&lt;li&gt;How do the users know what they can do?&lt;/li&gt;
&lt;li&gt;How do the users figure out how to make those goals a reality?&lt;/li&gt;
&lt;li&gt;How do they figure out what actions to take to make the state of the system match their goal state?&lt;/li&gt;
&lt;li&gt;How hard is it to do in the interface what is necessary to accomplish the goals?&lt;/li&gt;
&lt;li&gt;What is the difference between what the user thinks they have to do vs what they actually have to do?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Phases:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Identify Intentions&lt;/strong&gt; (what their goal is) &lt;strong&gt;in the context of the system&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Identify Actions&lt;/strong&gt; necessary to make the goal a reality&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Execute in Interface&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tips-for-gulf-of-execution&#34;&gt;Tips for Gulf of Execution&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Make functions discoverable&lt;/li&gt;
&lt;li&gt;Let the user mess around&lt;/li&gt;
&lt;li&gt;Be consistent with other tools - Ctrl+C for Copy, Ctrl+P for Paste&lt;/li&gt;
&lt;li&gt;Know your user - command line vs UI&lt;/li&gt;
&lt;li&gt;Feed-forward - Feedforward (give what will happen if you keep doing same thing, refresh icon on facebook timeline when users drag down)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;gulf-of-evaluation&#34;&gt;Gulf of evaluation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The distance between the effects of those actions and the user&amp;rsquo;s understanding of the results&lt;/li&gt;
&lt;li&gt;The output of the action that the user took&lt;/li&gt;
&lt;li&gt;Phases:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Interface output&lt;/strong&gt; - What did it do upon action (audio/video).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interpretation&lt;/strong&gt; - Can user interpret meaning of output?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Evaluation&lt;/strong&gt; - Evaluate the interpretation to check if goals was realized or not.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tips-for-gulf-of-evaluation&#34;&gt;Tips for Gulf of evaluation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Give feedback constantly: Give feedback at every step of the process&lt;/li&gt;
&lt;li&gt;Give feedback immediately: Let users know they have been heard (greying out icons when you click)&lt;/li&gt;
&lt;li&gt;Match the feedback to the action (Subtle action, subtle feedback; signification action, significant feedback )&lt;/li&gt;
&lt;li&gt;Vary your feedback (auditory, haptic etc.)&lt;/li&gt;
&lt;li&gt;Leverage direct manipulation (dragging in UI, pulling things around etc.)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;normans-feedback-cycle-stage&#34;&gt;Norman&amp;rsquo;s Feedback Cycle Stage&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;The goal&lt;/strong&gt;: What do I want to accomplish and why?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plan&lt;/strong&gt;: How can I do it?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Specify&lt;/strong&gt;: What options do I have?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Perform&lt;/strong&gt;: What can I do now?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Perceive&lt;/strong&gt;: What just happened?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interpret&lt;/strong&gt;: What does it mean?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compare&lt;/strong&gt;: Is this okay? Have I accomplished my goal?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img2.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img3.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img4.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;direct-manipulation&#34;&gt;Direct Manipulation&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Direct manipulation in Human-Computer Interaction (HCI) refers to a style of user interface design where the user interacts with graphical objects on the screen directly and immediately, as opposed to indirectly or through a separate command language. The goal of direct manipulation is to make the interface more intuitive and easier to use by allowing users to manipulate objects and see the results of their actions in real-time. Examples of direct manipulation interfaces include desktop environments like Microsoft Windows and Apple&amp;rsquo;s MacOS, as well as mobile operating systems like Apple&amp;rsquo;s iOS and Google&amp;rsquo;s Android.&lt;/li&gt;
&lt;li&gt;Invisible interface&lt;/li&gt;
&lt;li&gt;Directly manipulating to perform a task (touch screen allowing for zooming with hand gesture)&lt;/li&gt;
&lt;li&gt;Direct manipulation is a powerful method for shortening gulfs.&lt;/li&gt;
&lt;li&gt;VR is also allowing for direct manipulation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;don-normans-paper-on-direct-manipulation&#34;&gt;Don Normans paper on direct manipulation&lt;/h2&gt;
&lt;p&gt;Some lessons from the &lt;em&gt;Direct Manipulation Interfaces&lt;/em&gt; paper:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Distance&lt;/strong&gt; - the distance between users goals and the system itself. The greater the cognitive load required to use the system, the less direct to the interaction with the system actually feels. Distance can be broken into:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Semantic distance&lt;/strong&gt; - distance between users goals and their expression in the system, i.e., how hard it is to know what to do?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Articulatory distance&lt;/strong&gt; - distance between that expression and its execution, i.e., how hard it is to actually do what you know to do?&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Direct engagement&lt;/strong&gt; - systems that best exemplify direct manipulation all give the qualitative feeling that one is engaged with the control of the objects - not with the programs, not with the computer, but with the semantic object of our goals and intentions&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/direct_manipulation.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;invisibility-by-learning&#34;&gt;Invisibility by learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Cars are an example&lt;/li&gt;
&lt;li&gt;Leveraging prior expectation and providing quick feedback&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tips-for-invisible-interfaces&#34;&gt;Tips for invisible interfaces:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Use affordances&lt;/strong&gt;: Places where visual design suggest how its supposed to be used: buttons for pressing etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Know your user&lt;/strong&gt;: Invisible means different things to different users.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Differentiate your user&lt;/strong&gt;: Allow multiple ways of accomplishing something.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Let your interface teach&lt;/strong&gt;: Teach users more efficient ways of doing something.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Talk to your user&lt;/strong&gt;: Ask them what the users are thinking (if they are talking about the interface, do they talk about the task or the interface, if they talk about the interface, it is pretty visible).&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;human-abilities&#34;&gt;Human abilities&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Who the human is and what they are capable of doing?&lt;/li&gt;
&lt;li&gt;Input, processing and output&lt;/li&gt;
&lt;li&gt;Input, and how humans react&lt;/li&gt;
&lt;li&gt;Average person can sense and perceive (eyes: color and movement)
&lt;ul&gt;
&lt;li&gt;Visual&lt;/li&gt;
&lt;li&gt;Auditory&lt;/li&gt;
&lt;li&gt;Haptic Feedback&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use recognition over recall&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sensation-and-perception---visual&#34;&gt;Sensation and Perception - Visual&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Visual system is important for cognition&lt;/li&gt;
&lt;li&gt;HCI is majorly connected to visual perception&lt;/li&gt;
&lt;li&gt;Center - Color&lt;/li&gt;
&lt;li&gt;Periphery - Tracking movement&lt;/li&gt;
&lt;li&gt;Old audiences - Fonts, visual acuity drop&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sensation-and-perception---auditory&#34;&gt;Sensation and Perception - Auditory&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Noises - pitch and loudness&lt;/li&gt;
&lt;li&gt;Ears - Localize sounds &lt;em&gt;near vs far&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Cant process ears (move around)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sensation-and-perception---skin&#34;&gt;Sensation and Perception - Skin&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Pressure, vibration and temperature.&lt;/li&gt;
&lt;li&gt;Cant filter touch, like listening&lt;/li&gt;
&lt;li&gt;Its only used for personal feedback&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;memory&#34;&gt;Memory&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Chunking&lt;/strong&gt; - chunking is a grouping together several bits of information into one chunk&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Perceptual store&lt;/strong&gt; - very short term memory lasting less than a second.
&lt;ul&gt;
&lt;li&gt;Baddley - Hitch memory model
&lt;ul&gt;
&lt;li&gt;Visuospatial Sketchpad - stores visual information&lt;/li&gt;
&lt;li&gt;Phonologic loop - (verbal/ auditory information)&lt;/li&gt;
&lt;li&gt;Episodic Buffer - (integrating information from other system)&lt;/li&gt;
&lt;li&gt;Central Executive&lt;/li&gt;
&lt;li&gt;Expertise delays forgetting in perceptual buffer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Short-term memory&lt;/strong&gt; - memory that is able to hold about four to five chunks at a time
&lt;ul&gt;
&lt;li&gt;Chunking is grouping bits of information&lt;/li&gt;
&lt;li&gt;Focus on recognizing things rather than recall them&lt;/li&gt;
&lt;li&gt;Effect of HCI
&lt;ul&gt;
&lt;li&gt;Recognition vs Recall - Minibar (recognize the icons)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Long-term memory&lt;/strong&gt; - seemingly unlimited store of memories; it is harder to put things into long-term memory than short-term memory
&lt;ul&gt;
&lt;li&gt;Put short term memory system&lt;/li&gt;
&lt;li&gt;Reminder experiment - David&amp;rsquo;s card idea&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cognition&#34;&gt;Cognition&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;One of the elements of cognition is &lt;em&gt;learning&lt;/em&gt;, there are two types:&lt;/li&gt;
&lt;li&gt;Interfaces should teach them how to learn.
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Procedural learning&lt;/strong&gt; - how to do something. We do this HCI. Unconsciously competent (Cant translate them to declarative knowledge, as we don&amp;rsquo;t know). Easy for us to use hard for others.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Declarative learning&lt;/strong&gt; - knowledge about something&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cognitive-load&#34;&gt;Cognitive Load&lt;/h2&gt;
&lt;p&gt;When designing user interfaces, cognitive load comes into play as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We want to reduce the cognitive load posed by the interface so the user can focus on the task&lt;/li&gt;
&lt;li&gt;We want to understand the context of what else is going on while users are using our interface&lt;/li&gt;
&lt;li&gt;Example - IDE error checking in programming&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;reducing-cognitive-load&#34;&gt;Reducing cognitive load&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Tips:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use multiple modalities - Visual and Verbal&lt;/li&gt;
&lt;li&gt;Let the modalities complement each other&lt;/li&gt;
&lt;li&gt;Give the user control of the pace&lt;/li&gt;
&lt;li&gt;Emphasize essential content and avoid the clutter&lt;/li&gt;
&lt;li&gt;Offload tasks (to the interface)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Perception&lt;/strong&gt; - main ways people perceive the world around them through sight, sound, and touch.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cognition&lt;/strong&gt; - memory and learning&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Motor system&lt;/strong&gt; - how the person interacts with the world around them&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;design-principles-and-heuristics&#34;&gt;Design Principles and Heuristics&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/dp.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;discoverability&#34;&gt;Discoverability&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Relevant function should be made visible so the user can discover them as opposed to having to read about them in some documentation or learn them through some tutorials&lt;/li&gt;
&lt;li&gt;When user doesn&amp;rsquo;t know what to do, they should be able to figure out what to do&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img7.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;simplicity&#34;&gt;Simplicity&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;There is often tension between discoverability and simplicity. One argues to be seen and on argues to keep the interface simple, a balance between these two is often required.&lt;/li&gt;
&lt;li&gt;Use of design is easy to understand, regardless of user&amp;rsquo;s experience, knowledge, language skills, or current concentration level&lt;/li&gt;
&lt;li&gt;User should be given only whats needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img8.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;affordances&#34;&gt;Affordances&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The design of the thing affords or hints at the way it&amp;rsquo;s suppose to be used.&lt;/li&gt;
&lt;li&gt;Signifiers are meant to close the gap between the affordance of an object (how the object suggests it should be used) and the perceived affordance (what the user thinks on how the object should be used).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Affordance&lt;/strong&gt; - Inherent property of device. We cant introduce it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Perceived&lt;/strong&gt; - What human perceives. But it can be wrong.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Signifier&lt;/strong&gt; - It helps perceived affordance = Affordance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img9.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;mapping&#34;&gt;Mapping&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Relationship between two things.&lt;/li&gt;
&lt;li&gt;Mapping user - worlds (cut copy paste)&lt;/li&gt;
&lt;li&gt;Refers to creating interfaces where the design makes it clear what the effect will be when using them (this is different than affordances where affordances suggests how to use objects)&lt;/li&gt;
&lt;li&gt;(think about multiple monitors)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img10.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;mapping-vs-affordance&#34;&gt;Mapping vs Affordance&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Affordance - design suggests what to do&lt;/li&gt;
&lt;li&gt;Mapping - design shows what the effects will be
&lt;ul&gt;
&lt;li&gt;Ex - Light switch
&lt;ul&gt;
&lt;li&gt;Whats the effect?&lt;/li&gt;
&lt;li&gt;Dials on stove (icon for burners). More clear.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;perceptibility&#34;&gt;Perceptibility&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Refers to the user&amp;rsquo;s ability to perceive the current state of the system.&lt;/li&gt;
&lt;li&gt;(On or off in switch). Problem in David&amp;rsquo;s cieling fan&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img11.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;consistency&#34;&gt;Consistency&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We should be consistent both within and across interfaces to minimize the amount of learn the user needs to do to learn our interface; in this way we create affordances on our own.
&lt;ul&gt;
&lt;li&gt;URL in blue in wiki page.&lt;/li&gt;
&lt;li&gt;Common functions across interfaces.&lt;/li&gt;
&lt;li&gt;Ordering menus/ Shortcuts in PPT.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img12.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;flexibility&#34;&gt;Flexibility&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Wherever possible, we should support the different interactions in which people engage naturally, rather than forcing them into one against their expertise or against their preference&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img13.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;equity&#34;&gt;Equity&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Complementary to flexibility, helping all users have the same user experience.&lt;/li&gt;
&lt;li&gt;Avoid segregation and stigmatization.&lt;/li&gt;
&lt;li&gt;In the image below, it might look it they are competing, but no.&lt;/li&gt;
&lt;li&gt;Design is useful and marketable to people with diverse abilities.&lt;/li&gt;
&lt;li&gt;Equity is all about making sure users have similar user experience, and flexibility allows for the means to get there.&lt;/li&gt;
&lt;li&gt;Think Password resets settings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img14.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;ease-and-comfort&#34;&gt;Ease and comfort&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ease: the design can be used efficiently an comfortably and with a minimum of fatigue;&lt;/li&gt;
&lt;li&gt;Comfort: appropriate size and space is provided for approach, reach, manipulation, and use regardless of user&amp;rsquo;s body size, posture, or mobility&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img15.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;structure&#34;&gt;Structure&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We should organize our user interfaces in ways that helps the user&amp;rsquo;s mental model match the actual content of the task&lt;/li&gt;
&lt;li&gt;Wall Street website vs print version&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img16.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;constraints&#34;&gt;Constraints&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Preventing the user from putting an input that wasn&amp;rsquo;t going to work anyway. UI design is transparent. Constraint is visible.&lt;/li&gt;
&lt;li&gt;Limitting the set of possible actions (to make sure users do not use wrong input, and help users with right input)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img18.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Norman&amp;rsquo;s four types of constraints:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Physical&lt;/strong&gt; - Physically prevent wrong action. USB sticks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cultural&lt;/strong&gt; - Line in escalator in Japan.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Semantic&lt;/strong&gt; - Inherent to situation. Purpose of rare view mirror. Must reflect behind.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Logical&lt;/strong&gt; - Self evident based on situation at hand. One hole to one screw.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;How do we deal with constraints? There are two ways:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tolerance&lt;/strong&gt; - users shouldn&amp;rsquo;t be at risk of causing too much trouble accidentally. Undo and Redo. The design should be flexible and tolerant.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Feedback&lt;/strong&gt; - user should be informed on why the error happened and how to avoid it in the future. Worst example: blue screen of death.
&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img19.PNG&#34; alt=&#34;&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/manikandan-ravikiran/HCI_Notes/raw/master/Test%201/Notes/img20.PNG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;documentation&#34;&gt;Documentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;even though it&amp;rsquo;s better if the system can be used without documentation, it may be necessary to provide help and documentation.&lt;/li&gt;
&lt;li&gt;Any such information should be easy to search, focused on the user&amp;rsquo;s task, list concrete steps to be carried out, and not be too large&lt;/li&gt;
&lt;li&gt;Avoid this all together, but good to have&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;mental-models-and-representations&#34;&gt;Mental Models and Representations&lt;/h1&gt;
&lt;h2 id=&#34;mental-models&#34;&gt;Mental Models&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Understanding to the world around you, that you hold in your head&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mental model&lt;/strong&gt; - an internal, simulatable understanding of external reality. Good interface will give good mental models.
&lt;ul&gt;
&lt;li&gt;Is a person understanding of real word working - processes relationship and connection in real systems&lt;/li&gt;
&lt;li&gt;Predict and check outcome of mental model. Basket ball example. Simulate the event to make prediction&lt;/li&gt;
&lt;li&gt;When reality does match? why is mental model wrong? discomfort, curious? frustration and never will get it.&lt;/li&gt;
&lt;li&gt;Match users models and interface
&lt;ul&gt;
&lt;li&gt;Design systems that acts how its expected or teach people how they act.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mental models are not unique to HCI. Also in Edtech.&lt;/li&gt;
&lt;li&gt;Good representation show how system works. But very challenging&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Five Principals
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Predictability&lt;/strong&gt; - User should be able to predict what will happen before perform it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Synthesizability&lt;/strong&gt; - But you should know the process on how you reached current state. Log of commands in CLI.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Familiarity&lt;/strong&gt; - Leverage actions with user is familiar. Like affordance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generalizability&lt;/strong&gt; - Knowledge of one user interface should generalize to others.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Single action and consistent. Ctrl+X for cut only.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;representations&#34;&gt;Representations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Internal symbols for an external reality. Helps users learners to use our interface quickly.&lt;/li&gt;
&lt;li&gt;Make the solution self evident.&lt;/li&gt;
&lt;li&gt;Here are some characteristics of good representations:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Depicts explicit relationships&lt;/strong&gt; - Laying thing out helps easy understanding&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Brings objects and relationships together&lt;/strong&gt; - Objects and relationships are explicit.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No extraneous information&lt;/strong&gt; - Say only left to right, left out stupid information.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Expose natural constraints&lt;/strong&gt; - Brings environment into pictures.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;analogies-and-metaphors&#34;&gt;Analogies And Metaphors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;If you can ground your interface in something users already know, you can get a solid foundation in teaching them how to use your interface. Ex - Wall street website and paper are similar.&lt;/li&gt;
&lt;li&gt;However, when you use analogies to other interfaces, users may not know where the analogy ends. Therefore, we should pay special attention to misconceptions analogies introduce.&lt;/li&gt;
&lt;li&gt;Analogies make the interface more learnable, but they may restrict the interface to outdated constraints.&lt;/li&gt;
&lt;li&gt;Metaphors and analogies - used to create good representations.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;design-principles-revisited&#34;&gt;Design Principles Revisited&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;How do mental models and representations tie into HCI design principles?
&lt;ul&gt;
&lt;li&gt;Analogies and metaphors - &lt;strong&gt;Principle of consistency&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Interfaces should teach the user how the system works - &lt;strong&gt;Principle of affordances&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Representations map the interface to the task at hand - &lt;strong&gt;Principle of mapping&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;learning-curve&#34;&gt;Learning Curve&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Expertise vs Experience. Above line of proficiency.&lt;/li&gt;
&lt;li&gt;Rapid Learning curve with limited experience&lt;/li&gt;
&lt;li&gt;Difficult interface have slower learning curves&lt;/li&gt;
&lt;li&gt;Consistency with analogies and representations&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;slips&#34;&gt;Slips&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The user has the right mental model, but does the wrong thing anyway&lt;/li&gt;
&lt;li&gt;Norman&amp;rsquo;s division:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Action-based&lt;/strong&gt; - Places where the user performs the wrong action, or performs the right action on the wrong object, even though they knew the correct action&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memory lapse&lt;/strong&gt; - Occurs when the user forgets something they knew to do&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;mistakes&#34;&gt;Mistakes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The user has the wrong mental model, and does the wrong thing as a result&lt;/li&gt;
&lt;li&gt;Norman&amp;rsquo;s division:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Rule-based&lt;/strong&gt; - occurs when the user correctly assesses the state of the world but makes the wrong decision based on it&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Knowledge-based&lt;/strong&gt; - occur when the user incorrectly assesses the state of the world in the first place&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memory lapse&lt;/strong&gt; - similar to memory lapse slips but focuses on forgetting to fully execute a plan&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;learned-helplessness&#34;&gt;Learned Helplessness&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A user&amp;rsquo;s sense that they are helpless to accomplish their goals in an interface. Window hang while reading large dataset.&lt;/li&gt;
&lt;li&gt;It&amp;rsquo;s related to educational technology.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;expert-blind-spot&#34;&gt;Expert Blind Spot&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;When you are an expert in something there are parts of the task that you do subconsciously without even thinking about them.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;I am not my user.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;task-analysis&#34;&gt;Task Analysis&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Human information processor model&lt;/li&gt;
&lt;li&gt;Cognitive Task analysis (similar to the predictor model)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;human-information-processor-model&#34;&gt;Human information processor model&lt;/h2&gt;
&lt;p&gt;A human information processor model; it builds off the processor model of the human&amp;rsquo;s role in a system. One of the human information processor model is teh GOMS model. There are four categories in the GOMS model:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Elements_of_a_GOMS_model.svg/220px-Elements_of_a_GOMS_model.svg.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Goals&lt;/strong&gt; - users goals in the system&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Operators&lt;/strong&gt; - user operations to carry out method&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Methods&lt;/strong&gt; - user can use to complete (Methods - Operator 1&amp;mdash;n)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Selection rules&lt;/strong&gt; - which to select among different methods&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This model proposes that a human has a set of &lt;em&gt;goals&lt;/em&gt; and &lt;em&gt;methods&lt;/em&gt; they can choose from to accomplish those goals. Each method is comprised of a series of &lt;em&gt;operators&lt;/em&gt; which help carry out that method. Lastly, they use some set of &lt;em&gt;selection rules&lt;/em&gt; to help decide what method to choose from.&lt;/p&gt;
&lt;p&gt;Example - Transfer information to coworkers - Email, chat, In person, etc.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/goms.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;strengths-and-weaknesses-of-goms&#34;&gt;Strengths And Weaknesses Of GOMS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Weaknesses of GOMS model:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Does not address complexity&lt;/strong&gt; - There are many methods and sub-methods. Standard GOMS rules this out.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Assumes user is an expert&lt;/strong&gt; - GOMS doesn&amp;rsquo;t account for novices and user errors. I don&amp;rsquo;t know highway in USA.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Strengths of GOMS model:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Formalize user interaction into steps&lt;/strong&gt; - Interaction steps to measure for efficiency. Helps to narrow down the time for each steps. Finding areas of improvement. Count time for each operator, easy to get keychain while holding something in hand.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;types-of-goms&#34;&gt;Types of GOMS&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;KLM-GOMS&lt;/strong&gt; -&amp;gt; Keystroke level model
&lt;ul&gt;
&lt;li&gt;here operator + execution time - efficiency determination&lt;/li&gt;
&lt;li&gt;original work had 6 types of operators, won&amp;rsquo;t work on modern ideas&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CMN GOMS&lt;/strong&gt; -&amp;gt; Card, Moran and Newell GOMS
&lt;ul&gt;
&lt;li&gt;Hierarchical Goals and choose multiple goals&lt;/li&gt;
&lt;li&gt;Very low level goals (moving text, delete phrases)&lt;/li&gt;
&lt;li&gt;Model how long each individual GOMS to take
&lt;ul&gt;
&lt;li&gt;Find place which we can cut out&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NGOMSL&lt;/strong&gt; - Natural language GOMS
&lt;ul&gt;
&lt;li&gt;Working memory if exploited can be identified&lt;/li&gt;
&lt;li&gt;lends itself for human interpretation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-tips-developing-goms-models&#34;&gt;5 Tips: Developing GOMS Models&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Focus on small goals
&lt;ul&gt;
&lt;li&gt;GOMS should be small, abstract up from there.&lt;/li&gt;
&lt;li&gt;Example - Navigating end of document&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nest goals, not operators
&lt;ul&gt;
&lt;li&gt;GOMS of Navigation
&lt;ul&gt;
&lt;li&gt;GOMS for changing lanes and plotting routes&lt;/li&gt;
&lt;li&gt;Operators are smallest atoms of GOMS models. Don&amp;rsquo;t breakdown further&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Differentiate descriptive &lt;em&gt;What people do?&lt;/em&gt; and prescriptive &lt;em&gt;What they wanna do?&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;GOMS of former doesn&amp;rsquo;t mean they will do later. They will not do that?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Assign costs to operators
&lt;ul&gt;
&lt;li&gt;Measurement of operators will take.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use GOMS to trim waste
&lt;ul&gt;
&lt;li&gt;Use GOMS to cut cost by reducing operators.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;goms-to-cognitive-task-analysis&#34;&gt;GOMS to Cognitive Task Analysis&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The GOMS model assumes the human is an input-output machine (processor model).&lt;/li&gt;
&lt;li&gt;However, human reasoning may be too nuanced and complex to be so simplified.&lt;/li&gt;
&lt;li&gt;Cognitive task analysis is another way of examining tasks but it puts a much higher emphasis on things like memory, attention, and cognitive load (predictor model).&lt;/li&gt;
&lt;li&gt;Behaviorism vs Cognitivism
&lt;ul&gt;
&lt;li&gt;Observable of things&lt;/li&gt;
&lt;li&gt;Get into mind&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cognitive-task-analysis&#34;&gt;Cognitive Task Analysis&lt;/h2&gt;
&lt;p&gt;Its collection of methods focus on what we cant see.&lt;/p&gt;
&lt;p&gt;Cognitive task analysis are concerned with the underlying thought process associated with performing a task. Most methods follow a particular common sequence:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collecting preliminary knowledge
&lt;ul&gt;
&lt;li&gt;No experts needed, but need some familiarity (observe people performing tasks)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Identify knowledge representations
&lt;ul&gt;
&lt;li&gt;What does user know what they need to complete a task. Ex: Ordering of tasks/ Memorization etc.&lt;/li&gt;
&lt;li&gt;For navigation, monitoring and sequence of actions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Apply focused knowledge elicitation methods
&lt;ul&gt;
&lt;li&gt;Identify task, knowledge by think out loud about it.&lt;/li&gt;
&lt;li&gt;Get user to tell us what they have in mind.&lt;/li&gt;
&lt;li&gt;What changed their approach, what did they do in prior and what they do after change.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Analyze and verify data acquired
&lt;ul&gt;
&lt;li&gt;Confirming if understanding is correct&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Format results for intend application
&lt;ul&gt;
&lt;li&gt;We take results and models user&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Result looks like a flow chart, with various tasks in each box.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;hierarchical-task-analysis&#34;&gt;Hierarchical Task Analysis&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/hta.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tasks could be broken and small tasks could be reused. In the image above, Checkout can be represented as a subtask.&lt;/li&gt;
&lt;li&gt;This form of task analysis helps us understand what tools might already be available to accomplish certain portions of our task, or how we might design certain things to transfer between different tasks and different contexts.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hierarchical task analysis process&lt;/strong&gt;:
&lt;ol&gt;
&lt;li&gt;Abstracting out unnecessary details for a certain level of abstraction.&lt;/li&gt;
&lt;li&gt;Modularizing designs or principles so that they can be transferred between different tasks or different contexts.&lt;/li&gt;
&lt;li&gt;Organizing the cognitive task analysis in a way that makes it easier to understand and reason over.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cognitive-task-analysis-strengths-and-weaknesses&#34;&gt;Cognitive Task Analysis Strengths And Weaknesses&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Like the GOMS model, cognitive task analysis also have strengths and weaknesses.&lt;/li&gt;
&lt;li&gt;Strengths:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Emphasizes mental processes:&lt;/strong&gt; Unlike GOMS, emphasis on whats goes on users head&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Formal enough to for interface design:&lt;/strong&gt; Easy to communicate and compare&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Weaknesses:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Time-intensive&lt;/strong&gt; - They involve talking and systematic analysis of data&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;May deemphasize context&lt;/strong&gt; - Role of artifacts and details in world&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ill-suited for novices&lt;/strong&gt; - Who is trying to use an interface.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;other-task-analysis&#34;&gt;Other task analysis&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Human information&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KLM - Keystroke level model&lt;/li&gt;
&lt;li&gt;TLM - Touch level model&lt;/li&gt;
&lt;li&gt;MLP - Model human processor&lt;/li&gt;
&lt;li&gt;CPM-GOMS - Parallel tasks.&lt;/li&gt;
&lt;li&gt;NGOMSL - Natural language.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cognitive Models&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CDM - Critical decision model - Focus on critical decision&lt;/li&gt;
&lt;li&gt;TKS - Task knowledge structures - Focus on user knowledge.&lt;/li&gt;
&lt;li&gt;CFM - Cognitive function model - Focus on complexity&lt;/li&gt;
&lt;li&gt;Applied CTA&lt;/li&gt;
&lt;li&gt;Skilled CTA&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;distributed-cognition&#34;&gt;Distributed Cognition&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Distributed cognition suggests models of cognition should be extended outside the mind.&lt;/li&gt;
&lt;li&gt;An example is you can either add large numbers in your head (much more difficult) or add large numbers on a piece of paper.&lt;/li&gt;
&lt;li&gt;Each object in the the process can be said to extend the cognitive process. Don&amp;rsquo;t get smarter by pen and paper, cognition got distributed among the artifacts.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-a-cockpit-remembers-its-speeds&#34;&gt;How A Cockpit Remembers Its Speeds&lt;/h2&gt;
&lt;p&gt;Given the dynamic nature of flight, how does a cockpit remember its speeds?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/pilots.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The paper references to a cockpit and not one individual component as the cockpit comprises of more than one cognitive component to remember speeds:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Long-term memory&lt;/strong&gt;: a library of configurations (booklet)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Short-term memory&lt;/strong&gt;: a specific configuration (one sheet)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Working memory&lt;/strong&gt;: use of speed bugs on a dial&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deliberation&lt;/strong&gt;: the two pilots in the cockpit&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Each one of these components helps in remembering the speed of a plane by serving as an individual cognitive component in the cognitive system.&lt;/li&gt;
&lt;li&gt;Distributed Cognition To Cognition Load
&lt;ul&gt;
&lt;li&gt;Artifacts are extra memory to brain. Driving example is cognitive overload. GPS is a approach. Cruise control. Offload tasks to artifacts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Distributed Cognition as Lens
&lt;ul&gt;
&lt;li&gt;A way of approaching/looking at the problem/design. Separation of monitors.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;distributed-cognition-to-social-cognition&#34;&gt;Distributed Cognition To Social Cognition&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Distributed cognition is concerned with how the mind can be extended by relations with other artifacts and other individuals.&lt;/li&gt;
&lt;li&gt;Social cognition is concerned with distributing cognition across individuals. Example : map reading during driving in old days.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;social-cognition&#34;&gt;Social Cognition&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Social cognition is about how social connections create systems that can, together, accomplish tasks. For example, you and your friend navigating to a place.&lt;/li&gt;
&lt;li&gt;Social cognition is also concerned with the cognitive underpinning of social interactions themselves. it is interested in how perception, memory and learning relate to social phenomenon. (Think designing social media)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;situated-action&#34;&gt;Situated Action&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Situated action is strongly concerned with the context within which people interact.&lt;/li&gt;
&lt;li&gt;However, situation action is not interested in the long-term and enduring permanent interactions amongst these things.&lt;/li&gt;
&lt;li&gt;Situated action is interested in the kinds of novel situational problems that arise all the time. How do we find out more about these problems?
&lt;ol&gt;
&lt;li&gt;We must examine the interfaces we design within the context in which they&amp;rsquo;re used&lt;/li&gt;
&lt;li&gt;We must understand the task the user performs grows out of interaction with the interface&lt;/li&gt;
&lt;li&gt;The task doesn&amp;rsquo;t exist until the user gets started, and once they start, they define the task&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;situated-action-and-memory&#34;&gt;Situated Action And Memory&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Memory is context dependent. People will often remember e.g., a list of personal tasks because it is part of a larger narrative versus remembering a list of tasks someone else gave them.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;activity-theory&#34;&gt;Activity Theory&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A massive and well-developed set of theories regarding interaction between various pieces of an activity.&lt;/li&gt;
&lt;li&gt;This theory predates HCI and there are some contributions of activity theory to HCI we should be aware of:&lt;/li&gt;
&lt;li&gt;Task to Activity theory
&lt;ul&gt;
&lt;li&gt;Why we see task and then design&lt;/li&gt;
&lt;li&gt;Up and down hierarchy - due to learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;It predates HCI&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Activity theory generalizes our unit of analysis from the task to the activity; we&amp;rsquo;re not just interested in what users doing but why users are doing it&lt;/li&gt;
&lt;li&gt;Activity theory puts an emphasis on the idea that we can create low level operations from higher level actions&lt;/li&gt;
&lt;li&gt;Activity theory points out that actions by the user can actually move up and down a hierarchy&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;There are several similarities between Activity Theory and Distributed Cognition (both are focused on goals, where as Situated Action is focused on improvisation)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;interfaces-and-politics&#34;&gt;Interfaces and Politics&lt;/h1&gt;
&lt;p&gt;Designing for change, and anticipating the change from our design.&lt;/p&gt;
&lt;h3 id=&#34;change-a-third-motivation&#34;&gt;Change: A Third Motivation&lt;/h3&gt;
&lt;p&gt;There are three goals of HCI:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Help&lt;/strong&gt; a user do a task&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Understand&lt;/strong&gt; how a user does a task&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Change&lt;/strong&gt; the way the user does a task&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Car - Seatbelt example - Not usability but safety.&lt;/p&gt;
&lt;h3 id=&#34;paper---do-artifacts-have-politics&#34;&gt;Paper - Do artifacts have politics?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Nuclear Power
&lt;ul&gt;
&lt;li&gt;Can be used in Totalitarian. Push for tech carries politics&lt;/li&gt;
&lt;li&gt;Solar power equalitarian society&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;two-types&#34;&gt;Two types&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Inherently political&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Nuclear power (top down)-  Authoritarian&lt;/li&gt;
&lt;li&gt;Solar Power (distributed) - Egalitarian society&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Technical arrangements as forms of order&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Technology can change social order - Context and purpose - Busting unions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;change-by-design&#34;&gt;Change By Design&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ability of interfaces to change behavior can be abused.&lt;/li&gt;
&lt;li&gt;Normal designs with underlying politics
&lt;ul&gt;
&lt;li&gt;People can design things to intentionally create a negative (designing bridges too low so that it&amp;rsquo;s harder for poor people to go to a destination) or positive change (Facebook&amp;rsquo;s &lt;em&gt;like&lt;/em&gt; button).&lt;/li&gt;
&lt;li&gt;Wealthy people can go to park, low bridges for poor people (social order),&lt;/li&gt;
&lt;li&gt;Net neutrality&lt;/li&gt;
&lt;li&gt;Positive interactions: Like button and emotions in Facebook. Societal trend.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;change-by-happenstance&#34;&gt;Change By Happenstance&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Need not always by design. Bicycle - Societal change
&lt;ul&gt;
&lt;li&gt;Women using cycle instead relying on someone, wardrobe change.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;While people could intentionally create a positive or negative design, this could happen unintentionally as well for positive (the bicycle giving women freedom to travel independently) and negative (internet access) cases.&lt;/li&gt;
&lt;li&gt;Existing Infrastructure and Internet&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;value-sensitive-design&#34;&gt;Value-sensitive Design&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Value-sensitive design seeks to provide theory and method to account for human values in a principled and systematic manner throughout the design process.&lt;/li&gt;
&lt;li&gt;Another dimension to consider while designing: Usable, Useful and Value sensitive&lt;/li&gt;
&lt;li&gt;Privacy by design - Privacy is the value. Preserve value.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;value-sensitive-design-and-information-systems&#34;&gt;Value-sensitive Design and Information Systems&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Conceptual Investigations - Thought experiments, role value play in stakeholders&lt;/li&gt;
&lt;li&gt;Empirical Investigations - target users - exploring how they make sense of values&lt;/li&gt;
&lt;li&gt;Technical Investigation - target systems -&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Fundamental feature - Proactive, usability vs human values,&lt;/p&gt;
&lt;h2 id=&#34;value-sensitive-design-across-cultures&#34;&gt;Value-sensitive Design Across Cultures&lt;/h2&gt;
&lt;p&gt;One of the challenges of value-sensitive design is that values are different across cultures (culture that values privacy vs cultures that value frees speech due to censorship).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Right to be forgotten, value held by EU. Google was not developed based on that.&lt;/li&gt;
&lt;li&gt;Not universally shared.&lt;/li&gt;
&lt;li&gt;Privacy vs Free speech.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-tips-value-sensitive-design&#34;&gt;5 Tips: Value-sensitive Design&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Start early&lt;/strong&gt; - Identify values early on design process and check throughout&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Know your users&lt;/strong&gt; - Know user&amp;rsquo;s values. Challenges are to be identified.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consider both direct and indirect stakeholder&lt;/strong&gt; - People who don&amp;rsquo;t user but affected by it. Bank UI.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Brainstorm the interface&amp;rsquo;s possibilities&lt;/strong&gt; - How it could be used. Tracking hours - unjust call for termination.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Choose carefully between supporting values and prescribing values&lt;/strong&gt; - We should not prescribe values for everyone. Be careful about support and change.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;reversing-the-relationship&#34;&gt;Reversing The Relationship&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Technology changes society but society could also change technology too (e.g., demand for single platform to link to others for TV subscriptions).&lt;/li&gt;
&lt;li&gt;Bulbs - florescent bulbs vs Electricity Bill
&lt;ul&gt;
&lt;li&gt;Satisfaction of politics, preserve power of organization.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;conclusion-to-principles&#34;&gt;Conclusion To Principles&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Human As Processor&lt;/strong&gt;: At the narrowest level, we might view HCI as the interaction between a person and an interface. This view is shared by models such as the GOMS model.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Human As Predictor&lt;/strong&gt;: Most of the time we are viewing HCI as the user interacting through some interface to accomplish some task. At this level we can look interactions in terms of the gulf of execution and evaluation. We can use tools like cognitive task analysis and hierarchical task analysis to understand things like user&amp;rsquo;s mental models, errors, and mappings between representations and the underlying tasks. Design principles are made.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Human As Participant&lt;/strong&gt;: At the highest level, we are interested in how interactions occurs beyond just the individual, interface, and task. At this level we can look at interactions in terms of activity theory where interactions include elements of the context surrounding the task. We could also look at how artifacts combine to accomplish a task through distributed cognition. Other times we can look at deeply understanding the situated context in which a person is acting through situated action. Additionally, we could also look at how users integrate through norms and relations with social cognition. There are times where we should keep in mind the intended and unintended positive and negative changes our designs might have on society during design.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-tips-on-screen-ui-design&#34;&gt;5 Tips: On-Screen UI Design&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Use a grid&lt;/li&gt;
&lt;li&gt;Use a whitespace&lt;/li&gt;
&lt;li&gt;Know your Gestalt principles - how user perceive and group projects.&lt;/li&gt;
&lt;li&gt;Reduce clutter - #1-#3 helps in this.&lt;/li&gt;
&lt;li&gt;Design in grey-scale&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;gestalt-principles&#34;&gt;Gestalt principles&lt;/h2&gt;
&lt;p&gt;The following are the key Gestalt principles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Law of proximity&lt;/strong&gt;: This principle states that objects that are near each other tend to be grouped together.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Law of similarity&lt;/strong&gt;: This principle states that objects that share similar characteristics, such as shape, color, or texture, tend to be grouped together.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Law of closure&lt;/strong&gt;: This principle states that people tend to perceive incomplete shapes or forms as complete objects by filling in the missing information.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Law of symmetry&lt;/strong&gt;: This principle states that people tend to perceive objects that are symmetrical as a single unit or figure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Law of continuity&lt;/strong&gt;: This principle states that people tend to perceive objects as continuous and flowing, even when they are interrupted by other objects.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Law of figure-ground&lt;/strong&gt;: This principle states that people tend to perceive objects in a scene as either figures (the objects of focus) or the background against which they are seen.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://bs-uploads.toptal.io/blackfish-uploads/components/blog_post_page/content/cover_image_file/cover_image/1112591/retina_1708x683_cover-gestalt-principles-of-design-45cb1b7e7cada357ab317284e9a79a77.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h1 id=&#34;introduction-to-methods&#34;&gt;Introduction to Methods&lt;/h1&gt;
&lt;h2 id=&#34;research-methods&#34;&gt;Research Methods&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Design better than existing design&lt;/li&gt;
&lt;li&gt;In order to design interactions that are better than existing designs, it is important to take into consideration the user needs at each stage of the design process&lt;/li&gt;
&lt;li&gt;New way to old task&lt;/li&gt;
&lt;li&gt;Novelty should have the purpose, and understand the users task&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;user-centered-design&#34;&gt;User Centered Design&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Prioritizing user needs while recognizing we do not know their needs&lt;/li&gt;
&lt;li&gt;Design is often done to meet some functional specification, instead of meeting the user&amp;rsquo;s need&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;You are not your user&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;principles-of-user-centered-design&#34;&gt;Principles of User-Centered Design&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;There are six principles of user-centered design:
&lt;ol&gt;
&lt;li&gt;The design is based upon an explicit understanding of users, tasks, and environments - &lt;strong&gt;Do needfinding&lt;/strong&gt; Leverage this knowledge throughout the design process.&lt;/li&gt;
&lt;li&gt;Users are involved throughout design and development - &lt;strong&gt;Interviews, Surveys, working on design team etc&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The design is driven and refined by user-centered evaluation. &lt;strong&gt;Real users evaluate the prototype&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The process is iterative - &lt;strong&gt;No single shot results&lt;/strong&gt;. Even after being realesed.&lt;/li&gt;
&lt;li&gt;The design addresses the whole user experience - &lt;strong&gt;Entire experience is to be considered&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The design team includes multidisciplinary skills and perspectives - &lt;strong&gt;CS Scientists, Pyschologists, Designer, Domain experts and more&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;stakeholders&#34;&gt;Stakeholders&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;There are many types of stakeholders who user or are impacted by our interface:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Primary&lt;/strong&gt; - Our user who uses the interface directly. Grade book tool - Teachers send progress reports to parents&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Secondary&lt;/strong&gt; - are people who don&amp;rsquo;t use our system directly but who might interact with the output of it in some way. - Grade book tool Parents receive the output.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tertiary&lt;/strong&gt; - are people who never interact with the tool or output but who are nonetheless impacted by the existence of the tool. Grade book tool - Students&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;the-design-life-cycle&#34;&gt;The Design Life Cycle&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;User-centered design is about integrating the user into every phase of the design life cycle. We need to know two things:
&lt;ol&gt;
&lt;li&gt;What the design life cycle is?&lt;/li&gt;
&lt;li&gt;How to integrate the user into each phase?&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;The design life cycle in four phase:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Needfinding&lt;/strong&gt;: gather comprehensive understanding of task the user is are trying to perform: who the user is, what the context of the task is, why they are doing the task, and any other information&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Design alternatives&lt;/strong&gt; (early ideas on different ways to perform a task)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prototyping&lt;/strong&gt; (low fidelity to improved, so that we can put it in front of our users)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Evaluation&lt;/strong&gt; (put them in front of our users)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The cycle does not end at product launch.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/design_lifecycle.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;quantitative-data&#34;&gt;Quantitative data&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Descriptions, Measurements&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Observations described or summarized numerically&lt;/li&gt;
&lt;li&gt;Supports formal tests, comparisons, and conclusions&lt;/li&gt;
&lt;li&gt;Is strong for a small class of things&lt;/li&gt;
&lt;li&gt;Captures narrow view of what we might be interested in examining&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;qualitative-data&#34;&gt;Qualitative data&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Preferences, Performances&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Observations described or summarized non-numerically&lt;/li&gt;
&lt;li&gt;Supports any kind of response or observation&lt;/li&gt;
&lt;li&gt;Covers a broader picture of what we&amp;rsquo;re examining&lt;/li&gt;
&lt;li&gt;More flexible, but it is more prone to biases&lt;/li&gt;
&lt;li&gt;Description, observations, natural language&lt;/li&gt;
&lt;li&gt;Convert qualitative to quantitative data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;How and Why&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Mixed method&lt;/strong&gt;: A mixture of qualitative and quantitative data from same participants.&lt;/p&gt;
&lt;h2 id=&#34;types-of-nominal-data&#34;&gt;Types Of Nominal Data&lt;/h2&gt;
&lt;p&gt;There are four main types of quantitative data:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Nominal&lt;/strong&gt; - Categorical - Number of instances of different categories
&lt;ul&gt;
&lt;li&gt;Single nominal - One category&lt;/li&gt;
&lt;li&gt;Multiple nominal -  More than one category&lt;/li&gt;
&lt;li&gt;Binary (yes/no) and Non binary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ordinal&lt;/strong&gt; - Similar to nominal, but there is explicit ordering. Scale of 1-5. Gap is unclear.
&lt;ul&gt;
&lt;li&gt;It can be multinominal&lt;/li&gt;
&lt;li&gt;Binary (Fail/Pass) and Non binary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interval&lt;/strong&gt; - We do know exact difference between value. Commuting between 4-6am. 64 degree celcius is not twice as warm as 32. Can be Discrete or Continious.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ratio&lt;/strong&gt; - Ratio data. Absolute value and ratio could be established. Can be Discrete or Continious.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://dpbnri2zg3lc2.cloudfront.net/en/wp-content/uploads/old-blog-uploads/four-levels-of-measurement-data.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://thebiologynotes.com/wp-content/uploads/2019/03/Nominal-Ordinal-Interval-and-Ratio-Data.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;types-of-qualitative-data&#34;&gt;Types Of Qualitative Data&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Depends on how its gathered&lt;/li&gt;
&lt;li&gt;There are many types of qualitative data, below are some examples:
&lt;ol&gt;
&lt;li&gt;Transcripts - Interview/Focus group&lt;/li&gt;
&lt;li&gt;Field notes - Participant Observation&lt;/li&gt;
&lt;li&gt;Artifacts - Reviews for Existing interfaces&lt;/li&gt;
&lt;li&gt;Others - Many more/ Not mentioned&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Span is a lot larger&lt;/li&gt;
&lt;li&gt;Expensive to analyze, interpretation bias&lt;/li&gt;
&lt;li&gt;Qualitative data -to- Quantitative using &lt;strong&gt;coding&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;We don&amp;rsquo;t loose, only transformation&lt;/li&gt;
&lt;li&gt;Documented methodology is obtained (for review purposes/reproducibility)&lt;/li&gt;
&lt;li&gt;Always mix qualitative and quantitative data in HCI&lt;/li&gt;
&lt;li&gt;Typically these transformed data are nominal&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;ethics-and-human-research&#34;&gt;Ethics and Human Research&lt;/h1&gt;
&lt;h2 id=&#34;origin-of-institutional-review-board&#34;&gt;Origin Of Institutional Review Board&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Due to unethical experiments such as the &lt;em&gt;Milgram Experiment&lt;/em&gt;, &lt;em&gt;Tuskegee Syphilis Experiment&lt;/em&gt;, and &lt;em&gt;Stanford Prison Experiment&lt;/em&gt; the &lt;em&gt;National Research Act&lt;/em&gt; was enacted (1974). This led to the creation of institutional review boards to oversee research at universities.&lt;/li&gt;
&lt;li&gt;In general, the benefits to society must outweigh the risks to the subjects in the case of these experiments.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Belmont Report&lt;/strong&gt; - summarizes basic ethical principles that research must follow in order to receive government support.
&lt;ul&gt;
&lt;li&gt;demanded rigorous consent procedures&lt;/li&gt;
&lt;li&gt;positive outweighed negatives and rights are always preserved&lt;/li&gt;
&lt;li&gt;benefits of study should outweighs risk to participants&lt;/li&gt;
&lt;li&gt;Fair selection of subjects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;value-of-research-ethics&#34;&gt;Value of Research Ethics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Benefits are worth the risk and are significant in nature.&lt;/li&gt;
&lt;li&gt;IRB is sensitive about coercions when participants feel coerced, it impacts our results.&lt;/li&gt;
&lt;li&gt;Inherent bias on participants, effect on results.&lt;/li&gt;
&lt;li&gt;Not just ethical, but doing good research.&lt;/li&gt;
&lt;li&gt;IRB also monitors the research is sound and &lt;strong&gt;useful&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;irb-protocol&#34;&gt;IRB Protocol&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Protocol is a description regarding a project&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Status: Approved, New Waiting for PI, Withdrawn, Waiting for Sign-Off&lt;/li&gt;
&lt;li&gt;Add research personnel&lt;/li&gt;
&lt;li&gt;Protocol title&lt;/li&gt;
&lt;li&gt;Select role&lt;/li&gt;
&lt;li&gt;Certification is needed&lt;/li&gt;
&lt;li&gt;Primary Investigator (PI) will be always first, and must be a faculty&lt;/li&gt;
&lt;li&gt;How to create a protocol in IRBWISE
&lt;ul&gt;
&lt;li&gt;Protocol description covers study at high level.&lt;/li&gt;
&lt;li&gt;Research design and methodology (what users will experience and in what order)&lt;/li&gt;
&lt;li&gt;Experimental designs&lt;/li&gt;
&lt;li&gt;Duration of participation&lt;/li&gt;
&lt;li&gt;Data collection methods&lt;/li&gt;
&lt;li&gt;Benefits outweigh the risk&lt;/li&gt;
&lt;li&gt;Risks are to be added.&lt;/li&gt;
&lt;li&gt;Statistical Analysis (Qualitative research might not have this)&lt;/li&gt;
&lt;li&gt;Start and End dates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;human-subject-interaction-details&#34;&gt;Human Subject Interaction details&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Will directly involve direct interaction&lt;/li&gt;
&lt;li&gt;describe subjects and data we plan to collect (are we being fair to all genders)&lt;/li&gt;
&lt;li&gt;Vulnerable population - special accommodation is to be needed (they might not have the ability to give full consent)&lt;/li&gt;
&lt;li&gt;Scientific justification is needed for no of participants&lt;/li&gt;
&lt;li&gt;Effect size is needed&lt;/li&gt;
&lt;li&gt;Inclusion and Exclusion status&lt;/li&gt;
&lt;li&gt;Subjects age ranges&lt;/li&gt;
&lt;li&gt;Recruitment plan - (how are we going to find our subjects)&lt;/li&gt;
&lt;li&gt;Compensation provision&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;irb-consent-procedure&#34;&gt;IRB Consent Procedure&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;What kind of consent is received? Written or Waiver
&lt;ul&gt;
&lt;li&gt;Some narrow circumstances - Now direct effect&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Waiver of documentation of consent
&lt;ul&gt;
&lt;li&gt;Written consent is only identity of participant&lt;/li&gt;
&lt;li&gt;Implied consent and can withdraw anytime&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Justification is needed for consent waiver&lt;/li&gt;
&lt;li&gt;At risk population needs more information&lt;/li&gt;
&lt;li&gt;Concealment, deception - Temporary prototype is needed&lt;/li&gt;
&lt;li&gt;Upload concent form&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-management-question&#34;&gt;Data Management Question&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Clinical research and Biological research&lt;/li&gt;
&lt;li&gt;How do we keep data safe&lt;/li&gt;
&lt;li&gt;DoD, Radiation and Nano tech - Involvement&lt;/li&gt;
&lt;li&gt;Interview script, recruitment script, survey etc.&lt;/li&gt;
&lt;li&gt;No conflict of Interest and submit to PI.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;needfinding-and-requirements-gathering&#34;&gt;Needfinding and Requirements Gathering&lt;/h1&gt;
&lt;h2 id=&#34;introduction-to-needfinding&#34;&gt;Introduction to Needfinding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Avoid preconceived notions (if all you have is a hammer, everything looks like a nail)&lt;/li&gt;
&lt;li&gt;Defining general questions about the user&lt;/li&gt;
&lt;li&gt;Generating answers about the user&lt;/li&gt;
&lt;li&gt;Formalizing models of the users&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-inventory&#34;&gt;Data Inventory&lt;/h2&gt;
&lt;p&gt;Some understanding of the data we want to gather. These are the questions we want to answer:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Who are the users?&lt;/strong&gt; Age, gender, level of expertise etc&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Where are the users?&lt;/strong&gt; What is their environment?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What is the context of the task?&lt;/strong&gt; What is competing for user attention?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What are their goals?&lt;/strong&gt; What are they trying to accomplish?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What do they need?&lt;/strong&gt; What are the physical objects/information/collaborators they need?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What are their tasks?&lt;/strong&gt; What are they doing physically, cognitively, socially?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What are their subtasks?&lt;/strong&gt; How do they accomplish those subtasks?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;the-problem-space&#34;&gt;The Problem Space&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Where is the task occurring? What else is going on, what are the user&amp;rsquo;s explicit and implicit needs?&lt;/li&gt;
&lt;li&gt;broader view of the problem space&lt;/li&gt;
&lt;li&gt;start with general types and observations and move through progressively more targeted types of need finding.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;user-types&#34;&gt;User Types&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Full range of users for which we are designing&lt;/li&gt;
&lt;li&gt;Task is usually the same for both, but the audience, their motivation and their needs are different&lt;/li&gt;
&lt;li&gt;Identify different types of user and perform needfinding exercise on all of them
&lt;ul&gt;
&lt;li&gt;Kid vs Adults&lt;/li&gt;
&lt;li&gt;Experts vs Novices&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;avoiding-bias-in-needfinding&#34;&gt;Avoiding Bias in Needfinding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Confirmation bias&lt;/strong&gt;: we see what we want to see, preconceived ideas, test empirically, keep samples covered, involve multiple individuals in needfinding process&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Observer bias&lt;/strong&gt;: Subconsciously bias the users. Avoid leading questions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Social desirability bias&lt;/strong&gt;: Make naturalistic observations, record objective bias.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Voluntary response bias&lt;/strong&gt;: Oversampling. Reduce survey shown.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recall bias&lt;/strong&gt;: Misleading and incorrect recall, resulting in faulty data, people are not good what they did during activity done in past.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;naturalistic-observation&#34;&gt;Naturalistic Observation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Observing people in their natural context&lt;/li&gt;
&lt;li&gt;Cannot interact with users directly&lt;/li&gt;
&lt;li&gt;Not sure what those users are thinking&lt;/li&gt;
&lt;li&gt;Tips on Naturalistic Observation
&lt;ul&gt;
&lt;li&gt;Take notes&lt;/li&gt;
&lt;li&gt;Start specific, and then abstract (do not summarize too soon)&lt;/li&gt;
&lt;li&gt;Spread out your sessions&lt;/li&gt;
&lt;li&gt;Find a partner&lt;/li&gt;
&lt;li&gt;Look for questions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Five tips to use during observation:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Take notes&lt;/strong&gt; - Gather targeted information and observation about what you see.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Start specific, then abstract&lt;/strong&gt; - Risk Tunnel vision. Write down individual action, do not summarize/analyze from the beginning&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spread out your sessions&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Find a partner&lt;/strong&gt; - Take notes and compare with partners&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Look for questions&lt;/strong&gt; - Should inform questions what you need during targeted needfinding&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;participant-observation&#34;&gt;Participant Observation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Although you are not your user, you can act as a participant&lt;/li&gt;
&lt;li&gt;Do not overrepresented your own experience&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hacks-and-workarounds&#34;&gt;Hacks and Workarounds&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;How do users use hacks/workarounds to accomplish a task?&lt;/li&gt;
&lt;li&gt;But ask them why they use the hacks&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;errors&#34;&gt;Errors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Slips or mistakes that users frequently make while performing the task within the interface&lt;/li&gt;
&lt;li&gt;Errors happen because of weak mental models&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;apprenticeship-and-ethnography&#34;&gt;Apprenticeship and Ethnography&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Researching a community by becoming a participant in it (become an expert in it: pretty much)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;interviews-and-focus-groups&#34;&gt;Interviews and Focus Groups&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Just talk to them&lt;/li&gt;
&lt;li&gt;Focus group can lead to convergent thinking&lt;/li&gt;
&lt;li&gt;5 Tips for effective interviews:
&lt;ol&gt;
&lt;li&gt;Focus on the 6 W&amp;rsquo;s (who, what, where, when, why and how), open ended semi structured questions, Avoid yes and no, use openended and semiphrases questions&lt;/li&gt;
&lt;li&gt;Be aware of bias&lt;/li&gt;
&lt;li&gt;Listen&lt;/li&gt;
&lt;li&gt;Organize the interview (introduction, lighter qn for trust gathering, summary at end for the user to understand the purpose)&lt;/li&gt;
&lt;li&gt;Practice&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;think-aloud&#34;&gt;Think-Aloud&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Asking user to think out loud while in the context of the task&lt;/li&gt;
&lt;li&gt;Useful because we get info that user might forget later, but thinking out loud might cause them to act differently&lt;/li&gt;
&lt;li&gt;Post-Event Protocol (is better option)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;surveys&#34;&gt;Surveys&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Larger number of questions/surveyors&lt;/li&gt;
&lt;li&gt;Not as through, but powerful to get large number of data&lt;/li&gt;
&lt;li&gt;Also helpful in identifying what to ask during interviews&lt;/li&gt;
&lt;li&gt;Tips:
&lt;ol&gt;
&lt;li&gt;Less is more&lt;/li&gt;
&lt;li&gt;Be aware of bias&lt;/li&gt;
&lt;li&gt;Tie them to inventory&lt;/li&gt;
&lt;li&gt;Test them out&lt;/li&gt;
&lt;li&gt;Iterate&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Questions in survey:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Be clear&lt;/strong&gt;: Code numbers with what they mean (likert), don&amp;rsquo;t ask overlapping range, time box frequency based questions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be concise&lt;/strong&gt;: Might be a tradeoff with clear, ask in plain language&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be specific&lt;/strong&gt;: Avoid double barrel questions, avoid questions that allow internal conflict, avoid questions on super big ideas&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be expressive&lt;/strong&gt;: Allow users to be expressive, emphasize users opinions, user ranges instead of yes/no questions, give levels of frequency or agreement, allow users to add nominal categories&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be unbiased&lt;/strong&gt;: Leave open ended question open, avoid loaded questions (wasted vs spent)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be usable&lt;/strong&gt;: Provide progress bar, page length consistency, order your questions logically with a flow, alert users about unanswered questions, preview survey yourself.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;other-data-gathering&#34;&gt;Other Data Gathering&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Logs, Product Reviews, Already existing reviews (critique already existing interface) etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/needfinding.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;iterative-needfinding&#34;&gt;Iterative Needfinding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Needfinding on its own can be a cycle&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/iterative_needfinding.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;revisiting-the-inventory&#34;&gt;Revisiting the inventory&lt;/h2&gt;
&lt;p&gt;Revisit these:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Who are the users?&lt;/strong&gt; Age, gender, level of expertise etc&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Where are the users?&lt;/strong&gt; What is their environment?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What is the context of the task?&lt;/strong&gt; What is competing for user attention?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What are their goals?&lt;/strong&gt; What are they trying to accomplish?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What do they need?&lt;/strong&gt; What are the physical objects/information/collaborators they need?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What are their tasks?&lt;/strong&gt; What are they doing physically, cognitively, socially?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What are their subtasks?&lt;/strong&gt; How do they accomplish those subtasks?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;representing-the-need&#34;&gt;Representing the Need&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;User needs can be formulated to something usable&lt;/li&gt;
&lt;li&gt;Task and subtasks, hierarchy, flowchart with decisions, diagram of structural relationships between the components in the system and how they interact.&lt;/li&gt;
&lt;li&gt;summarize to task analysis (data gathered can summarize task analysis)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;defining-the-requirements&#34;&gt;Defining the Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;They should be specific and evaluative&lt;/li&gt;
&lt;li&gt;Functionality, usability, learnability, accessibility&lt;/li&gt;
&lt;li&gt;Compatibility, compliance, cost&lt;/li&gt;
&lt;li&gt;Used to evaluate the interface going forward&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;design-alternatives&#34;&gt;Design Alternatives&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;The biggest mistake a designer can make is jumping straight to designing an interface without understanding the users or understanding the task.&lt;/li&gt;
&lt;li&gt;The second biggest mistake is settling on a single design idea or a single genre of design ideas too early.&lt;/li&gt;
&lt;li&gt;After having a good understanding of needs of our user, brainstorm on task we have been investigating&lt;/li&gt;
&lt;li&gt;The settling on a single idea can take on multiple forms:
&lt;ul&gt;
&lt;li&gt;Staying too allegiant to existing designs or products&lt;/li&gt;
&lt;li&gt;Focusing too strongly on one alternative from the very beginning&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tunnel vision&lt;/strong&gt;: focusing on one alternative from the very beginning&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Design space&lt;/strong&gt;: the area in which we design our solution&lt;/li&gt;
&lt;li&gt;Our goal during the design alternative phase is to explore the possible design space. We do not want to narrow down the design space too early.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;brainstorming&#34;&gt;Brainstorming&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Explore possible design space (brainstorm lots of potential spaces)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Start with individual brainstorming&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Generate lots of ideas&lt;/li&gt;
&lt;li&gt;Groups tend to coalesce around conclusion earlier&lt;/li&gt;
&lt;li&gt;Tips on individual brainstorming
&lt;ul&gt;
&lt;li&gt;Write down the core problem&lt;/li&gt;
&lt;li&gt;Constrain yourself&lt;/li&gt;
&lt;li&gt;Aim for 20&lt;/li&gt;
&lt;li&gt;Take a break&lt;/li&gt;
&lt;li&gt;Divide and conquer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;challenges-in-group-brainstorming&#34;&gt;Challenges in Group Brainstorming&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The challenges are:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Social loafing&lt;/strong&gt; - the tendency to exert less effort working in groups than working alone&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conformity&lt;/strong&gt; - the tendency to agree with or follow the group&amp;rsquo;s reasoning and ideas&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Production blocking&lt;/strong&gt; - the tendency of some individuals in discussions to block other individual&amp;rsquo;s participation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Performance matching&lt;/strong&gt; - the tendency to match one&amp;rsquo;s level of performance to other collaborators&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Power dynamics&lt;/strong&gt; - the tendency to defer to more senior individuals, or to overpower less senior individuals (gender, race, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rules for Group Brainstorming
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Expressiveness&lt;/strong&gt; - Any idea that comes out share out loud&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-evaluation&lt;/strong&gt; - No evaluation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quantity&lt;/strong&gt; - More ideas better&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Building&lt;/strong&gt; - Build on the other ideas&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;There are four additional rules:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Stay focused&lt;/strong&gt; - keep goal in mind&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No explaining ideas&lt;/strong&gt; - Say idea and move on&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Revisit the problem&lt;/strong&gt; - Hit a road block and revisit&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;encourage others&lt;/strong&gt; - Encourage them to do so.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;5 Tips for group brainstorming
&lt;ol&gt;
&lt;li&gt;Go through every individual idea&lt;/li&gt;
&lt;li&gt;Find the optimal size&lt;/li&gt;
&lt;li&gt;Set clear rules for communication - Set timer and no one can block others&lt;/li&gt;
&lt;li&gt;Set clear expectations - How long session wil go? set an expectation&lt;/li&gt;
&lt;li&gt;End with ideas, not decisions - several ideas and come back to pursue&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;fleshing-out-ideas&#34;&gt;Fleshing out ideas&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;some ideas can be dismissed easily, which is fine&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;combine multiple ideas, dismiss with some analysis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Here are methods to flesh out ideas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Personas&lt;/strong&gt; - create actual characters to represent our users. Emphatic reasoning.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;User profiles&lt;/strong&gt; - defining a number of different variables about our users and possibilities within each - Expertise, Motivation, Usage Frequency, Literacy etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Timelines/Journey Maps&lt;/strong&gt; - Take a persona and stretch out over time. What does a user do before/during/after the task? What action lead to the task? What do they do later? What are they thinking when they are doing the task?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scenarios and Storyboards&lt;/strong&gt; - Examining the specific scenarios users will encounter while using our interfaces (a more specific approach). Timelines tend to be pretty general, scenarios are more specific. Particular user, particular events, while performing particular task. Ambulance/Audiobook example. Pretty close to mockups.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;User modeling&lt;/strong&gt; - Where personas are personal and will give us an empathetic view of the UX, user models are more objective and meant to give us measurable and comparable view of the UX. GOMS model. How does the user achieve a goal? Identification of phases and efficiencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/fleshing.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;prototyping&#34;&gt;Prototyping&lt;/h1&gt;
&lt;h2 id=&#34;basics-of-prototyping&#34;&gt;Basics Of Prototyping&lt;/h2&gt;
&lt;p&gt;Some basics to prototyping:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Early prototyping&lt;/strong&gt; - rapid revision on preliminary ideas&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Late prototyping&lt;/strong&gt; - finishing touches on final design/revising already live design&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;representation-types&#34;&gt;Representation (Types)&lt;/h3&gt;
&lt;p&gt;Different prototype representations from early (low-fidelity) to late (high fidelity):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Verbal prototype&lt;/strong&gt;: A verbal prototype is a concept or idea that is described in words, without any visual or physical representation. It can be used to quickly test and refine ideas without investing time or resources in creating a physical prototype.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Paper prototype&lt;/strong&gt;: A paper prototype is a simple, low-fidelity mockup of a product that is made using paper or cardboard. It is used to test the layout and functionality of a design, and can be easily modified as needed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wizard of Oz prototype&lt;/strong&gt;: A Wizard of Oz prototype is a type of interactive mockup that simulates the behavior of a fully functioning product by using human operators to perform the actions that would normally be performed by the product itself. This type of prototype can be used to test user interaction and identify usability issues before building a fully functional prototype.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wireframe prototype&lt;/strong&gt;: A wireframe prototype is a visual representation of a product that shows the layout and structure of the interface, without including detailed graphics or other design elements. It can be used to test the flow and functionality of a design.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Physical prototype&lt;/strong&gt;: A physical prototype is a working model of a product that is built using real materials. It can be used to test the form and function of a design and identify any manufacturing or engineering issues that may need to be addressed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Functional prototype&lt;/strong&gt;: A functional prototype is a working model of a product that includes some or all of the features and functionality of the final product. It can be used to test the performance and usability of a design before beginning mass production.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Live prototype&lt;/strong&gt;: A live prototype is a fully functional version of a product that is released to a limited audience for testing and feedback. It can be used to identify any remaining bugs or usability issues before launching the product to a wider audience.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/prototype.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;fidelity&#34;&gt;Fidelity&lt;/h3&gt;
&lt;p&gt;Fidelity - Completeness/Maturity of prototype. Far from being complete. Correlated to representation.&lt;/p&gt;
&lt;h3 id=&#34;evaluation&#34;&gt;Evaluation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Prototype evaluation from early to late:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Function&lt;/strong&gt; - Low fidelity - what button to press ? Can it do what it is meant to do? Can user figure out what to do by looking at it?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interface&lt;/strong&gt; -  Readability&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; - Higher fidelity - working/closing to working output&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;scope&#34;&gt;Scope&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Prototype scope from early to late:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Horizontal prototype&lt;/strong&gt; - covers the design as a whole but in a more shallow way
&lt;ul&gt;
&lt;li&gt;Entire FB website&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vertical prototype&lt;/strong&gt; - great detail on a small portion of the interaction
&lt;ul&gt;
&lt;li&gt;Status posting screen&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tradeoffs-in-prototyping&#34;&gt;Tradeoffs In Prototyping&lt;/h2&gt;
&lt;p&gt;We must note tradeoffs in prototyping:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Low-fidelity prototypes&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pros&lt;/strong&gt;: easy to create and modify&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cons&lt;/strong&gt;: not as effective for detailed comprehensive evaluations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;High-fidelity prototypes&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pros&lt;/strong&gt;: can be used for detailed feedback and evaluation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cons&lt;/strong&gt;: difficult to actually put together&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Remember that we are designing to get more feedback.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start easy get ideas and move to higher fidelity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Not complete interfaces.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-tips-prototyping&#34;&gt;5 Tips: Prototyping&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Keep prototypes easy to change&lt;/strong&gt; - Enable rapid revision (paper vs code)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Make it clear that it&amp;rsquo;s a prototype&lt;/strong&gt; - Don&amp;rsquo;t make too good, make it look like prototype&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be creative&lt;/strong&gt; - Do whatever it takes to get feedback. Find ones that get feedback.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Evaluate risks&lt;/strong&gt; - Minimize time spent on bad design by getting feedback early. Don&amp;rsquo;t waste time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prototype for feedback&lt;/strong&gt; - Goal of prototype is feedback. Prototype for kind of feedback.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;design-life-cycle-revisited&#34;&gt;Design Life Cycle Revisited&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;We do not just move to the evaluation stage after we are done with prototyping, rather a single prototype corresponds to a single iteration through the cycle.&lt;/li&gt;
&lt;li&gt;Success of prototype -&amp;gt; Raise the fidelity&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multi-level-prototyping&#34;&gt;Multi-Level Prototyping&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;All prototypes do not have to be at the same level at the same time. Instead, prototyping can and should exist at multiple levels of fidelity.&lt;/li&gt;
&lt;li&gt;Don&amp;rsquo;t do everything, part could be done from low to high fidelity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;evaluation-1&#34;&gt;Evaluation&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/evaluations.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;three-types-of-evaluation&#34;&gt;Three Types Of Evaluation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Qualitative evaluation&lt;/strong&gt; - evaluation that emphasizes the totality of a phenomenon. Likes dislike need doesn&amp;rsquo;t need, easy vs hard etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Empirical evaluation&lt;/strong&gt; - evaluation based on numeric summaries or observations of a phenomenon. More participants and qualitative is done in prior.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Predictive evaluation&lt;/strong&gt; - evaluation based on systematic application of pre-established principles and heuristics (no users).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;evaluation-terminology&#34;&gt;Evaluation Terminology&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reliability&lt;/strong&gt; - whether a measure consistently returns the same results for the same phenomenon.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Validity&lt;/strong&gt; - whether a measure&amp;rsquo;s results actually reflect the underlying phenomenon (reality and results)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generalizability&lt;/strong&gt; - whether a measure&amp;rsquo;s results can be used to predict phenomena beyond what it measured. Broader Audience (may or may not be applicable to all).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Precision&lt;/strong&gt; - the level of detail a measure supplies&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-tips-what-to-evaluate&#34;&gt;5 Tips: What To Evaluate&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Efficiency&lt;/strong&gt; - how long does user take to achieve text (Expert)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Accuracy&lt;/strong&gt; - how many users does users commit while executing a task (Expert)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learnability&lt;/strong&gt; - How long does user take to reach expertise.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memorability&lt;/strong&gt; - users ability to remember on how to use interface over time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Satisfaction&lt;/strong&gt; - Cognitive load, how many actually download the app? - Social desirability bias.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Important things needed to address the research:
&lt;ul&gt;
&lt;li&gt;What data are you gathering?&lt;/li&gt;
&lt;li&gt;What are you evaluating ?&lt;/li&gt;
&lt;li&gt;What approach will you use to evaluate?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;evaluation-timeline&#34;&gt;Evaluation Timeline&lt;/h2&gt;
&lt;p&gt;Change in evaluation with time, The evaluation timeline usually is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Regarding &lt;strong&gt;purpose&lt;/strong&gt;:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Formative&lt;/strong&gt; - primary purpose is to help redesign and improve our interface (early)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Summative&lt;/strong&gt; - the intention of conclusively saying at the end what the difference was (late, hopefully we only do formative)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Regarding &lt;strong&gt;approach&lt;/strong&gt;: Ways to fullfil purpose
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Qualitative&lt;/strong&gt; - the goal is to help us improve and understand tasks (early)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Predictive&lt;/strong&gt; - inform how we revise and improve our interface over time (Similar to qualitative evaluation)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Empirical&lt;/strong&gt; - the goal is to demonstrate or assess change (late)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Regarding &lt;strong&gt;data&lt;/strong&gt;:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Qualitative&lt;/strong&gt; - always useful to improve our interfaces (early and late)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quantitative&lt;/strong&gt; - while always useful, can only arise when we have rigorous evaluations (late)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Regarding &lt;strong&gt;setting&lt;/strong&gt;: where does it take place.
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Lab testing&lt;/strong&gt; - helps us focus exclusively on the interface early on&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Field testing&lt;/strong&gt; - helps us focus more on the interface in context&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;evaluation-design&#34;&gt;Evaluation Design&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Define the task&lt;/strong&gt; - very large or very small task.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Define performance measures&lt;/strong&gt; - how are we going to measure this. Define it and avoid confirmation bias. Create metrics. Qualitative vs Quantitative.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Develop the experiment&lt;/strong&gt; - How we find user performance on the measures. Survey or Interview/ What to control or vary empirically.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recruit participants&lt;/strong&gt; - Ethics - right awareness&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Do the experiment&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Analyze the data&lt;/strong&gt; - what data tells about performance measures. Do followups if you find something extra than expected.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Summarize the data&lt;/strong&gt; - Informs ongoing process&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/evaluations1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/evaluations3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;qualitative-evaluation&#34;&gt;Qualitative Evaluation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Get qualitative feedback about the interface.&lt;/li&gt;
&lt;li&gt;There are some questions we want to ask in this evaluation: (Similar to interviews)
&lt;ol&gt;
&lt;li&gt;What did you like/dislike?&lt;/li&gt;
&lt;li&gt;What were you thinking while using this interface?&lt;/li&gt;
&lt;li&gt;What was your goal when you took that particular action?&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Methods - Interview/Survey/ Think out load protocol/Focus Groups&lt;/li&gt;
&lt;li&gt;Use these techniques to get feedback on how our prototype changes the task.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;designing-a-qualitative-evaluation&#34;&gt;Designing A Qualitative Evaluation&lt;/h2&gt;
&lt;p&gt;There are options when designing a qualitative evaluation:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Prior experience or live demonstration? - bring user in to test. Mostly later case&lt;/li&gt;
&lt;li&gt;Synchronous or asynchronous? - watch live or complete and send&lt;/li&gt;
&lt;li&gt;One interface or multiple prototypes? - Vary the order based on bias.&lt;/li&gt;
&lt;li&gt;Think aloud protocol or post-event protocol? - explain while doing or do later at the end.&lt;/li&gt;
&lt;li&gt;Individuals or groups? - Focus groups (build and expand)/ Only source of knowledge (bad) but no bias.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;capturing-qualitative-evaluation&#34;&gt;Capturing Qualitative Evaluation&lt;/h2&gt;
&lt;p&gt;Options to capture qualitative evaluation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Video recording&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pros:&lt;/strong&gt; Automated, comprehensive and passive (focus on administering)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cons&lt;/strong&gt;: Intrusive, non-analyzable and screen-less. Overwhelming on analyses.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Note-taking&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pros&lt;/strong&gt;: Cheap, Non intrusive (Capture what we do/not everything) and Analyzable&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cons&lt;/strong&gt;: Slow, Manual and Limited&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Software logging&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pros&lt;/strong&gt;: Automated, passive and analyzable&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cons&lt;/strong&gt;: Limited (only some parts could be captured), Narrow and Tech Sensitive (prototype needs to reach certain level of fidelity)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-tips-qualitative-evaluation&#34;&gt;5 Tips: Qualitative Evaluation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Run pilot studies&lt;/strong&gt; - Recruiting is hard, gather useful data . Use friends and coworkers&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Focus on feedback&lt;/strong&gt; - Don&amp;rsquo;t explain rationale, don&amp;rsquo;t teach. Take it and design.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use questions&lt;/strong&gt; - when user get stuck? Guide user&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Instruct users what to do, not how&lt;/strong&gt; - Reduce bias&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Capture satisfaction&lt;/strong&gt; - Do they like it?&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;empirical-evaluation&#34;&gt;Empirical Evaluation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Something numerical in evaluation. What layout of button is useful?&lt;/li&gt;
&lt;li&gt;Comparing design and showing improvement in industry.&lt;/li&gt;
&lt;li&gt;Build new theories (gesture has tuf curve than voice)&lt;/li&gt;
&lt;li&gt;How can we show there is a difference between these designs?&lt;/li&gt;
&lt;li&gt;The goal of empirical evaluation is to come up with strong conclusions. Most empirical evaluations are comparisons.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;designing-empirical-evaluation&#34;&gt;Designing Empirical Evaluation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Treatment&lt;/strong&gt; - what a participant does in an experiment. Difference interface or design and comparison between them. Difference between two logo should be based on design color should be only comparable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Between subjects design&lt;/strong&gt; - comparison between two groups of subjects receiving different treatments. What do participants do or both treatment?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Within subjects design&lt;/strong&gt; - comparison within one group experiencing multiple treatments. Both treatments are given, what are seen first? order is randomized.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Random assignment&lt;/strong&gt; - using random chance to decide what treatment each participant receives. Control bias.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hypothesis-testing&#34;&gt;Hypothesis Testing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Reaction time study? Data is generated and compare this.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hypothesis testing&lt;/strong&gt; - testing whether or not the data allows us to conclude a difference exists.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Null&lt;/strong&gt; - Assume oppose is true&lt;/li&gt;
&lt;li&gt;Alternative if data doesn&amp;rsquo;t support that. Less than 5% chance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;quantitative-data-and-empirical-tests&#34;&gt;Quantitative Data And Empirical Tests&lt;/h2&gt;
&lt;p&gt;Recall that there are a number of tests for quantitative data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Nominal&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Recommended&lt;/strong&gt; - Chi-squared test&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alternatively&lt;/strong&gt;: Fisher&amp;rsquo;s exact test, G-test&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ordinal&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Recommended&lt;/strong&gt; - Kolmogorov-Smirnov test&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alternatively&lt;/strong&gt; - Chi-squared test, median test&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interval and ratio:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Recommended&lt;/strong&gt; - Student&amp;rsquo;s &lt;em&gt;t&lt;/em&gt;-test&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alternatively&lt;/strong&gt; - MWW test, Kruskal-Wallis test&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;special-test&#34;&gt;Special Test&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Three independent variable (hypothesis)&lt;/li&gt;
&lt;li&gt;Do pairwise
&lt;ul&gt;
&lt;li&gt;Repeated testing&lt;/li&gt;
&lt;li&gt;False positive&lt;/li&gt;
&lt;li&gt;Falsely reject null and agree alternative hypothesis.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Type I Error (False Positive): False rejection of null hypothesis&lt;/li&gt;
&lt;li&gt;Type II Error (False Negative): False retention of null hypothesis&lt;/li&gt;
&lt;li&gt;Fishers exact and G-test
&lt;ul&gt;
&lt;li&gt;Where is the difference?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ANOVA and Kruskal Wallis (Interval and Ratio)
&lt;ul&gt;
&lt;li&gt;Where is the difference?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Independent variable is mostly categorical. GPA is interval data.&lt;/li&gt;
&lt;li&gt;Binomial Data - Two sample binomial test&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;summary-of-empirical-tests&#34;&gt;Summary Of Empirical Tests&lt;/h2&gt;
&lt;p&gt;Below is a summary of empirical tests:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/test.png&#34; alt=&#34;Summary of Empirical Tests&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;5-tips-empirical-evaluation&#34;&gt;5 Tips: Empirical Evaluation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Control what you can, document what you can&amp;rsquo;t&lt;/strong&gt; - Try to make treatments identical as possible&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Limit your variables&lt;/strong&gt; - Noisy data false conclusion and monitor handful of things at a point.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Work backwards&lt;/strong&gt; in designing experiments - Decide what question you want to answer, the anaysis you want to use and the question you want to ask&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Script your analyses in advance&lt;/strong&gt; - Do not torture data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pay attention to power&lt;/strong&gt; - Size of difference the test can detect.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;predictive-evaluation&#34;&gt;Predictive Evaluation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Predictive evaluation should only be used where we wouldn&amp;rsquo;t otherwise be doing any evaluation.&lt;/li&gt;
&lt;li&gt;Rapid feedback, appropriately and when users are not available.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;types-of-predictive-evaluation&#34;&gt;Types Of Predictive Evaluation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Heuristic evaluation&lt;/strong&gt; - each individual evaluator inspects the interface alone, and identifies places where the interface violates some heuristic. Sit with an expert and get the report.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Model-based evaluation&lt;/strong&gt; - tracing through models in the context of the interface we designed (e.g., GOMS model). We can also compare interfaces. Also profiles of users could be used.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Simulation-based evaluation&lt;/strong&gt; - where we might construct an AI agent that interacts with our interface in the way a human would.  The human project - IIIT Germany.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cognitive-walkthrough&#34;&gt;Cognitive Walkthrough&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The most common type of predictive evaluation is actually cognitive walkthrough.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cognitive walkthrough&lt;/strong&gt; - stepping through the process of interacting with an interface, mentally simulating in each stage what the user is seeing and thinking and doing. To do this, we start with task and goal.
&lt;ul&gt;
&lt;li&gt;predict what action will user take&lt;/li&gt;
&lt;li&gt;Noting system response&lt;/li&gt;
&lt;li&gt;Investigate gulf for each step&lt;/li&gt;
&lt;li&gt;it may be fine for us, but we can put to user shoes we can identify something missing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;evaluating-prototypes&#34;&gt;Evaluating Prototypes&lt;/h2&gt;
&lt;p&gt;Our goal is to constantly apply multiple evaluation techniques to center our designs on the user.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Qualitative evaluation.&lt;/li&gt;
&lt;li&gt;Some quantitative evaluation.&lt;/li&gt;
&lt;li&gt;For all the prototypes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/evaluation_advantage.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;hci-and-agile-development&#34;&gt;HCI and Agile Development&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/agile.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-demand-for-rapid-hci&#34;&gt;The Demand For Rapid HCI&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Before, costs for development, distribution, and feedback regarding software and products were expensive compared to now.
&lt;ul&gt;
&lt;li&gt;Specialized development skills&lt;/li&gt;
&lt;li&gt;Distribution is physical&lt;/li&gt;
&lt;li&gt;Fix was hard&lt;/li&gt;
&lt;li&gt;By have users to come into testing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How do we take the principles we have covered so far and apply them to a rapid agile development process?
&lt;ul&gt;
&lt;li&gt;Cheap development&lt;/li&gt;
&lt;li&gt;Internet distribution - Free and update&lt;/li&gt;
&lt;li&gt;Usage data is free and live. Lots of feedback&lt;/li&gt;
&lt;li&gt;More incentive to build and save&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;when-to-go-agile&#34;&gt;When To Go Agile?&lt;/h2&gt;
&lt;p&gt;We can make the decision to go agile by considering the following:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Traditional&lt;/th&gt;
&lt;th&gt;Agile&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Criticality is&amp;hellip;&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Requirements change..&lt;/td&gt;
&lt;td&gt;Rarely&lt;/td&gt;
&lt;td&gt;Frequently&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team size is&amp;hellip;&lt;/td&gt;
&lt;td&gt;Large&lt;/td&gt;
&lt;td&gt;Small&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team embraces&amp;hellip;&lt;/td&gt;
&lt;td&gt;Order&lt;/td&gt;
&lt;td&gt;Change&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;towards-a-framework-for-integrating-agile-development-and-user-centred-design-ucd&#34;&gt;Towards a framework for integrating agile development and user-centred design (UCD).&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Similarities and Differences Between UCD and Agile Development&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;They rely on an iterative development process, building on empirical information from previous cycles or rounds. For instance, one of XP’s values is feedback, and the idea of refactoring code is an embodiment of this value. In UCD one of its founding principles is iterative design&lt;/li&gt;
&lt;li&gt;Agile techniques place an emphasis on the user, encouraging participation
throughout the development process. For instance, in Scrum, user evaluation of the product is encouraged on a monthly basis as users are ideally present during the sprint review  and the “Product Owner” is responsible for the requirements and feature prioritization for the product. A second founding principle of UCD, is early and continual focus on users.&lt;/li&gt;
&lt;li&gt;Both approaches emphasis the importance of team coherence. Beck states that one of the purposes of the planning game is to “bring the team together”. One of the features of the UCD approach is that the whole team should have the user in mind while developing the product.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The two main differences are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;UCD advocates maintain that certain design products are required to support communication with developers, while agile methods seek minimal documentation.&lt;/li&gt;
&lt;li&gt;UCD encourages the team to understand their users as much as possible before the product build begins, whereas agile methods are largely against an up-front period of investigation at the expense of writing code.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;live-prototyping&#34;&gt;Live Prototyping&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Optimizers - Drag and drop interface. Small revision its awesome. Benefit is high.&lt;/li&gt;
&lt;li&gt;Final interface vs Prototype&lt;/li&gt;
&lt;li&gt;Allows to get feedback&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ab-testing&#34;&gt;A/B Testing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Rapid software testing between two changes. B version to small users and change as positive before to all.&lt;/li&gt;
&lt;li&gt;Real user testing&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;agile-hci-in-the-design-life-cycle&#34;&gt;Agile HCI In The Design Life Cycle&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Agile development techniques don&amp;rsquo;t replace the design life cycle, they just change the rate at which we go through it and the types of prototypes and evaluation that we actually do. We&amp;rsquo;re still going to do the initial need-finding step.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/caffine.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;5-tips-mitigating-risk-in-hci-and-agile-development&#34;&gt;5 Tips: Mitigating Risk In HCI And Agile Development&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Start more traditional&lt;/strong&gt; - Once you have something up and running, move to agile&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Focus on small changes&lt;/strong&gt; - Don&amp;rsquo;t make huge change&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Adopt a parallel track method&lt;/strong&gt; - 2 week sprints, have HCI one sprint ahead&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be careful with consistency&lt;/strong&gt; - Don&amp;rsquo;t mess with user expectation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nest your design cycles&lt;/strong&gt; - Small cycles rapidly in Agile&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;approaches-to-user-centered-design&#34;&gt;Approaches To User-Centered Design&lt;/h2&gt;
&lt;p&gt;There are different approaches to user-centered design:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Participatory design&lt;/strong&gt; - all the stakeholders including the users themselves, are involved as part of the design team but we must be careful not to over represent the few users that are participating in the design with the rest of the users out there&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Action research&lt;/strong&gt; - addresses an immediate problem and researches it by trying to simultaneously solve it&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Design-based research&lt;/strong&gt; - similar to action research but it can be done by outside practitioners as well. Common in learning science research&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Redesigning the Goodreads bookshelf interaction</title>
      <link>https://ayushsubedi.github.io/posts/redesigning_goodreads/</link>
      <pubDate>Sat, 22 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/redesigning_goodreads/</guid>
      <description>&lt;iframe width=&#34;100%&#34; height =&#34;1024&#34; src=&#34;https://ayushsubedi.github.io/pdfs/cse6750_final_project.pdf#toolbar=0&#34;&gt;&lt;/iframe&gt;</description>
    </item>
    
  </channel>
</rss>