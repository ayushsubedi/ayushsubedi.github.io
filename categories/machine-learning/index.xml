<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine-learning on Ayush Subedi</title>
    <link>https://ayushsubedi.github.io/categories/machine-learning/</link>
    <description>Recent content in machine-learning on Ayush Subedi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 01 Jan 2023 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://ayushsubedi.github.io/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>AWS Certified ML - Specialty exam (MLS-C01) - Data Engineering</title>
      <link>https://ayushsubedi.github.io/posts/aws_ml_speciality_data_engineering/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/aws_ml_speciality_data_engineering/</guid>
      <description>&lt;h1 id=&#34;data-engineering&#34;&gt;Data Engineering&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#s3&#34;&gt;S3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kinesis&#34;&gt;Kinesis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#glue&#34;&gt;Glue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#redshift&#34;&gt;Redshift&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rds&#34;&gt;RDS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dynamodb&#34;&gt;DynamoDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#opensearch&#34;&gt;OpenSearch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#aws-data-pipeline&#34;&gt;AWS Data Pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#aws-batch&#34;&gt;AWS Batch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#aws-batch&#34;&gt;AWS DMS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-functions&#34;&gt;Step Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#efs&#34;&gt;EFS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ebs&#34;&gt;EBS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#emr&#34;&gt;EMR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#misc&#34;&gt;Misc&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This domain requires understanding of creating data repositories for machine learning, identification and implementation of data ingestion solution, and
identification and implementation of a data transformation solution.&lt;/p&gt;
&lt;p&gt;Data engineering is the process of building and maintaining the infrastructure and systems that are used to store, process, and analyze data. In the context of Amazon Web Services (AWS), data engineering involves the use of various AWS services and tools to build and operate data pipelines, data lakes, and other data processing systems.&lt;/p&gt;
&lt;p&gt;Some common AWS services and tools that are used in data engineering on AWS include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Amazon S3: A fully managed object storage service that is used to store and retrieve data.&lt;/li&gt;
&lt;li&gt;Amazon EMR: A fully managed big data processing service that is used to process and analyze large datasets using Apache Hadoop and Apache Spark.&lt;/li&gt;
&lt;li&gt;AWS Glue: A fully managed extract, transform, and load (ETL) service that is used to move and transform data between data stores.&lt;/li&gt;
&lt;li&gt;Amazon Redshift: A fully managed data warehouse service that is used to store and analyze large amounts of data using SQL and business intelligence tools.&lt;/li&gt;
&lt;li&gt;Amazon RDS: A fully managed database service that is used to set up, operate, and scale relational databases in the cloud.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By using these and other AWS services, data engineers can build and maintain robust, scalable, and cost-effective data processing systems on the AWS Cloud.&lt;/p&gt;
&lt;h2 id=&#34;s3&#34;&gt;S3&lt;/h2&gt;
&lt;p&gt;Amazon S3 (Simple Storage Service) is a cloud storage service that allows you to store and retrieve data at any time, from anywhere on the web. It is designed to make web-scale computing easier for developers by providing a simple, highly scalable, and cost-effective way to store and retrieve any amount of data. With S3, you can store and retrieve any amount of data, at any time, from anywhere on the web. S3 is designed to provide 99.999999999% durability and scale past trillions of objects worldwide. It is used to store and retrieve any amount of data, at any time, from anywhere on the web. It is an object storage service that offers industry-leading scalability, data availability, security, and performance.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;foundational for machine learning projects since it is a cost effective solution for datasets storage&lt;/li&gt;
&lt;li&gt;object based storage, bucket name need to be globally unique, however the storage itself is unique to regions&lt;/li&gt;
&lt;li&gt;key is the full path of the file and even though it looks like there is a folder based heirarchy, that is not how it works&lt;/li&gt;
&lt;li&gt;you can have a very long file name, in the sense that the path (key) can be very long&lt;/li&gt;
&lt;li&gt;individual Amazon S3 objects can range in size from a minimum of 0 bytes to a maximum of 5 TB. The largest object that can be uploaded in a single PUT is 5 GB.&lt;/li&gt;
&lt;li&gt;object tags can be added, helpful with classification and security lifecycle (these are key value pairs)&lt;/li&gt;
&lt;li&gt;decoupling of compute and storage side&lt;/li&gt;
&lt;li&gt;perfect use case of data lake, since it can store various formats of data (object storage)&lt;/li&gt;
&lt;li&gt;it is possible to partition the storage, which is helpful (speedy) when querying via athena. Kinesis partitions the data automatically.&lt;/li&gt;
&lt;li&gt;11 9&amp;rsquo;s durability (for all storage classes)&lt;/li&gt;
&lt;li&gt;availability differs between availability classes&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;storage-classes&#34;&gt;Storage classes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;S3, Standard / General Purpose: for frequently accessed data&lt;/li&gt;
&lt;li&gt;S3, Infrequent Access: lower cost than standard, for data accessed monthly, and requires milliseconds retrival, but there is a cost associated with retrival&lt;/li&gt;
&lt;li&gt;S3, Infrequent Access, One Zone, good for secondary copies of backup, or data that can be recreated, infrequent access for cost saving&lt;/li&gt;
&lt;li&gt;S3, Glacier Instant Retrival, price per storage + price per retrival, can access within milliseconds, for low cost storage for long-lived data&lt;/li&gt;
&lt;li&gt;S3, Glacier Flexible Retrival, expedited: 1-5 mins, standard: 3-5 hrs, bulk: 5-12 hrs (free), for long term low cost storage for backups and archives  with different retrival options&lt;/li&gt;
&lt;li&gt;S3, Glacier Deep Archive: lowest cost, 180 days of minimum storage, for rarely accessed archive data&lt;/li&gt;
&lt;li&gt;S3, Intelligent Tiering: move objects between tiers with monthly monitoring and auto-tiering fee&lt;/li&gt;
&lt;li&gt;It is possible to move objects between these storage classes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://d1.awsstatic.com/reInvent/re21-pdp-tier1/s3/Amazon-S3-Storage-Classes.pdf&#34;&gt;more info&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;lifecycle-rules&#34;&gt;Lifecycle rules&lt;/h3&gt;
&lt;p&gt;Amazon S3 Lifecycle rules allow you to define policies for how Amazon S3 stores objects. You can use Lifecycle rules to specify when objects transition to different storage classes, or when they expire and are deleted. This can help you reduce your storage costs by moving objects to lower-cost storage classes or deleting them when they are no longer needed. You can set up Lifecycle rules at the bucket level or at the object level (for individual objects or for groups of objects). You can also specify different rules for different prefixes or object tags.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transitioning objects between classes is possible&lt;/li&gt;
&lt;li&gt;Transition Actions can be used to configure objects to transition to another storage class&lt;/li&gt;
&lt;li&gt;Transition Actions can also be used for expiration, incomplete multi part uploads etc.&lt;/li&gt;
&lt;li&gt;Rules can be applied to buckets, specific paths of the project or also to tags&lt;/li&gt;
&lt;li&gt;Amazon S3 analytics works exclusively on S3 standard, and S3 IA, and provides analytics on usage&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;performance-chart&#34;&gt;Performance Chart&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/s3_storage_classes.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;encryption&#34;&gt;Encryption&lt;/h3&gt;
&lt;p&gt;Amazon S3 supports several encryption options to help users secure their data at rest. These options include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SSE-S3: This option uses server-side encryption with Amazon S3-managed keys. With this option, Amazon S3 encrypts the data as it is written to disks in its data centers and decrypts it when it is accessed.&lt;/li&gt;
&lt;li&gt;SSE-KMS: This option uses server-side encryption with AWS KMS-managed keys. With this option, users can create, rotate, and manage the keys used to encrypt their data.&lt;/li&gt;
&lt;li&gt;SSE-C: This option allows users to use their own encryption keys to encrypt their data. Users are responsible for securely managing their keys and rotating them as needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Users can enable encryption when creating a new bucket or when uploading an object to an existing bucket. They can also enable encryption for all objects in an existing bucket by enabling bucket-level encryption.&lt;/p&gt;
&lt;h3 id=&#34;security-policy&#34;&gt;Security Policy&lt;/h3&gt;
&lt;p&gt;Amazon S3 bucket policies allow users to add additional security controls to their S3 buckets and objects. A bucket policy is a JSON document that defines the permissions for an S3 bucket. It can be used to grant permissions to other AWS accounts, or to grant public access to a bucket and its objects.&lt;/p&gt;
&lt;p&gt;With a bucket policy, users can:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Grant read and write permissions to a specific AWS account for all objects in a bucket.&lt;/li&gt;
&lt;li&gt;Grant read-only permissions to the anonymous user for all objects in a bucket.&lt;/li&gt;
&lt;li&gt;Grant read and write permissions to a specific AWS account for all objects with a specific prefix (such as &amp;ldquo;private/&amp;rdquo;).&lt;/li&gt;
&lt;li&gt;Deny all access to a specific AWS account for all objects in a bucket.&lt;/li&gt;
&lt;li&gt;It is important for users to carefully consider the permissions they grant in their bucket policy, as it can have wide-ranging effects on the security of the bucket and its contents.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;misc&#34;&gt;Misc&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Amazon S3 VPC Endpoints allow users to access Amazon S3 from within their virtual private cloud (VPC) without the need for an Internet gateway, NAT device, or VPN connection. With VPC Endpoints, users can access S3 from their VPC over an optimized network path, reducing Internet traffic and improving performance.&lt;/li&gt;
&lt;li&gt;Users can create a VPC Endpoint for Amazon S3 in their VPC, and then configure their VPC security groups and IAM policies to allow access to the endpoint. They can then use the endpoint to access Amazon S3 using the Amazon S3 APIs or the AWS Management Console, just as they would over the Internet.&lt;/li&gt;
&lt;li&gt;VPC Endpoints for Amazon S3 are supported in all regions and are available in two types: Gateway Endpoints and Interface Endpoints. Gateway Endpoints are powered by a highly available network gateway, while Interface Endpoints are powered by a highly available Network Load Balancer. Users can choose the endpoint type that best meets their needs.&lt;/li&gt;
&lt;li&gt;Amazon S3 CloudTrail is a service that enables users to record API calls made to Amazon S3 and log the events to an Amazon S3 bucket. This allows users to track changes to their objects, buckets, and Amazon S3 configurations, and to identify and troubleshoot issues.&lt;/li&gt;
&lt;li&gt;With CloudTrail, users can:
&lt;ul&gt;
&lt;li&gt;Track changes to their Amazon S3 objects and bucket metadata.&lt;/li&gt;
&lt;li&gt;Determine who made a change and when it was made.&lt;/li&gt;
&lt;li&gt;Audit changes to their Amazon S3 bucket and object permissions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CloudTrail logs are stored in an Amazon S3 bucket that the user specifies, and they can be delivered to an Amazon CloudWatch Logs log group or an Amazon SNS topic. Users can use the CloudTrail logs to monitor their S3 resources and to ensure compliance with their policies.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kinesis&#34;&gt;Kinesis&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Kinesis is a fully managed (alternative to Kafka), cloud-based service that enables users to process and analyze streaming data in real-time. With Kinesis, users can build custom applications that process and analyze data as it arrives, and they can scale these applications to process any volume of data, at any time.&lt;/li&gt;
&lt;li&gt;Kinesis consists of three main components:
&lt;ul&gt;
&lt;li&gt;Producers: Producers are sources of data that send data records to Kinesis streams.&lt;/li&gt;
&lt;li&gt;Kinesis streams: A Kinesis stream is a sequence of data records that are persisted for a set period of time. Users can create and delete streams, and they can specify the number of shards in a stream.&lt;/li&gt;
&lt;li&gt;Consumers: Consumers are applications that read and process data records from Kinesis streams.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Kinesis is designed to be highly available and durable, and it can automatically scale to handle increases in traffic.&lt;/li&gt;
&lt;li&gt;Users can use Kinesis to build custom applications that can process and analyze real-time data streams, and they can use the service to support a wide range of use cases, such as real-time analytics, fraud detection, and Internet of Things (IoT) applications.&lt;/li&gt;
&lt;li&gt;Data is replicated to at least 3 AZ&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kinesis-streams&#34;&gt;Kinesis Streams&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Kinesis Streams is a fully managed, cloud-based service that allows real-time processing of streaming data at high scale.&lt;/li&gt;
&lt;li&gt;It can continuously capture and store terabytes of data per hour from hundreds of thousands of sources, such as website clickstreams, financial transactions, social media feeds, IT logs, and location-tracking events.&lt;/li&gt;
&lt;li&gt;With Kinesis Streams, users can build custom applications that process or analyze the data as it arrives, or they can use the provided Kinesis Data Streams API to load the data into other AWS services, such as Amazon S3, Amazon Redshift, or Amazon Elasticsearch Service, for long-term storage and analysis.&lt;/li&gt;
&lt;li&gt;Streams are divided into shards and partitions&lt;/li&gt;
&lt;li&gt;The maximum throughput of a single shard 1 mb/seconds or 1000 messages/seconds&lt;/li&gt;
&lt;li&gt;Data retention: 24 hours by default. It can go up to 365 days. This is useful for reprocessing/replaying data&lt;/li&gt;
&lt;li&gt;Immutable, 1 mb in size&lt;/li&gt;
&lt;li&gt;Provisioned mode: choose number of shards and scale manually or using an API&lt;/li&gt;
&lt;li&gt;Each shard gets 1mb/s in, 2mb/s out&lt;/li&gt;
&lt;li&gt;On demand mode: each capacity provisioned is 4mb/s&lt;/li&gt;
&lt;li&gt;If you can plan capacity, use provisioned. however, use on demand if capacity is unknown&lt;/li&gt;
&lt;li&gt;Custom code for producer or consumer is possible&lt;/li&gt;
&lt;li&gt;Real time (200 ms latency, possible all the way up to 70ms)&lt;/li&gt;
&lt;li&gt;Automatic scaling with on-demand mode&lt;/li&gt;
&lt;li&gt;Multi consumers is possible from one source&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kinesis-analytics&#34;&gt;Kinesis Analytics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Kinesis Analytics is a fully managed, cloud-based service that allows users to process and analyze streaming data in real-time with SQL.&lt;/li&gt;
&lt;li&gt;With Kinesis Analytics, users can run ad-hoc queries on the data, or they can set up a SQL-based stream processing application to perform transformations on the data as it arrives. SQL or Apache Flink can be used here.&lt;/li&gt;
&lt;li&gt;The output of these queries and transformations can be fed back into Kinesis Streams for further processing, or it can be stored in other AWS services, such as Amazon S3 or Amazon Redshift, for long-term analysis.&lt;/li&gt;
&lt;li&gt;Select columns, continious metric generation, responsive analytics, etc.&lt;/li&gt;
&lt;li&gt;Serverless, scales automatically, pay for resouces consumed but expensive&lt;/li&gt;
&lt;li&gt;Schema discovery&lt;/li&gt;
&lt;li&gt;Lambda can be used for preprocessing&lt;/li&gt;
&lt;li&gt;Two machine learning algorithms:
&lt;ul&gt;
&lt;li&gt;Random cut forest for anomaly detection on numeric columns in a stream, uses recent data to compute the model. A random cut forest (RCF) is a machine learning algorithm that is used for anomaly detection in streaming data. It works by constructing a number of decision trees on randomly selected subsets of the data, and then comparing the score for each new data point to the scores of similar points in the trees. If the score for a new data point is significantly lower than the scores of similar points in the trees, it is considered to be an anomaly. The number of trees in the forest and the size of the subsets of data used to train each tree can be adjusted to control the sensitivity of the model. RCFs are particularly well-suited for detecting anomalies in large, high-dimensional datasets, and they are often used in conjunction with streaming data platforms, such as Amazon Kinesis Streams.&lt;/li&gt;
&lt;li&gt;Hotspots: A hotspots algorithm is a type of machine learning algorithm that is used to identify spatial clusters of events or observations in a dataset. These clusters, which are also known as hotspots, are areas in which the concentration of events or observations is significantly higher than the surrounding areas. Hotspots algorithms are often used in a variety of applications, such as crime mapping, disease surveillance, and marketing analysis. There are several different approaches to identifying hotspots, including spatial clustering methods, spatial scan statistics, and kernel density estimation. These methods can be applied to a variety of types of data, including point data, such as crime incidents or disease cases, and areal data, such as census tracts or zip codes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kinesis-firehose&#34;&gt;Kinesis Firehose&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Kinesis Firehose is a fully managed service&lt;/li&gt;
&lt;li&gt;makes it easy to load streaming data into data stores and analytics tools&lt;/li&gt;
&lt;li&gt;It can capture, transform, and load data streams into Amazon S3, Amazon Redshift, and Amazon Elasticsearch Service, Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards&lt;/li&gt;
&lt;li&gt;Kinesis Firehose is a simple and reliable way to load streaming data into data stores and analytics tools.&lt;/li&gt;
&lt;li&gt;most common is firehose reading from kinesis streams&lt;/li&gt;
&lt;li&gt;near realtime service because it batch writes&lt;/li&gt;
&lt;li&gt;data desitination can be s3, redshift, elastisearch, splunk, new relic, or http endpoint&lt;/li&gt;
&lt;li&gt;60 seconds latency minimum for non full batches&lt;/li&gt;
&lt;li&gt;data ingestion into redshift, s3, elasticsearch, splunk&lt;/li&gt;
&lt;li&gt;automatic scaling&lt;/li&gt;
&lt;li&gt;conversions from csv/json to parquet and orc and requires the use of glue&lt;/li&gt;
&lt;li&gt;and transformation through lambda csv to json is possible&lt;/li&gt;
&lt;li&gt;compression is possible&lt;/li&gt;
&lt;li&gt;automates scaling&lt;/li&gt;
&lt;li&gt;no data storage&lt;/li&gt;
&lt;li&gt;no replay capability&lt;/li&gt;
&lt;li&gt;it is a serverless transformation tool&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kinesis-video-streams&#34;&gt;Kinesis Video Streams&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Web Services (AWS) Kinesis Video Streams is a fully managed service that allows users to stream live video from connected devices to the cloud.&lt;/li&gt;
&lt;li&gt;This service is designed to make it easy to build applications that process and analyze live video streams, as well as store and transmit videos securely at scale.&lt;/li&gt;
&lt;li&gt;With Kinesis Video Streams, users can stream live video from millions of devices and easily build applications for real-time video analytics and machine learning.&lt;/li&gt;
&lt;li&gt;In addition, the service allows users to stream video directly to other AWS services, such as Amazon S3, Amazon Kinesis Data Streams, and Amazon Rekognition, for further processing and analysis.&lt;/li&gt;
&lt;li&gt;Producers: security camera, body-worn cam, aws deeplens, radar data, camera&lt;/li&gt;
&lt;li&gt;One producer per video stream&lt;/li&gt;
&lt;li&gt;Video playback capability&lt;/li&gt;
&lt;li&gt;Sagemaker, rekognition video, 1 hour to 10 years of storage&lt;/li&gt;
&lt;li&gt;Checkpointing via dynamodb, frames to Sagemaker for ML inference, publish to stream, lambda can be used for notification.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;glue&#34;&gt;Glue&lt;/h2&gt;
&lt;h3 id=&#34;glue-data-catalog-and-glue-data-crawlers&#34;&gt;Glue Data Catalog and Glue Data Crawlers&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;AWS Glue Data Catalog is a fully managed, cloud-native metadata store that provides a central place to store, annotate, and share metadata across AWS services, applications, and tools.&lt;/li&gt;
&lt;li&gt;It makes it easy to discover and understand data, and facilitates the development of data-driven applications.&lt;/li&gt;
&lt;li&gt;With the Glue Data Catalog, users can create, maintain, and access metadata such as database and table definitions, column names and data types, and data lineage.&lt;/li&gt;
&lt;li&gt;The Glue Data Catalog is integrated with other AWS services such as Amazon Redshift, Amazon Athena, and Amazon EMR, and is accessible through the AWS Management Console, the AWS Glue API, and the AWS Glue ETL (extract, transform, and load) library.&lt;/li&gt;
&lt;li&gt;Schemas are versioned&lt;/li&gt;
&lt;li&gt;Glue crawlers help build the Catalog&lt;/li&gt;
&lt;li&gt;Glue will also extract the partitions, this is helpful for query optimization&lt;/li&gt;
&lt;li&gt;Glue Data Crawlers are a tool within the Amazon Glue service that allows users to extract metadata from their data stores and create table definitions in the Glue Data Catalog.&lt;/li&gt;
&lt;li&gt;This enables the creation of ETL jobs and development endpoints in Glue, which can be used to move and transform data.&lt;/li&gt;
&lt;li&gt;Glue Data Crawlers can connect to various data stores, including Amazon S3 and RDS, as well as any JDBC-compliant data store.&lt;/li&gt;
&lt;li&gt;Custom connectors for other data stores can also be created using the Glue ETL library. To use Glue Data Crawlers, a Glue ETL job or development endpoint must first be created, after which the Glue ETL library can be utilized for data movement and transformation tasks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;glue-etl&#34;&gt;Glue ETL&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Transform data, clean data, enrich data before doing analysis&lt;/li&gt;
&lt;li&gt;Generate ETL code in python or scala, you can modify the code&lt;/li&gt;
&lt;li&gt;Possible to provide your own spark or pyspark scripts&lt;/li&gt;
&lt;li&gt;Target can be S3, JDBC or in glue data catalog&lt;/li&gt;
&lt;li&gt;Fully managed, cost effective, pay only for the resources consumed&lt;/li&gt;
&lt;li&gt;Jobs are run on a serverless Spark platform&lt;/li&gt;
&lt;li&gt;Glue scheduler to schedule the jobs&lt;/li&gt;
&lt;li&gt;Glue triggers to automate job runs based on events&lt;/li&gt;
&lt;li&gt;Transformations can be bundled (drop, filter, join, map)&lt;/li&gt;
&lt;li&gt;Machine learning transformation (find matches, duplicates even when data do not match exactly, dedup)&lt;/li&gt;
&lt;li&gt;Any apache spark transformation is possible, and changing in format is possible.&lt;/li&gt;
&lt;li&gt;Multiple ways to create glue jobs including visual editors, python notebooks, python script, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;redshift&#34;&gt;Redshift&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Redshift is a fully managed data warehouse service offered by Amazon Web Services (AWS).&lt;/li&gt;
&lt;li&gt;It is designed to handle petabyte-scale data warehouses and make it easy to analyze data using SQL and business intelligence tools.&lt;/li&gt;
&lt;li&gt;Amazon Redshift is based on PostgreSQL, and it supports many of the same data types and functions as PostgreSQL.&lt;/li&gt;
&lt;li&gt;To use Amazon Redshift, users first need to set up a cluster of compute nodes. They can then load data into the cluster and perform SQL queries on the data. Amazon Redshift integrates with various data sources and destinations, including Amazon S3, Amazon EMR, and Amazon RDS.&lt;/li&gt;
&lt;li&gt;It also integrates with a variety of business intelligence tools, such as Quicksight, Tableau, Qlik, and MicroStrategy.&lt;/li&gt;
&lt;li&gt;Amazon Redshift offers a number of features to help users manage their data warehouses, including automatic data compression, data replication, and data security. It also provides a number of performance enhancements, such as columnar storage, data caching, and parallel query execution.&lt;/li&gt;
&lt;li&gt;Overall, Amazon Redshift is a powerful and scalable data warehouse solution for analyzing large datasets in the cloud.&lt;/li&gt;
&lt;li&gt;OLAP&lt;/li&gt;
&lt;li&gt;Uses SQL to analyze structured and semi-structured data across data warehouses, operational databases, and data lakes&lt;/li&gt;
&lt;li&gt;Redshift Spectrum can directly query from S3&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;rds&#34;&gt;RDS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Relational Database Service (RDS) is a fully managed database service offered by Amazon Web Services (AWS).&lt;/li&gt;
&lt;li&gt;It makes it easy to set up, operate, and scale a relational database in the cloud.&lt;/li&gt;
&lt;li&gt;Amazon RDS supports a variety of database engines, including MySQL, MariaDB, PostgreSQL, Oracle, and Microsoft SQL Server.&lt;/li&gt;
&lt;li&gt;With Amazon RDS, users can create and manage a database without the need to install and maintain database software.&lt;/li&gt;
&lt;li&gt;Amazon RDS handles tasks such as hardware provisioning, database setup, patching, and backups.&lt;/li&gt;
&lt;li&gt;It also provides features such as automated failover and read replicas to help users improve availability and scalability.&lt;/li&gt;
&lt;li&gt;Amazon RDS is a popular choice for applications that require a relational database, such as e-commerce, content management, and customer relationship management systems.&lt;/li&gt;
&lt;li&gt;It is particularly well-suited for use cases that require high availability and low latency, such as online transaction processing (OLTP).&lt;/li&gt;
&lt;li&gt;Must provision servers in advance&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;dynamodb&#34;&gt;DynamoDB&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Amazon DynamoDB is a fully managed NoSQL database service offered by Amazon Web Services (AWS).&lt;/li&gt;
&lt;li&gt;It is designed to be scalable, fast, and flexible, making it a good choice for applications that need high performance and low latency.&lt;/li&gt;
&lt;li&gt;DynamoDB stores data in tables, and each table has a primary key that uniquely identifies each item. The primary key can be either a simple primary key (a single attribute) or a composite primary key (a combination of two or more attributes).&lt;/li&gt;
&lt;li&gt;DynamoDB supports both key-value and document data models, and it offers a number of powerful features, such as global secondary indexes, auto scaling, and stream-based data replication.&lt;/li&gt;
&lt;li&gt;DynamoDB is a popular choice for applications that need to store large amounts of data that is frequently read or written, such as online gaming, real-time analytics, and IoT applications.&lt;/li&gt;
&lt;li&gt;It is also well-suited for applications that need to scale rapidly, as it can automatically adjust capacity to meet changing demand.&lt;/li&gt;
&lt;li&gt;Useful to store ML model (or checkpoints)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;opensearch&#34;&gt;OpenSearch&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Previously ElasticSearch&lt;/li&gt;
&lt;li&gt;Amazon OpenSearch is a search service that makes it easy to build and run search applications.&lt;/li&gt;
&lt;li&gt;It is based on the open source Apache Lucene search engine, and it provides a number of features to help users build sophisticated search experiences, such as full-text search, faceted search, and hit highlighting.&lt;/li&gt;
&lt;li&gt;With Amazon OpenSearch, users can index and search large datasets, such as websites, documents, and logs.&lt;/li&gt;
&lt;li&gt;They can also customize the search experience by adding search criteria, filters, and facets, and by displaying search results in various formats.&lt;/li&gt;
&lt;li&gt;Amazon OpenSearch also provides analytics and monitoring capabilities to help users understand how their search applications are being used.&lt;/li&gt;
&lt;li&gt;Amazon OpenSearch is a flexible and scalable search solution that is well-suited for a wide range of applications, such as e-commerce, content management, and data analysis.&lt;/li&gt;
&lt;li&gt;It is fully managed, so users do not need to worry about infrastructure or maintenance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;aws-data-pipeline&#34;&gt;AWS Data Pipeline&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Data Pipeline is a fully managed data processing service that helps users move and transform data between data stores.&lt;/li&gt;
&lt;li&gt;It is designed to be easy to use and highly reliable, and it can handle data processing tasks of any size.&lt;/li&gt;
&lt;li&gt;With Amazon Data Pipeline, users can create pipelines that move data between data stores, such as Amazon S3, Amazon RDS, and Amazon Redshift.&lt;/li&gt;
&lt;li&gt;They can also use Data Pipeline to transform data, such as by aggregating, filtering, or joining data from different sources. Data Pipeline supports a variety of data formats and sources, and it can be used to schedule and automate data processing tasks.&lt;/li&gt;
&lt;li&gt;Amazon Data Pipeline is a useful tool for a wide range of data processing tasks, such as data warehousing, ETL, and analytics. It is particularly well-suited for use cases that involve moving and transforming large amounts of data, as it can scale to handle data processing needs of any size.&lt;/li&gt;
&lt;li&gt;Data sources can be on premise&lt;/li&gt;
&lt;li&gt;Runs on EC2 but fully managed&lt;/li&gt;
&lt;li&gt;Orchestration service&lt;/li&gt;
&lt;li&gt;Glue is managed, serverless, spark focused, ETL focused, has catalog&lt;/li&gt;
&lt;li&gt;Data Pipeline is orchestation tool, and can do more&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;aws-batch&#34;&gt;AWS Batch&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;For any non-ETL batch is usually better than glue&lt;/li&gt;
&lt;li&gt;Amazon Web Services Batch is a fully managed batch processing service that makes it easy to run batch computing workloads on the AWS Cloud.&lt;/li&gt;
&lt;li&gt;It is designed to be scalable, fault-tolerant, and flexible, and it supports a wide range of workloads, such as machine learning, data processing, and scientific simulations.&lt;/li&gt;
&lt;li&gt;With AWS Batch, users can define batch computing workloads as &amp;ldquo;jobs&amp;rdquo; and &amp;ldquo;tasks,&amp;rdquo; and the service automatically provisions the required compute resources and executes the tasks.&lt;/li&gt;
&lt;li&gt;Users can specify the desired level of concurrency and resource allocation for their jobs, and AWS Batch will automatically scale up or down as needed.&lt;/li&gt;
&lt;li&gt;AWS Batch also integrates with other AWS services, such as Amazon S3 and Amazon ECS, to provide a complete batch processing solution.&lt;/li&gt;
&lt;li&gt;AWS Batch is a useful tool for organizations that need to run large-scale batch computing workloads, such as financial analysis, scientific simulations, and media processing.&lt;/li&gt;
&lt;li&gt;It is fully managed, so users do not need to worry about infrastructure or maintenance.&lt;/li&gt;
&lt;li&gt;Batch can be scheduled using cloudwatch, step functions&lt;/li&gt;
&lt;li&gt;Not just for ETL but absolutely anything at all&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;aws-dms&#34;&gt;AWS DMS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Web Services Database Migration Service (AWS DMS) is a fully managed service that makes it easy to migrate databases to the AWS Cloud.&lt;/li&gt;
&lt;li&gt;It is designed to be reliable, efficient, and flexible, and it supports a wide range of database platforms, including Oracle, MySQL, and Microsoft SQL Server.&lt;/li&gt;
&lt;li&gt;With AWS DMS, users can migrate their databases to the AWS Cloud with minimal downtime.&lt;/li&gt;
&lt;li&gt;The service handles tasks such as data extraction, transformation, and load, and it supports both one-time and ongoing migrations.&lt;/li&gt;
&lt;li&gt;AWS DMS also provides a number of features to help users manage their database migrations, such as change data capture, data transformation, and task scheduling.&lt;/li&gt;
&lt;li&gt;AWS DMS is a useful tool for organizations that want to migrate their databases to the cloud, or that need to replicate their databases across multiple regions for disaster recovery or other purposes.&lt;/li&gt;
&lt;li&gt;It is fully managed, so users do not need to worry about infrastructure or maintenance.&lt;/li&gt;
&lt;li&gt;Supports homogeneous migrations and heterogeneous migrations&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;step-functions&#34;&gt;Step Functions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Web Services Step Functions is a fully managed service that makes it easy to coordinate the various components of complex, distributed applications.&lt;/li&gt;
&lt;li&gt;It is based on the concepts of tasks and state machines, and it provides a visual workflow editor to help users design and manage their applications.&lt;/li&gt;
&lt;li&gt;With AWS Step Functions, users can define and execute workflows that coordinate multiple AWS services, such as AWS Lambda, Amazon ECS, and AWS Batch.&lt;/li&gt;
&lt;li&gt;The service automatically scales to meet the needs of the workflow, and it provides features such as error handling and retry logic to help users build resilient applications.&lt;/li&gt;
&lt;li&gt;AWS Step Functions is a useful tool for organizations that need to coordinate the various components of complex, distributed applications, such as data pipelines, machine learning workflows, and microservices architectures.&lt;/li&gt;
&lt;li&gt;It is fully managed, so users do not need to worry about infrastructure or maintenance.&lt;/li&gt;
&lt;li&gt;Audit of history of workflow&lt;/li&gt;
&lt;li&gt;Allows waiting&lt;/li&gt;
&lt;li&gt;Maximum execution time of 1 year&lt;/li&gt;
&lt;li&gt;Can be used to train/tune a ML model&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;efs&#34;&gt;EFS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Elastic File System (EFS) is a fully managed, cloud-native file storage service that makes it easy to store and access files from multiple Amazon Elastic Compute Cloud (EC2) instances.&lt;/li&gt;
&lt;li&gt;It is designed to be scalable, highly available, and easy to use, and it supports the Network File System (NFS) protocol.&lt;/li&gt;
&lt;li&gt;With AWS EFS, users can create file systems and store files in them, and they can access the files from multiple EC2 instances at the same time.&lt;/li&gt;
&lt;li&gt;EFS automatically scales up or down as needed to meet the storage and performance needs of the applications, and it provides features such as file system access control and data durability to help users manage their file storage.&lt;/li&gt;
&lt;li&gt;AWS EFS is a useful tool for organizations that need to store and access files from multiple EC2 instances, such as web servers, application servers, and development environments.&lt;/li&gt;
&lt;li&gt;It is fully managed, so users do not need to worry about infrastructure or maintenance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ebs&#34;&gt;EBS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Elastic Block Store (EBS) is a fully managed, cloud-native block storage service that makes it easy to store and access data from Amazon Elastic Compute Cloud (EC2) instances.&lt;/li&gt;
&lt;li&gt;It is designed to be scalable, highly available, and easy to use, and it supports a variety of storage types and performance levels.&lt;/li&gt;
&lt;li&gt;With AWS EBS, users can create storage volumes and attach them to EC2 instances, and they can use the volumes to store and access data.&lt;/li&gt;
&lt;li&gt;EBS provides a number of features to help users manage their storage, such as snapshotting, data replication, and encryption.&lt;/li&gt;
&lt;li&gt;It also supports a variety of storage types, including SSD-backed volumes for high performance and HDD-backed volumes for lower cost.&lt;/li&gt;
&lt;li&gt;AWS EBS is a useful tool for organizations that need to store and access data from EC2 instances, such as databases, file systems, and applications.&lt;/li&gt;
&lt;li&gt;It is fully managed, so users do not need to worry about infrastructure or maintenance.&lt;/li&gt;
&lt;li&gt;EBS volumes are attached to specific EC2 instances, and they scale with the needs of the applications running on those instances.&lt;/li&gt;
&lt;li&gt;EFS file systems, on the other hand, can be accessed concurrently by multiple EC2 instances, and they scale automatically to meet the needs of the workload.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;emr&#34;&gt;EMR&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Elastic MapReduce (EMR) is a fully managed, cloud-native big data processing service that makes it easy to process large amounts of data using Apache Hadoop and Apache Spark.&lt;/li&gt;
&lt;li&gt;It is designed to be scalable, highly available, and easy to use, and it integrates with a variety of data sources and destinations.&lt;/li&gt;
&lt;li&gt;With AWS EMR, users can create clusters of Amazon Elastic Compute Cloud (EC2) instances and use them to process and analyze large datasets stored in Amazon S3 or other data stores.&lt;/li&gt;
&lt;li&gt;EMR supports a variety of big data processing frameworks, including Hadoop, Spark, and Flink, and it provides tools to help users manage and monitor their clusters.&lt;/li&gt;
&lt;li&gt;AWS EMR is a useful tool for organizations that need to process and analyze large amounts of data, such as log files, scientific simulations, and machine learning models.&lt;/li&gt;
&lt;li&gt;It is fully managed, so users do not need to worry about infrastructure or maintenance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;misc-1&#34;&gt;Misc&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;AWS DataSync: for data migrations from on-premises to AWS storage services&lt;/li&gt;
&lt;li&gt;MQTT: IOT protocol, Standard messaging protocol&lt;/li&gt;
&lt;li&gt;Apache Spark, Apache Hive, Apache Hadoop, and Apache Pig are all open-source technologies that are used for data processing and analysis. However, they are designed for different purposes and have different strengths and weaknesses.
&lt;ul&gt;
&lt;li&gt;Apache Spark is a fast, in-memory data processing engine that is used for real-time data processing and analytics. It is particularly well-suited for use cases that require fast processing times, such as streaming data and interactive data exploration.&lt;/li&gt;
&lt;li&gt;Apache Hive is a data warehousing and SQL-like query language that is used to process and analyze large datasets stored in the Hadoop Distributed File System (HDFS). It is particularly well-suited for use cases that involve complex data transformations and aggregations.&lt;/li&gt;
&lt;li&gt;Apache Hadoop is a distributed computing platform that is used to store and process large amounts of data. It is composed of several modules, including HDFS for storing data, YARN for resource management, and MapReduce for parallel data processing. Hadoop is a popular choice for batch processing and offline data analysis.&lt;/li&gt;
&lt;li&gt;Apache Pig is a high-level data processing language that is used to write and execute MapReduce jobs on Apache Hadoop. It is particularly well-suited for use cases that involve complex data transformations and complex data structures.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>AWS Certified ML - Specialty exam (MLS-C01) - Exploratory Data Analysis</title>
      <link>https://ayushsubedi.github.io/posts/aws_ml_speciality_eda/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/aws_ml_speciality_eda/</guid>
      <description>&lt;h1 id=&#34;exploratory-data-analysis&#34;&gt;Exploratory Data Analysis&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#python-in-data-science-and-machine-learning&#34;&gt;Python in data science and machine learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#types-of-data&#34;&gt;Types of Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-distributions&#34;&gt;Data Distributions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#trends-and-seasonality&#34;&gt;Trends and seasonality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#athena&#34;&gt;Athena&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#quicksight&#34;&gt;Quicksight&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#types-of-visualization&#34;&gt;Types of visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#emr&#34;&gt;EMR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hadoop&#34;&gt;Hadoop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#apache-spark&#34;&gt;Apache Spark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#emr-notebooks,-security-and-instance-types&#34;&gt;EMR Notebooks, Security and Instance Types&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feature-engineering&#34;&gt;Feature Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#imputing-missing-data&#34;&gt;Imputing Missing Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#unbalanced-data&#34;&gt;Unbalanced Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#handling-outliers&#34;&gt;Handling Outliers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#binning,-transoforming,-encoding,-saling,-and-shuffling&#34;&gt;Binning, Transoforming, Encoding, Saling, and Shuffling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazing-sagemaker-ground-truth-and-label-generation&#34;&gt;Amazing Sagemaker Ground Truth and Label Generation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This section requires understanding of sanitizing and preparing data for modeling, performing feature engineering, and analyzing and visualizing data for machine learning.&lt;/p&gt;
&lt;h2 id=&#34;python-in-data-science-and-machine-learning&#34;&gt;Python in data science and machine learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Python code will not be tested in the exam.&lt;/li&gt;
&lt;li&gt;Python is the industry choice at this point, however there are other alternatives such as R and Julia. Also, Java, Scala, PySpark (a python package, running Spark).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;types-of-data&#34;&gt;Types of Data&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Numerical: quantitative, continious and discrete&lt;/li&gt;
&lt;li&gt;Categorical&lt;/li&gt;
&lt;li&gt;Ordinal&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-distributions&#34;&gt;Data Distributions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Normal Distribution, probability density function (continous data type)&lt;/li&gt;
&lt;li&gt;Probability Mass function (discrete data type)&lt;/li&gt;
&lt;li&gt;Poission (discrete data type)&lt;/li&gt;
&lt;li&gt;Binomial (discrete data type)&lt;/li&gt;
&lt;li&gt;Bernoulli (discrete data type)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;trends-and-seasonality&#34;&gt;Trends and seasonality&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Time series, but cyclical trends also exist&lt;/li&gt;
&lt;li&gt;Additive and Multiplicative&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;athena&#34;&gt;Athena&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Severless interactive queries of S3 data&lt;/li&gt;
&lt;li&gt;Presto under the hood&lt;/li&gt;
&lt;li&gt;Supports multiple formats&lt;/li&gt;
&lt;li&gt;Unstructured, semi structured or structured&lt;/li&gt;
&lt;li&gt;Ad hoc queries, querying data before loading to Redshift, analyze cloudtrail, integration with jupyter, zepplin, integration with quicksight, integration with odbc, jdbc&lt;/li&gt;
&lt;li&gt;AWS Glue datalog can extract the schema for Athena to use&lt;/li&gt;
&lt;li&gt;Pay as you go, inexpensive, converting to columner saves a lot of money, glue and s3 have their own charges&lt;/li&gt;
&lt;li&gt;IAM policies, excription is possible, TLS is possible&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;quicksight&#34;&gt;Quicksight&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Business analytics, cloud powered&lt;/li&gt;
&lt;li&gt;Build visualizations, perform ad-hoc analysis&lt;/li&gt;
&lt;li&gt;anytime on any device&lt;/li&gt;
&lt;li&gt;serverless&lt;/li&gt;
&lt;li&gt;can connect to wide variety of data sources, redshift, aurora, athena, ec2 hosted db, files, ETL&lt;/li&gt;
&lt;li&gt;can do calculated columns etc.&lt;/li&gt;
&lt;li&gt;SPICE: super fast parallel, in memory calculation engine 10 gb&lt;/li&gt;
&lt;li&gt;Quicksight is quick because of spice&lt;/li&gt;
&lt;li&gt;Quicksights machine learning insights: Anomaly detection using Random cut forest, Forecasting and auto narratives (not too mature).&lt;/li&gt;
&lt;li&gt;multifactor authentication&lt;/li&gt;
&lt;li&gt;works with vpc, row-level security&lt;/li&gt;
&lt;li&gt;users defined via iam or email signup&lt;/li&gt;
&lt;li&gt;AugoGraph feature selects the best graph for the respective data type&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;types-of-visualization&#34;&gt;Types of visualization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;bar charts&lt;/li&gt;
&lt;li&gt;line&lt;/li&gt;
&lt;li&gt;scatter plot, heat map&lt;/li&gt;
&lt;li&gt;pie graph, tree graph&lt;/li&gt;
&lt;li&gt;pivot table&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;emr&#34;&gt;EMR&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;managed hadoop framework that runs on EC2&lt;/li&gt;
&lt;li&gt;more than a hadoop cluster&lt;/li&gt;
&lt;li&gt;spark, hbase, hive, presto, flink, and more&lt;/li&gt;
&lt;li&gt;emr notebooks&lt;/li&gt;
&lt;li&gt;several integration points with AWS&lt;/li&gt;
&lt;li&gt;master nodes (manages the cluster), core node (holds hdfs data and run tasks), task node (only runs tasks)&lt;/li&gt;
&lt;li&gt;hdfs is epimerical&lt;/li&gt;
&lt;li&gt;transient cluster vs long running cluster&lt;/li&gt;
&lt;li&gt;EC2: nodes&lt;/li&gt;
&lt;li&gt;VPC: virtual network to launch instances&lt;/li&gt;
&lt;li&gt;S3: to store input/output&lt;/li&gt;
&lt;li&gt;Cloudwatch: monitor cluster performance&lt;/li&gt;
&lt;li&gt;IAM configure permissions&lt;/li&gt;
&lt;li&gt;CloudTrail: audit requests&lt;/li&gt;
&lt;li&gt;Data Pipeline: schedule and start clusters&lt;/li&gt;
&lt;li&gt;EMRFS: access s3 as if it were hdfs, uses dynamodb to track consistency&lt;/li&gt;
&lt;li&gt;local file system&lt;/li&gt;
&lt;li&gt;EBS for HDFS is also possible&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hadoop&#34;&gt;Hadoop&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;MapReduce: map/reduce, but Spark can sit here on top of yarn and hdfs&lt;/li&gt;
&lt;li&gt;Yarn: resource negotiater&lt;/li&gt;
&lt;li&gt;Hdfs: storage&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;apache-spark&#34;&gt;Apache Spark&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;open source&lt;/li&gt;
&lt;li&gt;in memory caching, DAGs&lt;/li&gt;
&lt;li&gt;java, scala, python, R&lt;/li&gt;
&lt;li&gt;batch processing and real time analytics, graph processing, machine learning&lt;/li&gt;
&lt;li&gt;data transformation&lt;/li&gt;
&lt;li&gt;Spark context, cluster manager via spark or yarn, executors&lt;/li&gt;
&lt;li&gt;Spark core&lt;/li&gt;
&lt;li&gt;Spark RDD&lt;/li&gt;
&lt;li&gt;DataFrames and Datasets are built on top of RDD, and they are most commonly used at the moment&lt;/li&gt;
&lt;li&gt;Spark Streaming is possible (works in mini batches). unbounded database table&lt;/li&gt;
&lt;li&gt;mllib (distributed machine learning)&lt;/li&gt;
&lt;li&gt;graphx (distributed graph processing)&lt;/li&gt;
&lt;li&gt;Zepplin can run spark code interactively, and can also use charts/plots&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spark-mllib&#34;&gt;Spark mllib&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Classification: logistic regression and naive bayes&lt;/li&gt;
&lt;li&gt;Regression&lt;/li&gt;
&lt;li&gt;Decision trees&lt;/li&gt;
&lt;li&gt;Recommendation engine (ALS)&lt;/li&gt;
&lt;li&gt;Clustering (K-means)&lt;/li&gt;
&lt;li&gt;LDA (topic modeling)&lt;/li&gt;
&lt;li&gt;ML workflow utilities (pipelines, feature transformation, persistence)&lt;/li&gt;
&lt;li&gt;SVD, PCA and statistics&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;emr-notebooks-security-and-instance-types&#34;&gt;EMR Notebooks, Security and Instance Types&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Similar concept to Zeppelin, with more AWS integration&lt;/li&gt;
&lt;li&gt;notebooks backed up to s3&lt;/li&gt;
&lt;li&gt;provision clusters from the notebooks&lt;/li&gt;
&lt;li&gt;hosted inside a vpc&lt;/li&gt;
&lt;li&gt;accessed only via aws console&lt;/li&gt;
&lt;li&gt;IAM policies, Kerberos (a computer-network authentication protocol that works on the basis of tickets to allow nodes communicating over a non-secure network to prove their identity to one another in a secure manner), SSH, IAM roles&lt;/li&gt;
&lt;li&gt;Spot instances are good choice for task nodes, only use on core or master if you are testing or very cost sensitive, however, you are risking partial data loss&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;feature-engineering&#34;&gt;Feature Engineering&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;create better features&lt;/li&gt;
&lt;li&gt;learnt on experience&lt;/li&gt;
&lt;li&gt;too many features leads to sparse data&lt;/li&gt;
&lt;li&gt;every feature is a new dimension&lt;/li&gt;
&lt;li&gt;dimensionality reduction (PCA and k-means/clustering)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;imputing-missing-data&#34;&gt;Imputing Missing Data&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;this is an art&lt;/li&gt;
&lt;li&gt;mean replacement&lt;/li&gt;
&lt;li&gt;dropping&lt;/li&gt;
&lt;li&gt;linear regression, deep learning, knn and mean/median&lt;/li&gt;
&lt;li&gt;MICE (multiple imputation by chained equations)&lt;/li&gt;
&lt;li&gt;categorical data vs numeric data (categorical is usually not trivial)&lt;/li&gt;
&lt;li&gt;just get more data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;unbalanced-data&#34;&gt;Unbalanced Data&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;oversample&lt;/li&gt;
&lt;li&gt;undersample&lt;/li&gt;
&lt;li&gt;smote (synthetic minority over sampling technique), better than just oversampling&lt;/li&gt;
&lt;li&gt;adjusting thresholds&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;handling-outliers&#34;&gt;Handling Outliers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;do not throw ouliers unless it is incosistent with what you want to do&lt;/li&gt;
&lt;li&gt;Random cut forest (kinesis analytics, quicksight, sagemaker and more)&lt;/li&gt;
&lt;li&gt;use common sense&lt;/li&gt;
&lt;li&gt;box and whisker&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;binning-transforming-encoding-scaling-and-shuffling&#34;&gt;Binning, Transforming, Encoding, Scaling, and Shuffling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;binning: numeric to categorical (ordinal)&lt;/li&gt;
&lt;li&gt;transforming: log&lt;/li&gt;
&lt;li&gt;encoding: example one hot encoder&lt;/li&gt;
&lt;li&gt;scaling and normalizing&lt;/li&gt;
&lt;li&gt;shuffling&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazing-sagemaker-ground-truth-and-label-generation&#34;&gt;Amazing Sagemaker Ground Truth and Label Generation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;using humans to label the data&lt;/li&gt;
&lt;li&gt;ambiguous data is sent to humans&lt;/li&gt;
&lt;li&gt;ends reducing the cost by up to 70%&lt;/li&gt;
&lt;li&gt;mechanical turk&lt;/li&gt;
&lt;li&gt;other ways to generate training labels: rekognition (AWS service for image recognition, automatically classify images, Comprehend)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tf-idf&#34;&gt;TF-IDF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Term Frequency: how often does a word occur in a document&lt;/li&gt;
&lt;li&gt;Document Frequency: how often does a word occur in a entire set of documents&lt;/li&gt;
&lt;li&gt;Term Frequency/Document Frequence (TF&lt;em&gt;Inverse&lt;/em&gt;DF)&lt;/li&gt;
&lt;li&gt;bag of words, we do not pay attention&lt;/li&gt;
&lt;li&gt;scale is hard, spark comes in&lt;/li&gt;
&lt;li&gt;n-grams&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>AWS Certified ML - Specialty exam (MLS-C01) - Machine Learning Implementation and Operations</title>
      <link>https://ayushsubedi.github.io/posts/aws_ml_speciality_ml/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/aws_ml_speciality_ml/</guid>
      <description>&lt;h1 id=&#34;machine-learning-implementation-and-operations&#34;&gt;Machine Learning Implementation and Operations&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#section-intro-machine-learning-implementation-and-operations&#34;&gt;Section Intro: Machine Learning Implementation and Operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemakers-inner-details-and-production-variants&#34;&gt;SageMaker&amp;rsquo;s Inner Details and Production Variants&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-on-the-edge-sagemaker-neo-and-iot-greengrass&#34;&gt;SageMaker On the Edge: SageMaker Neo and IoT Greengrass&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-security-encryption-at-rest-and-in-transit&#34;&gt;SageMaker Security: Encryption at Rest and In Transit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-security-vpcs-iam-logging-and-monitoring&#34;&gt;SageMaker Security: VPC&amp;rsquo;s, IAM, Logging, and Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-resource-management-instance-types-and-spot-training&#34;&gt;SageMaker Resource Management: Instance Types and Spot Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-resource-management-elastic-inference-automatic-scaling-azs&#34;&gt;SageMaker Resource Management: Elastic Inference, Automatic Scaling, AZ&amp;rsquo;s&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-serverless-inference-and-inference-recommender&#34;&gt;SageMaker Serverless Inference and Inference Recommender&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-inference-pipelines&#34;&gt;SageMaker Inference Pipelines&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This section covers building machine learning solutions for performance, availability, scalability, resiliency, and fault tolerance, recommending and implementing the appropriate machine learning services and features for a given problem, applying basic AWS security practices to machine learning solutions and deploying and operationalizing machine learning solutions.&lt;/p&gt;
&lt;h2 id=&#34;section-intro-machine-learning-implementation-and-operations&#34;&gt;Section Intro: Machine Learning Implementation and Operations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;scaling, productionalization and security&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemakers-inner-details-and-production-variants&#34;&gt;SageMaker&amp;rsquo;s Inner Details and Production Variants&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;all models in agemaker are hosted in docker containers&lt;/li&gt;
&lt;li&gt;the docker container is registered with ECR&lt;/li&gt;
&lt;li&gt;pre built deep learning, scikit learn and spark ml&lt;/li&gt;
&lt;li&gt;pre built tensorflow, mxnet, chainer, pytorch etc. horovod or parameter server is a way to distribute tensorflow training&lt;/li&gt;
&lt;li&gt;you can also use any script or algorithm within sagemaker&lt;/li&gt;
&lt;li&gt;the containers are isolated and contain all dependencies&lt;/li&gt;
&lt;li&gt;Dockerfile structure&lt;/li&gt;
&lt;li&gt;using your own image&lt;/li&gt;
&lt;li&gt;you can test muliple models on live traffic using Production Variants (Roll out variant weights)&lt;/li&gt;
&lt;li&gt;A/B test is posible&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-on-the-edge-sagemaker-neo-and-iot-greengrass&#34;&gt;SageMaker On the Edge: SageMaker Neo and IoT Greengrass&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Train once, run anywhere&lt;/li&gt;
&lt;li&gt;supports multiple architecture&lt;/li&gt;
&lt;li&gt;optimizes code for specific devices&lt;/li&gt;
&lt;li&gt;consists of a compiler and a runtime&lt;/li&gt;
&lt;li&gt;Neo compiled models can be deployed to an https endpoint, must be the same instance type used for compilation&lt;/li&gt;
&lt;li&gt;or you can deploy to iot greengrass&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-security-encryption-at-rest-and-in-transit&#34;&gt;SageMaker Security: Encryption at Rest and In Transit&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;IAM&lt;/li&gt;
&lt;li&gt;MFA&lt;/li&gt;
&lt;li&gt;SSL/TLS&lt;/li&gt;
&lt;li&gt;Cloudtrail to log API and user activity&lt;/li&gt;
&lt;li&gt;encryption&lt;/li&gt;
&lt;li&gt;AWS key mangement service is accepted by notebooks and all sagemaker jobs&lt;/li&gt;
&lt;li&gt;s3 can be encrypted as well&lt;/li&gt;
&lt;li&gt;All traffic supports TLS/SSL&lt;/li&gt;
&lt;li&gt;inter node training communication may be optionally encrypted&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-security-vpcs-iam-logging-and-monitoring&#34;&gt;SageMaker Security: VPC&amp;rsquo;s, IAM, Logging, and Monitoring&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;training jobs run in VPC&lt;/li&gt;
&lt;li&gt;private VPC&lt;/li&gt;
&lt;li&gt;s3 vpc endpoints&lt;/li&gt;
&lt;li&gt;IAM user permissions for CreateTrainingJob, CreateModel, CreateEndpointConfig, CreateTransformJob, CreateHyperParameterTuningJob, CreateNotebookInstance, UpdateNotebookInstance&lt;/li&gt;
&lt;li&gt;Predefined policies for AmazonSageMakerReadOnly, AmazonSageMakerFullAccess, AdministratorAccess, DataScientist&lt;/li&gt;
&lt;li&gt;cloudwatch can log, monitor and alarm on invocations and latency of endpoints, health of instance nodes, ground truth (active workers)&lt;/li&gt;
&lt;li&gt;cloudtrail records actions from users, roles, and services within Sagemaker: log files are delivered to s3 for auditing purposes&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-resource-management-instance-types-and-spot-training&#34;&gt;SageMaker Resource Management: Instance Types and Spot Training&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;depends but usually gpu for training and cpu for inference&lt;/li&gt;
&lt;li&gt;EC2 spot training: checkpoints to s3 so training can resume&lt;/li&gt;
&lt;li&gt;can increate training time&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-resource-management-elastic-inference-automatic-scaling-azs&#34;&gt;SageMaker Resource Management: Elastic Inference, Automatic Scaling, AZ&amp;rsquo;s&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;accelerates deep learning inference at a fraction of a cost&lt;/li&gt;
&lt;li&gt;EI accelerator may be added alongside a CPU instance&lt;/li&gt;
&lt;li&gt;EI accelerators can also be applied to notebooks&lt;/li&gt;
&lt;li&gt;works with tensorflow, pytorch, mxnet, onnx may be used to export models to mxnet&lt;/li&gt;
&lt;li&gt;works with custom containers built with El-enabled Tensorflow, Pytorch or mxnet&lt;/li&gt;
&lt;li&gt;works with image classification and object detection built in algorithms&lt;/li&gt;
&lt;li&gt;Automatic scaling: can be used to define target metrics, min or max capacity, cooldown periods, works with cloudwatch, dynamically adjusts number of instances for a production variant, load test your configuration before using it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-serverless-inference-and-inference-recommender&#34;&gt;SageMaker Serverless Inference and Inference Recommender&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;specify your container, memory requirement, concurrency requirements&lt;/li&gt;
&lt;li&gt;underlying capacity is automatically provisioned and scaled&lt;/li&gt;
&lt;li&gt;good for infrequent or unpredictable traffic, will scale down to zero when there are no requests&lt;/li&gt;
&lt;li&gt;chared based on usage&lt;/li&gt;
&lt;li&gt;monitor via cloudwatch&lt;/li&gt;
&lt;li&gt;Inference Recommender  recommends what instance type and configuration for your model&lt;/li&gt;
&lt;li&gt;automates load testing and model tuning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-inference-pipelines&#34;&gt;SageMaker Inference Pipelines&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;linear sequence of 2-15 containers&lt;/li&gt;
&lt;li&gt;any combination of pre-trained built-in algorithms or your own algorithms in Docker&lt;/li&gt;
&lt;li&gt;combine pre-processing, predictions, post-processing&lt;/li&gt;
&lt;li&gt;Spark ML and scikit-learn&lt;/li&gt;
&lt;li&gt;chaining multiple inference containers into a pipeline of results&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>AWS Certified ML - Specialty exam (MLS-C01) - Modeling</title>
      <link>https://ayushsubedi.github.io/posts/aws_ml_speciality_modeling/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/aws_ml_speciality_modeling/</guid>
      <description>&lt;h1 id=&#34;modeling&#34;&gt;Modeling&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#activation-functions&#34;&gt;Activation Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#convolutional-neural-network&#34;&gt;Convolutional Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#recurrent-neural-networks&#34;&gt;Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modern-nlp-with-bert-and-gpt-and-transfer-learning&#34;&gt;Modern NLP with BERT and GPT, and Transfer Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deep-learning-on-ec2-and-emr&#34;&gt;Deep Learning on EC2 and EMR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tuning-neural-networks&#34;&gt;Tuning Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#regularization-techniques-for-neural-networks-dropout-early-stopping&#34;&gt;Regularization Techniques for Neural Networks (Dropout, Early Stopping)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#l1-and-l2-regularization&#34;&gt;L1 and L2 Regularization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#grief-with-gradients-the-vanishing-gradient-problem&#34;&gt;Grief with Gradients The Vanishing Gradient problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-confusion-matrix&#34;&gt;The Confusion Matrix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#precision-recall-f1-auc-and-more&#34;&gt;Precision, Recall, F1, AUC, and more&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ensemble-methods-bagging-and-boosting&#34;&gt;Ensemble Methods Bagging and Boosting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#introducing-amazon-sagemaker&#34;&gt;Introducing Amazon SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#linear-learner-in-sagemaker&#34;&gt;Linear Learner in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#xgboost-in-sagemaker&#34;&gt;XGBoost in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#seq2seq-in-sagemaker&#34;&gt;Seq2Seq in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deepar-in-sagemaker&#34;&gt;DeepAR in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#blazingtext-in-sagemaker&#34;&gt;BlazingText in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#object2vec-in-sagemaker&#34;&gt;Object2Vec in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#object-detection-in-sagemaker&#34;&gt;Object Detection in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#image-classification-in-sagemaker&#34;&gt;Image Classification in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#semantic-segmentation-in-sagemaker&#34;&gt;Semantic Segmentation in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#random-cut-forest-in-sagemaker&#34;&gt;Random Cut Forest in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#neural-topic-model-in-sagemaker&#34;&gt;Neural Topic Model in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#latent-dirichlet-allocation-lda-in-sagemaker&#34;&gt;Latent Dirichlet Allocation (LDA) in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#k-nearest-neighbors-knn-in-sagemaker&#34;&gt;K-Nearest-Neighbors (KNN) in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#k-means-clustering-in-sagemaker&#34;&gt;K-Means Clustering in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#principal-component-analysis-pca-in-sagemaker&#34;&gt;Principal Component Analysis (PCA) in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#factorization-machines-in-sagemaker&#34;&gt;Factorization Machines in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ip-insights-in-sagemaker&#34;&gt;IP Insights in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reinforcement-learning-in-sagemaker&#34;&gt;Reinforcement Learning in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#automatic-model-tuning&#34;&gt;Automatic Model Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#apache-spark-with-sagemaker&#34;&gt;Apache Spark with SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-studio-and-sagemaker-experiments&#34;&gt;SageMaker Studio, and SageMaker Experiments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-debugger&#34;&gt;SageMaker Debugger&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-autopilot-automl&#34;&gt;SageMaker Autopilot / AutoML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-model-monitor&#34;&gt;SageMaker Model Monitor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#other-recent-features-jumpstart-data-wrangler-features-store-edge-manager&#34;&gt;Other recent features (JumpStart, Data Wrangler, Features Store, Edge Manager)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-canvas&#34;&gt;SageMaker Canvas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bias-measures-in-sagemaker-canvas&#34;&gt;Bias Measures in SageMaker Canvas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-training-compiler&#34;&gt;SageMaker Training Compiler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-comprehend&#34;&gt;Amazon Comprehend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-translate&#34;&gt;Amazon Translate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-transcribe&#34;&gt;Amazon Transcribe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-polly&#34;&gt;Amazon Polly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-rekognition&#34;&gt;Amazon Rekognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-forecast&#34;&gt;Amazon Forecast&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-forecast-algorithms&#34;&gt;Amazon Forecast Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-lex&#34;&gt;Amazon Lex&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-personalize&#34;&gt;Amazon Personalize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#lightning-round-textract-deeplens-deepracher-lookout-and-monitron&#34;&gt;Lightning round! TexTract, DeepLens, DeepRacher, Lookout, and Monitron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#torchserve-aws-neuron-and-aws-panorama&#34;&gt;TorchServe, AWS Neuron, and AWS Panorama&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deep-composer-fraud-detection-codeguru-and-contact-lens&#34;&gt;Deep Composer, Fraud Detection, CodeGuru, and Contact Lens&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-kendra-and-amazon-augmented-ai-a2i&#34;&gt;Amazon Kendra and Amazon Augmented AI (A2I)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This section covers framing business problems as machine learning problems, selecting the appropriate model(s) for a given machine learning problem, training machine learning models, performing hyperparameter optimization, and evaluate machine learning models.&lt;/p&gt;
&lt;h2 id=&#34;deeplearning-frameworks&#34;&gt;Deeplearning Frameworks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tensorflow/Keras (Google)&lt;/li&gt;
&lt;li&gt;PyTorch (Meta)&lt;/li&gt;
&lt;li&gt;MXNet (Apache, and therefore AWS leans towards this)&lt;/li&gt;
&lt;li&gt;Scikit-Learn (for simple DL)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;activation-functions&#34;&gt;Activation Functions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Apply a non linear transformation&lt;/li&gt;
&lt;li&gt;Given the input, what should by output be&lt;/li&gt;
&lt;li&gt;Can be applied in between layers, or in the output layer&lt;/li&gt;
&lt;li&gt;Step Function, Sigmoid, TanH, ReLU, Leaky ReLU&lt;/li&gt;
&lt;li&gt;Binary Step Function is either on or off, cannot handle multiple classification, vertical slopes do not work with calculus&lt;/li&gt;
&lt;li&gt;Sigmoid: 0 to 1&lt;/li&gt;
&lt;li&gt;TanH: -1 to 1&lt;/li&gt;
&lt;li&gt;For Sigmoid and TanH there is a vanishing gradient problem (value changes slowly for high or low value)&lt;/li&gt;
&lt;li&gt;Sigmoid and TanH are computationally expensive&lt;/li&gt;
&lt;li&gt;ReLu: fast to compute, for inputs that are zero or negative, it is a linear function (dying relu problem)&lt;/li&gt;
&lt;li&gt;Leaky ReLU solves this&lt;/li&gt;
&lt;li&gt;Parametric ReLU, slope in the negative part is learned via backpropagation, complicated&lt;/li&gt;
&lt;li&gt;Exponential Linear Unit (ELU)&lt;/li&gt;
&lt;li&gt;Maxout: usually not worth the effort&lt;/li&gt;
&lt;li&gt;Softmax: usually the final layer of a classification model&lt;/li&gt;
&lt;li&gt;RNN&amp;rsquo;s do well with Tanh&lt;/li&gt;
&lt;li&gt;Sigmoid if more that one classification is required for the same thing&lt;/li&gt;
&lt;li&gt;For everything else, start with ReLU&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;convolutional-neural-network&#34;&gt;Convolutional Neural Network&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;CNN vs MLP (Multilayer perceptron)&lt;/li&gt;
&lt;li&gt;They have convolutional layers&lt;/li&gt;
&lt;li&gt;Some filters may detect edges, lines, shapes etc. and deeper layers can detect objects&lt;/li&gt;
&lt;li&gt;Feature location invariant, Shift Invariant, Space Invariant Artificial Neural Networks&lt;/li&gt;
&lt;li&gt;Image and video recognition, recommender systems, image classification, image segmentations,&lt;/li&gt;
&lt;li&gt;Machine translation, Sentence Classification, Sentiment analysis&lt;/li&gt;
&lt;li&gt;AlexNet, LeNet, GoogLeNet, ResNet as an example&lt;/li&gt;
&lt;li&gt;source data must be of appropriate dimensions&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;recurrent-neural-networks&#34;&gt;Recurrent Neural Networks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;deals with sequences in time (predict stock prices, understand words in a sentence, translation etc)&lt;/li&gt;
&lt;li&gt;time series data, sequence of arbitrary length&lt;/li&gt;
&lt;li&gt;captions for images, order matters&lt;/li&gt;
&lt;li&gt;structure and context is relevant&lt;/li&gt;
&lt;li&gt;machine generated music&lt;/li&gt;
&lt;li&gt;past behaviour of neuron impacts the future&lt;/li&gt;
&lt;li&gt;Sequence to Sequence: predict stock prices based on series of historic data&lt;/li&gt;
&lt;li&gt;Sequence to vector: words in a sentence to sentiment&lt;/li&gt;
&lt;li&gt;Vector to sequence: create captions from an image&lt;/li&gt;
&lt;li&gt;Encoder -&amp;gt; Decoder: Sequence -&amp;gt; vector -&amp;gt; sequence, machine translation&lt;/li&gt;
&lt;li&gt;Backpropogation through time&lt;/li&gt;
&lt;li&gt;Ends up looking like a really really deep neural network&lt;/li&gt;
&lt;li&gt;Therefore, we use truncated backpropagation through time&lt;/li&gt;
&lt;li&gt;State from earlier time steps get diluted over time, Long Short-Term memory cell LSTM cell&lt;/li&gt;
&lt;li&gt;GRU cell: Gated Recurrent Unit, Simplified LSTM which performs almost as well&lt;/li&gt;
&lt;li&gt;Traning RNN&amp;rsquo;s is hard, very sensitive to topologies, choice of hyperparameters, very resource intensive, a wrong choice can lead to a RNN that does not converge at all.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;modern-nlp-with-bert-and-gpt-and-transfer-learning&#34;&gt;Modern NLP with BERT and GPT, and Transfer Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Transformer deep learning architectures&lt;/li&gt;
&lt;li&gt;BERT, RoBERTa, T5, GPT2, GPT3, etc&lt;/li&gt;
&lt;li&gt;DistilBERT: uses knowledge distillation to reduce model size by 40%&lt;/li&gt;
&lt;li&gt;BERT: Bi-directional Encoder Representations from Transformers&lt;/li&gt;
&lt;li&gt;GPT: Generative Pre-trained Transformer&lt;/li&gt;
&lt;li&gt;Transfer Learning&lt;/li&gt;
&lt;li&gt;Model zoos: hugging face offer pre trained models to start with&lt;/li&gt;
&lt;li&gt;Hugging face DLC (deep learning containers)&lt;/li&gt;
&lt;li&gt;Transfer Learning, retrain=True vs False&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deep-learning-on-ec2emr&#34;&gt;Deep Learning on EC2/EMR&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;EMR supports Apache MXNet and GPU instance types&lt;/li&gt;
&lt;li&gt;Appropriate instance types for deep learning&lt;/li&gt;
&lt;li&gt;P3, P2, G3&lt;/li&gt;
&lt;li&gt;Deep Learning AMI&amp;rsquo;s&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tuning-neural-networks&#34;&gt;Tuning Neural Networks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Neural nets are trained by gradient descent or sth similar&lt;/li&gt;
&lt;li&gt;We start at some random point, and sample different solutions seeking to minimize some cost functions, over many epochs&lt;/li&gt;
&lt;li&gt;how far apart these samples are is the learning rate&lt;/li&gt;
&lt;li&gt;learning rate is an example of a hyperparameter&lt;/li&gt;
&lt;li&gt;batch size is also a hyperparameter, smaller batch size can work out of local minima&lt;/li&gt;
&lt;li&gt;small batch size tend to not get stuck in local minima&lt;/li&gt;
&lt;li&gt;large batch sizes can converge on the wrong solution at random&lt;/li&gt;
&lt;li&gt;large learning rates can overshoot the correct solution&lt;/li&gt;
&lt;li&gt;small learning rates increate training time&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;regularization-techniques-for-neural-networks-dropout-early-stopping&#34;&gt;Regularization Techniques for Neural Networks (Dropout, Early Stopping)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Regularization helps with avoiding overfitting&lt;/li&gt;
&lt;li&gt;build simple model, dropout, early stopping can also help with avoiding overfitting&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;l1-and-l2-regularization&#34;&gt;L1 and L2 Regularization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;L1: sum of abs value of weights: perform feature selection, computationally inefficient, sparse output&lt;/li&gt;
&lt;li&gt;L2: sum of square of weights, all features considered but weighted, computationally efficient, dence output&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;grief-with-gradients-the-vanishing-gradient-problem&#34;&gt;Grief with Gradients The Vanishing Gradient problem&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;vanishing gradient propogate to deeper layer&lt;/li&gt;
&lt;li&gt;slope is approaching zero&lt;/li&gt;
&lt;li&gt;it could be the local miminum or global where the convergence is happening&lt;/li&gt;
&lt;li&gt;long short term memory RNN can be used&lt;/li&gt;
&lt;li&gt;resnet also helps with vanishing gradient problem&lt;/li&gt;
&lt;li&gt;better activation function (relu is a good choice)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;the-confusion-matrix&#34;&gt;The Confusion Matrix&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;sometimes accuracy does not tell the whole story&lt;/li&gt;
&lt;li&gt;TP, TN, FP, FN&lt;/li&gt;
&lt;li&gt;Confusion matrix shows this&lt;/li&gt;
&lt;li&gt;multi class confusion matrix: heatmap&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;precision-recall-f1-auc-and-more&#34;&gt;Precision, Recall, F1, AUC, and more&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Precision/Correct Positives/Percent of relevant results: when you are a lot about false positives: TP/(TP+FP)&lt;/li&gt;
&lt;li&gt;Recall/Sensitivity/True Positive Rate:  TP/(TP + FN): when you care about false negatives&lt;/li&gt;
&lt;li&gt;F1 score: harmonic mean of Precision and Recall&lt;/li&gt;
&lt;li&gt;Specificity: TN/(TN+FP)&lt;/li&gt;
&lt;li&gt;RMSE, AMSE, etc.&lt;/li&gt;
&lt;li&gt;ROC curve: Receiver Operating Characteristic Curve: Plot of true positive rate (recall) vs false positive rate at various threshold setting.&lt;/li&gt;
&lt;li&gt;AUC curve: area under the ROC curve.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ensemble-methods-bagging-and-boosting&#34;&gt;Ensemble Methods Bagging and Boosting&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bagging: Generate N new training sets by random sampling with replacement, each resampled model can be trained in parallel&lt;/li&gt;
&lt;li&gt;Boosting: Observations are weighted, training is sequential&lt;/li&gt;
&lt;li&gt;XGBoost is the latest hotness, boosting generally yields better accuracy, bagging avoids overfitting, bagging is easier to parallelize&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introducing-amazon-sagemaker&#34;&gt;Introducing Amazon SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;built to handle the entire machine learning workflow&lt;/li&gt;
&lt;li&gt;deploy model, evaluate results in production, fetch, clean and prepare data, train and evaluate a model&lt;/li&gt;
&lt;li&gt;training data will be in s3, sagemakaker docker EC2 for inference&lt;/li&gt;
&lt;li&gt;spins as many hosts, spins as many endpoints&lt;/li&gt;
&lt;li&gt;Sagemaker notebook: notebook instance on EC2, has access to s3, scikit learn, spark, tensorflow, ability to deploy trained models for making predictions at scale&lt;/li&gt;
&lt;li&gt;hyperparameter tuning from notebook&lt;/li&gt;
&lt;li&gt;Sagemaker console&lt;/li&gt;
&lt;li&gt;Data comes from S3, ideal format is RecordIO/Protobuf/csv&lt;/li&gt;
&lt;li&gt;Can also ingest from Athena, EMR, Redshift, Amazon Keyspaces DB&lt;/li&gt;
&lt;li&gt;Apache Spark integrates with Sagemaker&lt;/li&gt;
&lt;li&gt;Scikit learn, numpy, pandas all work&lt;/li&gt;
&lt;li&gt;Create training job&lt;/li&gt;
&lt;li&gt;save your trained model to s3&lt;/li&gt;
&lt;li&gt;can be deployed using persistent endpoint for making individual predictions on demand&lt;/li&gt;
&lt;li&gt;or batch transform to get prediction for and entire dataset&lt;/li&gt;
&lt;li&gt;inference pipelines&lt;/li&gt;
&lt;li&gt;sagemaker neo for deploying to edge devices&lt;/li&gt;
&lt;li&gt;elastic inference for accelerating deep learning models&lt;/li&gt;
&lt;li&gt;automatic scaling of endpoints as needed&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;linear-learner-in-sagemaker&#34;&gt;Linear Learner in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Linear learer can handle both classification and regression&lt;/li&gt;
&lt;li&gt;can do classification using Linear Learner threshold&lt;/li&gt;
&lt;li&gt;as long as a line will fit&lt;/li&gt;
&lt;li&gt;RecordIO wrapped protobuf float32, or csv (first column assumed to be the label)&lt;/li&gt;
&lt;li&gt;File or pipe mode both supported&lt;/li&gt;
&lt;li&gt;pipe mode will be more efficient&lt;/li&gt;
&lt;li&gt;if s3 is taking to long to train, pipe is a simple optimization&lt;/li&gt;
&lt;li&gt;training data should be normalized&lt;/li&gt;
&lt;li&gt;input data should be shuffled&lt;/li&gt;
&lt;li&gt;uses SGD&lt;/li&gt;
&lt;li&gt;multiple models are optimized in parallel&lt;/li&gt;
&lt;li&gt;tune l1, l2 regularization&lt;/li&gt;
&lt;li&gt;balance multiclass weights: give each class equal importance in loss functions&lt;/li&gt;
&lt;li&gt;learning rate, mini batch size, l1 regualization&lt;/li&gt;
&lt;li&gt;multi gpu does not help&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;xgboost-in-sagemaker&#34;&gt;XGBoost in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;eXtreme gradient boosting&lt;/li&gt;
&lt;li&gt;boosted group of decision trees&lt;/li&gt;
&lt;li&gt;gradient descent&lt;/li&gt;
&lt;li&gt;winning a lot of kaggle competitions&lt;/li&gt;
&lt;li&gt;fast&lt;/li&gt;
&lt;li&gt;classification/regression&lt;/li&gt;
&lt;li&gt;CSV/libsvm/recordIO-protobuf/parquet&lt;/li&gt;
&lt;li&gt;models are searilized/deserialized with pickle&lt;/li&gt;
&lt;li&gt;can use as a framework withing notebooks&lt;/li&gt;
&lt;li&gt;or as a built in sagemaker algorithm&lt;/li&gt;
&lt;li&gt;subsample (prevent overfitting)&lt;/li&gt;
&lt;li&gt;ETA (step size shrinkage, prevents overfitting)&lt;/li&gt;
&lt;li&gt;Gamma (minimul loss reduction to create a partition)&lt;/li&gt;
&lt;li&gt;Alpha (L1 regularization term, larger = more conservative)&lt;/li&gt;
&lt;li&gt;Lambda (L2 regularization term, larger = more conservative)&lt;/li&gt;
&lt;li&gt;eval_metric: Optimize on AUC, example: if you care about false positives more than accuracy&lt;/li&gt;
&lt;li&gt;scale_pos_weight: adjusts balance of positive and negative weights, helpful for unbalanced classes&lt;/li&gt;
&lt;li&gt;max_depth : too high may overfit&lt;/li&gt;
&lt;li&gt;Xgboost with cpu: M5 is a good choice (optimize for memory and not compute)&lt;/li&gt;
&lt;li&gt;Xgboost with gpu: tree_method hyperparameter: gpu_hist, cheaper and faster, P3 is good choice&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;seq2seq-in-sagemaker&#34;&gt;Seq2Seq in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;sequence to sequence (example machine translation, text summarization, speech to text)&lt;/li&gt;
&lt;li&gt;implemented with RNN&amp;rsquo;s and CNN&amp;rsquo;s with attention&lt;/li&gt;
&lt;li&gt;RecordIO-Protobuf tokens must be integers&lt;/li&gt;
&lt;li&gt;start with tokenized text files&lt;/li&gt;
&lt;li&gt;convert to protobuf using sample code&lt;/li&gt;
&lt;li&gt;must provide training data, validation data and vocabulary files&lt;/li&gt;
&lt;li&gt;training machine translation can take days, pretrained models are available&lt;/li&gt;
&lt;li&gt;public training datasets are avaialable for specific translation tasks&lt;/li&gt;
&lt;li&gt;batch_size, optimizer_type, learning_rate, num_layers_encoder, num_layers_decoder, can optimize on accuracy, bleu score (compares against multiple reference translations), perplexity (cross-entropy)&lt;/li&gt;
&lt;li&gt;cannot be parallelized&lt;/li&gt;
&lt;li&gt;can only use gpu instance&lt;/li&gt;
&lt;li&gt;can use multi gpu within an instance machine&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deepar-in-sagemaker&#34;&gt;DeepAR in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Forecasting one dimensional time series data&lt;/li&gt;
&lt;li&gt;uses rnn&amp;rsquo;s&lt;/li&gt;
&lt;li&gt;allows you to train the same model over several related time series&lt;/li&gt;
&lt;li&gt;finds frequencies and seasonality&lt;/li&gt;
&lt;li&gt;json lines format, Gzip or Parquet&lt;/li&gt;
&lt;li&gt;each record must contain, start and target&lt;/li&gt;
&lt;li&gt;each record can contain dynamic features and categorical features&lt;/li&gt;
&lt;li&gt;always include entire time series for training, testing and inference&lt;/li&gt;
&lt;li&gt;use entire dataset as test set&lt;/li&gt;
&lt;li&gt;do not use very large values for prediction (&amp;gt;400)&lt;/li&gt;
&lt;li&gt;train on many time series&lt;/li&gt;
&lt;li&gt;contect length, epochs, mini batch size, learning rate, num cells&lt;/li&gt;
&lt;li&gt;can use cpu or gpu&lt;/li&gt;
&lt;li&gt;single or multi machine&lt;/li&gt;
&lt;li&gt;cpu only for inferene&lt;/li&gt;
&lt;li&gt;may need larger instances for tuning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;blazingtext-in-sagemaker&#34;&gt;BlazingText in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Text classification: predict labels for a sentence, useful in web searches, information retrieal, supervised&lt;/li&gt;
&lt;li&gt;Word2vec: creates a vector representation of workds&lt;/li&gt;
&lt;li&gt;semantically similar words are represented by vectors close to each otehr&lt;/li&gt;
&lt;li&gt;this is called a word embedding&lt;/li&gt;
&lt;li&gt;it is useful for nlp, but is not an nlp algorithm itself&lt;/li&gt;
&lt;li&gt;it only works on individual words, not sentences or documents&lt;/li&gt;
&lt;li&gt;for supervised mode, one sentence per line, first word in the sentence is the string &lt;em&gt;label&lt;/em&gt; followed by the label&lt;/li&gt;
&lt;li&gt;Also, &amp;ldquo;augmented manifest text format&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Word3vec just wants a text file with one training sentence per line&lt;/li&gt;
&lt;li&gt;There are multiple modes:&lt;/li&gt;
&lt;li&gt;Cbow (Continuous Bag of Words)&lt;/li&gt;
&lt;li&gt;Skip-gram&lt;/li&gt;
&lt;li&gt;Batch skip-gram (Distributed computation over many CPU nodes)&lt;/li&gt;
&lt;li&gt;Word2vec: mode, learning rate, window size, verctor dim, negative samples&lt;/li&gt;
&lt;li&gt;Text classification: epochs, learning rate, word ngrams, vector dim&lt;/li&gt;
&lt;li&gt;For cbow and skipgram, recommend a single ml.p3.2xlarge, any single CPU or single GPU instance will work&lt;/li&gt;
&lt;li&gt;for batch_skipgram, can use single or multiple CPU instances&lt;/li&gt;
&lt;li&gt;for text classification C5 recommended if less than 2GB training data, for larger datasets use a single GPU instance ml.p2.xlarge or ml.p3.2xlarge&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;object2vec-in-sagemaker&#34;&gt;Object2Vec in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;creates low-dimensional dense embeddings of high-dimensional objects&lt;/li&gt;
&lt;li&gt;compute nearest neighbors of objects&lt;/li&gt;
&lt;li&gt;visualize clusters&lt;/li&gt;
&lt;li&gt;genre prediction&lt;/li&gt;
&lt;li&gt;recommendations&lt;/li&gt;
&lt;li&gt;data must be tokenized into integers&lt;/li&gt;
&lt;li&gt;training data consists of pairs of tokens and or sequenses of tokens&lt;/li&gt;
&lt;li&gt;process data into json lines and shuffle it&lt;/li&gt;
&lt;li&gt;train with two input channels, two encoders, and a comparator&lt;/li&gt;
&lt;li&gt;encoder choices: average-pooled embeddings, cnn&amp;rsquo;s, bidirectional lstm&lt;/li&gt;
&lt;li&gt;comparator is followed by feed-fowrard neural network&lt;/li&gt;
&lt;li&gt;usual suspect: dropout, early stopping, epochs, learning rate, bbatch size, layers, activation function, optimizer, weight decay&lt;/li&gt;
&lt;li&gt;Enc1_network, enc2_network&lt;/li&gt;
&lt;li&gt;instance types: can only train on a single machine (cpu or gpu, multi-gpu ok)&lt;/li&gt;
&lt;li&gt;inference: use ml.p2.2xlarge&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;object-detection-in-sagemaker&#34;&gt;Object Detection in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;identify all objects in an image with bounding box&lt;/li&gt;
&lt;li&gt;detects and classifies objects with a single deep neural network&lt;/li&gt;
&lt;li&gt;classes are accompanied by confidence scores&lt;/li&gt;
&lt;li&gt;can train from scratch, or use pretrained models based on imagenet&lt;/li&gt;
&lt;li&gt;recodrio or image format&lt;/li&gt;
&lt;li&gt;with image format, supply a json file for annotation data for each image&lt;/li&gt;
&lt;li&gt;takes and image input, outputs all instances of objects in teh imagte with categories and confidence scores&lt;/li&gt;
&lt;li&gt;uses cnn with single shot multibox detector ssd algorithm, the base being vgg-16 or resnet-50&lt;/li&gt;
&lt;li&gt;transfer learning mode/incrementatl training: use pretrained model for the base network instead of random inintial weights&lt;/li&gt;
&lt;li&gt;uses flip, rescale, and jitter internally to avoid overfitting&lt;/li&gt;
&lt;li&gt;mini batch size, learning rate, optimizer&lt;/li&gt;
&lt;li&gt;gpu instances for training&lt;/li&gt;
&lt;li&gt;multi gpu multi machines&lt;/li&gt;
&lt;li&gt;for inference cpu is enough&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;image-classification-in-sagemaker&#34;&gt;Image Classification in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;assign one or more labels to an image&lt;/li&gt;
&lt;li&gt;does not tell you where objects are&lt;/li&gt;
&lt;li&gt;mxnet recordio (not protobuf)&lt;/li&gt;
&lt;li&gt;raw jpg or png&lt;/li&gt;
&lt;li&gt;.lst files to associate image index and class&lt;/li&gt;
&lt;li&gt;augmented manifest image format enables pipe mode&lt;/li&gt;
&lt;li&gt;resnet cnn under the hood&lt;/li&gt;
&lt;li&gt;full training mode&lt;/li&gt;
&lt;li&gt;transfer learning mode&lt;/li&gt;
&lt;li&gt;default image is 224 224 3&lt;/li&gt;
&lt;li&gt;bbatch size, learning rate, optimizer&lt;/li&gt;
&lt;li&gt;weight decay, beta 1, beta 2, eps, gamma&lt;/li&gt;
&lt;li&gt;gpu instance fr training&lt;/li&gt;
&lt;li&gt;cpu or gpu for inference&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;semantic-segmentation-in-sagemaker&#34;&gt;Semantic Segmentation in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;pixel level object classificaion&lt;/li&gt;
&lt;li&gt;different from image classification&lt;/li&gt;
&lt;li&gt;useful for self driving vehicles, medical imaging, robot sensing&lt;/li&gt;
&lt;li&gt;produces a semantic mask&lt;/li&gt;
&lt;li&gt;jpg or img with annotations&lt;/li&gt;
&lt;li&gt;augmented manifest image format supported for pipe mode&lt;/li&gt;
&lt;li&gt;jpg images accepted for inference&lt;/li&gt;
&lt;li&gt;mxnet gluon and gluon cv&lt;/li&gt;
&lt;li&gt;fully convolution network, pyramid scene parsing, deeplabv3&lt;/li&gt;
&lt;li&gt;resnet50, renet101, both rained on imagenet&lt;/li&gt;
&lt;li&gt;incremental training, or scratch&lt;/li&gt;
&lt;li&gt;epochs, learning rate, batch size, optimizer, algorithm, backbone&lt;/li&gt;
&lt;li&gt;only gpu for training (p2 or p3), and only on one maching&lt;/li&gt;
&lt;li&gt;cpu or gpu for inference&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;random-cut-forest-in-sagemaker&#34;&gt;Random Cut Forest in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;anomaly detection&lt;/li&gt;
&lt;li&gt;unsupervised&lt;/li&gt;
&lt;li&gt;detect unexpected spikes in time series data&lt;/li&gt;
&lt;li&gt;breaks in periodicity&lt;/li&gt;
&lt;li&gt;unclassifiable data points&lt;/li&gt;
&lt;li&gt;assigns and anamoly score to each data points&lt;/li&gt;
&lt;li&gt;recordio protobuf or csv&lt;/li&gt;
&lt;li&gt;can use file or pipe mode on either&lt;/li&gt;
&lt;li&gt;optional test channel for computation&lt;/li&gt;
&lt;li&gt;creates a forest of trees where each tree is a partition of the training data, looks at expected change in complexity of the tree as a result of adding a point into it&lt;/li&gt;
&lt;li&gt;data is sampled randomly and then trained&lt;/li&gt;
&lt;li&gt;rcf shows up in kinesis analytics as well, it can work on streaming data as well.&lt;/li&gt;
&lt;li&gt;num_trees, num_samples_per_tree (should be chosen such that 1/num_samples_per_tree approximates the ratio of anomalous to normal data)&lt;/li&gt;
&lt;li&gt;does not take advantage of gpu&lt;/li&gt;
&lt;li&gt;ml.c5.xl for inference&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;neural-topic-model-in-sagemaker&#34;&gt;Neural Topic Model in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;organize documents into topics&lt;/li&gt;
&lt;li&gt;classify or summarize documents based on topics&lt;/li&gt;
&lt;li&gt;it is not just tf/idf&lt;/li&gt;
&lt;li&gt;unsupervised: algorithm is neural variational inference&lt;/li&gt;
&lt;li&gt;four data channels, train, validation, test and auxiliary&lt;/li&gt;
&lt;li&gt;record io or csv&lt;/li&gt;
&lt;li&gt;words muyst be tokenized into integers&lt;/li&gt;
&lt;li&gt;file or pipe mode&lt;/li&gt;
&lt;li&gt;you define how many topics you want, these topics are latent representation based on top ranking words&lt;/li&gt;
&lt;li&gt;one of two modelling algorithms sagemaker offers&lt;/li&gt;
&lt;li&gt;batch size, num_topics&lt;/li&gt;
&lt;li&gt;gpu or cpu&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;latent-dirichlet-allocation-lda-in-sagemaker&#34;&gt;Latent Dirichlet Allocation (LDA) in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;latent dirichlet allocation&lt;/li&gt;
&lt;li&gt;another topic modeling algorithm but not based on deep learning&lt;/li&gt;
&lt;li&gt;unsupervised: topics are unlabeled, they are just grouping of documents with a shared subseet of words&lt;/li&gt;
&lt;li&gt;can be used for other purposes as well&lt;/li&gt;
&lt;li&gt;train channel, optional test channel&lt;/li&gt;
&lt;li&gt;protobuf or csv&lt;/li&gt;
&lt;li&gt;each document has counts for every word in vocabulary&lt;/li&gt;
&lt;li&gt;pipe mode: only supported with proto&lt;/li&gt;
&lt;li&gt;unsupervised, generates however many topics you specify&lt;/li&gt;
&lt;li&gt;per-word log likelyhood&lt;/li&gt;
&lt;li&gt;num_topics, alpha0&lt;/li&gt;
&lt;li&gt;cpu single instance, cannot parallelize&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;k-nearest-neighbors-knn-in-sagemaker&#34;&gt;K-Nearest-Neighbors (KNN) in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;simple classification or regression algorithm&lt;/li&gt;
&lt;li&gt;classification: k closest points&lt;/li&gt;
&lt;li&gt;regression: average values&lt;/li&gt;
&lt;li&gt;train channel, test channel emits accuracy or MSE&lt;/li&gt;
&lt;li&gt;protobuf or csv (first column is label)&lt;/li&gt;
&lt;li&gt;data is sampled, sagemaker includes dimensionality reduction stage, build an index for looking up neighbors, serialize the model, query the model for given K&lt;/li&gt;
&lt;li&gt;hyperparameter K, sample_size&lt;/li&gt;
&lt;li&gt;cpu or gpu&lt;/li&gt;
&lt;li&gt;cpu or gpu for inference&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;k-means-clustering-in-sagemaker&#34;&gt;K-Means Clustering in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;unsupervised clustering&lt;/li&gt;
&lt;li&gt;divide data into k groups, where members of a group are as similar as possible to each other&lt;/li&gt;
&lt;li&gt;web scale k means clustering&lt;/li&gt;
&lt;li&gt;training input: train channel, train in shardedbys3key and testing: fullyreplicated&lt;/li&gt;
&lt;li&gt;recordio or csv&lt;/li&gt;
&lt;li&gt;file or pipemode&lt;/li&gt;
&lt;li&gt;every ovservation is mapped to n-dimensional space&lt;/li&gt;
&lt;li&gt;works to optimize the center of k clusters&lt;/li&gt;
&lt;li&gt;algorithm: k means++ tries to make initial clusters far away, lloyd&amp;rsquo;s method&lt;/li&gt;
&lt;li&gt;mini_batch_size, extra_center_factor, init_method&lt;/li&gt;
&lt;li&gt;cpu or gpu, but cpu recommended&lt;/li&gt;
&lt;li&gt;only one gpu per instance used on gpu&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;principal-component-analysis-pca-in-sagemaker&#34;&gt;Principal Component Analysis (PCA) in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;dimensionality reduction&lt;/li&gt;
&lt;li&gt;unsupervised&lt;/li&gt;
&lt;li&gt;covariance matrix is created, then SVD&lt;/li&gt;
&lt;li&gt;two modesL regular: for sparse matrix, randomized: for large number of observations and features&lt;/li&gt;
&lt;li&gt;algorithm_mode and subtract_mean&lt;/li&gt;
&lt;li&gt;gpu or cpu&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;factorization-machines-in-sagemaker&#34;&gt;Factorization Machines in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;dealing with sparse data&lt;/li&gt;
&lt;li&gt;item recommendations&lt;/li&gt;
&lt;li&gt;supervised: classification or regression&lt;/li&gt;
&lt;li&gt;limited to pair-wise interactions&lt;/li&gt;
&lt;li&gt;protobuf with float32&lt;/li&gt;
&lt;li&gt;bias, factors, and linear terms&lt;/li&gt;
&lt;li&gt;cpu or gpu, cpu recommended&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ip-insights-in-sagemaker&#34;&gt;IP Insights in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;finding fishy behaviour&lt;/li&gt;
&lt;li&gt;unsupervised learning of ip address&lt;/li&gt;
&lt;li&gt;identifies suspicious behaviour from ip addresses&lt;/li&gt;
&lt;li&gt;user names, account ids, not need to pre process&lt;/li&gt;
&lt;li&gt;training channel, optional validation (computes auc score)&lt;/li&gt;
&lt;li&gt;csv only (entity, ips)&lt;/li&gt;
&lt;li&gt;neural network to learn latent vector representations of entities and ip addresses&lt;/li&gt;
&lt;li&gt;entities are hashed and embedded&lt;/li&gt;
&lt;li&gt;automatically generates negative samples during training by randomly pairing entities and ips&lt;/li&gt;
&lt;li&gt;num_entity vectors, vector_dim, epochs, learning rate, batch size&lt;/li&gt;
&lt;li&gt;cpu or gpu&lt;/li&gt;
&lt;li&gt;gpu recommended&lt;/li&gt;
&lt;li&gt;multiple gpu can be used withing an instance&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reinforcement-learning-in-sagemaker&#34;&gt;Reinforcement Learning in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;agent and environment&lt;/li&gt;
&lt;li&gt;supply chain management, hvac systems, industrial robots, dialog systems, autonomous vehicles&lt;/li&gt;
&lt;li&gt;yields fast on-line performance once the space has been explored&lt;/li&gt;
&lt;li&gt;Q learning: environment, actions, state/action part&lt;/li&gt;
&lt;li&gt;uses a deep learning framework with tensorflow and mxnet&lt;/li&gt;
&lt;li&gt;supports intel coach and ray rllib toolkits&lt;/li&gt;
&lt;li&gt;custom, open-source or commercial environments supported&lt;/li&gt;
&lt;li&gt;can distribute trining and environment rollout&lt;/li&gt;
&lt;li&gt;multi core and multi instance&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;automatic-model-tuning&#34;&gt;Automatic Model Tuning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;define the hyperparameters you care about&lt;/li&gt;
&lt;li&gt;sagemaker spins up a hyperparameter tuning job that trains as many combinations as you will allow&lt;/li&gt;
&lt;li&gt;it learns as it goes, so it does not have to try every possible combination&lt;/li&gt;
&lt;li&gt;intelligent&lt;/li&gt;
&lt;li&gt;do not optimize too many hyperparameters at once&lt;/li&gt;
&lt;li&gt;limit your ranges to as samall range&lt;/li&gt;
&lt;li&gt;use logarithmic scales&lt;/li&gt;
&lt;li&gt;do not run too many training jobs concurently&lt;/li&gt;
&lt;li&gt;make sure training jobs running on multiple instance report the correct objective metric in the end&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;apache-spark-with-sagemaker&#34;&gt;Apache Spark with SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;apache spark allows for preprocessing and also has mllib&lt;/li&gt;
&lt;li&gt;combination of sagemaker and spark is possible&lt;/li&gt;
&lt;li&gt;preprocess with spark, and instead of using mllib, you can use sagemaker estimator, you can use kmeans, pca, xgboost&lt;/li&gt;
&lt;li&gt;sagemakermodel, can be used to make inferences&lt;/li&gt;
&lt;li&gt;connect notebook to a remote emr&lt;/li&gt;
&lt;li&gt;fit, transform in sagemaker&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-studio-and-sagemaker-experiments&#34;&gt;SageMaker Studio, and SageMaker Experiments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;visual ide&lt;/li&gt;
&lt;li&gt;sagemaker notebooks&lt;/li&gt;
&lt;li&gt;sagemaker experiments&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-debugger&#34;&gt;SageMaker Debugger&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;saves internal model state at periodical intervals&lt;/li&gt;
&lt;li&gt;gradients/tensors over time is saved&lt;/li&gt;
&lt;li&gt;define rules for detecting unwanted conditions while training&lt;/li&gt;
&lt;li&gt;a debug job is run for each rule&lt;/li&gt;
&lt;li&gt;logs and fires a cloudwatch event when the rule is hit&lt;/li&gt;
&lt;li&gt;sagemaker studio debugger dashboards&lt;/li&gt;
&lt;li&gt;auto generated training reports&lt;/li&gt;
&lt;li&gt;built in rules: monitor system bottlenecks, profile model framework operations, debug model parameters&lt;/li&gt;
&lt;li&gt;supported framewords and algorithms: tensorflow, pytorch, mxnet, xgboost, sagemaker generic estimator&lt;/li&gt;
&lt;li&gt;debugger api&amp;rsquo;s available in github&lt;/li&gt;
&lt;li&gt;smdebug is the library&lt;/li&gt;
&lt;li&gt;Sagemaker debugger insights dashboard&lt;/li&gt;
&lt;li&gt;profiler report, hardware system metrics, framework metrics&lt;/li&gt;
&lt;li&gt;built in actions to receive notifications or stop training&lt;/li&gt;
&lt;li&gt;profiling system resource usage and training&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-autopilot--automl&#34;&gt;SageMaker Autopilot / AutoML&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;automates algorithm selection, data preprocessing, model tuning&lt;/li&gt;
&lt;li&gt;it does all the trial and error for you&lt;/li&gt;
&lt;li&gt;automl&lt;/li&gt;
&lt;li&gt;automatic model creation&lt;/li&gt;
&lt;li&gt;model leaderboard&lt;/li&gt;
&lt;li&gt;ranks&lt;/li&gt;
&lt;li&gt;can add in human guidance&lt;/li&gt;
&lt;li&gt;human in the loop&lt;/li&gt;
&lt;li&gt;with or without code in sagemaker studio&lt;/li&gt;
&lt;li&gt;problem types: binary/multiclass classification&lt;/li&gt;
&lt;li&gt;linear learner, xgboost, mlp&lt;/li&gt;
&lt;li&gt;data must be tabular csv&lt;/li&gt;
&lt;li&gt;autopilot explainability&lt;/li&gt;
&lt;li&gt;integrates with sagemaker clarify&lt;/li&gt;
&lt;li&gt;transparency on how models arrive at predictions&lt;/li&gt;
&lt;li&gt;feature attributions: uses shap baselines/shapley values, research from cooperative game theory, assigns each feature an importance value for a give prediction&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-model-monitor&#34;&gt;SageMaker Model Monitor&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;get alery on quality deviations on your deployed models via cloudwatch&lt;/li&gt;
&lt;li&gt;visualize data drift&lt;/li&gt;
&lt;li&gt;detect anomalies and outliers&lt;/li&gt;
&lt;li&gt;detect new features&lt;/li&gt;
&lt;li&gt;no code required&lt;/li&gt;
&lt;li&gt;data is stored in s3, monitoring jobs are scheduled via a monitoring schedule, metrics are emitted to cloudwatch, integrates with quicksight, tensorboard etc.&lt;/li&gt;
&lt;li&gt;drift in statistical properties of the features&lt;/li&gt;
&lt;li&gt;drift in model quality&lt;/li&gt;
&lt;li&gt;bias drift&lt;/li&gt;
&lt;li&gt;feature attribution drift&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;other-recent-features-jumpstart-data-wrangler-features-store-edge-manager&#34;&gt;Other recent features (JumpStart, Data Wrangler, Features Store, Edge Manager)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;jumpstart: one click models and algorithms from model zoos: 150 open source models in nlp, object detection, image classification etc&lt;/li&gt;
&lt;li&gt;data wrangler: import transform analayze and export data withing sagemaker studio&lt;/li&gt;
&lt;li&gt;feature studio: find, discover and share features in studio:online and offline modes&lt;/li&gt;
&lt;li&gt;sagemaker edge manager: software agent for edge devices, models optimized with agemaker neo, collects and samples data for monitoring, labeling and retraining&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-canvas&#34;&gt;SageMaker Canvas&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;no code machine learning for business analysts&lt;/li&gt;
&lt;li&gt;upload csv data, select a column to predict, build it and make predictions&lt;/li&gt;
&lt;li&gt;can also join datasets&lt;/li&gt;
&lt;li&gt;classification or regressions&lt;/li&gt;
&lt;li&gt;automatic data cleaning, missing values, outlier and duplicates&lt;/li&gt;
&lt;li&gt;share models and datasets with sagemaker studio&lt;/li&gt;
&lt;li&gt;import from redshift is possible&lt;/li&gt;
&lt;li&gt;time series must be enabled via IAM&lt;/li&gt;
&lt;li&gt;vpc&lt;/li&gt;
&lt;li&gt;a little expensive&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bias-measures-in-sagemaker-clarify&#34;&gt;Bias Measures in SageMaker Clarify&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;class imbalance&lt;/li&gt;
&lt;li&gt;difference in proportions of labels&lt;/li&gt;
&lt;li&gt;kullback-leibler divergence, jensen-shannon divergence&lt;/li&gt;
&lt;li&gt;lp-norm&lt;/li&gt;
&lt;li&gt;total variation distance&lt;/li&gt;
&lt;li&gt;kolmogorov-smirnov&lt;/li&gt;
&lt;li&gt;conditional demographic disparity&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-training-compiler&#34;&gt;SageMaker Training Compiler&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;integrates into AWS deep learning containers&lt;/li&gt;
&lt;li&gt;compile and optimize training jobs on gpu&lt;/li&gt;
&lt;li&gt;can accelerate training up to 50%&lt;/li&gt;
&lt;li&gt;converts models into hardware-optimized instructions&lt;/li&gt;
&lt;li&gt;tested with hugging face transformers library, or bring your own model&lt;/li&gt;
&lt;li&gt;ensure gpu instance are used in ml.p3, ml.p4&lt;/li&gt;
&lt;li&gt;pytorch models must use pytorch xla&amp;rsquo;s model save function&lt;/li&gt;
&lt;li&gt;enable dubug flask in compiler_config parameter to enable debugging&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-comprehend&#34;&gt;Amazon Comprehend&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;nlp and text analytics&lt;/li&gt;
&lt;li&gt;input social media, emails, web pages, documents, transcripts, medical records (comprehend medical)&lt;/li&gt;
&lt;li&gt;extract key phrases, entities, sentiment, language, syntax, topics, and document classifications&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-translate&#34;&gt;Amazon Translate&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;translates text&lt;/li&gt;
&lt;li&gt;uses deep learning&lt;/li&gt;
&lt;li&gt;supports custom terminology for proper names&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-transcribe&#34;&gt;Amazon Transcribe&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;speech to text&lt;/li&gt;
&lt;li&gt;speaker identification&lt;/li&gt;
&lt;li&gt;channel identification&lt;/li&gt;
&lt;li&gt;language identification&lt;/li&gt;
&lt;li&gt;custom vocabularies&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-polly&#34;&gt;Amazon Polly&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;text to speech&lt;/li&gt;
&lt;li&gt;polly is parrot&lt;/li&gt;
&lt;li&gt;lexicons&lt;/li&gt;
&lt;li&gt;ssml (speech synthesis markup language)&lt;/li&gt;
&lt;li&gt;speech marks&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-rekognition&#34;&gt;Amazon Rekognition&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;compute vision&lt;/li&gt;
&lt;li&gt;object and scene detection&lt;/li&gt;
&lt;li&gt;image moderation, facial analysis, celebrity recognition, face comparison, text in image, video analysis&lt;/li&gt;
&lt;li&gt;kinesis video stream h.264 encoded, 5-30 fps&lt;/li&gt;
&lt;li&gt;can use lambda to trigger image analysis upon upload&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-forecast&#34;&gt;Amazon Forecast&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;fully managed service to deliver highly accurate forecasts with ml&lt;/li&gt;
&lt;li&gt;automl chooses the best model for your time series data&lt;/li&gt;
&lt;li&gt;arima, deepar, ets, npts, prophet&lt;/li&gt;
&lt;li&gt;works with any time series&lt;/li&gt;
&lt;li&gt;inventory planning, financial planning, resource planning, based on dataset groups, predictors and forecasts&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-forecast-algorithms&#34;&gt;Amazon Forecast Algorithms&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;cnnqr: convolutional neural network quantile regression, best for large datasets with hundreds of time series, accepts related historical time series data and metadata&lt;/li&gt;
&lt;li&gt;deepar+ : recurrent neural network, best for large datasets, accepts related forward-looking time series and metadata&lt;/li&gt;
&lt;li&gt;prophet: additive model with non linear trends and seasonality&lt;/li&gt;
&lt;li&gt;npts: non parametric time series: good for sparse data&lt;/li&gt;
&lt;li&gt;arima: simple datasets&lt;/li&gt;
&lt;li&gt;ets: exponential smoothing&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-lex&#34;&gt;Amazon Lex&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;chatbot engine&lt;/li&gt;
&lt;li&gt;lambda to fulfill intent from text&lt;/li&gt;
&lt;li&gt;can deploy to aws mobile sdk, facebook messenger, slack, twilio&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-personalize&#34;&gt;Amazon Personalize&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;fully managed recommendation engine&lt;/li&gt;
&lt;li&gt;api access: feed in data, provide schema in avro, javascript or sdk, get recommendations, get personalized ranking&lt;/li&gt;
&lt;li&gt;real time or batch recommendations&lt;/li&gt;
&lt;li&gt;recommendations for new users and new items&lt;/li&gt;
&lt;li&gt;contextual recommendations&lt;/li&gt;
&lt;li&gt;similar items&lt;/li&gt;
&lt;li&gt;datasets, recipes, solutions, compaignhs&lt;/li&gt;
&lt;li&gt;hidden_dimensions, bptt, recency_mask, min/max_user_history_length_percentile, exploration_weight, exploration_item_age_cut_off&lt;/li&gt;
&lt;li&gt;necessary to maintain recency&lt;/li&gt;
&lt;li&gt;bucket policy&lt;/li&gt;
&lt;li&gt;data ingestion: per gb, training per training hour, inference per tps-hour, batch recommendations: per user or per item&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lightning-round-textract-deeplens-deepracher-lookout-and-monitron&#34;&gt;Lightning round! TexTract, DeepLens, DeepRacher, Lookout, and Monitron&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;TexTract: ocr with forms, fields, tables support&lt;/li&gt;
&lt;li&gt;DeepLens: deep learning enabled video camera, integrated with rekognition, sagemaker, polly, tensorflow, mxnet, caffe&lt;/li&gt;
&lt;li&gt;DeepRacer: reinforcement learning powered 1/18 scale race car&lt;/li&gt;
&lt;li&gt;Lookout: equipment, metrics and vision: detect defects in silicon wafers, circuit boards etc.&lt;/li&gt;
&lt;li&gt;Monitron: end to end system for monitoring equipment and predictive maintenance&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;torchserve-aws-neuron-and-aws-panorama&#34;&gt;TorchServe, AWS Neuron, and AWS Panorama&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;TorchServe: model serving framework for pytorch&lt;/li&gt;
&lt;li&gt;AWS Neuron: ml inferentia chip, Ec2 inf1 instance type&lt;/li&gt;
&lt;li&gt;Panorama: computer vision at the edge&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deep-composer-fraud-detection-codeguru-and-contact-lens&#34;&gt;Deep Composer, Fraud Detection, CodeGuru, and Contact Lens&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;DeepComposer: ai powered keyboard&lt;/li&gt;
&lt;li&gt;fraud detection: upload your own data&lt;/li&gt;
&lt;li&gt;Codeguru: automated code reviews, finds lines of code that hurt performance&lt;/li&gt;
&lt;li&gt;contact lens: for customer support call centers, ingests audio, sentiment analysis&lt;/li&gt;
&lt;li&gt;finds utterances that correlate with successful calls&lt;/li&gt;
&lt;li&gt;categorize calls automatically&lt;/li&gt;
&lt;li&gt;measure talk speed and interruptions&lt;/li&gt;
&lt;li&gt;theme detection: discovers emerging issues&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-kendra-and-amazon-augmented-ai-a2i&#34;&gt;Amazon Kendra and Amazon Augmented AI (A2I)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Enterprise search with natural languate&lt;/li&gt;
&lt;li&gt;combines data from sharepoint, intranet, sharing services, jdbc, s4 into one searchable repo&lt;/li&gt;
&lt;li&gt;ml powered, uses thumbs up/down&lt;/li&gt;
&lt;li&gt;relevance tuning, boost strength of document freshness&lt;/li&gt;
&lt;li&gt;Kendra: Alexa&amp;rsquo;s sister&lt;/li&gt;
&lt;li&gt;AugmentedAI: human review of ml predictions, mechanical turk workforce or vendors&lt;/li&gt;
&lt;li&gt;integrated into textract and rekognition&lt;/li&gt;
&lt;li&gt;integrates with sagemaker&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Term Frequecy Inverse Document Frequency (TFIDF)</title>
      <link>https://ayushsubedi.github.io/posts/tfidf/</link>
      <pubDate>Sun, 25 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/tfidf/</guid>
      <description>&lt;h1 id=&#34;wikipedia-search-using-tfidf&#34;&gt;Wikipedia search using TFIDF&lt;/h1&gt;
&lt;h2 id=&#34;term-frequecy-inverse-document-frequency&#34;&gt;Term Frequecy Inverse Document Frequency&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://ayushsubedi.github.io/img/tfidf.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;please, call, the, number, below, do, not, us, please call, call the, the number, number below, please do, do not, not call, call us&lt;/p&gt;
&lt;p&gt;dimension = [2, 16]&lt;/p&gt;
&lt;h1 id=&#34;example-of-unigram-tfidf&#34;&gt;Example of unigram TFIDF&lt;/h1&gt;
&lt;h2 id=&#34;imports&#34;&gt;Imports&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pyspark
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyspark.sql &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; SparkSession
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyspark.sql.types &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyspark.sql.functions &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; udf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyspark.ml.feature &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; HashingTF, IDF, Tokenizer
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;sparksession&#34;&gt;SparkSession&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SparkSession&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;builder \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;appName(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tfidf&amp;#39;&lt;/span&gt;)\
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;config(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;spark.jars&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;../jars/snowflake-jdbc-3.13.6.jar, ../jars/spark-snowflake_2.12-2.9.0-spark_3.1.jar&amp;#39;&lt;/span&gt;) \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;getOrCreate()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sparkContext&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;setLogLevel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;WARN&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;22/12/27 13:35:58 WARN Utils: Your hostname, SPMBP136.local resolves to a loopback address: 127.0.0.1; using 192.168.0.101 instead (on interface en6)
22/12/27 13:35:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
22/12/27 13:35:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable


Setting default log level to &amp;quot;WARN&amp;quot;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;file_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;../datasets/wiki.csv&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wiki &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;csv&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;option(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;header&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(file_path)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wiki&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;+---+--------------------+-------------------+--------------------+
| ID|               Title|               Time|            Document|
+---+--------------------+-------------------+--------------------+
| 12|           Anarchism|2008-12-30 06:23:05|&amp;quot;Anarchism (somet...|
| 25|              Autism|2008-12-24 20:41:05|&amp;quot;Autism is a brai...|
| 39|              Albedo|2008-12-29 18:19:09|&amp;quot;The albedo of an...|
|290|                   A|2008-12-27 04:33:16|&amp;quot;The letter A is ...|
|303|             Alabama|2008-12-29 08:15:47|&amp;quot;Alabama (formall...|
|305|            Achilles|2008-12-30 06:18:01|&amp;quot;thumb\n\nIn Gree...|
|307|     Abraham Lincoln|2008-12-28 20:18:23|&amp;quot;Abraham Lincoln ...|
|308|           Aristotle|2008-12-29 23:54:48|&amp;quot;Aristotle (Greek...|
|309|An American in Paris|2008-09-27 19:29:28|&amp;quot;An American in P...|
|324|       Academy Award|2008-12-28 17:50:43|&amp;quot;The Academy Awar...|
|330|             Actrius|2008-05-23 15:24:32|Actrius (Actresse...|
|332|     Animalia (book)|2008-12-18 11:12:34|thumbAnimalia (IS...|
|334|International Ato...|2008-11-21 22:40:20|International Ato...|
|336|            Altruism|2008-12-27 03:57:17|&amp;quot;Altruism is self...|
|339|            Ayn Rand|2008-12-30 08:03:06|&amp;quot;Ayn Rand (,  – M...|
|340|        Alain Connes|2008-09-03 13:41:39|Alain Connes (bor...|
|344|          Allan Dwan|2008-11-14 05:28:58|Allan Dwan (April...|
|358|             Algeria|2008-12-29 02:54:36|&amp;quot;Algeria (, al-Ja...|
|359|List of character...|2008-12-23 20:20:21|&amp;quot;This is a list o...|
|569|        Anthropology|2008-12-28 23:04:30|&amp;quot;Anthropology (, ...|
+---+--------------------+-------------------+--------------------+
only showing top 20 rows
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wiki&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filter(wiki&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Document&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;isNull())&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;count()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;1
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wiki &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wiki&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filter(&lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt;wiki&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Document&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;isNull())
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wiki&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;+---+--------------------+-------------------+--------------------+
| ID|               Title|               Time|            Document|
+---+--------------------+-------------------+--------------------+
| 12|           Anarchism|2008-12-30 06:23:05|&amp;quot;Anarchism (somet...|
| 25|              Autism|2008-12-24 20:41:05|&amp;quot;Autism is a brai...|
| 39|              Albedo|2008-12-29 18:19:09|&amp;quot;The albedo of an...|
|290|                   A|2008-12-27 04:33:16|&amp;quot;The letter A is ...|
|303|             Alabama|2008-12-29 08:15:47|&amp;quot;Alabama (formall...|
|305|            Achilles|2008-12-30 06:18:01|&amp;quot;thumb\n\nIn Gree...|
|307|     Abraham Lincoln|2008-12-28 20:18:23|&amp;quot;Abraham Lincoln ...|
|308|           Aristotle|2008-12-29 23:54:48|&amp;quot;Aristotle (Greek...|
|309|An American in Paris|2008-09-27 19:29:28|&amp;quot;An American in P...|
|324|       Academy Award|2008-12-28 17:50:43|&amp;quot;The Academy Awar...|
|330|             Actrius|2008-05-23 15:24:32|Actrius (Actresse...|
|332|     Animalia (book)|2008-12-18 11:12:34|thumbAnimalia (IS...|
|334|International Ato...|2008-11-21 22:40:20|International Ato...|
|336|            Altruism|2008-12-27 03:57:17|&amp;quot;Altruism is self...|
|339|            Ayn Rand|2008-12-30 08:03:06|&amp;quot;Ayn Rand (,  – M...|
|340|        Alain Connes|2008-09-03 13:41:39|Alain Connes (bor...|
|344|          Allan Dwan|2008-11-14 05:28:58|Allan Dwan (April...|
|358|             Algeria|2008-12-29 02:54:36|&amp;quot;Algeria (, al-Ja...|
|359|List of character...|2008-12-23 20:20:21|&amp;quot;This is a list o...|
|569|        Anthropology|2008-12-28 23:04:30|&amp;quot;Anthropology (, ...|
+---+--------------------+-------------------+--------------------+
only showing top 20 rows
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Tokenizer(inputCol&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Document&amp;#34;&lt;/span&gt;, outputCol&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;words&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wordsData &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(wiki)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wordsData&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;+---+--------------------+-------------------+--------------------+--------------------+
| ID|               Title|               Time|            Document|               words|
+---+--------------------+-------------------+--------------------+--------------------+
| 12|           Anarchism|2008-12-30 06:23:05|&amp;quot;Anarchism (somet...|[&amp;quot;anarchism, (som...|
| 25|              Autism|2008-12-24 20:41:05|&amp;quot;Autism is a brai...|[&amp;quot;autism, is, a, ...|
| 39|              Albedo|2008-12-29 18:19:09|&amp;quot;The albedo of an...|[&amp;quot;the, albedo, of...|
|290|                   A|2008-12-27 04:33:16|&amp;quot;The letter A is ...|[&amp;quot;the, letter, a,...|
|303|             Alabama|2008-12-29 08:15:47|&amp;quot;Alabama (formall...|[&amp;quot;alabama, (forma...|
|305|            Achilles|2008-12-30 06:18:01|&amp;quot;thumb\n\nIn Gree...|[&amp;quot;thumb\n\nin, gr...|
|307|     Abraham Lincoln|2008-12-28 20:18:23|&amp;quot;Abraham Lincoln ...|[&amp;quot;abraham, lincol...|
|308|           Aristotle|2008-12-29 23:54:48|&amp;quot;Aristotle (Greek...|[&amp;quot;aristotle, (gre...|
|309|An American in Paris|2008-09-27 19:29:28|&amp;quot;An American in P...|[&amp;quot;an, american, i...|
|324|       Academy Award|2008-12-28 17:50:43|&amp;quot;The Academy Awar...|[&amp;quot;the, academy, a...|
|330|             Actrius|2008-05-23 15:24:32|Actrius (Actresse...|[actrius, (actres...|
|332|     Animalia (book)|2008-12-18 11:12:34|thumbAnimalia (IS...|[thumbanimalia, (...|
|334|International Ato...|2008-11-21 22:40:20|International Ato...|[international, a...|
|336|            Altruism|2008-12-27 03:57:17|&amp;quot;Altruism is self...|[&amp;quot;altruism, is, s...|
|339|            Ayn Rand|2008-12-30 08:03:06|&amp;quot;Ayn Rand (,  – M...|[&amp;quot;ayn, rand, (,, ...|
|340|        Alain Connes|2008-09-03 13:41:39|Alain Connes (bor...|[alain, connes, (...|
|344|          Allan Dwan|2008-11-14 05:28:58|Allan Dwan (April...|[allan, dwan, (ap...|
|358|             Algeria|2008-12-29 02:54:36|&amp;quot;Algeria (, al-Ja...|[&amp;quot;algeria, (,, al...|
|359|List of character...|2008-12-23 20:20:21|&amp;quot;This is a list o...|[&amp;quot;this, is, a, li...|
|569|        Anthropology|2008-12-28 23:04:30|&amp;quot;Anthropology (, ...|[&amp;quot;anthropology, (...|
+---+--------------------+-------------------+--------------------+--------------------+
only showing top 20 rows
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hashingTF &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; HashingTF(inputCol&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;words&amp;#34;&lt;/span&gt;, outputCol&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rawFeatures&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;featuredData &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; hashingTF&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(wordsData)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;featuredData&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;+---+--------------------+-------------------+--------------------+--------------------+--------------------+
| ID|               Title|               Time|            Document|               words|         rawFeatures|
+---+--------------------+-------------------+--------------------+--------------------+--------------------+
| 12|           Anarchism|2008-12-30 06:23:05|&amp;quot;Anarchism (somet...|[&amp;quot;anarchism, (som...|(262144,[15157,27...|
| 25|              Autism|2008-12-24 20:41:05|&amp;quot;Autism is a brai...|[&amp;quot;autism, is, a, ...|(262144,[15,1546,...|
| 39|              Albedo|2008-12-29 18:19:09|&amp;quot;The albedo of an...|[&amp;quot;the, albedo, of...|(262144,[7853,240...|
|290|                   A|2008-12-27 04:33:16|&amp;quot;The letter A is ...|[&amp;quot;the, letter, a,...|(262144,[6037,942...|
|303|             Alabama|2008-12-29 08:15:47|&amp;quot;Alabama (formall...|[&amp;quot;alabama, (forma...|(262144,[1797,256...|
|305|            Achilles|2008-12-30 06:18:01|&amp;quot;thumb\n\nIn Gree...|[&amp;quot;thumb\n\nin, gr...|(262144,[10758,16...|
|307|     Abraham Lincoln|2008-12-28 20:18:23|&amp;quot;Abraham Lincoln ...|[&amp;quot;abraham, lincol...|(262144,[2564,460...|
|308|           Aristotle|2008-12-29 23:54:48|&amp;quot;Aristotle (Greek...|[&amp;quot;aristotle, (gre...|(262144,[2767,356...|
|309|An American in Paris|2008-09-27 19:29:28|&amp;quot;An American in P...|[&amp;quot;an, american, i...|(262144,[2366,670...|
|324|       Academy Award|2008-12-28 17:50:43|&amp;quot;The Academy Awar...|[&amp;quot;the, academy, a...|(262144,[2931,328...|
|330|             Actrius|2008-05-23 15:24:32|Actrius (Actresse...|[actrius, (actres...|(262144,[6558,674...|
|332|     Animalia (book)|2008-12-18 11:12:34|thumbAnimalia (IS...|[thumbanimalia, (...|(262144,[2284,609...|
|334|International Ato...|2008-11-21 22:40:20|International Ato...|[international, a...|(262144,[847,925,...|
|336|            Altruism|2008-12-27 03:57:17|&amp;quot;Altruism is self...|[&amp;quot;altruism, is, s...|(262144,[5675,680...|
|339|            Ayn Rand|2008-12-30 08:03:06|&amp;quot;Ayn Rand (,  – M...|[&amp;quot;ayn, rand, (,, ...|(262144,[528,1091...|
|340|        Alain Connes|2008-09-03 13:41:39|Alain Connes (bor...|[alain, connes, (...|(262144,[154,1595...|
|344|          Allan Dwan|2008-11-14 05:28:58|Allan Dwan (April...|[allan, dwan, (ap...|(262144,[1578,181...|
|358|             Algeria|2008-12-29 02:54:36|&amp;quot;Algeria (, al-Ja...|[&amp;quot;algeria, (,, al...|(262144,[3852,492...|
|359|List of character...|2008-12-23 20:20:21|&amp;quot;This is a list o...|[&amp;quot;this, is, a, li...|(262144,[14376,19...|
|569|        Anthropology|2008-12-28 23:04:30|&amp;quot;Anthropology (, ...|[&amp;quot;anthropology, (...|(262144,[57138,10...|
+---+--------------------+-------------------+--------------------+--------------------+--------------------+
only showing top 20 rows
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;idf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; IDF(inputCol&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rawFeatures&amp;#34;&lt;/span&gt;, outputCol&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;features&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;idfModel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; idf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(featuredData)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rescaledData &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; idfModel&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(featuredData)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rescaledData&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;22/12/27 13:36:11 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB
+---+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+
| ID|               Title|               Time|            Document|               words|         rawFeatures|            features|
+---+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+
| 12|           Anarchism|2008-12-30 06:23:05|&amp;quot;Anarchism (somet...|[&amp;quot;anarchism, (som...|(262144,[15157,27...|(262144,[15157,27...|
| 25|              Autism|2008-12-24 20:41:05|&amp;quot;Autism is a brai...|[&amp;quot;autism, is, a, ...|(262144,[15,1546,...|(262144,[15,1546,...|
| 39|              Albedo|2008-12-29 18:19:09|&amp;quot;The albedo of an...|[&amp;quot;the, albedo, of...|(262144,[7853,240...|(262144,[7853,240...|
|290|                   A|2008-12-27 04:33:16|&amp;quot;The letter A is ...|[&amp;quot;the, letter, a,...|(262144,[6037,942...|(262144,[6037,942...|
|303|             Alabama|2008-12-29 08:15:47|&amp;quot;Alabama (formall...|[&amp;quot;alabama, (forma...|(262144,[1797,256...|(262144,[1797,256...|
|305|            Achilles|2008-12-30 06:18:01|&amp;quot;thumb\n\nIn Gree...|[&amp;quot;thumb\n\nin, gr...|(262144,[10758,16...|(262144,[10758,16...|
|307|     Abraham Lincoln|2008-12-28 20:18:23|&amp;quot;Abraham Lincoln ...|[&amp;quot;abraham, lincol...|(262144,[2564,460...|(262144,[2564,460...|
|308|           Aristotle|2008-12-29 23:54:48|&amp;quot;Aristotle (Greek...|[&amp;quot;aristotle, (gre...|(262144,[2767,356...|(262144,[2767,356...|
|309|An American in Paris|2008-09-27 19:29:28|&amp;quot;An American in P...|[&amp;quot;an, american, i...|(262144,[2366,670...|(262144,[2366,670...|
|324|       Academy Award|2008-12-28 17:50:43|&amp;quot;The Academy Awar...|[&amp;quot;the, academy, a...|(262144,[2931,328...|(262144,[2931,328...|
|330|             Actrius|2008-05-23 15:24:32|Actrius (Actresse...|[actrius, (actres...|(262144,[6558,674...|(262144,[6558,674...|
|332|     Animalia (book)|2008-12-18 11:12:34|thumbAnimalia (IS...|[thumbanimalia, (...|(262144,[2284,609...|(262144,[2284,609...|
|334|International Ato...|2008-11-21 22:40:20|International Ato...|[international, a...|(262144,[847,925,...|(262144,[847,925,...|
|336|            Altruism|2008-12-27 03:57:17|&amp;quot;Altruism is self...|[&amp;quot;altruism, is, s...|(262144,[5675,680...|(262144,[5675,680...|
|339|            Ayn Rand|2008-12-30 08:03:06|&amp;quot;Ayn Rand (,  – M...|[&amp;quot;ayn, rand, (,, ...|(262144,[528,1091...|(262144,[528,1091...|
|340|        Alain Connes|2008-09-03 13:41:39|Alain Connes (bor...|[alain, connes, (...|(262144,[154,1595...|(262144,[154,1595...|
|344|          Allan Dwan|2008-11-14 05:28:58|Allan Dwan (April...|[allan, dwan, (ap...|(262144,[1578,181...|(262144,[1578,181...|
|358|             Algeria|2008-12-29 02:54:36|&amp;quot;Algeria (, al-Ja...|[&amp;quot;algeria, (,, al...|(262144,[3852,492...|(262144,[3852,492...|
|359|List of character...|2008-12-23 20:20:21|&amp;quot;This is a list o...|[&amp;quot;this, is, a, li...|(262144,[14376,19...|(262144,[14376,19...|
|569|        Anthropology|2008-12-28 23:04:30|&amp;quot;Anthropology (, ...|[&amp;quot;anthropology, (...|(262144,[57138,10...|(262144,[57138,10...|
+---+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+
only showing top 20 rows
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;search&#34;&gt;Search&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;search_article&lt;/span&gt;(keyword):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# get the hash val from keyword&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    schema &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; StructType([StructField(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;words&amp;#34;&lt;/span&gt;, ArrayType(StringType()))])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    temp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;createDataFrame(([[[keyword]]]), schema)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;toDF(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;words&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    temp_unhashed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; hashingTF&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(temp)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;select(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rawFeatures&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    val &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(temp_unhashed[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rawFeatures&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;indices[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;#&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    termExtractor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; udf(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x:float(x[val]), FloatType())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    final &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rescaledData&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;withColumn(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;score&amp;#39;&lt;/span&gt;, termExtractor(rescaledData&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;features))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    final &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; final&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filter(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;score&amp;gt;0&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;orderBy(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;score&amp;#34;&lt;/span&gt;, ascending&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; final&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;select(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ID&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Title&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;score&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;search_article(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mystery&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;22/12/27 13:36:12 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB


[Stage 11:===================&amp;gt;                                      (1 + 2) / 3]

+----+--------------------+--------+
|  ID|               Title|   score|
+----+--------------------+--------+
| 984|     Agatha Christie|5.521461|
| 986|          The Plague|5.521461|
|1307|The Alan Parsons ...|5.521461|
+----+--------------------+--------+
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;search_article(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;comic&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;22/12/27 13:36:14 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB
+----+--------------------+----------+
|  ID|               Title|     score|
+----+--------------------+----------+
| 931|The Amazing Spide...|14.4849415|
|2101|             Asterix|  9.656628|
|1549|             Agathon|  9.656628|
|2023|           Aeschylus|  9.656628|
|1028|        Aristophanes|  9.656628|
|1614|              Alexis|  4.828314|
|1784|  Athenian democracy|  4.828314|
+----+--------------------+----------+
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;search_article(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;revolution&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;22/12/27 13:36:15 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB
+----+--------------------+---------+
|  ID|               Title|    score|
+----+--------------------+---------+
|1973| American Revolution|12.052151|
|2273|            AFC Ajax|4.0173836|
| 339|            Ayn Rand|4.0173836|
| 572|Agricultural science|4.0173836|
| 771|American Revoluti...|4.0173836|
| 915|       Andrey Markov|4.0173836|
| 930|       Alvin Toffler|4.0173836|
|1030|     Austrian School|4.0173836|
|1057|      Anatole France|4.0173836|
|1192| Artistic revolution|4.0173836|
|1316|      Annales School|4.0173836|
|1676|Alfonso XII of Spain|4.0173836|
|1363|  André-Marie Ampère|4.0173836|
|2075|  Aircraft hijacking|4.0173836|
|1784|  Athenian democracy|4.0173836|
|1844|          Archimedes|4.0173836|
|2070|Act of Settlement...|4.0173836|
+----+--------------------+---------+
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;search_article(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;football&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;22/12/27 13:36:16 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB
+----+--------------------+---------+
|  ID|               Title|    score|
+----+--------------------+---------+
|2273|            AFC Ajax|54.596165|
|2357|American Football...|46.196754|
|2174|        Arsenal F.C.|29.397936|
|2358|           A.S. Roma| 25.19823|
|2102|   Arizona Cardinals|20.998526|
|2103|     Atlanta Falcons| 16.79882|
| 615|American Football...| 16.79882|
| 925|Alumni Athletic Club|12.599115|
|2289|  AZ (football club)| 4.199705|
|2310|       Arthur Miller| 4.199705|
|1797|                Acre| 4.199705|
|2363|Alessandro Scarlatti| 4.199705|
|2382|               Aalen| 4.199705|
|1016|       Achill Island| 4.199705|
+----+--------------------+---------+
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;search_article(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;emirates&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;22/12/27 13:36:17 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB
+----+------------+--------+
|  ID|       Title|   score|
+----+------------+--------+
|2174|Arsenal F.C.|6.214608|
+----+------------+--------+
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;search_article(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;the&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;22/12/27 13:36:18 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB
+----+--------------------+---------+
|  ID|               Title|    score|
+----+--------------------+---------+
|1854| Geography of Africa|56.093544|
|2273|            AFC Ajax|43.326492|
|2023|           Aeschylus|41.968296|
|1216|              Athens|30.287798|
| 717|             Alberta|26.213207|
|2358|           A.S. Roma|23.904272|
| 841|      Attila the Hun|23.360992|
|1285|Geography of Alabama|23.089354|
|2338|Rise and Fall of ...|21.323696|
|1440|       Abydos, Egypt|19.150581|
| 904|           Aluminium| 18.87894|
|1905|              Ambush|18.199842|
|1962|  Apparent magnitude|17.928204|
|1557|Agrippina the You...|17.792383|
|1613|  Alexios I Komnenos|17.792383|
|1234|     Acoustic theory|17.520744|
|2064|      Antonio Canova|15.619268|
|1686| Alfonso V of Aragon| 15.07599|
|1451|APL (programming ...| 15.07599|
|2274|Arthur Stanley Ed...| 14.80435|
+----+--------------------+---------+
only showing top 20 rows
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Flight delay prediction and exploration in the United States</title>
      <link>https://ayushsubedi.github.io/posts/airlines_delay/</link>
      <pubDate>Thu, 15 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/airlines_delay/</guid>
      <description>&lt;h1 id=&#34;flight-delay-prediction-and-exploration-in-the-us&#34;&gt;Flight delay prediction and exploration in the US&lt;/h1&gt;
&lt;h3 id=&#34;as-a-part-of-georgia-tech-omsa-cse-6242-data-and-visual-analytics&#34;&gt;As a part of Georgia Tech OMSA, CSE 6242: Data and Visual Analytics&lt;/h3&gt;
&lt;p&gt;Poster Presentation&lt;/p&gt;
&lt;iframe width=&#34;100%&#34; height=&#34;420&#34; src=&#34;https://www.youtube.com/embed/ChbIK66ka1A&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Poster&lt;/p&gt;
&lt;iframe width=&#34;100%&#34; height =&#34;1024&#34; src=&#34;https://ayushsubedi.github.io/pdfs/Poster.pdf#toolbar=0&#34;&gt;&lt;/iframe&gt;
&lt;hr/&gt;
&lt;p&gt;Final Report&lt;/p&gt;
&lt;iframe width=&#34;100%&#34; height =&#34;1024&#34; src=&#34;https://ayushsubedi.github.io/pdfs/cse6242_airlines.pdf#toolbar=0&#34;&gt;&lt;/iframe&gt;
</description>
    </item>
    
  </channel>
</rss>