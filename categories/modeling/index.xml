<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Modeling on Ayush Subedi</title>
    <link>https://ayushsubedi.github.io/categories/modeling/</link>
    <description>Recent content in Modeling on Ayush Subedi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 01 Jan 2023 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://ayushsubedi.github.io/categories/modeling/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>AWS Certified ML - Specialty exam (MLS-C01) - 3a. Modeling Pre-requisite</title>
      <link>https://ayushsubedi.github.io/posts/aws_ml_speciality_modeling_prereq/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/aws_ml_speciality_modeling_prereq/</guid>
      <description>&lt;h1 id=&#34;modeling-pre-reqs&#34;&gt;Modeling Pre-reqs&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#basic-machine-learning&#34;&gt;Basic Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#confusion-matrix&#34;&gt;Confusion Matrix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data&#34;&gt;Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#design-of-experiments&#34;&gt;Design of Experiments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#game-theory&#34;&gt;Game Theory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-quality&#34;&gt;Model Quality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#non-parametric-tests&#34;&gt;Non-Parametric Tests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#optimization&#34;&gt;Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#probability-based-models&#34;&gt;Probability based models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#regression&#34;&gt;Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#variable-selection&#34;&gt;Variable Selection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#misc&#34;&gt;Misc&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;basic-machine-learning&#34;&gt;Basic Machine Learning&lt;/h2&gt;
&lt;h3 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In the context of machine learning, an algorithm is a set of instructions that a computer follows in order to learn from data.&lt;/li&gt;
&lt;li&gt;Machine learning algorithms take input data and use statistical analysis to predict an output value within an acceptable range.&lt;/li&gt;
&lt;li&gt;The goal of a machine learning algorithm is to improve its prediction accuracy over time by adjusting the parameters of the model based on the input data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;change-detection&#34;&gt;Change detection&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Change detection is a process in which a system is able to identify changes in a given environment over time.&lt;/li&gt;
&lt;li&gt;In the context of machine learning, change detection involves using algorithms to analyze data from a given environment in order to identify any changes that have occurred.&lt;/li&gt;
&lt;li&gt;This can be useful in a variety of different applications, including monitoring changes in financial markets, detecting changes in customer behavior, or identifying changes in the physical environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;classification&#34;&gt;Classification&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Classification is a supervised learning problem in which the model is trained to predict a discrete label or class for a given input data.&lt;/li&gt;
&lt;li&gt;The goal is to predict the class or category that a new instance belongs to, based on the training data.&lt;/li&gt;
&lt;li&gt;For example, a classifier could be trained to predict whether an email is spam or not spam, based on the contents of the email. The input data would be the contents of the email, and the output class would be either &amp;ldquo;spam&amp;rdquo; or &amp;ldquo;not spam&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;There are many different algorithms that can be used for classification, including logistic regression, support vector machines (SVMs), and decision trees. The choice of algorithm depends on the characteristics of the data and the desired complexity of the model.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;classifier&#34;&gt;Classifier&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A classifier is a machine learning model that is trained to predict a discrete class or category for a given input data. Classifiers are used in a variety of applications, including spam filtering, image classification, and natural language processing.&lt;/li&gt;
&lt;li&gt;There are many different types of classifiers, including logistic regression, support vector machines (SVMs), and decision trees. The choice of classifier depends on the characteristics of the data and the desired complexity of the model.&lt;/li&gt;
&lt;li&gt;To train a classifier, the model is presented with a labeled dataset that includes input data and the corresponding correct class or category. The model then &amp;ldquo;learns&amp;rdquo; to predict the correct class by finding patterns in the training data. Once trained, the classifier can then be used to predict the class for new, unseen data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cluster&#34;&gt;Cluster&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In the context of machine learning, a cluster refers to a group of data points that are similar to one another. Clustering is an unsupervised learning problem in which the goal is to divide the data into distinct groups, or clusters, such that the data points within each cluster are more similar to one another than they are to data points in other clusters.&lt;/li&gt;
&lt;li&gt;There are many different algorithms that can be used for clustering, including k-means clustering and hierarchical clustering. The choice of algorithm depends on the characteristics of the data and the desired properties of the clusters.&lt;/li&gt;
&lt;li&gt;Clustering can be used for a variety of purposes, including data compression, anomaly detection, and generating hypotheses for further testing. It is a useful tool for exploring and understanding the structure of a dataset.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cluster-center&#34;&gt;Cluster center&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In the context of clustering, a cluster center is a representative data point for a cluster. It is typically the mean or median of the points in the cluster, depending on the specific clustering algorithm being used.&lt;/li&gt;
&lt;li&gt;In k-means clustering, for example, the cluster center is the mean of all the data points in the cluster. The k-means algorithm works by iteratively assigning each data point to the cluster with the closest cluster center and then updating the cluster center to be the mean of the points in the cluster.&lt;/li&gt;
&lt;li&gt;In hierarchical clustering, the cluster center can be thought of as the point at the center of the cluster, which is determined by the specific linkage criterion being used.&lt;/li&gt;
&lt;li&gt;The cluster center is used to represent the &amp;ldquo;typical&amp;rdquo; data point in a cluster, and can be useful for understanding the characteristics of the cluster and for visualization purposes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;clustering&#34;&gt;Clustering&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Clustering is an unsupervised learning problem in which the goal is to divide a dataset into distinct groups, or clusters, such that the data points within each cluster are more similar to one another than they are to data points in other clusters. Clustering is a useful tool for exploring and understanding the structure of a dataset, and can be used for a variety of purposes, including data compression, anomaly detection, and generating hypotheses for further testing.&lt;/li&gt;
&lt;li&gt;There are many different algorithms that can be used for clustering, including k-means clustering, hierarchical clustering, and density-based clustering. The choice of algorithm depends on the characteristics of the data and the desired properties of the clusters.&lt;/li&gt;
&lt;li&gt;In k-means clustering, for example, the goal is to partition the data into a specified number (k) of clusters by iteratively assigning each data point to the cluster with the closest cluster center and then updating the cluster center to be the mean of the points in the cluster. Hierarchical clustering, on the other hand, involves creating a hierarchy of clusters, where at each step, the two closest clusters are merged together. Density-based clustering algorithms, such as DBSCAN, identify clusters as areas of higher density surrounded by areas of lower density.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cusum&#34;&gt;CUSUM&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;CUSUM is an acronym for &amp;ldquo;Cumulative Sum.&amp;rdquo; It is a statistical algorithm that is used to detect small shifts in the mean of a process over time. It is often used in quality control and reliability engineering to monitor processes and detect changes that may indicate a problem or deviation from the norm.&lt;/li&gt;
&lt;li&gt;The CUSUM algorithm works by keeping track of a running total of the difference between the observed values and the expected or target value. When the running total exceeds a pre-determined threshold, it indicates that the process has shifted and may need to be corrected or investigated.&lt;/li&gt;
&lt;li&gt;CUSUM charts are often used to visualize the performance of the CUSUM algorithm, with the running total being plotted on the y-axis and the time steps on the x-axis. The chart can then be used to identify when the running total exceeds the threshold and to identify any trends or patterns in the data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deep-learning&#34;&gt;Deep learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Deep learning is a subfield of machine learning that is inspired by the structure and function of the brain, specifically the neural networks that make up the brain. It involves the use of artificial neural networks, which are computational models inspired by the structure and function of the brain, to learn from data and make decisions.&lt;/li&gt;
&lt;li&gt;Deep learning algorithms learn by example, just like humans do. They learn by being presented with a large amount of labeled data and adjusting the internal parameters of the network to optimize performance on a specific task. The &amp;ldquo;deep&amp;rdquo; in deep learning refers to the fact that these algorithms typically have multiple layers of artificial neurons, with each layer learning to extract higher-level features of the data.&lt;/li&gt;
&lt;li&gt;Deep learning has been successful in a wide range of applications, including image and speech recognition, natural language processing, and autonomous driving. It has revolutionized the field of machine learning and has enabled the development of many practical applications that were previously thought to be impossible.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dimension&#34;&gt;Dimension&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In the context of machine learning, a dimension refers to a particular feature or attribute of a dataset. For example, if you are working with a dataset that includes information about houses (such as price, number of bedrooms, square footage, and location), each of these features would be considered a separate dimension.&lt;/li&gt;
&lt;li&gt;The number of dimensions in a dataset is often referred to as the &amp;ldquo;dimensionality&amp;rdquo; of the dataset. High-dimensional datasets, which have a large number of dimensions, can be difficult to work with and visualize, as it can be challenging to represent the relationships between all of the dimensions in a meaningful way.&lt;/li&gt;
&lt;li&gt;In machine learning, techniques such as dimensionality reduction can be used to reduce the number of dimensions in a dataset, while still preserving the important information. This can be useful for tasks such as visualization and training machine learning models, which may be more efficient and effective on lower-dimensional data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;expectation-maximization-algorithm-em-algorithm&#34;&gt;Expectation-maximization algorithm (EM algorithm)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The EM algorithm (Expectation-Maximization algorithm) is a widely used method for estimating the parameters of a statistical model when there is missing or incomplete data. It is an iterative algorithm that alternates between two steps: the expectation (E) step and the maximization (M) step.&lt;/li&gt;
&lt;li&gt;In the E step, the algorithm estimates the expected value of the complete data likelihood function (a measure of the probability of the data given the model parameters) based on the current parameter values. In the M step, the algorithm updates the parameter values to maximize the expected complete data likelihood. The process is then repeated until convergence, at which point the parameter estimates are considered to be optimal.&lt;/li&gt;
&lt;li&gt;The EM algorithm is widely used in a variety of applications, including machine learning, natural language processing, and bioinformatics. It is particularly useful when the data are incomplete or when the model is a mixture model (i.e., a model that consists of a mixture of different underlying distributions).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;heuristic&#34;&gt;Heuristic&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In machine learning, a heuristic is a simplified, approximate solution to a problem that is used to quickly find a satisfactory answer. It is often used in situations where finding the optimal solution is computationally infeasible or impractical.&lt;/li&gt;
&lt;li&gt;Heuristics are often used in machine learning as a way to quickly search through a large space of possible solutions and find a good, but not necessarily optimal, solution. They can be useful for tasks such as optimization, feature selection, and model selection.&lt;/li&gt;
&lt;li&gt;Heuristics are often designed to be domain-specific and are based on the specific characteristics of the problem at hand. They can be useful for providing a rough estimate or approximation of the solution, but they may not always be reliable or accurate. In general, heuristics should be used with caution and should be validated against more rigorous methods where possible.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ùëò-means-algorithm&#34;&gt;ùëò-means algorithm&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The k-means algorithm is a method for clustering data into a specified number (k) of distinct clusters. It is an iterative algorithm that works by first randomly initializing k cluster centers, and then iteratively assigning each data point to the cluster with the closest cluster center and updating the cluster center to be the mean of the points in the cluster.&lt;/li&gt;
&lt;li&gt;The k-means algorithm has the following steps:
&lt;ul&gt;
&lt;li&gt;Initialize k cluster centers randomly.&lt;/li&gt;
&lt;li&gt;Assign each data point to the cluster with the closest cluster center.&lt;/li&gt;
&lt;li&gt;Update the cluster centers to be the mean of the points in the cluster.&lt;/li&gt;
&lt;li&gt;Repeat steps 2 and 3 until the cluster assignments stop changing or a maximum number of iterations is reached.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The k-means algorithm is sensitive to the initial cluster assignments, so it is common to run the algorithm multiple times with different random initializations to ensure that the final clusters are stable. The algorithm is also sensitive to outliers and may produce suboptimal clusters if the data contain outliers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ùëò-nearest-neighbor-knn&#34;&gt;ùëò-Nearest-Neighbor (KNN)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The k-nearest neighbor (KNN) algorithm is a method for classifying objects based on the closest training examples in the feature space. It is a non-parametric method, which means that it does not make any assumptions about the underlying distribution of the data.&lt;/li&gt;
&lt;li&gt;The KNN algorithm works by calculating the distance between the new data point and all the training data, and then selecting the k training points that are closest to the new data point. The class label of the new data point is then determined by majority vote among the k nearest neighbors.&lt;/li&gt;
&lt;li&gt;The value of k is a hyperparameter of the KNN algorithm and must be chosen by the practitioner. A larger value of k will make the model more robust to noise, but a smaller value may be more sensitive to the underlying structure of the data.&lt;/li&gt;
&lt;li&gt;KNN is a simple and effective method for classification, but it can be computationally expensive for large datasets, as it requires calculating the distance between the new data point and all the training examples.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kernel&#34;&gt;Kernel&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In the context of machine learning, a kernel is a function that takes in two inputs and returns a scalar value. Kernels are used in a variety of machine learning algorithms, including support vector machines (SVMs) and kernel principal component analysis (PCA).&lt;/li&gt;
&lt;li&gt;In SVMs, kernels are used to define a similarity measure between two data points. The kernel function is applied to the data points to transform them into a higher-dimensional space, where it is then possible to find a linear separation between the classes. By using a kernel function, it is possible to learn a non-linear decision boundary in the original feature space using a linear classifier in the transformed space.&lt;/li&gt;
&lt;li&gt;In kernel PCA, kernels are used to define a similarity measure between data points in the original space, and the resulting kernel matrix is used to perform PCA in the feature space. This allows for non-linear dimensionality reduction, which can be useful for data that is not linearly separable.&lt;/li&gt;
&lt;li&gt;There are many different kernel functions that can be used, including linear kernels, polynomial kernels, and radial basis function (RBF) kernels. The choice of kernel depends on the characteristics of the data and the desired properties of the model.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;margin&#34;&gt;Margin&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In the context of machine learning, the margin is the distance between the decision boundary (i.e., the line or hyperplane that separates the classes) and the nearest training data points. The margin is an important concept in certain types of algorithms, such as support vector machines (SVMs), where the goal is to find the decision boundary that has the largest margin.&lt;/li&gt;
&lt;li&gt;In SVMs, the margin is the distance between the decision boundary and the closest data points from each class. The margin is maximized when the decision boundary is as far as possible from the closest data points from each class, which leads to a model that is more robust and generalizable to new data.&lt;/li&gt;
&lt;li&gt;The margin can also be thought of as a measure of the confidence of the classifier. A larger margin indicates that the classifier is more confident in its predictions, as it is based on a wider separation between the classes.&lt;/li&gt;
&lt;li&gt;The margin is an important consideration when training a machine learning model, as a model with a large margin is often preferred to a model with a small margin, as it is likely to be more robust and generalizable to new data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;machine-learning&#34;&gt;Machine learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Machine learning is a field of artificial intelligence that involves the use of computational models to learn from data and make predictions or decisions without being explicitly programmed. It involves the development of algorithms that can automatically improve their performance through experience.&lt;/li&gt;
&lt;li&gt;There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning.&lt;/li&gt;
&lt;li&gt;In supervised learning, the goal is to learn a function that maps input data to output labels, based on a labeled training dataset. The model is trained on the training data and then evaluated on a separate test dataset to evaluate its performance. Examples of supervised learning tasks include classification and regression.&lt;/li&gt;
&lt;li&gt;In unsupervised learning, the goal is to discover patterns or relationships in the data without any prior knowledge or labeled training data. Examples of unsupervised learning tasks include clustering and dimensionality reduction.&lt;/li&gt;
&lt;li&gt;In reinforcement learning, the goal is to learn a policy that maximizes a reward signal. The model is trained by interacting with its environment and receiving feedback in the form of rewards or punishments. Reinforcement learning is used in a variety of applications, including robotics and control systems.&lt;/li&gt;
&lt;li&gt;Machine learning has been successful in a wide range of applications, including image and speech recognition, natural language processing, and autonomous driving. It has revolutionized many fields and has enabled the development of practical applications that were previously thought to be impossible.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;neural-network&#34;&gt;Neural network&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A neural network is a type of machine learning model inspired by the structure and function of the brain. It is composed of layers of interconnected &amp;ldquo;neurons,&amp;rdquo; which process and transmit information. Neural networks are able to learn and adapt to new data by adjusting the strengths of the connections between neurons.&lt;/li&gt;
&lt;li&gt;The basic building block of a neural network is the neuron, which is a simple computational unit that receives input, processes it, and produces an output. The input is passed through multiple layers of neurons, with each layer learning to extract higher-level features of the data. The output of the final layer is the prediction or decision made by the neural network.&lt;/li&gt;
&lt;li&gt;There are many different types of neural networks, including feedforward neural networks, convolutional neural networks (CNNs), and recurrent neural networks (RNNs). The choice of neural network architecture depends on the characteristics of the data and the desired properties of the model.&lt;/li&gt;
&lt;li&gt;Neural networks have been successful in a wide range of applications, including image and speech recognition, natural language processing, and autonomous driving. They have revolutionized the field of machine learning and have enabled the development of many practical applications that were previously thought to be impossible.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;supervised-learning&#34;&gt;Supervised learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Supervised learning is a type of machine learning in which the model is trained on a labeled dataset, where the correct output is provided for each example in the training set. The goal of supervised learning is to learn a function that can map input data to the correct output labels.&lt;/li&gt;
&lt;li&gt;Supervised learning algorithms can be divided into two main categories: regression and classification.&lt;/li&gt;
&lt;li&gt;In regression, the goal is to predict a continuous value, such as the price of a house or the likelihood of a customer churning. Examples of regression algorithms include linear regression and support vector regression.&lt;/li&gt;
&lt;li&gt;In classification, the goal is to predict a discrete label or class, such as whether an email is spam or not spam. Examples of classification algorithms include logistic regression, k-nearest neighbors, and decision trees.&lt;/li&gt;
&lt;li&gt;Supervised learning is the most widely used type of machine learning and has been successful in a wide range of applications, including image and speech recognition, natural language processing, and fraud detection. It requires a labeled dataset to train the model, which can be expensive and time-consuming to obtain.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;support-vector-machine-svm&#34;&gt;Support vector machine (SVM)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Support vector machine (SVM) is a type of supervised learning algorithm that can be used for classification or regression. It is based on the idea of finding a hyperplane in a high-dimensional space that maximally separates the classes.&lt;/li&gt;
&lt;li&gt;In the case of classification, the goal is to find a hyperplane that separates the data points into different classes as well as possible. The SVM algorithm finds the hyperplane that has the largest margin, or distance, between the closest data points of each class. This maximizes the separation between the classes and leads to a more robust and generalizable model.&lt;/li&gt;
&lt;li&gt;In the case of regression, the goal is to find a hyperplane that predicts the output value for a given input value. The SVM algorithm finds the hyperplane that minimizes the error between the predicted and actual values.&lt;/li&gt;
&lt;li&gt;SVMs are effective in high-dimensional spaces and are widely used in a variety of applications, including image and speech recognition, natural language processing, and bioinformatics. They are also robust to noise and can handle datasets with a large number of features. However, they can be computationally expensive to train and are not well-suited for very large datasets.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;unsupervised-learning&#34;&gt;Unsupervised learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Unsupervised learning is a type of machine learning in which the model is not given any labeled training data and must find patterns or relationships in the data on its own. The goal of unsupervised learning is to discover the underlying structure of the data, without any prior knowledge or assumptions.&lt;/li&gt;
&lt;li&gt;Unsupervised learning algorithms can be divided into two main categories: clustering and dimensionality reduction.&lt;/li&gt;
&lt;li&gt;In clustering, the goal is to group the data points into distinct clusters such that the points within each cluster are more similar to one another than they are to points in other clusters. Examples of clustering algorithms include k-means clustering and hierarchical clustering.&lt;/li&gt;
&lt;li&gt;In dimensionality reduction, the goal is to reduce the number of dimensions (features) in the data while preserving as much of the information as possible. This can be useful for tasks such as visualization and feature selection. Examples of dimensionality reduction algorithms include principal component analysis (PCA) and t-SNE (t-distributed stochastic neighbor embedding).&lt;/li&gt;
&lt;li&gt;Unsupervised learning is useful for exploring and understanding the structure of a dataset, and can be used for tasks such as anomaly detection and data compression. It does not require labeled data and can be used with data that has not been labeled or has incomplete labels. However, it can be more difficult to evaluate the performance of unsupervised learning algorithms, as there is no ground truth to compare the results to.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;voronoi-diagram&#34;&gt;Voronoi diagram&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A Voronoi diagram is a graphical representation of the partitioning of a plane into regions based on the distance to a set of points. It is named after Russian mathematician Georgy Voronoi, who developed the concept in 1908.&lt;/li&gt;
&lt;li&gt;In a Voronoi diagram, the plane is divided into a set of cells, with each cell corresponding to one of the input points. The points are called the &amp;ldquo;generators&amp;rdquo; of the Voronoi diagram. Each cell consists of all points that are closer to its generator than to any other generator. The boundary between cells is called a Voronoi edge, and the points where Voronoi edges intersect are called Voronoi vertices.&lt;/li&gt;
&lt;li&gt;Voronoi diagrams have a wide range of applications, including computer graphics, image processing, and spatial analysis. They are used to model the spatial distribution of points and can be used to optimize the placement of facilities, such as warehouses or cell phone towers, to minimize the distance to the nearest facility. They are also used in computer games to determine the visibility of objects on the screen and in the design of efficient algorithms for solving problems in computational geometry.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;confusion-matrix&#34;&gt;Confusion Matrix&lt;/h2&gt;
&lt;h3 id=&#34;accuracy&#34;&gt;Accuracy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Accuracy is a measure of how well a model correctly predicts the outcome of a given data sample. It is commonly used in classification problems, where the model is trying to predict a label for a given input.&lt;/li&gt;
&lt;li&gt;The accuracy score is calculated by dividing the number of correct predictions made by the model by the total number of predictions made. This value is then expressed as a percentage. For example, if a model made 100 predictions and 75 of them were correct, the accuracy score would be 75%.&lt;/li&gt;
&lt;li&gt;To calculate the accuracy score, you need a set of predictions made by the model and the corresponding true labels for those predictions. You can then compare the predictions to the true labels to see how many were correct.&lt;/li&gt;
&lt;li&gt;Here is an example of how to calculate the accuracy score in Python:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def accuracy_score(y_true, y_pred):
    # Calculate the number of correct predictions
    correct = sum(y_true == y_pred)
    # Calculate the total number of predictions
    total = len(y_true)
    # Calculate the accuracy score as a percentage
    return correct / total * 100
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Here, y_true is a list of the true labels and y_pred is a list of the predictions made by the model. The function first calculates the number of correct predictions and then divides that by the total number of predictions to get the accuracy as a decimal. It then multiplies that value by 100 to express the accuracy as a percentage.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;confusion-matrix-1&#34;&gt;Confusion matrix&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A confusion matrix is a table that is used to evaluate the performance of a classification algorithm. It helps to visualize the correct and incorrect predictions made by the model and allows you to see which classes are being predicted accurately and which are not.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The rows of the matrix represent the actual classes of the samples and the columns represent the predicted classes. The diagonal elements of the matrix represent the number of samples that have been correctly classified, while the off-diagonal elements represent the number of misclassified samples.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Here is an example of a confusion matrix:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;              Predicted Positive    Predicted Negative
Actual Positive          TP                  FP
Actual Negative          FN                  TN
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;In this example, TP (true positive) is the number of samples that are actually positive and have been correctly predicted as positive. TN (true negative) is the number of samples that are actually negative and have been correctly predicted as negative. FP (false positive) is the number of samples that are actually negative but have been predicted as positive. FN (false negative) is the number of samples that are actually positive but have been predicted as negative.&lt;/li&gt;
&lt;li&gt;To calculate the values for the confusion matrix, you need a set of predictions made by the model and the corresponding true labels for those predictions. You can then compare the predictions to the true labels to see how many were correct and how many were incorrect.&lt;/li&gt;
&lt;li&gt;Here is an example of how to calculate a confusion matrix in Python:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;from sklearn.metrics import confusion_matrix

y_true = [1, 0, 1, 1, 0, 1]
y_pred = [1, 1, 1, 1, 0, 0]

confusion_matrix(y_true, y_pred)
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;This will output the following confusion matrix:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;array([[2, 1],
       [1, 2]])
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;diagnostic-odds-ratio&#34;&gt;Diagnostic odds ratio&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The diagnostic odds ratio (DOR) is a measure of the accuracy of a diagnostic test. It is used to compare the accuracy of two or more diagnostic tests or to compare the accuracy of a diagnostic test to a reference standard.&lt;/li&gt;
&lt;li&gt;The DOR is calculated as the ratio of the odds of a positive test result in patients with the condition being tested for to the odds of a positive test result in patients without the condition.&lt;/li&gt;
&lt;li&gt;Here is the formula for calculating the DOR:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;DOR = (TP / FP) / (FN / TN)
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Where TP (true positive) is the number of samples that are actually positive and have been correctly predicted as positive, TN (true negative) is the number of samples that are actually negative and have been correctly predicted as negative, FP (false positive) is the number of samples that are actually negative but have been predicted as positive, and FN (false negative) is the number of samples that are actually positive but have been predicted as negative.&lt;/li&gt;
&lt;li&gt;The DOR can range from 0 to infinity, with higher values indicating a more accurate diagnostic test. A DOR of 1 indicates that the test is no better than a coin flip, while a DOR of infinity indicates perfect accuracy.&lt;/li&gt;
&lt;li&gt;To calculate the DOR, you need a set of predictions made by the diagnostic test and the corresponding true labels for those predictions. You can then use the formula above to calculate the DOR.&lt;/li&gt;
&lt;li&gt;Here is an example of how to calculate the DOR in Python:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def diagnostic_odds_ratio(y_true, y_pred):
    tp = sum((y_true == 1) &amp;amp; (y_pred == 1))
    tn = sum((y_true == 0) &amp;amp; (y_pred == 0))
    fp = sum((y_true == 0) &amp;amp; (y_pred == 1))
    fn = sum((y_true == 1) &amp;amp; (y_pred == 0))
    dor = (tp / fp) / (fn / tn)
    return dor
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Here, y_true is a list of the true labels and y_pred is a list of the predictions made by the diagnostic test. The function calculates the values for TP, TN, FP, and FN using boolean masks and then uses these values to calculate the DOR using the formula above.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fall-out&#34;&gt;Fall out&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Fallout (also known as false positive rate or type I error) is a measure of the performance of a diagnostic test or classification algorithm. It is the percentage of negative samples that are incorrectly classified as positive.&lt;/li&gt;
&lt;li&gt;In the context of a diagnostic test, fallout represents the probability that a person without the condition being tested for will receive a positive test result. In the context of a classification algorithm, fallout represents the percentage of negative samples that are incorrectly classified as positive.&lt;/li&gt;
&lt;li&gt;Here is the formula for calculating fallout:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Fallout = FP / (FP + TN)
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Where FP (false positive) is the number of samples that are actually negative but have been predicted as positive, and TN (true negative) is the number of samples that are actually negative and have been correctly predicted as negative.&lt;/li&gt;
&lt;li&gt;To calculate fallout, you need a set of predictions made by the diagnostic test or classification algorithm and the corresponding true labels for those predictions. You can then use the formula above to calculate the fallout.&lt;/li&gt;
&lt;li&gt;Here is an example of how to calculate fallout in Python:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def fallout(y_true, y_pred):
    fp = sum((y_true == 0) &amp;amp; (y_pred == 1))
    tn = sum((y_true == 0) &amp;amp; (y_pred == 0))
    fallout = fp / (fp + tn)
    return fallout
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Here, y_true is a list of the true labels and y_pred is a list of the predictions made by the diagnostic test or classification algorithm. The function calculates the values for FP and TN using boolean masks and then uses these values to calculate the fallout using the formula above.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;false-negative-fn&#34;&gt;False negative (FN)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A false negative (FN) is a prediction made by a diagnostic test or classification algorithm that is incorrect. It refers to a situation where the test or algorithm predicts a negative result for a sample that is actually positive.&lt;/li&gt;
&lt;li&gt;In the context of a diagnostic test, a false negative means that the test failed to detect the presence of a condition in a person who actually has the condition. In the context of a classification algorithm, a false negative means that the algorithm failed to correctly classify a positive sample.&lt;/li&gt;
&lt;li&gt;False negatives are often more serious than false positives, as they can have more serious consequences. For example, if a diagnostic test for a disease returns a false negative result, the person may not receive the necessary treatment and their condition may worsen.&lt;/li&gt;
&lt;li&gt;To calculate the number of false negatives, you need a set of predictions made by the diagnostic test or classification algorithm and the corresponding true labels for those predictions. You can then compare the predictions to the true labels to see how many were incorrect.&lt;/li&gt;
&lt;li&gt;Here is an example of how to calculate the number of false negatives in Python:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def false_negatives(y_true, y_pred):
    fn = sum((y_true == 1) &amp;amp; (y_pred == 0))
    return fn
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Here, y_true is a list of the true labels and y_pred is a list of the predictions made by the diagnostic test or classification algorithm. The function calculates the number of false negatives using a boolean mask that compares the true labels to the predictions&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;false-negative-rate&#34;&gt;False negative rate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The false negative rate (FNR) is a measure of the performance of a diagnostic test or classification algorithm. It is the percentage of positive samples that are incorrectly classified as negative.&lt;/li&gt;
&lt;li&gt;In the context of a diagnostic test, the false negative rate represents the probability that a person with the condition being tested for will receive a negative test result. In the context of a classification algorithm, the false negative rate represents the percentage of positive samples that are incorrectly classified as negative.&lt;/li&gt;
&lt;li&gt;Here is the formula for calculating the false negative rate:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;FNR = FN / (FN + TP)
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Where FN (false negative) is the number of samples that are actually positive but have been predicted as negative, and TP (true positive) is the number of samples that are actually positive and have been correctly predicted as positive.&lt;/li&gt;
&lt;li&gt;To calculate the false negative rate, you need a set of predictions made by the diagnostic test or classification algorithm and the corresponding true labels for those predictions. You can then use the formula above to calculate the false negative rate.&lt;/li&gt;
&lt;li&gt;Here is an example of how to calculate the false negative rate in Python:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def false_negative_rate(y_true, y_pred):
    fn = sum((y_true == 1) &amp;amp; (y_pred == 0))
    tp = sum((y_true == 1) &amp;amp; (y_pred == 1))
    fnr = fn / (fn + tp)
    return fnr
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Here, y_true is a list of the true labels and y_pred is a list of the predictions made by the diagnostic test or classification algorithm. The function calculates the values for FN and TP using boolean masks and then uses these values to calculate the false negative rate using the formula above.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;false-positive-fp&#34;&gt;False positive (FP)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A false positive (FP) is a prediction made by a diagnostic test or classification algorithm that is incorrect. It refers to a situation where the test or algorithm predicts a positive result for a sample that is actually negative.&lt;/li&gt;
&lt;li&gt;In the context of a diagnostic test, a false positive means that the test detected the presence of a condition in a person who actually does not have the condition. In the context of a classification algorithm, a false positive means that the algorithm incorrectly classified a negative sample.&lt;/li&gt;
&lt;li&gt;False positives can sometimes be less serious than false negatives, as they may lead to unnecessary follow-up tests or treatment. However, they can also be costly and cause anxiety for the person being tested.&lt;/li&gt;
&lt;li&gt;To calculate the number of false positives, you need a set of predictions made by the diagnostic test or classification algorithm and the corresponding true labels for those predictions. You can then compare the predictions to the true labels to see how many were incorrect.&lt;/li&gt;
&lt;li&gt;Here is an example of how to calculate the number of false positives in Python:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def false_positives(y_true, y_pred):
    fp = sum((y_true == 0) &amp;amp; (y_pred == 1))
    return fp
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Here, y_true is a list of the true labels and y_pred is a list of the predictions made by the diagnostic test or classification algorithm. The function calculates the number of false positives using a boolean mask that compares the true labels to the predictions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;false-positive-rate&#34;&gt;False positive rate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In the context of diagnostic tests, the false positive rate is the probability that a patient with a negative disease status will receive a positive test result. In other words, it is the probability of a false alarm. A high false positive rate means that there is a high probability of a patient being told they have a disease when they actually do not. This can lead to unnecessary anxiety and further testing, and can also reduce the overall credibility of the diagnostic test.&lt;/li&gt;
&lt;li&gt;The false positive rate is often considered in conjunction with the sensitivity and specificity of a diagnostic test. Sensitivity is the probability of a positive test result given that the patient actually has the disease, and specificity is the probability of a negative test result given that the patient does not have the disease. Together, these measures can give a more complete picture of the performance of a diagnostic test.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;false-omission-rate&#34;&gt;False omission rate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In the context of diagnostic tests, the false omission rate, also known as the false negative rate, is the probability that a patient with a positive disease status will receive a negative test result. A high false negative rate means that there is a high probability of a patient being told they do not have a disease when they actually do. This can have serious consequences, as the patient may not receive the necessary treatment.&lt;/li&gt;
&lt;li&gt;The false negative rate is often considered in conjunction with the sensitivity and specificity of a diagnostic test. Sensitivity is the probability of a positive test result given that the patient actually has the disease, and specificity is the probability of a negative test result given that the patient does not have the disease. Together, these measures can give a more complete picture of the performance of a diagnostic test.&lt;/li&gt;
&lt;li&gt;For example, consider a diagnostic test for a particular disease. The test has a sensitivity of 90%, meaning that it correctly identifies 90% of patients with the disease. It also has a specificity of 95%, meaning that it correctly identifies 95% of patients who do not have the disease. However, if the disease is relatively rare, the false negative rate may still be unacceptably high. For example, if the prevalence of the disease is 1%, and the test has a false negative rate of 10%, then out of 100 patients with the disease, the test will correctly identify only 81 of them (90% sensitivity), while 19 will be misdiagnosed as not having the disease (10% false negative rate). This could lead to a significant number of missed diagnoses.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;hit-rate&#34;&gt;Hit rate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Hit rate, also known as the hit ratio, is a measure of the accuracy of a classifier, predictor, or other machine learning model. It is the number of times the model correctly predicts the outcome (a &amp;ldquo;hit&amp;rdquo;) divided by the total number of predictions made. For example, if a model makes 100 predictions and is correct 70 times, the hit rate is 70%.&lt;/li&gt;
&lt;li&gt;Hit rate is often used as a measure of performance for models that make binary predictions (e.g., &amp;ldquo;positive&amp;rdquo; or &amp;ldquo;negative&amp;rdquo;). In this case, a hit is a correct prediction of the positive or negative class, and the hit rate is the proportion of positive or negative predictions that are correct.&lt;/li&gt;
&lt;li&gt;Hit rate is related to the true positive rate and the false positive rate, which are measures of the performance of a binary classifier. The true positive rate is the proportion of positive cases that are correctly classified as positive, while the false positive rate is the proportion of negative cases that are incorrectly classified as positive. Together, these measures can give a more complete picture of the performance of a classifier.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;miss-rate&#34;&gt;Miss rate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Miss rate, also known as the miss ratio or false negative rate, is a measure of the accuracy of a classifier, predictor, or other machine learning model. It is the number of times the model incorrectly predicts the outcome (a &amp;ldquo;miss&amp;rdquo;) divided by the total number of predictions made. For example, if a model makes 100 predictions and is incorrect 30 times, the miss rate is 30%.&lt;/li&gt;
&lt;li&gt;Miss rate is often used as a measure of performance for models that make binary predictions (e.g., &amp;ldquo;positive&amp;rdquo; or &amp;ldquo;negative&amp;rdquo;). In this case, a miss is an incorrect prediction of the positive or negative class, and the miss rate is the proportion of positive or negative predictions that are incorrect.&lt;/li&gt;
&lt;li&gt;Miss rate is related to the true positive rate and the false positive rate, which are measures of the performance of a binary classifier. The true positive rate is the proportion of positive cases that are correctly classified as positive, while the false positive rate is the proportion of negative cases that are incorrectly classified as positive. Together, these measures can give a more complete picture of the performance of a classifier.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;negative-likelihood-ratio&#34;&gt;Negative likelihood ratio&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The negative likelihood ratio (NLR) is a measure of the performance of a diagnostic test or other classifier. It is the ratio of the probability of a negative test result given that the patient does not have the disease (specificity) to the probability of a negative test result given that the patient does have the disease (1 - sensitivity). The NLR is used to assess the ability of a test to rule out the presence of a disease.&lt;/li&gt;
&lt;li&gt;The NLR can be calculated using the following formula: NLR = (1 - sensitivity) / specificity&lt;/li&gt;
&lt;li&gt;A diagnostic test with a high NLR (greater than 1) is said to have a high negative predictive value, meaning that it is good at ruling out the presence of a disease. A test with a low NLR (less than 1) has a low negative predictive value, meaning that it is not good at ruling out the presence of a disease.&lt;/li&gt;
&lt;li&gt;The NLR is often used in conjunction with the positive likelihood ratio (PLR), which is the ratio of the probability of a positive test result given that the patient has the disease (sensitivity) to the probability of a positive test result given that the patient does not have the disease (1 - specificity). The PLR is used to assess the ability of a test to detect the presence of a disease. Together, the NLR and PLR can give a more complete picture of the performance of a diagnostic test.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;negative-predictive-value&#34;&gt;Negative predictive value&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The negative predictive value (NPV) is a measure of the performance of a diagnostic test or other classifier. It is the probability that a patient with a negative test result does not have the disease. The NPV is used to assess the ability of a test to rule out the presence of a disease.&lt;/li&gt;
&lt;li&gt;The NPV can be calculated using the following formula: NPV = TN / (TN + FN)
where TN is the number of true negatives (patients with a negative test result who do not have the disease) and FN is the number of false negatives (patients with a negative test result who do have the disease).&lt;/li&gt;
&lt;li&gt;A diagnostic test with a high NPV (close to 1) is said to have a high negative predictive value, meaning that it is good at ruling out the presence of a disease. A test with a low NPV (close to 0) has a low negative predictive value, meaning that it is not good at ruling out the presence of a disease.&lt;/li&gt;
&lt;li&gt;The NPV is often used in conjunction with the positive predictive value (PPV), which is the probability that a patient with a positive test result does have the disease. The PPV is used to assess the ability of a test to detect the presence of a disease. Together, the NPV and PPV can give a more complete picture of the performance of a diagnostic test.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;positive-likelihood-ratio&#34;&gt;Positive likelihood ratio&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The positive likelihood ratio (PLR) is a measure of the performance of a diagnostic test or other classifier. It is the ratio of the probability of a positive test result given that the patient has the disease (sensitivity) to the probability of a positive test result given that the patient does not have the disease (1 - specificity). The PLR is used to assess the ability of a test to detect the presence of a disease.&lt;/li&gt;
&lt;li&gt;The PLR can be calculated using the following formula: PLR = sensitivity / (1 - specificity)&lt;/li&gt;
&lt;li&gt;A diagnostic test with a high PLR (greater than 1) is said to have a high positive predictive value, meaning that it is good at detecting the presence of a disease. A test with a low PLR (less than 1) has a low positive predictive value, meaning that it is not good at detecting the presence of a disease.&lt;/li&gt;
&lt;li&gt;The PLR is often used in conjunction with the negative likelihood ratio (NLR), which is the ratio of the probability of a negative test result given that the patient does not have the disease (specificity) to the probability of a negative test result given that the patient does have the disease (1 - sensitivity). The NLR is used to assess the ability of a test to rule out the presence of a disease. Together, the PLR and NLR can give a more complete picture of the performance of a diagnostic test.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;positive-predictive-value&#34;&gt;Positive predictive value&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The positive predictive value (PPV) is a measure of the performance of a diagnostic test or other classifier. It is the probability that a patient with a positive test result does have the disease. The PPV is used to assess the ability of a test to detect the presence of a disease.&lt;/li&gt;
&lt;li&gt;The PPV can be calculated using the following formula: PPV = TP / (TP + FP)
where TP is the number of true positives (patients with a positive test result who do have the disease) and FP is the number of false positives (patients with a positive test result who do not have the disease).&lt;/li&gt;
&lt;li&gt;A diagnostic test with a high PPV (close to 1) is said to have a high positive predictive value, meaning that it is good at detecting the presence of a disease. A test with a low PPV (close to 0) has a low positive predictive value, meaning that it is not good at detecting the presence of a disease.&lt;/li&gt;
&lt;li&gt;The PPV is often used in conjunction with the negative predictive value (NPV), which is the probability that a patient with a negative test result does not have the disease. The NPV is used to assess the ability of a test to rule out the presence of a disease. Together, the PPV and NPV can give a more complete picture of the performance of a diagnostic test.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;precision&#34;&gt;Precision&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In the context of statistical hypothesis testing and machine learning, precision is a measure of the accuracy of a classifier, predictor, or other model. It is the number of true positive predictions made by the model divided by the total number of positive predictions made by the model. Precision is used to evaluate the performance of a model that makes binary predictions (e.g., &amp;ldquo;positive&amp;rdquo; or &amp;ldquo;negative&amp;rdquo;).&lt;/li&gt;
&lt;li&gt;For example, consider a model that makes 100 predictions, of which 70 are positive and 30 are negative. If the model is correct in 60 of the positive predictions and all of the negative predictions, the precision of the model is 60/70 = 0.86. This means that of all the positive predictions made by the model, 86% are correct.&lt;/li&gt;
&lt;li&gt;Precision is often used in conjunction with the recall, which is the number of true positive predictions made by the model divided by the total number of actual positive cases. Precision and recall are both used to evaluate the performance of a binary classifier, and can be balanced against each other to achieve the desired trade-off in a particular application.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;recall&#34;&gt;Recall&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In the context of statistical hypothesis testing and machine learning, recall is a measure of the accuracy of a classifier, predictor, or other model. It is the number of true positive predictions made by the model divided by the total number of actual positive cases. Recall is used to evaluate the performance of a model that makes binary predictions (e.g., &amp;ldquo;positive&amp;rdquo; or &amp;ldquo;negative&amp;rdquo;).&lt;/li&gt;
&lt;li&gt;For example, consider a model that makes 100 predictions, of which 70 are positive and 30 are negative. If the model is correct in 60 of the positive predictions and all of the negative predictions, and there are 80 actual positive cases, the recall of the model is 60/80 = 0.75. This means that of all the actual positive cases, 75% are correctly predicted by the model.&lt;/li&gt;
&lt;li&gt;Recall is often used in conjunction with the precision, which is the number of true positive predictions made by the model divided by the total number of positive predictions made by the model. Precision and recall are both used to evaluate the performance of a binary classifier, and can be balanced against each other to achieve the desired trade-off in a particular application.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sensitivity&#34;&gt;Sensitivity&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Sensitivity, also known as the true positive rate or the recall, is a measure of the performance of a diagnostic test or other classifier. It is the probability of a positive test result given that the patient actually has the disease. Sensitivity is used to evaluate the ability of a test to detect the presence of a disease.&lt;/li&gt;
&lt;li&gt;The sensitivity of a diagnostic test can be calculated using the following formula: sensitivity = TP / (TP + FN) where TP is the number of true positives (patients with a positive test result who do have the disease) and FN is the number of false negatives (patients with a negative test result who do have the disease).&lt;/li&gt;
&lt;li&gt;A diagnostic test with a high sensitivity (close to 1) is said to have a high true positive rate, meaning that it is good at detecting the presence of a disease. A test with a low sensitivity (close to 0) has a low true positive rate, meaning that it is not good at detecting the presence of a disease.&lt;/li&gt;
&lt;li&gt;Sensitivity is often used in conjunction with the specificity of a diagnostic test, which is the probability of a negative test result given that the patient does not have the disease. Together, sensitivity and specificity can give a more complete picture of the performance of a diagnostic test.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;specificity&#34;&gt;Specificity&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Specificity, also known as the true negative rate, is a measure of the performance of a diagnostic test or other classifier. It is the probability of a negative test result given that the patient does not have the disease. Specificity is used to evaluate the ability of a test to rule out the presence of a disease.&lt;/li&gt;
&lt;li&gt;The specificity of a diagnostic test can be calculated using the following formula: specificity = TN / (TN + FP) where TN is the number of true negatives (patients with a negative test result who do not have the disease) and FP is the number of false positives (patients with a positive test result who do not have the disease).&lt;/li&gt;
&lt;li&gt;A diagnostic test with a high specificity (close to 1) is said to have a high true negative rate, meaning that it is good at ruling out the presence of a disease. A test with a low specificity (close to 0) has a low true negative rate, meaning that it is not good at ruling out the presence of a disease.&lt;/li&gt;
&lt;li&gt;Specificity is often used in conjunction with the sensitivity of a diagnostic test, which is the probability of a positive test result given that the patient does have the disease. Together, sensitivity and specificity can give a more complete picture of the performance of a diagnostic test.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;true-negative-tn&#34;&gt;True negative (TN)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A true negative is a prediction made by a diagnostic test or other classifier that an event or condition is absent, and the event or condition is indeed absent. In the context of statistical hypothesis testing and machine learning, a true negative is a prediction made by a model that an instance belongs to the negative class, and the instance does indeed belong to the negative class.&lt;/li&gt;
&lt;li&gt;True negatives are typically represented by the letter TN in performance metrics such as sensitivity, specificity, and the positive and negative predictive values. These metrics are used to evaluate the accuracy of a diagnostic test or other classifier. For example, the sensitivity of a test is the proportion of true positive predictions made by the test to the total number of actual positive cases, while the specificity of a test is the proportion of true negative predictions made by the test to the total number of actual negative cases.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;true-positive-tp&#34;&gt;True positive (TP)&lt;/h3&gt;
&lt;p&gt;A true positive is a prediction made by a diagnostic test or other classifier that an event or condition is present, and the event or condition is indeed present. In the context of statistical hypothesis testing and machine learning, a true positive is a prediction made by a model that an instance belongs to the positive class, and the instance does indeed belong to the positive class.&lt;/p&gt;
&lt;p&gt;True positives are typically represented by the letter TP in performance metrics such as sensitivity, specificity, and the positive and negative predictive values. These metrics are used to evaluate the accuracy of a diagnostic test or other classifier. For example, the sensitivity of a test is the proportion of true positive predictions made by the test to the total number of actual positive cases, while the specificity of a test is the proportion of true negative predictions made by the test to the total number of actual negative cases.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;h3 id=&#34;attribute&#34;&gt;Attribute&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In the context of data modeling and database design, an attribute is a property or characteristic of an entity, typically represented as a column in a database table. An attribute can be a simple data value (e.g., a string, integer, or date) or a complex data structure (e.g., an array or object).&lt;/li&gt;
&lt;li&gt;For example, consider a database table that represents a collection of users. Each user in the table might have attributes such as name, email, and date of birth. These attributes can be used to describe the characteristics of each user in the table.&lt;/li&gt;
&lt;li&gt;In the context of machine learning, an attribute is a feature or characteristic of a data instance that can be used for prediction or classification. For example, in a dataset of customer data, each customer might have attributes such as age, income, and location, which could be used to predict their purchasing behavior.&lt;/li&gt;
&lt;li&gt;In both cases, the attributes of an entity or data instance are used to describe and differentiate it from other entities or instances in the same data set.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;box-and-whisker-plot&#34;&gt;Box and whisker plot&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A box and whisker plot (also known as a box plot) is a graphical representation of a set of numerical data that summarizes several important features of the data using a simple and visually effective display. It is typically used to visualize the distribution of the data and to identify any outliers or unusual observations.&lt;/li&gt;
&lt;li&gt;To create a box and whisker plot, the data is first sorted into numerical order. The middle 50% of the data is then represented by a box, which extends from the lower quartile (the 25th percentile) to the upper quartile (the 75th percentile). The lower and upper quartiles are the points that divide the data into four equal parts.&lt;/li&gt;
&lt;li&gt;The median (the 50th percentile) is represented by a line inside the box. The median is the middle value of the data, such that half of the data is above it and half is below it.&lt;/li&gt;
&lt;li&gt;The &amp;ldquo;whiskers&amp;rdquo; of the plot extend from the box to the minimum and maximum values of the data, unless there are outliers present, in which case the whiskers extend only to the most extreme data points that are not outliers. Outliers are data points that are significantly farther from the main body of the data than the rest of the data. They are typically plotted separately as individual points on the plot.&lt;/li&gt;
&lt;li&gt;Box and whisker plots are useful for comparing the distributions of different sets of data, or for identifying patterns and trends in a single set of data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;categorical-data&#34;&gt;Categorical data&lt;/h3&gt;
&lt;h3 id=&#34;collective-outlier&#34;&gt;Collective outlier&lt;/h3&gt;
&lt;h3 id=&#34;contextual-outlier&#34;&gt;Contextual outlier&lt;/h3&gt;
&lt;h3 id=&#34;covariate&#34;&gt;Covariate&lt;/h3&gt;
&lt;h3 id=&#34;data-point&#34;&gt;Data point&lt;/h3&gt;
&lt;h3 id=&#34;detrending&#34;&gt;Detrending&lt;/h3&gt;
&lt;h3 id=&#34;eigenvalue&#34;&gt;Eigenvalue&lt;/h3&gt;
&lt;h3 id=&#34;eigenvector&#34;&gt;Eigenvector&lt;/h3&gt;
&lt;h3 id=&#34;feature&#34;&gt;Feature&lt;/h3&gt;
&lt;h3 id=&#34;imputation&#34;&gt;Imputation&lt;/h3&gt;
&lt;h3 id=&#34;observation&#34;&gt;Observation&lt;/h3&gt;
&lt;h3 id=&#34;outcome&#34;&gt;Outcome&lt;/h3&gt;
&lt;h3 id=&#34;pca&#34;&gt;PCA&lt;/h3&gt;
&lt;h3 id=&#34;point-outlier&#34;&gt;Point outlier&lt;/h3&gt;
&lt;h3 id=&#34;predictor&#34;&gt;Predictor&lt;/h3&gt;
&lt;h3 id=&#34;principal-component-analysis-pca&#34;&gt;Principal component analysis (PCA)&lt;/h3&gt;
&lt;h3 id=&#34;quantitative-data&#34;&gt;Quantitative data&lt;/h3&gt;
&lt;h3 id=&#34;response&#34;&gt;Response&lt;/h3&gt;
&lt;h3 id=&#34;scaling&#34;&gt;Scaling&lt;/h3&gt;
&lt;h3 id=&#34;standardization&#34;&gt;Standardization&lt;/h3&gt;
&lt;h3 id=&#34;structured-data&#34;&gt;Structured data&lt;/h3&gt;
&lt;h3 id=&#34;time-series-data&#34;&gt;Time series data&lt;/h3&gt;
&lt;h3 id=&#34;unstructured-data&#34;&gt;Unstructured data&lt;/h3&gt;
&lt;h2 id=&#34;design-of-experiments&#34;&gt;Design of Experiments&lt;/h2&gt;
&lt;h3 id=&#34;ab-testing&#34;&gt;A/B testing&lt;/h3&gt;
&lt;h3 id=&#34;analysis-of-varianceanova&#34;&gt;Analysis of Variance/ANOVA&lt;/h3&gt;
&lt;h3 id=&#34;balanced-design&#34;&gt;Balanced design&lt;/h3&gt;
&lt;h3 id=&#34;blocking&#34;&gt;Blocking&lt;/h3&gt;
&lt;h3 id=&#34;control&#34;&gt;Control&lt;/h3&gt;
&lt;h3 id=&#34;design-of-experiments-1&#34;&gt;Design of experiments&lt;/h3&gt;
&lt;h3 id=&#34;exploitation&#34;&gt;Exploitation&lt;/h3&gt;
&lt;h3 id=&#34;exploration&#34;&gt;Exploration&lt;/h3&gt;
&lt;h3 id=&#34;factorial-design&#34;&gt;Factorial design&lt;/h3&gt;
&lt;h3 id=&#34;fractional-factorial-design&#34;&gt;Fractional factorial design&lt;/h3&gt;
&lt;h3 id=&#34;full-factorial-design&#34;&gt;Full factorial design&lt;/h3&gt;
&lt;h3 id=&#34;multi-armed-bandit&#34;&gt;Multi-armed bandit&lt;/h3&gt;
&lt;h3 id=&#34;response-surface&#34;&gt;Response surface&lt;/h3&gt;
&lt;h2 id=&#34;game-theory&#34;&gt;Game Theory&lt;/h2&gt;
&lt;h3 id=&#34;cooperative-game-theory&#34;&gt;Cooperative game theory&lt;/h3&gt;
&lt;h3 id=&#34;game-theory-1&#34;&gt;Game theory&lt;/h3&gt;
&lt;h3 id=&#34;mixed-strategyrandomized-strategy&#34;&gt;Mixed strategy/randomized strategy&lt;/h3&gt;
&lt;h3 id=&#34;prisoners-dilemma&#34;&gt;Prisoner&amp;rsquo;s dilemma&lt;/h3&gt;
&lt;h3 id=&#34;pure-strategy&#34;&gt;Pure strategy&lt;/h3&gt;
&lt;h3 id=&#34;sequential-game&#34;&gt;Sequential game&lt;/h3&gt;
&lt;h3 id=&#34;simultaneous-game&#34;&gt;Simultaneous game&lt;/h3&gt;
&lt;h3 id=&#34;stable-equilibrium&#34;&gt;Stable equilibrium&lt;/h3&gt;
&lt;h3 id=&#34;zero-sum-game&#34;&gt;Zero-sum game&lt;/h3&gt;
&lt;h2 id=&#34;model-quality&#34;&gt;Model Quality&lt;/h2&gt;
&lt;h3 id=&#34;aic&#34;&gt;AIC&lt;/h3&gt;
&lt;h3 id=&#34;akaike-information-criterion-aic&#34;&gt;Akaike information criterion (AIC)&lt;/h3&gt;
&lt;h3 id=&#34;bayesian-information-criterion-bic&#34;&gt;Bayesian Information criterion (BIC)&lt;/h3&gt;
&lt;h3 id=&#34;bic&#34;&gt;BIC&lt;/h3&gt;
&lt;h3 id=&#34;causation&#34;&gt;Causation&lt;/h3&gt;
&lt;h3 id=&#34;corrected-aic&#34;&gt;Corrected AIC&lt;/h3&gt;
&lt;h3 id=&#34;correlation&#34;&gt;Correlation&lt;/h3&gt;
&lt;h3 id=&#34;cross-validation&#34;&gt;Cross-validation&lt;/h3&gt;
&lt;h3 id=&#34;hypothesis-test&#34;&gt;Hypothesis test&lt;/h3&gt;
&lt;h3 id=&#34;k-fold-cross-validation&#34;&gt;k-fold cross-validation&lt;/h3&gt;
&lt;h3 id=&#34;likelihood&#34;&gt;Likelihood&lt;/h3&gt;
&lt;h3 id=&#34;maximum-likelihood&#34;&gt;Maximum likelihood&lt;/h3&gt;
&lt;h3 id=&#34;missing-data&#34;&gt;Missing data&lt;/h3&gt;
&lt;h3 id=&#34;random-effects&#34;&gt;Random effects&lt;/h3&gt;
&lt;h3 id=&#34;real-effects&#34;&gt;Real effects&lt;/h3&gt;
&lt;h3 id=&#34;sum-of-squared-errors&#34;&gt;Sum-of-squared errors&lt;/h3&gt;
&lt;h3 id=&#34;test-datatest-set&#34;&gt;Test data/test set&lt;/h3&gt;
&lt;h3 id=&#34;training-datatraining-set&#34;&gt;Training data/training set&lt;/h3&gt;
&lt;h3 id=&#34;validation&#34;&gt;Validation&lt;/h3&gt;
&lt;h3 id=&#34;validation-datavalidation-set&#34;&gt;Validation data/validation set&lt;/h3&gt;
&lt;h2 id=&#34;non-parametric-tests&#34;&gt;Non-Parametric Tests&lt;/h2&gt;
&lt;h3 id=&#34;mann-whitney-test&#34;&gt;Mann-Whitney test&lt;/h3&gt;
&lt;h3 id=&#34;mcnemars-test&#34;&gt;McNemar&amp;rsquo;s test&lt;/h3&gt;
&lt;h3 id=&#34;nonparametric-test&#34;&gt;Nonparametric test&lt;/h3&gt;
&lt;h3 id=&#34;paired-samples&#34;&gt;Paired samples&lt;/h3&gt;
&lt;h3 id=&#34;parametric-test&#34;&gt;Parametric test&lt;/h3&gt;
&lt;h3 id=&#34;wilcoxon-signed-rank-test-one-sample&#34;&gt;Wilcoxon signed rank test (one sample)&lt;/h3&gt;
&lt;h3 id=&#34;wilcoxon-signed-rank-test&#34;&gt;Wilcoxon signed rank test&lt;/h3&gt;
&lt;h2 id=&#34;optimization&#34;&gt;Optimization&lt;/h2&gt;
&lt;h3 id=&#34;approximate-dynamic-program&#34;&gt;Approximate dynamic program&lt;/h3&gt;
&lt;h3 id=&#34;arc&#34;&gt;Arc&lt;/h3&gt;
&lt;h3 id=&#34;assignment-problem&#34;&gt;Assignment problem&lt;/h3&gt;
&lt;h3 id=&#34;bellmans-equation&#34;&gt;Bellman&amp;rsquo;s equation&lt;/h3&gt;
&lt;h3 id=&#34;binary-integer-program&#34;&gt;Binary integer program&lt;/h3&gt;
&lt;h3 id=&#34;binary-variable&#34;&gt;Binary variable&lt;/h3&gt;
&lt;h3 id=&#34;chance-constraint&#34;&gt;Chance constraint&lt;/h3&gt;
&lt;h3 id=&#34;clique&#34;&gt;Clique&lt;/h3&gt;
&lt;h3 id=&#34;concave-function&#34;&gt;Concave function&lt;/h3&gt;
&lt;h3 id=&#34;constant&#34;&gt;Constant&lt;/h3&gt;
&lt;h3 id=&#34;constraint&#34;&gt;Constraint&lt;/h3&gt;
&lt;h3 id=&#34;convex-function&#34;&gt;Convex function&lt;/h3&gt;
&lt;h3 id=&#34;convex-optimization-model&#34;&gt;Convex optimization model&lt;/h3&gt;
&lt;h3 id=&#34;convex-quadratic-function&#34;&gt;Convex quadratic function&lt;/h3&gt;
&lt;h3 id=&#34;convex-quadratic-program&#34;&gt;Convex quadratic program&lt;/h3&gt;
&lt;h3 id=&#34;convex-set&#34;&gt;Convex set&lt;/h3&gt;
&lt;h3 id=&#34;decision&#34;&gt;Decision&lt;/h3&gt;
&lt;h3 id=&#34;diet-problem&#34;&gt;Diet problem&lt;/h3&gt;
&lt;h3 id=&#34;dynamic-programming&#34;&gt;Dynamic programming&lt;/h3&gt;
&lt;h3 id=&#34;edge&#34;&gt;Edge&lt;/h3&gt;
&lt;h3 id=&#34;feasible-solution&#34;&gt;Feasible solution&lt;/h3&gt;
&lt;h3 id=&#34;fixed-charge&#34;&gt;Fixed charge&lt;/h3&gt;
&lt;h3 id=&#34;flow&#34;&gt;Flow&lt;/h3&gt;
&lt;h3 id=&#34;global-optimummaximumminimum&#34;&gt;Global optimum/maximum/minimum&lt;/h3&gt;
&lt;h3 id=&#34;graph&#34;&gt;Graph&lt;/h3&gt;
&lt;h3 id=&#34;greedy-algorithm&#34;&gt;Greedy algorithm&lt;/h3&gt;
&lt;h3 id=&#34;improving-direction&#34;&gt;Improving direction&lt;/h3&gt;
&lt;h3 id=&#34;initialization&#34;&gt;Initialization&lt;/h3&gt;
&lt;h3 id=&#34;integer-program&#34;&gt;Integer program&lt;/h3&gt;
&lt;h3 id=&#34;iterate&#34;&gt;Iterate&lt;/h3&gt;
&lt;h3 id=&#34;linear-equation&#34;&gt;Linear equation&lt;/h3&gt;
&lt;h3 id=&#34;linear-function&#34;&gt;Linear function&lt;/h3&gt;
&lt;h3 id=&#34;linear-inequality&#34;&gt;Linear inequality&lt;/h3&gt;
&lt;h3 id=&#34;linear-program&#34;&gt;Linear program&lt;/h3&gt;
&lt;h3 id=&#34;local-optimummaximumminimum&#34;&gt;Local optimum/maximum/minimum&lt;/h3&gt;
&lt;h3 id=&#34;louvain-algorithm&#34;&gt;Louvain algorithm&lt;/h3&gt;
&lt;h3 id=&#34;markov-decision-process&#34;&gt;Markov decision process&lt;/h3&gt;
&lt;h3 id=&#34;mathematical-programming&#34;&gt;Mathematical programming&lt;/h3&gt;
&lt;h3 id=&#34;maximization-problem&#34;&gt;Maximization problem&lt;/h3&gt;
&lt;h3 id=&#34;maximum-flow-problem&#34;&gt;Maximum flow problem&lt;/h3&gt;
&lt;h3 id=&#34;minimization-problem&#34;&gt;Minimization problem&lt;/h3&gt;
&lt;h3 id=&#34;modularity&#34;&gt;Modularity&lt;/h3&gt;
&lt;h3 id=&#34;most-optimal&#34;&gt;Most optimal&lt;/h3&gt;
&lt;h3 id=&#34;network&#34;&gt;Network&lt;/h3&gt;
&lt;h3 id=&#34;network-optimization-problem&#34;&gt;Network optimization problem&lt;/h3&gt;
&lt;h3 id=&#34;node&#34;&gt;Node&lt;/h3&gt;
&lt;h3 id=&#34;non-convex-program&#34;&gt;Non-convex program&lt;/h3&gt;
&lt;h3 id=&#34;non-negativity-constraints&#34;&gt;Non-negativity constraints&lt;/h3&gt;
&lt;h3 id=&#34;objective-function&#34;&gt;Objective function&lt;/h3&gt;
&lt;h3 id=&#34;optimal&#34;&gt;Optimal&lt;/h3&gt;
&lt;h3 id=&#34;optimal-solution&#34;&gt;Optimal solution&lt;/h3&gt;
&lt;h3 id=&#34;optimization-1&#34;&gt;Optimization&lt;/h3&gt;
&lt;h3 id=&#34;robust-solution&#34;&gt;Robust solution&lt;/h3&gt;
&lt;h3 id=&#34;scenario&#34;&gt;Scenario&lt;/h3&gt;
&lt;h3 id=&#34;shortest-path-problem&#34;&gt;Shortest path problem&lt;/h3&gt;
&lt;h3 id=&#34;solution-in-the-optimization-sense&#34;&gt;Solution (in the optimization sense)&lt;/h3&gt;
&lt;h3 id=&#34;state&#34;&gt;State&lt;/h3&gt;
&lt;h3 id=&#34;step-size&#34;&gt;Step size&lt;/h3&gt;
&lt;h3 id=&#34;stochastic-dynamic-program&#34;&gt;Stochastic dynamic program&lt;/h3&gt;
&lt;h3 id=&#34;stochastic-optimization&#34;&gt;Stochastic optimization&lt;/h3&gt;
&lt;h3 id=&#34;uncertainty&#34;&gt;Uncertainty&lt;/h3&gt;
&lt;h3 id=&#34;variable-optimization-sense&#34;&gt;Variable (optimization sense)&lt;/h3&gt;
&lt;h3 id=&#34;variable-statistics-sense&#34;&gt;Variable (statistics sense)&lt;/h3&gt;
&lt;h3 id=&#34;vertex&#34;&gt;Vertex&lt;/h3&gt;
&lt;h2 id=&#34;probability-based-models&#34;&gt;Probability based models&lt;/h2&gt;
&lt;h3 id=&#34;action&#34;&gt;Action&lt;/h3&gt;
&lt;h3 id=&#34;arrival-rate&#34;&gt;Arrival rate&lt;/h3&gt;
&lt;h3 id=&#34;balking&#34;&gt;Balking&lt;/h3&gt;
&lt;h3 id=&#34;bayes-theorembayes-rule&#34;&gt;Bayes&amp;rsquo; theorem/Bayes&amp;rsquo; rule&lt;/h3&gt;
&lt;h3 id=&#34;continuous-time-simulation&#34;&gt;Continuous-time simulation&lt;/h3&gt;
&lt;h3 id=&#34;decision-point&#34;&gt;Decision point&lt;/h3&gt;
&lt;h3 id=&#34;deterministic-simulation&#34;&gt;Deterministic simulation&lt;/h3&gt;
&lt;h3 id=&#34;discrete-event-simulation&#34;&gt;Discrete-event simulation&lt;/h3&gt;
&lt;h3 id=&#34;empirical-bayes-model&#34;&gt;Empirical Bayes model&lt;/h3&gt;
&lt;h3 id=&#34;entity&#34;&gt;Entity&lt;/h3&gt;
&lt;h3 id=&#34;fifo&#34;&gt;FIFO&lt;/h3&gt;
&lt;h3 id=&#34;interarrival-time&#34;&gt;Interarrival time&lt;/h3&gt;
&lt;h3 id=&#34;kendall-notation&#34;&gt;Kendall notation&lt;/h3&gt;
&lt;h3 id=&#34;lifo&#34;&gt;LIFO&lt;/h3&gt;
&lt;h3 id=&#34;markov-chain&#34;&gt;Markov chain&lt;/h3&gt;
&lt;h3 id=&#34;memoryless-markov-chain&#34;&gt;Memoryless (Markov chain)&lt;/h3&gt;
&lt;h3 id=&#34;module&#34;&gt;Module&lt;/h3&gt;
&lt;h3 id=&#34;queue&#34;&gt;Queue&lt;/h3&gt;
&lt;h3 id=&#34;queuing&#34;&gt;Queuing&lt;/h3&gt;
&lt;h3 id=&#34;replication&#34;&gt;Replication&lt;/h3&gt;
&lt;h3 id=&#34;resource&#34;&gt;Resource&lt;/h3&gt;
&lt;h3 id=&#34;service-rate&#34;&gt;Service rate&lt;/h3&gt;
&lt;h3 id=&#34;simulation&#34;&gt;Simulation&lt;/h3&gt;
&lt;h3 id=&#34;steady-state&#34;&gt;Steady state&lt;/h3&gt;
&lt;h3 id=&#34;stochastic-simulation&#34;&gt;Stochastic simulation&lt;/h3&gt;
&lt;h3 id=&#34;transition-matrix&#34;&gt;Transition matrix&lt;/h3&gt;
&lt;h3 id=&#34;transition-probability&#34;&gt;Transition probability&lt;/h3&gt;
&lt;h3 id=&#34;validation-of-simulation&#34;&gt;Validation (of simulation)&lt;/h3&gt;
&lt;h2 id=&#34;probability-distributions&#34;&gt;Probability distributions&lt;/h2&gt;
&lt;h3 id=&#34;bernoulli-distribution&#34;&gt;Bernoulli distribution&lt;/h3&gt;
&lt;h3 id=&#34;bias&#34;&gt;Bias&lt;/h3&gt;
&lt;h3 id=&#34;binomial-distribution&#34;&gt;Binomial distribution&lt;/h3&gt;
&lt;h3 id=&#34;distribution-fitting&#34;&gt;Distribution-fitting&lt;/h3&gt;
&lt;h3 id=&#34;exponential-distribution&#34;&gt;Exponential distribution&lt;/h3&gt;
&lt;h3 id=&#34;geometric-distribution&#34;&gt;Geometric distribution&lt;/h3&gt;
&lt;h3 id=&#34;iid&#34;&gt;iid&lt;/h3&gt;
&lt;h3 id=&#34;independent&#34;&gt;Independent&lt;/h3&gt;
&lt;h3 id=&#34;independent-and-identically-distributed-iid&#34;&gt;Independent and identically distributed (iid)&lt;/h3&gt;
&lt;h3 id=&#34;lower-tail&#34;&gt;Lower tail&lt;/h3&gt;
&lt;h3 id=&#34;memoryless-distribution&#34;&gt;Memoryless (distribution)&lt;/h3&gt;
&lt;h3 id=&#34;normal-distribution&#34;&gt;Normal distribution&lt;/h3&gt;
&lt;h3 id=&#34;poisson-distribution&#34;&gt;Poisson distribution&lt;/h3&gt;
&lt;h3 id=&#34;q-q-plot&#34;&gt;Q-Q plot&lt;/h3&gt;
&lt;h3 id=&#34;tails&#34;&gt;Tail(s)&lt;/h3&gt;
&lt;h3 id=&#34;upper-tail&#34;&gt;Upper tail&lt;/h3&gt;
&lt;h3 id=&#34;weibull-distribution&#34;&gt;Weibull distribution&lt;/h3&gt;
&lt;h2 id=&#34;regression&#34;&gt;Regression&lt;/h2&gt;
&lt;h3 id=&#34;adjusted-r-squaredadjusted-r2&#34;&gt;Adjusted R-squared/Adjusted R2&lt;/h3&gt;
&lt;h3 id=&#34;area-under-curveauc&#34;&gt;Area under curve/AUC&lt;/h3&gt;
&lt;h3 id=&#34;bayesian-regression&#34;&gt;Bayesian regression&lt;/h3&gt;
&lt;h3 id=&#34;box-cox-transformation&#34;&gt;Box-Cox transformation&lt;/h3&gt;
&lt;h3 id=&#34;branching&#34;&gt;Branching&lt;/h3&gt;
&lt;h3 id=&#34;cart&#34;&gt;CART&lt;/h3&gt;
&lt;h3 id=&#34;classification-tree&#34;&gt;Classification tree&lt;/h3&gt;
&lt;h3 id=&#34;concordance-index&#34;&gt;Concordance index&lt;/h3&gt;
&lt;h3 id=&#34;decision-tree&#34;&gt;Decision tree&lt;/h3&gt;
&lt;h3 id=&#34;earth&#34;&gt;Earth&lt;/h3&gt;
&lt;h3 id=&#34;elastic-net&#34;&gt;Elastic net&lt;/h3&gt;
&lt;h3 id=&#34;forest&#34;&gt;Forest&lt;/h3&gt;
&lt;h3 id=&#34;interaction-term&#34;&gt;Interaction term&lt;/h3&gt;
&lt;h3 id=&#34;ùëò-nearest-neighbor-regression&#34;&gt;ùëò-Nearest-Neighbor regression&lt;/h3&gt;
&lt;h3 id=&#34;knot&#34;&gt;Knot&lt;/h3&gt;
&lt;h3 id=&#34;lassolasso-regression&#34;&gt;Lasso/Lasso regression&lt;/h3&gt;
&lt;h3 id=&#34;leaf&#34;&gt;Leaf&lt;/h3&gt;
&lt;h3 id=&#34;linear-regression&#34;&gt;Linear regression&lt;/h3&gt;
&lt;h3 id=&#34;logistic-regression&#34;&gt;Logistic regression&lt;/h3&gt;
&lt;h3 id=&#34;logit-model&#34;&gt;Logit model&lt;/h3&gt;
&lt;h3 id=&#34;mars&#34;&gt;MARS&lt;/h3&gt;
&lt;h3 id=&#34;multi-adaptive-regression-splines-mars&#34;&gt;Multi-adaptive regression splines (MARS)&lt;/h3&gt;
&lt;h3 id=&#34;p-value&#34;&gt;p-value&lt;/h3&gt;
&lt;h3 id=&#34;p-value-fishing&#34;&gt;p-value fishing&lt;/h3&gt;
&lt;h3 id=&#34;poisson-regression&#34;&gt;Poisson regression&lt;/h3&gt;
&lt;h3 id=&#34;pruning&#34;&gt;Pruning&lt;/h3&gt;
&lt;h3 id=&#34;pseudo-r-squaredpseudo-r2&#34;&gt;Pseudo-R-squared/Pseudo-R2&lt;/h3&gt;
&lt;h3 id=&#34;r-squaredr2&#34;&gt;R-squared/R2&lt;/h3&gt;
&lt;h3 id=&#34;random-forest&#34;&gt;Random forest&lt;/h3&gt;
&lt;h3 id=&#34;receiver-operating-characteristic-curve-roc-curve&#34;&gt;Receiver operating characteristic curve (ROC curve)&lt;/h3&gt;
&lt;h3 id=&#34;regression-1&#34;&gt;Regression&lt;/h3&gt;
&lt;h3 id=&#34;regression-splines&#34;&gt;Regression splines&lt;/h3&gt;
&lt;h3 id=&#34;regression-tree&#34;&gt;Regression tree&lt;/h3&gt;
&lt;h3 id=&#34;ridge-regression&#34;&gt;Ridge regression&lt;/h3&gt;
&lt;h3 id=&#34;roc-curve&#34;&gt;ROC curve&lt;/h3&gt;
&lt;h3 id=&#34;root&#34;&gt;Root&lt;/h3&gt;
&lt;h3 id=&#34;spline-regression&#34;&gt;Spline regression&lt;/h3&gt;
&lt;h3 id=&#34;transformation&#34;&gt;Transformation&lt;/h3&gt;
&lt;h3 id=&#34;tree&#34;&gt;Tree&lt;/h3&gt;
&lt;h2 id=&#34;time-series-models&#34;&gt;Time series models&lt;/h2&gt;
&lt;h3 id=&#34;additive-seasonality&#34;&gt;Additive seasonality&lt;/h3&gt;
&lt;h3 id=&#34;arima&#34;&gt;ARIMA&lt;/h3&gt;
&lt;h3 id=&#34;autoregression&#34;&gt;Autoregression&lt;/h3&gt;
&lt;h3 id=&#34;autoregressive-integrated-moving-average-arima&#34;&gt;Autoregressive integrated moving average (ARIMA)&lt;/h3&gt;
&lt;h3 id=&#34;differencing&#34;&gt;Differencing&lt;/h3&gt;
&lt;h3 id=&#34;double-exponential&#34;&gt;Double exponential&lt;/h3&gt;
&lt;h3 id=&#34;smoothing&#34;&gt;smoothing&lt;/h3&gt;
&lt;h3 id=&#34;exponential-smoothing&#34;&gt;Exponential smoothing&lt;/h3&gt;
&lt;h3 id=&#34;garch&#34;&gt;GARCH&lt;/h3&gt;
&lt;h3 id=&#34;generalized-autoregressive-conditional-heteroscedasticity-garch&#34;&gt;Generalized autoregressive conditional heteroscedasticity (GARCH)&lt;/h3&gt;
&lt;h3 id=&#34;holt-winters-method&#34;&gt;Holt-Winters method&lt;/h3&gt;
&lt;h3 id=&#34;moving-average&#34;&gt;Moving average&lt;/h3&gt;
&lt;h3 id=&#34;multiplicative-seasonality&#34;&gt;Multiplicative seasonality&lt;/h3&gt;
&lt;h3 id=&#34;seasonalitycycles&#34;&gt;Seasonality/cycles&lt;/h3&gt;
&lt;h3 id=&#34;seasonality-lengthcycle-length&#34;&gt;Seasonality length/cycle length&lt;/h3&gt;
&lt;h3 id=&#34;single-exponential-smoothing&#34;&gt;Single exponential smoothing&lt;/h3&gt;
&lt;h3 id=&#34;smoothing-1&#34;&gt;Smoothing&lt;/h3&gt;
&lt;h3 id=&#34;smoothing-constant&#34;&gt;Smoothing constant&lt;/h3&gt;
&lt;h3 id=&#34;stationary-process&#34;&gt;Stationary process&lt;/h3&gt;
&lt;h3 id=&#34;trend&#34;&gt;Trend&lt;/h3&gt;
&lt;h3 id=&#34;triple-exponential-smoothing&#34;&gt;Triple exponential smoothing&lt;/h3&gt;
&lt;h3 id=&#34;winters-method&#34;&gt;Winters&amp;rsquo; method&lt;/h3&gt;
&lt;h2 id=&#34;variable-selection&#34;&gt;Variable Selection&lt;/h2&gt;
&lt;h3 id=&#34;backward-elimination&#34;&gt;Backward elimination&lt;/h3&gt;
&lt;h3 id=&#34;elastic-net-1&#34;&gt;Elastic net&lt;/h3&gt;
&lt;h3 id=&#34;forward-selection&#34;&gt;Forward selection&lt;/h3&gt;
&lt;h3 id=&#34;lassolasso-regression-1&#34;&gt;Lasso/Lasso regression&lt;/h3&gt;
&lt;h3 id=&#34;overfitting&#34;&gt;Overfitting&lt;/h3&gt;
&lt;h3 id=&#34;regularization&#34;&gt;Regularization&lt;/h3&gt;
&lt;h3 id=&#34;ridge-regression-1&#34;&gt;Ridge regression&lt;/h3&gt;
&lt;h3 id=&#34;simplicity-of-a-model&#34;&gt;Simplicity (of a model)&lt;/h3&gt;
&lt;h3 id=&#34;stepwise-regression&#34;&gt;Stepwise regression&lt;/h3&gt;
&lt;h3 id=&#34;variable-selection-1&#34;&gt;Variable selection&lt;/h3&gt;
&lt;h2 id=&#34;misc&#34;&gt;Misc&lt;/h2&gt;
&lt;h3 id=&#34;1-norm&#34;&gt;1-norm&lt;/h3&gt;
&lt;h3 id=&#34;2-norm&#34;&gt;2-norm&lt;/h3&gt;
&lt;h3 id=&#34;convex-hull-of-a-set-of-points&#34;&gt;Convex hull (of a set of points)&lt;/h3&gt;
&lt;h3 id=&#34;descriptive-analytics&#34;&gt;Descriptive analytics&lt;/h3&gt;
&lt;h3 id=&#34;distance&#34;&gt;Distance&lt;/h3&gt;
&lt;h3 id=&#34;elbow-diagram&#34;&gt;Elbow diagram&lt;/h3&gt;
&lt;h3 id=&#34;error-per-data-point&#34;&gt;Error (per data point)&lt;/h3&gt;
&lt;h3 id=&#34;error-total-over-data-set&#34;&gt;Error (total over data set)&lt;/h3&gt;
&lt;h3 id=&#34;euclidian-distancestraight--line-distance&#34;&gt;Euclidian distance/straight- line distance&lt;/h3&gt;
&lt;h3 id=&#34;fitting&#34;&gt;Fitting&lt;/h3&gt;
&lt;h3 id=&#34;heteroscedasticity&#34;&gt;Heteroscedasticity&lt;/h3&gt;
&lt;h3 id=&#34;infinity-norm&#34;&gt;Infinity-norm&lt;/h3&gt;
&lt;h3 id=&#34;linear-combination&#34;&gt;Linear combination&lt;/h3&gt;
&lt;h3 id=&#34;manhattan-distance&#34;&gt;Manhattan distance&lt;/h3&gt;
&lt;h3 id=&#34;minkowski-distance-of-order-ùëù&#34;&gt;Minkowski distance (of order ùëù)&lt;/h3&gt;
&lt;h3 id=&#34;model-mathematical&#34;&gt;Model (mathematical)&lt;/h3&gt;
&lt;h3 id=&#34;multiplier&#34;&gt;Multiplier&lt;/h3&gt;
&lt;h3 id=&#34;normdistance-norm&#34;&gt;Norm/distance norm&lt;/h3&gt;
&lt;h3 id=&#34;order-of-magnitude&#34;&gt;Order of magnitude&lt;/h3&gt;
&lt;h3 id=&#34;orthogonal&#34;&gt;Orthogonal&lt;/h3&gt;
&lt;h3 id=&#34;outlier&#34;&gt;Outlier&lt;/h3&gt;
&lt;h3 id=&#34;overfitting-1&#34;&gt;Overfitting&lt;/h3&gt;
&lt;h3 id=&#34;ùëù-norm&#34;&gt;ùëù-norm&lt;/h3&gt;
&lt;h3 id=&#34;parameter&#34;&gt;Parameter&lt;/h3&gt;
&lt;h3 id=&#34;perturbation&#34;&gt;Perturbation&lt;/h3&gt;
&lt;h3 id=&#34;prediction&#34;&gt;Prediction&lt;/h3&gt;
&lt;h3 id=&#34;predictive-analytics&#34;&gt;Predictive analytics&lt;/h3&gt;
&lt;h3 id=&#34;prescriptive-analytics&#34;&gt;Prescriptive analytics&lt;/h3&gt;
&lt;h3 id=&#34;rectilinear-distance&#34;&gt;Rectilinear distance&lt;/h3&gt;
&lt;h3 id=&#34;threshold&#34;&gt;Threshold&lt;/h3&gt;
&lt;h3 id=&#34;transformation-1&#34;&gt;Transformation&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>AWS Certified ML - Specialty exam (MLS-C01) - 3b. Modeling</title>
      <link>https://ayushsubedi.github.io/posts/aws_ml_speciality_modeling/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ayushsubedi.github.io/posts/aws_ml_speciality_modeling/</guid>
      <description>&lt;h1 id=&#34;modeling&#34;&gt;Modeling&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#activation-functions&#34;&gt;Activation Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#convolutional-neural-network&#34;&gt;Convolutional Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#recurrent-neural-networks&#34;&gt;Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modern-nlp-with-bert-and-gpt-and-transfer-learning&#34;&gt;Modern NLP with BERT and GPT, and Transfer Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deep-learning-on-ec2-and-emr&#34;&gt;Deep Learning on EC2 and EMR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tuning-neural-networks&#34;&gt;Tuning Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#regularization-techniques-for-neural-networks-dropout-early-stopping&#34;&gt;Regularization Techniques for Neural Networks (Dropout, Early Stopping)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#l1-and-l2-regularization&#34;&gt;L1 and L2 Regularization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#grief-with-gradients-the-vanishing-gradient-problem&#34;&gt;Grief with Gradients The Vanishing Gradient problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-confusion-matrix&#34;&gt;The Confusion Matrix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#precision-recall-f1-auc-and-more&#34;&gt;Precision, Recall, F1, AUC, and more&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ensemble-methods-bagging-and-boosting&#34;&gt;Ensemble Methods Bagging and Boosting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#introducing-amazon-sagemaker&#34;&gt;Introducing Amazon SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#linear-learner-in-sagemaker&#34;&gt;Linear Learner in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#xgboost-in-sagemaker&#34;&gt;XGBoost in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#seq2seq-in-sagemaker&#34;&gt;Seq2Seq in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deepar-in-sagemaker&#34;&gt;DeepAR in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#blazingtext-in-sagemaker&#34;&gt;BlazingText in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#object2vec-in-sagemaker&#34;&gt;Object2Vec in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#object-detection-in-sagemaker&#34;&gt;Object Detection in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#image-classification-in-sagemaker&#34;&gt;Image Classification in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#semantic-segmentation-in-sagemaker&#34;&gt;Semantic Segmentation in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#random-cut-forest-in-sagemaker&#34;&gt;Random Cut Forest in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#neural-topic-model-in-sagemaker&#34;&gt;Neural Topic Model in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#latent-dirichlet-allocation-lda-in-sagemaker&#34;&gt;Latent Dirichlet Allocation (LDA) in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#k-nearest-neighbors-knn-in-sagemaker&#34;&gt;K-Nearest-Neighbors (KNN) in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#k-means-clustering-in-sagemaker&#34;&gt;K-Means Clustering in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#principal-component-analysis-pca-in-sagemaker&#34;&gt;Principal Component Analysis (PCA) in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#factorization-machines-in-sagemaker&#34;&gt;Factorization Machines in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ip-insights-in-sagemaker&#34;&gt;IP Insights in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reinforcement-learning-in-sagemaker&#34;&gt;Reinforcement Learning in SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#automatic-model-tuning&#34;&gt;Automatic Model Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#apache-spark-with-sagemaker&#34;&gt;Apache Spark with SageMaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-studio-and-sagemaker-experiments&#34;&gt;SageMaker Studio, and SageMaker Experiments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-debugger&#34;&gt;SageMaker Debugger&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-autopilot-automl&#34;&gt;SageMaker Autopilot / AutoML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-model-monitor&#34;&gt;SageMaker Model Monitor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#other-recent-features-jumpstart-data-wrangler-features-store-edge-manager&#34;&gt;Other recent features (JumpStart, Data Wrangler, Features Store, Edge Manager)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-canvas&#34;&gt;SageMaker Canvas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bias-measures-in-sagemaker-canvas&#34;&gt;Bias Measures in SageMaker Canvas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sagemaker-training-compiler&#34;&gt;SageMaker Training Compiler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-comprehend&#34;&gt;Amazon Comprehend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-translate&#34;&gt;Amazon Translate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-transcribe&#34;&gt;Amazon Transcribe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-polly&#34;&gt;Amazon Polly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-rekognition&#34;&gt;Amazon Rekognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-forecast&#34;&gt;Amazon Forecast&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-forecast-algorithms&#34;&gt;Amazon Forecast Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-lex&#34;&gt;Amazon Lex&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-personalize&#34;&gt;Amazon Personalize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#lightning-round-textract-deeplens-deepracher-lookout-and-monitron&#34;&gt;Lightning round! TexTract, DeepLens, DeepRacher, Lookout, and Monitron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#torchserve-aws-neuron-and-aws-panorama&#34;&gt;TorchServe, AWS Neuron, and AWS Panorama&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deep-composer-fraud-detection-codeguru-and-contact-lens&#34;&gt;Deep Composer, Fraud Detection, CodeGuru, and Contact Lens&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amazon-kendra-and-amazon-augmented-ai-a2i&#34;&gt;Amazon Kendra and Amazon Augmented AI (A2I)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This section covers framing business problems as machine learning problems, selecting the appropriate model(s) for a given machine learning problem, training machine learning models, performing hyperparameter optimization, and evaluate machine learning models.&lt;/p&gt;
&lt;h2 id=&#34;deeplearning-frameworks&#34;&gt;Deeplearning Frameworks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tensorflow/Keras (Google)&lt;/li&gt;
&lt;li&gt;PyTorch (Meta)&lt;/li&gt;
&lt;li&gt;MXNet (Apache, and therefore AWS leans towards this)&lt;/li&gt;
&lt;li&gt;Scikit-Learn (for simple DL)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;activation-functions&#34;&gt;Activation Functions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Apply a non linear transformation&lt;/li&gt;
&lt;li&gt;Given the input, what should by output be&lt;/li&gt;
&lt;li&gt;Can be applied in between layers, or in the output layer&lt;/li&gt;
&lt;li&gt;Step Function, Sigmoid, TanH, ReLU, Leaky ReLU&lt;/li&gt;
&lt;li&gt;Binary Step Function is either on or off, cannot handle multiple classification, vertical slopes do not work with calculus&lt;/li&gt;
&lt;li&gt;Sigmoid: 0 to 1&lt;/li&gt;
&lt;li&gt;TanH: -1 to 1&lt;/li&gt;
&lt;li&gt;For Sigmoid and TanH there is a vanishing gradient problem (value changes slowly for high or low value)&lt;/li&gt;
&lt;li&gt;Sigmoid and TanH are computationally expensive&lt;/li&gt;
&lt;li&gt;ReLu: fast to compute, for inputs that are zero or negative, it is a linear function (dying relu problem)&lt;/li&gt;
&lt;li&gt;Leaky ReLU solves this&lt;/li&gt;
&lt;li&gt;Parametric ReLU, slope in the negative part is learned via backpropagation, complicated&lt;/li&gt;
&lt;li&gt;Exponential Linear Unit (ELU)&lt;/li&gt;
&lt;li&gt;Maxout: usually not worth the effort&lt;/li&gt;
&lt;li&gt;Softmax: usually the final layer of a classification model&lt;/li&gt;
&lt;li&gt;RNN&amp;rsquo;s do well with Tanh&lt;/li&gt;
&lt;li&gt;Sigmoid if more that one classification is required for the same thing&lt;/li&gt;
&lt;li&gt;For everything else, start with ReLU&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;convolutional-neural-network&#34;&gt;Convolutional Neural Network&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;CNN vs MLP (Multilayer perceptron)&lt;/li&gt;
&lt;li&gt;They have convolutional layers&lt;/li&gt;
&lt;li&gt;Some filters may detect edges, lines, shapes etc. and deeper layers can detect objects&lt;/li&gt;
&lt;li&gt;Feature location invariant, Shift Invariant, Space Invariant Artificial Neural Networks&lt;/li&gt;
&lt;li&gt;Image and video recognition, recommender systems, image classification, image segmentations,&lt;/li&gt;
&lt;li&gt;Machine translation, Sentence Classification, Sentiment analysis&lt;/li&gt;
&lt;li&gt;AlexNet, LeNet, GoogLeNet, ResNet as an example&lt;/li&gt;
&lt;li&gt;source data must be of appropriate dimensions&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;recurrent-neural-networks&#34;&gt;Recurrent Neural Networks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;deals with sequences in time (predict stock prices, understand words in a sentence, translation etc)&lt;/li&gt;
&lt;li&gt;time series data, sequence of arbitrary length&lt;/li&gt;
&lt;li&gt;captions for images, order matters&lt;/li&gt;
&lt;li&gt;structure and context is relevant&lt;/li&gt;
&lt;li&gt;machine generated music&lt;/li&gt;
&lt;li&gt;past behaviour of neuron impacts the future&lt;/li&gt;
&lt;li&gt;Sequence to Sequence: predict stock prices based on series of historic data&lt;/li&gt;
&lt;li&gt;Sequence to vector: words in a sentence to sentiment&lt;/li&gt;
&lt;li&gt;Vector to sequence: create captions from an image&lt;/li&gt;
&lt;li&gt;Encoder -&amp;gt; Decoder: Sequence -&amp;gt; vector -&amp;gt; sequence, machine translation&lt;/li&gt;
&lt;li&gt;Backpropogation through time&lt;/li&gt;
&lt;li&gt;Ends up looking like a really really deep neural network&lt;/li&gt;
&lt;li&gt;Therefore, we use truncated backpropagation through time&lt;/li&gt;
&lt;li&gt;State from earlier time steps get diluted over time, Long Short-Term memory cell LSTM cell&lt;/li&gt;
&lt;li&gt;GRU cell: Gated Recurrent Unit, Simplified LSTM which performs almost as well&lt;/li&gt;
&lt;li&gt;Traning RNN&amp;rsquo;s is hard, very sensitive to topologies, choice of hyperparameters, very resource intensive, a wrong choice can lead to a RNN that does not converge at all.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;modern-nlp-with-bert-and-gpt-and-transfer-learning&#34;&gt;Modern NLP with BERT and GPT, and Transfer Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Transformer deep learning architectures&lt;/li&gt;
&lt;li&gt;BERT, RoBERTa, T5, GPT2, GPT3, etc&lt;/li&gt;
&lt;li&gt;DistilBERT: uses knowledge distillation to reduce model size by 40%&lt;/li&gt;
&lt;li&gt;BERT: Bi-directional Encoder Representations from Transformers&lt;/li&gt;
&lt;li&gt;GPT: Generative Pre-trained Transformer&lt;/li&gt;
&lt;li&gt;Transfer Learning&lt;/li&gt;
&lt;li&gt;Model zoos: hugging face offer pre trained models to start with&lt;/li&gt;
&lt;li&gt;Hugging face DLC (deep learning containers)&lt;/li&gt;
&lt;li&gt;Transfer Learning, retrain=True vs False&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deep-learning-on-ec2emr&#34;&gt;Deep Learning on EC2/EMR&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;EMR supports Apache MXNet and GPU instance types&lt;/li&gt;
&lt;li&gt;Appropriate instance types for deep learning&lt;/li&gt;
&lt;li&gt;P3, P2, G3&lt;/li&gt;
&lt;li&gt;Deep Learning AMI&amp;rsquo;s&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tuning-neural-networks&#34;&gt;Tuning Neural Networks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Neural nets are trained by gradient descent or sth similar&lt;/li&gt;
&lt;li&gt;We start at some random point, and sample different solutions seeking to minimize some cost functions, over many epochs&lt;/li&gt;
&lt;li&gt;how far apart these samples are is the learning rate&lt;/li&gt;
&lt;li&gt;learning rate is an example of a hyperparameter&lt;/li&gt;
&lt;li&gt;batch size is also a hyperparameter, smaller batch size can work out of local minima&lt;/li&gt;
&lt;li&gt;small batch size tend to not get stuck in local minima&lt;/li&gt;
&lt;li&gt;large batch sizes can converge on the wrong solution at random&lt;/li&gt;
&lt;li&gt;large learning rates can overshoot the correct solution&lt;/li&gt;
&lt;li&gt;small learning rates increate training time&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;regularization-techniques-for-neural-networks-dropout-early-stopping&#34;&gt;Regularization Techniques for Neural Networks (Dropout, Early Stopping)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Regularization helps with avoiding overfitting&lt;/li&gt;
&lt;li&gt;build simple model, dropout, early stopping can also help with avoiding overfitting&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;l1-and-l2-regularization&#34;&gt;L1 and L2 Regularization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;L1: sum of abs value of weights: perform feature selection, computationally inefficient, sparse output&lt;/li&gt;
&lt;li&gt;L2: sum of square of weights, all features considered but weighted, computationally efficient, dence output&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;grief-with-gradients-the-vanishing-gradient-problem&#34;&gt;Grief with Gradients The Vanishing Gradient problem&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;vanishing gradient propogate to deeper layer&lt;/li&gt;
&lt;li&gt;slope is approaching zero&lt;/li&gt;
&lt;li&gt;it could be the local miminum or global where the convergence is happening&lt;/li&gt;
&lt;li&gt;long short term memory RNN can be used&lt;/li&gt;
&lt;li&gt;resnet also helps with vanishing gradient problem&lt;/li&gt;
&lt;li&gt;better activation function (relu is a good choice)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;the-confusion-matrix&#34;&gt;The Confusion Matrix&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;sometimes accuracy does not tell the whole story&lt;/li&gt;
&lt;li&gt;TP, TN, FP, FN&lt;/li&gt;
&lt;li&gt;Confusion matrix shows this&lt;/li&gt;
&lt;li&gt;multi class confusion matrix: heatmap&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;precision-recall-f1-auc-and-more&#34;&gt;Precision, Recall, F1, AUC, and more&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Precision/Correct Positives/Percent of relevant results: when you are a lot about false positives: TP/(TP+FP)&lt;/li&gt;
&lt;li&gt;Recall/Sensitivity/True Positive Rate:  TP/(TP + FN): when you care about false negatives&lt;/li&gt;
&lt;li&gt;F1 score: harmonic mean of Precision and Recall&lt;/li&gt;
&lt;li&gt;Specificity: TN/(TN+FP)&lt;/li&gt;
&lt;li&gt;RMSE, AMSE, etc.&lt;/li&gt;
&lt;li&gt;ROC curve: Receiver Operating Characteristic Curve: Plot of true positive rate (recall) vs false positive rate at various threshold setting.&lt;/li&gt;
&lt;li&gt;AUC curve: area under the ROC curve.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ensemble-methods-bagging-and-boosting&#34;&gt;Ensemble Methods Bagging and Boosting&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bagging: Generate N new training sets by random sampling with replacement, each resampled model can be trained in parallel&lt;/li&gt;
&lt;li&gt;Boosting: Observations are weighted, training is sequential&lt;/li&gt;
&lt;li&gt;XGBoost is the latest hotness, boosting generally yields better accuracy, bagging avoids overfitting, bagging is easier to parallelize&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introducing-amazon-sagemaker&#34;&gt;Introducing Amazon SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;built to handle the entire machine learning workflow&lt;/li&gt;
&lt;li&gt;deploy model, evaluate results in production, fetch, clean and prepare data, train and evaluate a model&lt;/li&gt;
&lt;li&gt;training data will be in s3, sagemakaker docker EC2 for inference&lt;/li&gt;
&lt;li&gt;spins as many hosts, spins as many endpoints&lt;/li&gt;
&lt;li&gt;Sagemaker notebook: notebook instance on EC2, has access to s3, scikit learn, spark, tensorflow, ability to deploy trained models for making predictions at scale&lt;/li&gt;
&lt;li&gt;hyperparameter tuning from notebook&lt;/li&gt;
&lt;li&gt;Sagemaker console&lt;/li&gt;
&lt;li&gt;Data comes from S3, ideal format is RecordIO/Protobuf/csv&lt;/li&gt;
&lt;li&gt;Can also ingest from Athena, EMR, Redshift, Amazon Keyspaces DB&lt;/li&gt;
&lt;li&gt;Apache Spark integrates with Sagemaker&lt;/li&gt;
&lt;li&gt;Scikit learn, numpy, pandas all work&lt;/li&gt;
&lt;li&gt;Create training job&lt;/li&gt;
&lt;li&gt;save your trained model to s3&lt;/li&gt;
&lt;li&gt;can be deployed using persistent endpoint for making individual predictions on demand&lt;/li&gt;
&lt;li&gt;or batch transform to get prediction for and entire dataset&lt;/li&gt;
&lt;li&gt;inference pipelines&lt;/li&gt;
&lt;li&gt;sagemaker neo for deploying to edge devices&lt;/li&gt;
&lt;li&gt;elastic inference for accelerating deep learning models&lt;/li&gt;
&lt;li&gt;automatic scaling of endpoints as needed&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;linear-learner-in-sagemaker&#34;&gt;Linear Learner in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Linear learer can handle both classification and regression&lt;/li&gt;
&lt;li&gt;can do classification using Linear Learner threshold&lt;/li&gt;
&lt;li&gt;as long as a line will fit&lt;/li&gt;
&lt;li&gt;RecordIO wrapped protobuf float32, or csv (first column assumed to be the label)&lt;/li&gt;
&lt;li&gt;File or pipe mode both supported&lt;/li&gt;
&lt;li&gt;pipe mode will be more efficient&lt;/li&gt;
&lt;li&gt;if s3 is taking to long to train, pipe is a simple optimization&lt;/li&gt;
&lt;li&gt;training data should be normalized&lt;/li&gt;
&lt;li&gt;input data should be shuffled&lt;/li&gt;
&lt;li&gt;uses SGD&lt;/li&gt;
&lt;li&gt;multiple models are optimized in parallel&lt;/li&gt;
&lt;li&gt;tune l1, l2 regularization&lt;/li&gt;
&lt;li&gt;balance multiclass weights: give each class equal importance in loss functions&lt;/li&gt;
&lt;li&gt;learning rate, mini batch size, l1 regualization&lt;/li&gt;
&lt;li&gt;multi gpu does not help&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;xgboost-in-sagemaker&#34;&gt;XGBoost in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;eXtreme gradient boosting&lt;/li&gt;
&lt;li&gt;boosted group of decision trees&lt;/li&gt;
&lt;li&gt;gradient descent&lt;/li&gt;
&lt;li&gt;winning a lot of kaggle competitions&lt;/li&gt;
&lt;li&gt;fast&lt;/li&gt;
&lt;li&gt;classification/regression&lt;/li&gt;
&lt;li&gt;CSV/libsvm/recordIO-protobuf/parquet&lt;/li&gt;
&lt;li&gt;models are searilized/deserialized with pickle&lt;/li&gt;
&lt;li&gt;can use as a framework withing notebooks&lt;/li&gt;
&lt;li&gt;or as a built in sagemaker algorithm&lt;/li&gt;
&lt;li&gt;subsample (prevent overfitting)&lt;/li&gt;
&lt;li&gt;ETA (step size shrinkage, prevents overfitting)&lt;/li&gt;
&lt;li&gt;Gamma (minimul loss reduction to create a partition)&lt;/li&gt;
&lt;li&gt;Alpha (L1 regularization term, larger = more conservative)&lt;/li&gt;
&lt;li&gt;Lambda (L2 regularization term, larger = more conservative)&lt;/li&gt;
&lt;li&gt;eval_metric: Optimize on AUC, example: if you care about false positives more than accuracy&lt;/li&gt;
&lt;li&gt;scale_pos_weight: adjusts balance of positive and negative weights, helpful for unbalanced classes&lt;/li&gt;
&lt;li&gt;max_depth : too high may overfit&lt;/li&gt;
&lt;li&gt;Xgboost with cpu: M5 is a good choice (optimize for memory and not compute)&lt;/li&gt;
&lt;li&gt;Xgboost with gpu: tree_method hyperparameter: gpu_hist, cheaper and faster, P3 is good choice&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;seq2seq-in-sagemaker&#34;&gt;Seq2Seq in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;sequence to sequence (example machine translation, text summarization, speech to text)&lt;/li&gt;
&lt;li&gt;implemented with RNN&amp;rsquo;s and CNN&amp;rsquo;s with attention&lt;/li&gt;
&lt;li&gt;RecordIO-Protobuf tokens must be integers&lt;/li&gt;
&lt;li&gt;start with tokenized text files&lt;/li&gt;
&lt;li&gt;convert to protobuf using sample code&lt;/li&gt;
&lt;li&gt;must provide training data, validation data and vocabulary files&lt;/li&gt;
&lt;li&gt;training machine translation can take days, pretrained models are available&lt;/li&gt;
&lt;li&gt;public training datasets are avaialable for specific translation tasks&lt;/li&gt;
&lt;li&gt;batch_size, optimizer_type, learning_rate, num_layers_encoder, num_layers_decoder, can optimize on accuracy, bleu score (compares against multiple reference translations), perplexity (cross-entropy)&lt;/li&gt;
&lt;li&gt;cannot be parallelized&lt;/li&gt;
&lt;li&gt;can only use gpu instance&lt;/li&gt;
&lt;li&gt;can use multi gpu within an instance machine&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deepar-in-sagemaker&#34;&gt;DeepAR in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Forecasting one dimensional time series data&lt;/li&gt;
&lt;li&gt;uses rnn&amp;rsquo;s&lt;/li&gt;
&lt;li&gt;allows you to train the same model over several related time series&lt;/li&gt;
&lt;li&gt;finds frequencies and seasonality&lt;/li&gt;
&lt;li&gt;json lines format, Gzip or Parquet&lt;/li&gt;
&lt;li&gt;each record must contain, start and target&lt;/li&gt;
&lt;li&gt;each record can contain dynamic features and categorical features&lt;/li&gt;
&lt;li&gt;always include entire time series for training, testing and inference&lt;/li&gt;
&lt;li&gt;use entire dataset as test set&lt;/li&gt;
&lt;li&gt;do not use very large values for prediction (&amp;gt;400)&lt;/li&gt;
&lt;li&gt;train on many time series&lt;/li&gt;
&lt;li&gt;contect length, epochs, mini batch size, learning rate, num cells&lt;/li&gt;
&lt;li&gt;can use cpu or gpu&lt;/li&gt;
&lt;li&gt;single or multi machine&lt;/li&gt;
&lt;li&gt;cpu only for inferene&lt;/li&gt;
&lt;li&gt;may need larger instances for tuning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;blazingtext-in-sagemaker&#34;&gt;BlazingText in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Text classification: predict labels for a sentence, useful in web searches, information retrieal, supervised&lt;/li&gt;
&lt;li&gt;Word2vec: creates a vector representation of workds&lt;/li&gt;
&lt;li&gt;semantically similar words are represented by vectors close to each otehr&lt;/li&gt;
&lt;li&gt;this is called a word embedding&lt;/li&gt;
&lt;li&gt;it is useful for nlp, but is not an nlp algorithm itself&lt;/li&gt;
&lt;li&gt;it only works on individual words, not sentences or documents&lt;/li&gt;
&lt;li&gt;for supervised mode, one sentence per line, first word in the sentence is the string &lt;em&gt;label&lt;/em&gt; followed by the label&lt;/li&gt;
&lt;li&gt;Also, &amp;ldquo;augmented manifest text format&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Word3vec just wants a text file with one training sentence per line&lt;/li&gt;
&lt;li&gt;There are multiple modes:&lt;/li&gt;
&lt;li&gt;Cbow (Continuous Bag of Words)&lt;/li&gt;
&lt;li&gt;Skip-gram&lt;/li&gt;
&lt;li&gt;Batch skip-gram (Distributed computation over many CPU nodes)&lt;/li&gt;
&lt;li&gt;Word2vec: mode, learning rate, window size, verctor dim, negative samples&lt;/li&gt;
&lt;li&gt;Text classification: epochs, learning rate, word ngrams, vector dim&lt;/li&gt;
&lt;li&gt;For cbow and skipgram, recommend a single ml.p3.2xlarge, any single CPU or single GPU instance will work&lt;/li&gt;
&lt;li&gt;for batch_skipgram, can use single or multiple CPU instances&lt;/li&gt;
&lt;li&gt;for text classification C5 recommended if less than 2GB training data, for larger datasets use a single GPU instance ml.p2.xlarge or ml.p3.2xlarge&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;object2vec-in-sagemaker&#34;&gt;Object2Vec in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;creates low-dimensional dense embeddings of high-dimensional objects&lt;/li&gt;
&lt;li&gt;compute nearest neighbors of objects&lt;/li&gt;
&lt;li&gt;visualize clusters&lt;/li&gt;
&lt;li&gt;genre prediction&lt;/li&gt;
&lt;li&gt;recommendations&lt;/li&gt;
&lt;li&gt;data must be tokenized into integers&lt;/li&gt;
&lt;li&gt;training data consists of pairs of tokens and or sequenses of tokens&lt;/li&gt;
&lt;li&gt;process data into json lines and shuffle it&lt;/li&gt;
&lt;li&gt;train with two input channels, two encoders, and a comparator&lt;/li&gt;
&lt;li&gt;encoder choices: average-pooled embeddings, cnn&amp;rsquo;s, bidirectional lstm&lt;/li&gt;
&lt;li&gt;comparator is followed by feed-fowrard neural network&lt;/li&gt;
&lt;li&gt;usual suspect: dropout, early stopping, epochs, learning rate, bbatch size, layers, activation function, optimizer, weight decay&lt;/li&gt;
&lt;li&gt;Enc1_network, enc2_network&lt;/li&gt;
&lt;li&gt;instance types: can only train on a single machine (cpu or gpu, multi-gpu ok)&lt;/li&gt;
&lt;li&gt;inference: use ml.p2.2xlarge&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;object-detection-in-sagemaker&#34;&gt;Object Detection in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;identify all objects in an image with bounding box&lt;/li&gt;
&lt;li&gt;detects and classifies objects with a single deep neural network&lt;/li&gt;
&lt;li&gt;classes are accompanied by confidence scores&lt;/li&gt;
&lt;li&gt;can train from scratch, or use pretrained models based on imagenet&lt;/li&gt;
&lt;li&gt;recodrio or image format&lt;/li&gt;
&lt;li&gt;with image format, supply a json file for annotation data for each image&lt;/li&gt;
&lt;li&gt;takes and image input, outputs all instances of objects in teh imagte with categories and confidence scores&lt;/li&gt;
&lt;li&gt;uses cnn with single shot multibox detector ssd algorithm, the base being vgg-16 or resnet-50&lt;/li&gt;
&lt;li&gt;transfer learning mode/incrementatl training: use pretrained model for the base network instead of random inintial weights&lt;/li&gt;
&lt;li&gt;uses flip, rescale, and jitter internally to avoid overfitting&lt;/li&gt;
&lt;li&gt;mini batch size, learning rate, optimizer&lt;/li&gt;
&lt;li&gt;gpu instances for training&lt;/li&gt;
&lt;li&gt;multi gpu multi machines&lt;/li&gt;
&lt;li&gt;for inference cpu is enough&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;image-classification-in-sagemaker&#34;&gt;Image Classification in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;assign one or more labels to an image&lt;/li&gt;
&lt;li&gt;does not tell you where objects are&lt;/li&gt;
&lt;li&gt;mxnet recordio (not protobuf)&lt;/li&gt;
&lt;li&gt;raw jpg or png&lt;/li&gt;
&lt;li&gt;.lst files to associate image index and class&lt;/li&gt;
&lt;li&gt;augmented manifest image format enables pipe mode&lt;/li&gt;
&lt;li&gt;resnet cnn under the hood&lt;/li&gt;
&lt;li&gt;full training mode&lt;/li&gt;
&lt;li&gt;transfer learning mode&lt;/li&gt;
&lt;li&gt;default image is 224 224 3&lt;/li&gt;
&lt;li&gt;bbatch size, learning rate, optimizer&lt;/li&gt;
&lt;li&gt;weight decay, beta 1, beta 2, eps, gamma&lt;/li&gt;
&lt;li&gt;gpu instance fr training&lt;/li&gt;
&lt;li&gt;cpu or gpu for inference&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;semantic-segmentation-in-sagemaker&#34;&gt;Semantic Segmentation in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;pixel level object classificaion&lt;/li&gt;
&lt;li&gt;different from image classification&lt;/li&gt;
&lt;li&gt;useful for self driving vehicles, medical imaging, robot sensing&lt;/li&gt;
&lt;li&gt;produces a semantic mask&lt;/li&gt;
&lt;li&gt;jpg or img with annotations&lt;/li&gt;
&lt;li&gt;augmented manifest image format supported for pipe mode&lt;/li&gt;
&lt;li&gt;jpg images accepted for inference&lt;/li&gt;
&lt;li&gt;mxnet gluon and gluon cv&lt;/li&gt;
&lt;li&gt;fully convolution network, pyramid scene parsing, deeplabv3&lt;/li&gt;
&lt;li&gt;resnet50, renet101, both rained on imagenet&lt;/li&gt;
&lt;li&gt;incremental training, or scratch&lt;/li&gt;
&lt;li&gt;epochs, learning rate, batch size, optimizer, algorithm, backbone&lt;/li&gt;
&lt;li&gt;only gpu for training (p2 or p3), and only on one maching&lt;/li&gt;
&lt;li&gt;cpu or gpu for inference&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;random-cut-forest-in-sagemaker&#34;&gt;Random Cut Forest in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;anomaly detection&lt;/li&gt;
&lt;li&gt;unsupervised&lt;/li&gt;
&lt;li&gt;detect unexpected spikes in time series data&lt;/li&gt;
&lt;li&gt;breaks in periodicity&lt;/li&gt;
&lt;li&gt;unclassifiable data points&lt;/li&gt;
&lt;li&gt;assigns and anamoly score to each data points&lt;/li&gt;
&lt;li&gt;recordio protobuf or csv&lt;/li&gt;
&lt;li&gt;can use file or pipe mode on either&lt;/li&gt;
&lt;li&gt;optional test channel for computation&lt;/li&gt;
&lt;li&gt;creates a forest of trees where each tree is a partition of the training data, looks at expected change in complexity of the tree as a result of adding a point into it&lt;/li&gt;
&lt;li&gt;data is sampled randomly and then trained&lt;/li&gt;
&lt;li&gt;rcf shows up in kinesis analytics as well, it can work on streaming data as well.&lt;/li&gt;
&lt;li&gt;num_trees, num_samples_per_tree (should be chosen such that 1/num_samples_per_tree approximates the ratio of anomalous to normal data)&lt;/li&gt;
&lt;li&gt;does not take advantage of gpu&lt;/li&gt;
&lt;li&gt;ml.c5.xl for inference&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;neural-topic-model-in-sagemaker&#34;&gt;Neural Topic Model in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;organize documents into topics&lt;/li&gt;
&lt;li&gt;classify or summarize documents based on topics&lt;/li&gt;
&lt;li&gt;it is not just tf/idf&lt;/li&gt;
&lt;li&gt;unsupervised: algorithm is neural variational inference&lt;/li&gt;
&lt;li&gt;four data channels, train, validation, test and auxiliary&lt;/li&gt;
&lt;li&gt;record io or csv&lt;/li&gt;
&lt;li&gt;words muyst be tokenized into integers&lt;/li&gt;
&lt;li&gt;file or pipe mode&lt;/li&gt;
&lt;li&gt;you define how many topics you want, these topics are latent representation based on top ranking words&lt;/li&gt;
&lt;li&gt;one of two modelling algorithms sagemaker offers&lt;/li&gt;
&lt;li&gt;batch size, num_topics&lt;/li&gt;
&lt;li&gt;gpu or cpu&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;latent-dirichlet-allocation-lda-in-sagemaker&#34;&gt;Latent Dirichlet Allocation (LDA) in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;latent dirichlet allocation&lt;/li&gt;
&lt;li&gt;another topic modeling algorithm but not based on deep learning&lt;/li&gt;
&lt;li&gt;unsupervised: topics are unlabeled, they are just grouping of documents with a shared subseet of words&lt;/li&gt;
&lt;li&gt;can be used for other purposes as well&lt;/li&gt;
&lt;li&gt;train channel, optional test channel&lt;/li&gt;
&lt;li&gt;protobuf or csv&lt;/li&gt;
&lt;li&gt;each document has counts for every word in vocabulary&lt;/li&gt;
&lt;li&gt;pipe mode: only supported with proto&lt;/li&gt;
&lt;li&gt;unsupervised, generates however many topics you specify&lt;/li&gt;
&lt;li&gt;per-word log likelyhood&lt;/li&gt;
&lt;li&gt;num_topics, alpha0&lt;/li&gt;
&lt;li&gt;cpu single instance, cannot parallelize&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;k-nearest-neighbors-knn-in-sagemaker&#34;&gt;K-Nearest-Neighbors (KNN) in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;simple classification or regression algorithm&lt;/li&gt;
&lt;li&gt;classification: k closest points&lt;/li&gt;
&lt;li&gt;regression: average values&lt;/li&gt;
&lt;li&gt;train channel, test channel emits accuracy or MSE&lt;/li&gt;
&lt;li&gt;protobuf or csv (first column is label)&lt;/li&gt;
&lt;li&gt;data is sampled, sagemaker includes dimensionality reduction stage, build an index for looking up neighbors, serialize the model, query the model for given K&lt;/li&gt;
&lt;li&gt;hyperparameter K, sample_size&lt;/li&gt;
&lt;li&gt;cpu or gpu&lt;/li&gt;
&lt;li&gt;cpu or gpu for inference&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;k-means-clustering-in-sagemaker&#34;&gt;K-Means Clustering in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;unsupervised clustering&lt;/li&gt;
&lt;li&gt;divide data into k groups, where members of a group are as similar as possible to each other&lt;/li&gt;
&lt;li&gt;web scale k means clustering&lt;/li&gt;
&lt;li&gt;training input: train channel, train in shardedbys3key and testing: fullyreplicated&lt;/li&gt;
&lt;li&gt;recordio or csv&lt;/li&gt;
&lt;li&gt;file or pipemode&lt;/li&gt;
&lt;li&gt;every ovservation is mapped to n-dimensional space&lt;/li&gt;
&lt;li&gt;works to optimize the center of k clusters&lt;/li&gt;
&lt;li&gt;algorithm: k means++ tries to make initial clusters far away, lloyd&amp;rsquo;s method&lt;/li&gt;
&lt;li&gt;mini_batch_size, extra_center_factor, init_method&lt;/li&gt;
&lt;li&gt;cpu or gpu, but cpu recommended&lt;/li&gt;
&lt;li&gt;only one gpu per instance used on gpu&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;principal-component-analysis-pca-in-sagemaker&#34;&gt;Principal Component Analysis (PCA) in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;dimensionality reduction&lt;/li&gt;
&lt;li&gt;unsupervised&lt;/li&gt;
&lt;li&gt;covariance matrix is created, then SVD&lt;/li&gt;
&lt;li&gt;two modesL regular: for sparse matrix, randomized: for large number of observations and features&lt;/li&gt;
&lt;li&gt;algorithm_mode and subtract_mean&lt;/li&gt;
&lt;li&gt;gpu or cpu&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;factorization-machines-in-sagemaker&#34;&gt;Factorization Machines in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;dealing with sparse data&lt;/li&gt;
&lt;li&gt;item recommendations&lt;/li&gt;
&lt;li&gt;supervised: classification or regression&lt;/li&gt;
&lt;li&gt;limited to pair-wise interactions&lt;/li&gt;
&lt;li&gt;protobuf with float32&lt;/li&gt;
&lt;li&gt;bias, factors, and linear terms&lt;/li&gt;
&lt;li&gt;cpu or gpu, cpu recommended&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ip-insights-in-sagemaker&#34;&gt;IP Insights in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;finding fishy behaviour&lt;/li&gt;
&lt;li&gt;unsupervised learning of ip address&lt;/li&gt;
&lt;li&gt;identifies suspicious behaviour from ip addresses&lt;/li&gt;
&lt;li&gt;user names, account ids, not need to pre process&lt;/li&gt;
&lt;li&gt;training channel, optional validation (computes auc score)&lt;/li&gt;
&lt;li&gt;csv only (entity, ips)&lt;/li&gt;
&lt;li&gt;neural network to learn latent vector representations of entities and ip addresses&lt;/li&gt;
&lt;li&gt;entities are hashed and embedded&lt;/li&gt;
&lt;li&gt;automatically generates negative samples during training by randomly pairing entities and ips&lt;/li&gt;
&lt;li&gt;num_entity vectors, vector_dim, epochs, learning rate, batch size&lt;/li&gt;
&lt;li&gt;cpu or gpu&lt;/li&gt;
&lt;li&gt;gpu recommended&lt;/li&gt;
&lt;li&gt;multiple gpu can be used withing an instance&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reinforcement-learning-in-sagemaker&#34;&gt;Reinforcement Learning in SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;agent and environment&lt;/li&gt;
&lt;li&gt;supply chain management, hvac systems, industrial robots, dialog systems, autonomous vehicles&lt;/li&gt;
&lt;li&gt;yields fast on-line performance once the space has been explored&lt;/li&gt;
&lt;li&gt;Q learning: environment, actions, state/action part&lt;/li&gt;
&lt;li&gt;uses a deep learning framework with tensorflow and mxnet&lt;/li&gt;
&lt;li&gt;supports intel coach and ray rllib toolkits&lt;/li&gt;
&lt;li&gt;custom, open-source or commercial environments supported&lt;/li&gt;
&lt;li&gt;can distribute trining and environment rollout&lt;/li&gt;
&lt;li&gt;multi core and multi instance&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;automatic-model-tuning&#34;&gt;Automatic Model Tuning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;define the hyperparameters you care about&lt;/li&gt;
&lt;li&gt;sagemaker spins up a hyperparameter tuning job that trains as many combinations as you will allow&lt;/li&gt;
&lt;li&gt;it learns as it goes, so it does not have to try every possible combination&lt;/li&gt;
&lt;li&gt;intelligent&lt;/li&gt;
&lt;li&gt;do not optimize too many hyperparameters at once&lt;/li&gt;
&lt;li&gt;limit your ranges to as samall range&lt;/li&gt;
&lt;li&gt;use logarithmic scales&lt;/li&gt;
&lt;li&gt;do not run too many training jobs concurently&lt;/li&gt;
&lt;li&gt;make sure training jobs running on multiple instance report the correct objective metric in the end&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;apache-spark-with-sagemaker&#34;&gt;Apache Spark with SageMaker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;apache spark allows for preprocessing and also has mllib&lt;/li&gt;
&lt;li&gt;combination of sagemaker and spark is possible&lt;/li&gt;
&lt;li&gt;preprocess with spark, and instead of using mllib, you can use sagemaker estimator, you can use kmeans, pca, xgboost&lt;/li&gt;
&lt;li&gt;sagemakermodel, can be used to make inferences&lt;/li&gt;
&lt;li&gt;connect notebook to a remote emr&lt;/li&gt;
&lt;li&gt;fit, transform in sagemaker&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-studio-and-sagemaker-experiments&#34;&gt;SageMaker Studio, and SageMaker Experiments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;visual ide&lt;/li&gt;
&lt;li&gt;sagemaker notebooks&lt;/li&gt;
&lt;li&gt;sagemaker experiments&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-debugger&#34;&gt;SageMaker Debugger&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;saves internal model state at periodical intervals&lt;/li&gt;
&lt;li&gt;gradients/tensors over time is saved&lt;/li&gt;
&lt;li&gt;define rules for detecting unwanted conditions while training&lt;/li&gt;
&lt;li&gt;a debug job is run for each rule&lt;/li&gt;
&lt;li&gt;logs and fires a cloudwatch event when the rule is hit&lt;/li&gt;
&lt;li&gt;sagemaker studio debugger dashboards&lt;/li&gt;
&lt;li&gt;auto generated training reports&lt;/li&gt;
&lt;li&gt;built in rules: monitor system bottlenecks, profile model framework operations, debug model parameters&lt;/li&gt;
&lt;li&gt;supported framewords and algorithms: tensorflow, pytorch, mxnet, xgboost, sagemaker generic estimator&lt;/li&gt;
&lt;li&gt;debugger api&amp;rsquo;s available in github&lt;/li&gt;
&lt;li&gt;smdebug is the library&lt;/li&gt;
&lt;li&gt;Sagemaker debugger insights dashboard&lt;/li&gt;
&lt;li&gt;profiler report, hardware system metrics, framework metrics&lt;/li&gt;
&lt;li&gt;built in actions to receive notifications or stop training&lt;/li&gt;
&lt;li&gt;profiling system resource usage and training&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-autopilot--automl&#34;&gt;SageMaker Autopilot / AutoML&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;automates algorithm selection, data preprocessing, model tuning&lt;/li&gt;
&lt;li&gt;it does all the trial and error for you&lt;/li&gt;
&lt;li&gt;automl&lt;/li&gt;
&lt;li&gt;automatic model creation&lt;/li&gt;
&lt;li&gt;model leaderboard&lt;/li&gt;
&lt;li&gt;ranks&lt;/li&gt;
&lt;li&gt;can add in human guidance&lt;/li&gt;
&lt;li&gt;human in the loop&lt;/li&gt;
&lt;li&gt;with or without code in sagemaker studio&lt;/li&gt;
&lt;li&gt;problem types: binary/multiclass classification&lt;/li&gt;
&lt;li&gt;linear learner, xgboost, mlp&lt;/li&gt;
&lt;li&gt;data must be tabular csv&lt;/li&gt;
&lt;li&gt;autopilot explainability&lt;/li&gt;
&lt;li&gt;integrates with sagemaker clarify&lt;/li&gt;
&lt;li&gt;transparency on how models arrive at predictions&lt;/li&gt;
&lt;li&gt;feature attributions: uses shap baselines/shapley values, research from cooperative game theory, assigns each feature an importance value for a give prediction&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-model-monitor&#34;&gt;SageMaker Model Monitor&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;get alery on quality deviations on your deployed models via cloudwatch&lt;/li&gt;
&lt;li&gt;visualize data drift&lt;/li&gt;
&lt;li&gt;detect anomalies and outliers&lt;/li&gt;
&lt;li&gt;detect new features&lt;/li&gt;
&lt;li&gt;no code required&lt;/li&gt;
&lt;li&gt;data is stored in s3, monitoring jobs are scheduled via a monitoring schedule, metrics are emitted to cloudwatch, integrates with quicksight, tensorboard etc.&lt;/li&gt;
&lt;li&gt;drift in statistical properties of the features&lt;/li&gt;
&lt;li&gt;drift in model quality&lt;/li&gt;
&lt;li&gt;bias drift&lt;/li&gt;
&lt;li&gt;feature attribution drift&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;other-recent-features-jumpstart-data-wrangler-features-store-edge-manager&#34;&gt;Other recent features (JumpStart, Data Wrangler, Features Store, Edge Manager)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;jumpstart: one click models and algorithms from model zoos: 150 open source models in nlp, object detection, image classification etc&lt;/li&gt;
&lt;li&gt;data wrangler: import transform analayze and export data withing sagemaker studio&lt;/li&gt;
&lt;li&gt;feature studio: find, discover and share features in studio:online and offline modes&lt;/li&gt;
&lt;li&gt;sagemaker edge manager: software agent for edge devices, models optimized with agemaker neo, collects and samples data for monitoring, labeling and retraining&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-canvas&#34;&gt;SageMaker Canvas&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;no code machine learning for business analysts&lt;/li&gt;
&lt;li&gt;upload csv data, select a column to predict, build it and make predictions&lt;/li&gt;
&lt;li&gt;can also join datasets&lt;/li&gt;
&lt;li&gt;classification or regressions&lt;/li&gt;
&lt;li&gt;automatic data cleaning, missing values, outlier and duplicates&lt;/li&gt;
&lt;li&gt;share models and datasets with sagemaker studio&lt;/li&gt;
&lt;li&gt;import from redshift is possible&lt;/li&gt;
&lt;li&gt;time series must be enabled via IAM&lt;/li&gt;
&lt;li&gt;vpc&lt;/li&gt;
&lt;li&gt;a little expensive&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bias-measures-in-sagemaker-clarify&#34;&gt;Bias Measures in SageMaker Clarify&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;class imbalance&lt;/li&gt;
&lt;li&gt;difference in proportions of labels&lt;/li&gt;
&lt;li&gt;kullback-leibler divergence, jensen-shannon divergence&lt;/li&gt;
&lt;li&gt;lp-norm&lt;/li&gt;
&lt;li&gt;total variation distance&lt;/li&gt;
&lt;li&gt;kolmogorov-smirnov&lt;/li&gt;
&lt;li&gt;conditional demographic disparity&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sagemaker-training-compiler&#34;&gt;SageMaker Training Compiler&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;integrates into AWS deep learning containers&lt;/li&gt;
&lt;li&gt;compile and optimize training jobs on gpu&lt;/li&gt;
&lt;li&gt;can accelerate training up to 50%&lt;/li&gt;
&lt;li&gt;converts models into hardware-optimized instructions&lt;/li&gt;
&lt;li&gt;tested with hugging face transformers library, or bring your own model&lt;/li&gt;
&lt;li&gt;ensure gpu instance are used in ml.p3, ml.p4&lt;/li&gt;
&lt;li&gt;pytorch models must use pytorch xla&amp;rsquo;s model save function&lt;/li&gt;
&lt;li&gt;enable dubug flask in compiler_config parameter to enable debugging&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-comprehend&#34;&gt;Amazon Comprehend&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;nlp and text analytics&lt;/li&gt;
&lt;li&gt;input social media, emails, web pages, documents, transcripts, medical records (comprehend medical)&lt;/li&gt;
&lt;li&gt;extract key phrases, entities, sentiment, language, syntax, topics, and document classifications&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-translate&#34;&gt;Amazon Translate&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;translates text&lt;/li&gt;
&lt;li&gt;uses deep learning&lt;/li&gt;
&lt;li&gt;supports custom terminology for proper names&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-transcribe&#34;&gt;Amazon Transcribe&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;speech to text&lt;/li&gt;
&lt;li&gt;speaker identification&lt;/li&gt;
&lt;li&gt;channel identification&lt;/li&gt;
&lt;li&gt;language identification&lt;/li&gt;
&lt;li&gt;custom vocabularies&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-polly&#34;&gt;Amazon Polly&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;text to speech&lt;/li&gt;
&lt;li&gt;polly is parrot&lt;/li&gt;
&lt;li&gt;lexicons&lt;/li&gt;
&lt;li&gt;ssml (speech synthesis markup language)&lt;/li&gt;
&lt;li&gt;speech marks&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-rekognition&#34;&gt;Amazon Rekognition&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;compute vision&lt;/li&gt;
&lt;li&gt;object and scene detection&lt;/li&gt;
&lt;li&gt;image moderation, facial analysis, celebrity recognition, face comparison, text in image, video analysis&lt;/li&gt;
&lt;li&gt;kinesis video stream h.264 encoded, 5-30 fps&lt;/li&gt;
&lt;li&gt;can use lambda to trigger image analysis upon upload&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-forecast&#34;&gt;Amazon Forecast&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;fully managed service to deliver highly accurate forecasts with ml&lt;/li&gt;
&lt;li&gt;automl chooses the best model for your time series data&lt;/li&gt;
&lt;li&gt;arima, deepar, ets, npts, prophet&lt;/li&gt;
&lt;li&gt;works with any time series&lt;/li&gt;
&lt;li&gt;inventory planning, financial planning, resource planning, based on dataset groups, predictors and forecasts&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-forecast-algorithms&#34;&gt;Amazon Forecast Algorithms&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;cnnqr: convolutional neural network quantile regression, best for large datasets with hundreds of time series, accepts related historical time series data and metadata&lt;/li&gt;
&lt;li&gt;deepar+ : recurrent neural network, best for large datasets, accepts related forward-looking time series and metadata&lt;/li&gt;
&lt;li&gt;prophet: additive model with non linear trends and seasonality&lt;/li&gt;
&lt;li&gt;npts: non parametric time series: good for sparse data&lt;/li&gt;
&lt;li&gt;arima: simple datasets&lt;/li&gt;
&lt;li&gt;ets: exponential smoothing&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-lex&#34;&gt;Amazon Lex&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;chatbot engine&lt;/li&gt;
&lt;li&gt;lambda to fulfill intent from text&lt;/li&gt;
&lt;li&gt;can deploy to aws mobile sdk, facebook messenger, slack, twilio&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-personalize&#34;&gt;Amazon Personalize&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;fully managed recommendation engine&lt;/li&gt;
&lt;li&gt;api access: feed in data, provide schema in avro, javascript or sdk, get recommendations, get personalized ranking&lt;/li&gt;
&lt;li&gt;real time or batch recommendations&lt;/li&gt;
&lt;li&gt;recommendations for new users and new items&lt;/li&gt;
&lt;li&gt;contextual recommendations&lt;/li&gt;
&lt;li&gt;similar items&lt;/li&gt;
&lt;li&gt;datasets, recipes, solutions, compaignhs&lt;/li&gt;
&lt;li&gt;hidden_dimensions, bptt, recency_mask, min/max_user_history_length_percentile, exploration_weight, exploration_item_age_cut_off&lt;/li&gt;
&lt;li&gt;necessary to maintain recency&lt;/li&gt;
&lt;li&gt;bucket policy&lt;/li&gt;
&lt;li&gt;data ingestion: per gb, training per training hour, inference per tps-hour, batch recommendations: per user or per item&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lightning-round-textract-deeplens-deepracher-lookout-and-monitron&#34;&gt;Lightning round! TexTract, DeepLens, DeepRacher, Lookout, and Monitron&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;TexTract: ocr with forms, fields, tables support&lt;/li&gt;
&lt;li&gt;DeepLens: deep learning enabled video camera, integrated with rekognition, sagemaker, polly, tensorflow, mxnet, caffe&lt;/li&gt;
&lt;li&gt;DeepRacer: reinforcement learning powered 1/18 scale race car&lt;/li&gt;
&lt;li&gt;Lookout: equipment, metrics and vision: detect defects in silicon wafers, circuit boards etc.&lt;/li&gt;
&lt;li&gt;Monitron: end to end system for monitoring equipment and predictive maintenance&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;torchserve-aws-neuron-and-aws-panorama&#34;&gt;TorchServe, AWS Neuron, and AWS Panorama&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;TorchServe: model serving framework for pytorch&lt;/li&gt;
&lt;li&gt;AWS Neuron: ml inferentia chip, Ec2 inf1 instance type&lt;/li&gt;
&lt;li&gt;Panorama: computer vision at the edge&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deep-composer-fraud-detection-codeguru-and-contact-lens&#34;&gt;Deep Composer, Fraud Detection, CodeGuru, and Contact Lens&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;DeepComposer: ai powered keyboard&lt;/li&gt;
&lt;li&gt;fraud detection: upload your own data&lt;/li&gt;
&lt;li&gt;Codeguru: automated code reviews, finds lines of code that hurt performance&lt;/li&gt;
&lt;li&gt;contact lens: for customer support call centers, ingests audio, sentiment analysis&lt;/li&gt;
&lt;li&gt;finds utterances that correlate with successful calls&lt;/li&gt;
&lt;li&gt;categorize calls automatically&lt;/li&gt;
&lt;li&gt;measure talk speed and interruptions&lt;/li&gt;
&lt;li&gt;theme detection: discovers emerging issues&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-kendra-and-amazon-augmented-ai-a2i&#34;&gt;Amazon Kendra and Amazon Augmented AI (A2I)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Enterprise search with natural languate&lt;/li&gt;
&lt;li&gt;combines data from sharepoint, intranet, sharing services, jdbc, s4 into one searchable repo&lt;/li&gt;
&lt;li&gt;ml powered, uses thumbs up/down&lt;/li&gt;
&lt;li&gt;relevance tuning, boost strength of document freshness&lt;/li&gt;
&lt;li&gt;Kendra: Alexa&amp;rsquo;s sister&lt;/li&gt;
&lt;li&gt;AugmentedAI: human review of ml predictions, mechanical turk workforce or vendors&lt;/li&gt;
&lt;li&gt;integrated into textract and rekognition&lt;/li&gt;
&lt;li&gt;integrates with sagemaker&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>